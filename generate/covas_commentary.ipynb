{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhaVUO952e_m",
    "outputId": "23236de6-3f47-4dfc-bacc-3cce8cf29f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: python-dotenv in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: filelock in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (0.23.3)\n",
      "Requirement already satisfied: packaging in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install datasets python-dotenv\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 147914.79 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139378.28 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 74567.97 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 156968.88 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136756.51 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91430.13 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 147253.99 examples/s]les]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130550.46 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 66694.43 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146282.13 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138363.11 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 80431.87 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134198.42 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146908.47 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79817.26 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130607.55 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145749.07 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79954.07 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135961.34 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131341.08 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 71963.56 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 152244.83 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141951.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 69914.10 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 148561.69 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145727.73 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 56030.61 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 151263.12 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 96145.21 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 70173.43 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 148011.93 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131391.17 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 74373.23 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139460.59 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147219.96 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92944.17 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112473.95 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 106505.94 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90400.52 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139942.10 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 148478.01 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90343.17 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 153842.92 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 152110.25 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 57593.21 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145310.35 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136896.55 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93457.91 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133963.45 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138812.35 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94677.89 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137634.77 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142662.72 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95818.02 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 149812.04 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130015.11 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85614.29 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145301.49 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143343.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88207.57 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130778.58 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 94494.91 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78918.50 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 140073.15 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141937.03 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83753.63 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145667.61 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141029.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82016.86 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143382.22 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137588.40 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90018.50 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142456.37 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132747.47 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90488.21 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142273.49 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144105.29 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83836.69 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132666.63 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138338.54 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82183.79 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139996.14 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139955.41 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91340.61 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135776.50 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139061.27 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92740.26 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 109094.92 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144127.32 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88397.79 examples/s]\n",
      "Map (num_proc=20):  24%|██▍       | 174/723 [22:31<1:13:36,  8.04s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Compliance Officer', 'process': 'Risk Assessment', 'situation': \"The process of Risk Assessment involves identifying, analyzing, and evaluating potential risks that could negatively impact the operations and objectives of an organization. The goal is to determine the likelihood and impact of these risks and implement appropriate measures to mitigate them. This process is crucial for regulatory compliance and maintaining a safe and efficient work environment. The desired outcome is a comprehensive risk management plan that can guide decision-making and help protect the organization's assets and reputation.\", 'situation_json': '{\"details\": {\"process_goal\": \"Determine likelihood and impact of risks and implement mitigation measures\", \"desired_outcome\": \"Comprehensive risk management plan\", \"importance\": \"Crucial for regulatory compliance and safe work environment\", \"specific_details\": {\"assets_impacted\": \"Organization\\'s assets and reputation\", \"risk_analysis_steps\": [\"Identify risks\", \"Analyze risks\", \"Evaluate risks\"]}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 227, in generate_covas_commentary\n",
      "    while len(filter_metadata(messages)) < 40 or (messages and messages[-1][\"role\"] != \"assistant\"):\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 41, in filter_metadata\n",
      "    tool_call['id'] = clean_tool_id(tool_call['id'])\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 27, in clean_tool_id\n",
      "    return tool_id.replace(\" \", \"\").replace('_', '').replace('-', '')[0:9]\n",
      "           ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138506.29 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142844.73 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77757.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Bookkeeping, Accounting, & Audit Clerk', 'process': 'Record Financial Transactions', 'situation': 'In the quiet and focused workspace of the accounting department, surrounded by the hum of the office environment, a Bookkeeping, Accounting, & Audit Clerk is immersed in the ongoing daily task of recording financial transactions. The clerk sits at a spacious desk with a well-maintained computer in front of them, a calculator within reach, and filing cabinets lined up against the wall. On one side of the desk is a neat stack of receipts, invoices, and bank statements, while on the other side is a printer, ready to churn out reports and financial documents. The room is free from distracting noise, allowing the clerk to concentrate on maintaining accurate financial records with utmost precision. The clerk is recording daily financial transactions, including income, expenses, accounts payable, and receivable, all with a sense of purpose and responsibility. Nearby, an accountant is reviewing the clerk’s work and providing guidance on how to improve financial record-keeping. Within the same office, a finance manager is using these financial records to make informed business decisions. The success of this daily task lies in the ability of the clerk to maintain financial control and make informed business decisions, all under the watchful eye of nearby accountants and managers.', 'situation_json': '{\"office_environment\": \"focused and quiet\", \"office_noise_level\": \"low\", \"office_equipment_states\": {\"computer\": \"well-maintained\", \"calculator\": \"within reach\", \"filing_cabinets\": \"lined up against the wall\", \"printer\": \"ready to print\"}, \"financial_documents_states\": {\"receipts\": \"neatly stacked\", \"invoices\": \"neatly stacked\", \"bank_statements\": \"neatly stacked\"}, \"transactions_being_recorded\": [\"income\", \"expenses\", \"accounts payable\", \"accounts receivable\"], \"professional_present\": [\"accountant\", \"finance manager\"], \"collaboration\": \"clerk receiving guidance from the accountant\", \"business_decisions\": \"informed by financial records\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 186, in generate_event\n",
      "    event_name = json.loads(openrouter_response.choices[0].message.tool_calls[0].function.arguments)[\"next_event\"]\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131440.76 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123915.69 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87562.34 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Logistician', 'process': 'Warehouse Management', 'situation': \"In the heart of the warehouse, an industrious Logistician juggles various tasks, one of which is the daily routine of Warehouse Management. They navigate three primary areas: the receiving area where goods arrive from suppliers, the storage area where goods are temporarily housed, and the shipping area where goods are meticulously prepared for customer shipments. The warehouse is a bustling hub of activity, filled with towering shelves and pallets of goods, all patiently awaiting their next journey. The Logistician, armed with a rugged forklift, a compact scanner, and a reliable laptop, ensures everything runs smoothly. The office, a break from the warehouse's physical demands, is where comprehensive planning and coordination occur. Here, they collaborate closely with the forecasting department and the supply chain team, optimizing inventory levels and ensuring demand forecasts are accurate. The warehouse staff in the nearby loading dock and the control room assist with operations, ensuring timely delivery of goods to customers. The sourroundings are a harmonious blend of functional docks for loading and unloading trucks, and an office for administrative tasks. The Logistician's day is challenging yet rewarding, as they efficiently manage the warehouse, ensuring goods are always where they need to be.\", 'situation_json': '{\"receiving_area\": {\"is_active\": true, \"description\": \"Area where goods arrive from suppliers\", \"is_occupied\": true, \"is_lit\": true, \"is_temperature_controlled\": false, \"has_loading_docks\": true}, \"storage_area\": {\"is_active\": true, \"description\": \"Area where goods are temporarily housed\", \"is_occupied\": true, \"is_lit\": true, \"is_temperature_controlled\": true, \"has_loading_docks\": false}, \"shipping_area\": {\"is_active\": true, \"description\": \"Area where goods are prepared for customer shipments\", \"is_occupied\": true, \"is_lit\": true, \"is_temperature_controlled\": false, \"has_loading_docks\": true}, \"office\": {\"is_active\": true, \"description\": \"Area for comprehensive planning and coordination\", \"is_occupied\": true, \"is_lit\": true, \"is_temperature_controlled\": true, \"has_loading_docks\": false}, \"equipment_states\": {\"rugged_forklift\": {\"is_operational\": true, \"status\": \"ready\", \"last_maintenance\": \"2021-10-01\", \"is_charged\": true}, \"compact_scanner\": {\"is_operational\": true, \"status\": \"ready\", \"last_service\": \"2021-09-15\", \"does_require_calibration\": false}, \"reliable_laptop\": {\"is_operational\": true, \"status\": \"on\", \"last_service\": \"2021-09-30\", \"software_versions\": [\"Warehouse Management System 2.0\"]}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 230, in generate_covas_commentary\n",
      "    raise Exception(\"Too many runs\")\n",
      "Exception: Too many runs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130522.72 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141997.78 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93853.46 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Hairdresser', 'process': 'Hair Coloring', 'situation': 'In the bustling indoor salon, The Loft Hair Lounge, a busy hairdresser meticulously performs the hair coloring process on a patient client. The task, which typically takes 1-2 hours, is a delicate challenge involving a myriad of tools and products. The hairdresser is surrounded by three stainless steel trays, each laden with a variety of instruments. The first tray is littered with hair coloring products, featuring an array of permanent and semi-permanent dyes, highlights, and lowlights, each with their own specific set of instructions and precautions. The second tray holds the hair dye applicator, a versatile tool which can be a brush, comb, or bottle with a nozzle. The third tray is home to a shimmering hair protection cape, waiting to be worn by clients to shield their clothing from the hair dye. In the vicinity, there are various other stations catering to different aspects of hair care, including a hair washing station, styling chairs, and a retail shelf boasting a wide range of hair care products. The waiting area is currently occupied by three individuals, each engrossed in their own thoughts and immersed in the magazines scattered around. Despite the seemingly chaotic scene, the hairdresser remains focused, moving deftly from one task to the next, a testament to their expertise in the field.', 'situation_json': '{\"profession\": \"Hairdresser\", \"process\": \"Hair Coloring\", \"location\": \"indoor salon named The Loft Hair Lounge\", \"time\": \"1-2 hours\", \"tools\": [\"stainless steel trays\", \"permanent and semi-permanent dyes\", \"highlights and lowlights\", \"hair dye applicator\", \"hair protection cape\"], \"other_stations\": [\"hair washing station\", \"styling chairs\", \"retail shelf\"], \"number_of_people_in_waiting_area\": 3, \"atmosphere\": \"busy and focused\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 230, in generate_covas_commentary\n",
      "    raise Exception(\"Too many runs\")\n",
      "Exception: Too many runs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135507.89 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 117759.13 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77763.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Cost Estimator', 'process': 'Contract Review', 'situation': 'In the quiet and peaceful confines of the office building, the Cost Estimator begins their daily routine of contract review. They perch themselves at their cubicle, a space brimming with the tools of their trade - a laptop, customized software, and a vast database of cost-related information. The air is filled with the soft hum of the computer, the occasional clacking of keys, and the muted chatter from the nearby meeting room. The estimator glances at their laptop screen, the bright glow casting a soft light on their focused face. Today, they are tasked with evaluating the costs and feasibility of a construction project. They pull up the blueprints on their laptop, the intricate lines and details of the design coming to life on the screen. They notice the number of dental mirrors required on a medical facility project, a small detail but crucial for an accurate estimate. They have a plethora of resources at their disposal. Sources of information ranging from industry publications to online platforms where they can connect with fellow professionals. They also have the support of the project manager, who provides clear guidelines on the project’s scope and requirements. The Cost Estimator, a professional who transforms complex data into clear, concise numbers, is ready to ensure the company’s financial stability, one estimate at a time.', 'situation_json': '{\"location\": \"office building\", \"task\": \"evaluating the costs and feasibility of a construction project\", \"ambient_noise\": \"soft hum of the computer, occasional clacking of keys, muted chatter from the nearby meeting room\", \"lighting\": \"bright glow from laptop screen\", \"tools\": \"laptop, customized software, vast database of cost-related information\", \"observable_detail\": \"number of dental mirrors required on a medical facility project\", \"resources\": \"industry publications, online platforms, support of the project manager\", \"purpose\": \"ensure company\\\\u2019s financial stability\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145159.86 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145439.04 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85752.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Telemarketer', 'process': 'Market Research', 'situation': 'In the heart of a bustling indoor office, a telemarketer for market research meticulously prepares for their daily challenge. They are stationed at their dedicated workstation, nestled within a quiet space for optimal communication. The workstation is equipped with a well-used, standard phone, a top-of-the-line computer, and a comfortable headset for hands-free operation. The telemarketer is surrounded by fellow professionals, each engrossed in their own tasks, creating an atmosphere of focused productivity. A supervisor is nearby, keeping a watchful eye and offering guidance when needed. For the next hour, the telemarketer will make calls to potential customers, engaging in verbal exchanges to gather valuable market information. Their tools and professional environment are vital to their role, supporting their task of gathering data, analyzing trends, and preparing comprehensive reports.', 'situation_json': '{\"location\": \"indoor office\", \"ambient_noise_level\": \"low\", \"lighting\": \"adequate\", \"equipment_availability\": \"present\", \"equipment_condition\": \"functioning\", \"phone_availability\": \"present\", \"phone_condition\": \"used\", \"computer_availability\": \"present\", \"computer_condition\": \"top-of-the-line\", \"headset_availability\": \"present\", \"headset_condition\": \"comfortable\", \"colleague_availability\": \"present\", \"supervisor_availability\": \"present\", \"task_duration\": \"1 hour\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142917.18 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132709.11 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 97457.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Nursing Aide', 'process': 'Record Keeping', 'situation': \"In the bustling indoor/outdoor setting of a healthcare facility, a dedicated nursing aide diligently attends to the process of record keeping. Their primary location of work, often a patient's room or bedside, is a hub of activity where they collect patient information, such as vital signs and symptoms. Equipped with the essentials - a computer to document patient records electronically and a pen and paper to jot down immediate observations - the nursing aide meticulously ensures all records are accurately maintained and up-to-date. Nearby, a nurse oversees the nursing aide's work and provides guidance and support, while patients, the primary focus of the nursing aide's care, patiently wait for their needs to be tended to. The main challenge of this process is to ensure accuracy and completeness of records, while also maintaining patient confidentiality, all the while operating in an environment that is both physically and emotionally demanding.\", 'situation_json': '{\"location\": \"indoor/outdoor healthcare facility\", \"primary_location\": \"patient\\'s room or bedside\", \"equipment_states\": {\"computer\": \"on\", \"pen\": \"ready\", \"paper\": \"available\"}, \"observations\": {\"patient_information\": [\"vital_signs\", \"symptoms\"], \"nurse_supervision\": \"present\", \"patient_status\": \"waiting\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 230, in generate_covas_commentary\n",
      "    raise Exception(\"Too many runs\")\n",
      "Exception: Too many runs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 101199.26 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 127104.63 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81559.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Financial Advisor', 'process': 'Portfolio Management', 'situation': \"In the quiet, library-like environment of a financial institution, the Financial Advisor sits at their desk in their office space, engrossed in managing a diverse range of client portfolios. The digital hum of their high-performance computer fills the room, its screen displaying a plethora of financial software. A neatly arranged stack of financial reports and analytical tools sits on one side of the desk, while a state-of-the-art calculator rests on the other. The Financial Advisor, wearing a meticulously tailored business suit, occasionally glances up from the screen to gaze out of the large office window, overlooking the bustling waiting area filled with clients. The air is filled with the murmur of hushed conversations as the support team, made up of other Financial Advisors and administrative staff, engage with the clients, keeping them comfortable and informed. In the conference room nearby, the quiet hum of muted discussion can be heard as colleagues collaborate on complex financial strategies. The atmosphere is one of calm concentration, where the Financial Advisor's mental challenge is to navigate the ever-changing seas of the financial market and ensure their clients' portfolios remain profitable.\", 'situation_json': '{\"environment\": \"quiet, library-like\", \"setting\": \"financial institution\", \"equipment_states\": {\"computer\": \"high-performance, digital hum\", \"screen\": \"displaying financial software\", \"financial_reports\": \"neatly arranged stack\", \"analytical_tools\": \"neatly arranged stack\", \"calculator\": \"state-of-the-art, resting on the desk\"}, \"observable_attributes\": {\"office_window\": \"large, overlooking bustling waiting area\", \"waiting_area\": \"filled with clients, murmur of hushed conversations\", \"support_team\": \"other Financial Advisors and administrative staff, keeping clients comfortable and informed\", \"conference_room\": \"nearby, quiet hum of muted discussion\", \"atmosphere\": \"calm concentration\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129857.09 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 119673.94 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87277.03 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Plumber', 'process': 'Inspect Plumbing Systems', 'situation': 'In a quiet and distraction-free environment, the plumber meticulously prepares for their annual inspection of the plumbing system in a towering commercial building. The plumber is armed with an assortment of tools meticulously arranged on their utility belt: two sturdy wrenches for tightening and loosening fittings, a flashlight for navigating dark and confined spaces, and a camera to document potential issues. As they enter the utility room, they take a moment to survey the furnace, water heater, and other appliances connected to the plumbing system. With a clear understanding of the layout, they proceed to the basement, a crucial location where the main water supply and other essential components reside. Here, the plumber uses their flashlight to inspect the pipes for any signs of leaks or damage, while also ensuring that the main water shutoff valve is easily accessible in case of an emergency. The plumber then moves on to the bathroom and kitchen, common areas where plumbing systems are inspected due to the presence of multiple sinks, faucets, and appliances. As they work, they remain vigilant for any potential issues, their focus unwavering, ensuring the building remains free from plumbing complications.', 'situation_json': '{\"environment\": \"quiet and distraction-free\", \"location\": \"towering commercial building\", \"preparation\": \"meticulously\", \"tools\": [\"sturdy wrenches\", \"flashlight\", \"camera\"], \"inspection_locations\": [\"utility room\", \"basement\", \"bathroom\", \"kitchen\"], \"inspection_focus\": [\"pipes\", \"main water supply\", \"essential components\", \"sinks\", \"faucets\", \"appliances\"], \"items_inspected\": [\"furnace\", \"water heater\", \"other appliances\"], \"inspection_purpose\": [\"leaks\", \"damage\", \"accessibility of main water shutoff valve\"], \"inspection_outcome\": [\"no issues found\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 98112.30 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136775.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 57709.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Software Developer', 'process': 'Client Communication', 'situation': \"In the heart of a bustling office, the weekly client communication process unfolds. A software developer, armed with a sleek, silver laptop and a sleek black smartphone, prepares to delve into the world of coding and problem-solving. The laptop, a powerful machine with a 15-inch HD screen, is where the magic happens. It is equipped with an Integrated Development Environment (IDE), a tool that allows the developer to write, test, and debug code with ease. The IDE's intuitive interface, littered with lines of code and various software development tools, is a testament to the developer's dedication and skill. Nearby, the smartphone sits silently, ready to spring into action for any urgent calls or messages. A whiteboard, adorned with multicolored dry-erase markers, stands ready for brainstorming sessions. In the background, the hum of a nearby coffee maker fills the air, providing a cozy ambiance to the otherwise professional environment. The client, sitting across the table, observes the developer intently, their expressions a mixture of curiosity and anticipation.\", 'situation_json': '{\"location\": \"office\", \"equipment\": {\"laptop\": {\"color\": \"silver\", \"screen_size\": \"15-inch\", \"screen_type\": \"HD\", \"equipped_with\": [\"Integrated Development Environment\"]}, \"smartphone\": {\"color\": \"black\", \"status\": \"idle\"}, \"whiteboard\": {\"status\": \"available\"}, \"coffee_maker\": {\"status\": \"on\", \"sound\": \"humming\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  26%|██▌       | 185/723 [23:39<20:17,  2.26s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Electrician', 'process': 'Repair Electrical Systems', 'situation': \"In the quiet, pristine office environment, a seasoned Electrician is hard at work repairing the electrical systems. The hum of the fluorescent lights overhead casts a soft white glow on the neatly arranged tools spread out on the desk. A well-maintained multimeter sits beside a pair of wire strippers, their gleaming blades ready for action. Nearby, a worn screwdriver lays in wait, its sturdy form attesting to years of dedicated service. The circuit breaker box, a sturdy grey structure, stands sentinel in the corner, its internals a complex web of wiring and circuitry. In the adjacent electrical room, a transformer hums softly, its steady rhythm a testament to its efficient operation. Elsewhere, an Electrician's assistant, a young apprentice, watches keenly, eager to learn the nuances of the trade. Up in the attic, another Electrician is meticulously threading wires through the narrow spaces, his face a mask of concentration. Down in the crawl spaces, a third Electrician is conducting a meticulous inspection, their flashlight casting long shadows in the confined space. The air is filled with the scent of fresh plastic and the soft whir of drills punctuates the silence, a symphony of repair and maintenance. The Electrician's task is a delicate balance of mental acuity and physical dexterity, a task they approach with the precision of a surgeon and the resourcefulness of a master craftsman.\", 'situation_json': '{\"environment_light\": \"fluorescent\", \"environment_sound\": \"soft whir of drills\", \"environment_scent\": \"fresh plastic\", \"equipment\": {\"multimeter\": \"well-maintained\", \"wire_strippers\": \"gleaming blades\", \"screwdriver\": \"worn\", \"circuit_breaker_box\": \"sturdy grey structure\", \"transformer\": \"humming softly\", \"assistant\": \"Electrician\\'s assistant, a young apprentice\"}, \"working_conditions\": {\"attic\": \"meticulously threading wires\", \"crawl_spaces\": \"meticulous inspection\", \"office\": \"neatly arranged tools spread out on the desk\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 230, in generate_covas_commentary\n",
      "    raise Exception(\"Too many runs\")\n",
      "Exception: Too many runs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143679.90 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123842.02 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92572.07 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Real Estate Agent', 'process': 'Property Evaluation', 'situation': 'As a real estate agent, you find yourself standing at the freshly manicured lawn of yet another property awaiting evaluation. Your crisp navy blue blazer, adorned with the gleaming gold lapel pin of your reputable real estate firm, reflects the professionalism you exude. In your hands, you clutch a well-loved, slightly worn clipboard, its surface covered with neatly jotted notes and forms, meticulously organized for the task at hand. Beside you, a sleek, state-of-the-art camera hangs from your shoulder, ready to capture the essence of the property with high-definition precision. The sun casts a warm glow, highlighting the charming colonial architecture of the house before you. You take a deep breath, the scent of blooming flowers and freshly cut grass filling your lungs, as you prepare to assess every inch of this potential gem. Inside, the spacious layout, bathed in natural light, beckons you to explore. The kitchen, with its gleaming countertops and top-notch appliances, catches your eye. The living room, adorned with elegant furniture and featuring a cozy fireplace, whispers tales of comfort and relaxation. Your keen observer’s eye notes every detail, from the pristine condition of the hardwood floors to the subtle wear on the carpeting. You whip out your tablet, the screen illuminating as you begin to take digital notes, ensuring no detail, no matter how minute, escapes your scrutiny. The surrounding neighborhood, with its well-maintained homes and lush greenery, promises a sense of community and tranquility. As you wrap up your inspection, the hum of activity in the nearby office reminds you of the tireless work your colleagues are spearheading, each striving to make another client’s dream a reality. This is your world—a blend of precision, creativity, and unwavering dedication to excellence.', 'situation_json': '{\"description\": \"As a real estate agent, you find yourself standing at the freshly manicured lawn of yet another property awaiting evaluation. Your crisp navy blue blazer, adorned with the gleaming gold lapel pin of your reputable real estate firm, reflects the professionalism you exude. In your hands, you clutch a well-loved, slightly worn clipboard, its surface covered with neatly jotted notes and forms, meticulously organized for the task at hand. Beside you, a sleek, state-of-the-art camera hangs from your shoulder, ready to capture the essence of the property with high-definition precision. The sun casts a warm glow, highlighting the charming colonial architecture of the house before you. You take a deep breath, the scent of blooming flowers and freshly cut grass filling your lungs, as you prepare to assess every inch of this potential gem. Inside, the spacious layout, bathed in natural light, beckons you to explore. The kitchen, with its gleaming countertops and top-notch appliances, catches your eye. The living room, adorned with elegant furniture and featuring a cozy fireplace, whispers tales of comfort and relaxation. Your keen observer\\\\u2019s eye notes every detail, from the pristine condition of the hardwood floors to the subtle wear on the carpeting. You whip out your tablet, the screen illuminating as you begin to take digital notes, ensuring no detail, no matter how minute, escapes your scrutiny. The surrounding neighborhood, with its well-maintained homes and lush greenery, promises a sense of community and tranquility. As you wrap up your inspection, the hum of activity in the nearby office reminds you of the tireless work your colleagues are spearheading, each striving to make another client\\\\u2019s dream a reality. This is your world\\\\u2014a blend of precision, creativity, and unwavering dedication to excellence.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135379.75 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137666.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85142.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dental Assistant', 'process': 'Appointment Scheduling', 'situation': 'Inside the bustling indoor office of a dental clinic, I, a dental assistant, am stationed at the front desk, my fingers swiftly tapping away on the computer as I manage appointments. The computer screen flickers with the scheduling software, each colorful block representing a patient and their respective appointment time. The waiting room, just a few steps away, echoes with the muffled chatter of patients, their numbers varying throughout the day. A large clock ticks away the minutes on the wall, its hands slowly inching towards the next appointment. Directly behind my chair, a tray laden with dental equipment stands ready for the next patient. Five dental mirrors - each a gleaming, chrome-plated tool - reflect the sterile white lights from above, casting a clinical shine across the room. Two high-speed dental drills, their tips encased in protective coverings, accompany the mirrors. The accompanying suction devices, six of them, are lined up neatly alongside, their clear, plastic tubes standing at attention. The dentist, my colleague, is currently engrossed in an appointment, his face a picture of concentration. The patient, draped in a navy blue bib, reclines in the dental chair, their eyes closed in a moment of relaxation amidst the buzzing of the drill.', 'situation_json': '{\"location\": \"indoor office of a dental clinic\", \"equipment_states\": {\"computer\": {\"status\": \"on\", \"screen_flickering\": true, \"software\": \"scheduling software\"}, \"tray\": {\"status\": \"ready\", \"contents\": {\"dental mirrors\": 5, \"dental drills\": 2, \"suction devices\": 6}}, \"dental mirrors\": {\"state\": \"gleaming\", \"number\": 5}, \"dental drills\": {\"state\": \"tips encased in protective coverings\", \"number\": 2}, \"suction devices\": {\"state\": \"lined up neatly\", \"number\": 6}, \"clock\": {\"status\": \"ticking\", \"hands_moving\": true}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 115739.14 examples/s]ples]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 80429.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Personal Care Aide', 'process': 'Medication Management', 'situation': 'In the cozy, indoor setting of a patient’s residence, a Personal Care Aide meticulously manages the medication process. The soft light filters through the window of the patient’s bedroom, casting a warm glow on the medication organizer placed neatly on the nightstand. The organizer, divided into seven compartments for each day of the week, houses a myriad of medications - a total of ten small, blue pills for hypertension, five large, round pills for arthritis, and two oblong capsules for cholesterol. Each is carefully labeled with the day and time they are to be taken. Nearby, a pill crusher rests on the table, ready for use should the patient have difficulty swallowing larger pills. An alarm on the Personal Care Aide’s mobile device softly beeps, signaling the patient’s scheduled medication time. Surrounding this scene is the peaceful, quiet environment of the home, ensuring the patient can focus on their health and well-being. The entire process, which plays out daily, takes about ten minutes to complete, demonstrating the Personal Care Aide’s commitment to supporting the patient’s health, independence, and quality of life.', 'situation_json': '{\"setting\": \"indoor\", \"specific_location\": \"patient\\'s residence\", \"light_conditions\": \"soft light filters through the window\", \"equipment\": {\"medication_organizer\": {\"placement\": \"neatly on the nightstand\", \"compartments\": 7, \"medications\": [{\"type\": \"small, blue pills\", \"condition_treated\": \"hypertension\", \"quantity\": 10}, {\"type\": \"large, round pills\", \"condition_treated\": \"arthritis\", \"quantity\": 5}, {\"type\": \"oblong capsules\", \"condition_treated\": \"cholesterol\", \"quantity\": 2}], \"labeling\": \"carefully labeled with the day and time\"}, \"pill_crusher\": {\"placement\": \"nearby on the table\"}}, \"additional_items\": {\"alarm\": {\"device\": \"Personal Care Aide\\'s mobile device\", \"timing\": \"soft beep signaling the patient\\\\u2019s scheduled medication time\"}}, \"environment_conditions\": {\"peacefulness\": \"peaceful\", \"noisiness\": \"quiet\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  26%|██▌       | 189/723 [23:43<10:01,  1.13s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Medical Secretary', 'process': 'Prescription Processing', 'situation': 'In the bustling environment of a medical practice, a medical secretary is diligently processing prescriptions. Seated at their well-organized desk, cluttered with a variety of colored paperwork and a computer humming softly, they navigate a user-friendly medical software with ease. A corded telephone rests nearby, its flashing light signaling an incoming call. The file room, a few steps away, houses a multitude of patient records, meticulously filed and readily available for retrieval. The medical library is steadfast, offering a wide array of resources for the medical staff to peruse and stay updated with the latest medical information. In the waiting room, a handful of patients sit comfortably, waiting to be seen by their respective healthcare providers. The medical secretary, in their role, is constantly engaged in a delicate dance of managing, transcribing, and distributing prescriptions, while simultaneously handling a flurry of phone calls and scheduling appointments. The process is a continuous one, requiring constant vigilance and attention to detail.', 'situation_json': '{\"description\": \"In the bustling environment of a medical practice, a medical secretary is diligently processing prescriptions. Seated at their well-organized desk, cluttered with a variety of colored paperwork and a computer humming softly, they navigate a user-friendly medical software with ease. A corded telephone rests nearby, its flashing light signaling an incoming call. The file room, a few steps away, houses a multitude of patient records, meticulously filed and readily available for retrieval. The medical library is steadfast, offering a wide array of resources for the medical staff to peruse and stay updated with the latest medical information. In the waiting room, a handful of patients sit comfortably, waiting to be seen by their respective healthcare providers. The medical secretary, in their role, is constantly engaged in a delicate dance of managing, transcribing, and distributing prescriptions, while simultaneously handling a flurry of phone calls and scheduling appointments. The process is a continuous one, requiring constant vigilance and attention to detail.\", \"desk_state\": \"well-organized\", \"paperwork_state\": \"cluttered with a variety of colored paperwork\", \"computer_state\": \"humming softly\", \"software_state\": \"a user-friendly medical software\", \"telephone_state\": \"corded, flashing light signaling an incoming call\", \"file_room_state\": \"a few steps away, houses a multitude of patient records, meticulously filed and readily available for retrieval\", \"medical_library_state\": \"steadfast, offering a wide array of resources for the medical staff to peruse and stay updated with the latest medical information\", \"waiting_room_state\": \"a handful of patients sitting comfortably\", \"prescription_management_state\": \"diligently processing prescriptions\", \"phone_calls_state\": \"handling a flurry of phone calls\", \"appointment_scheduling_state\": \"simultaneously scheduling appointments\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119174.92 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145096.24 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92136.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Marketing Manager', 'process': 'Performance Reporting', 'situation': 'In the corporate office, a Marketing Manager diligently works in their indoor office, surrounded by a bustling marketing department. Their office is filled with the gentle hum of a computer and the soft glow of multiple screens, each displaying crucial data and marketing software. On their desk, a sleek laptop and a smartphone are meticulously organized, the latter constantly buzzing with team communications and social media updates. Nearby, open workspace areas and creative spaces like design studios buzz with the collaborative energy of the marketing and sales teams. A meeting room, where regular discussions with the finance team and other departments take place, is just a few strides away. In this environment, the Marketing Manager collects, analyzes, and reports marketing performance data on a monthly basis. They use tools like Google Analytics, CRM systems, and marketing automation platforms to track key performance indicators (KPIs) and provide actionable insights to stakeholders, senior management, and departmental heads. They also collaborate with the research and IT departments to ensure accurate and secure data systems. The process is both challenging and rewarding, requiring a deep analytical understanding and the ability to translate complex data into strategic insights.', 'situation_json': '{\"situation\": \"In the corporate office, a Marketing Manager diligently works in their indoor office, surrounded by a bustling marketing department. Their office is filled with the gentle hum of a computer and the soft glow of multiple screens, each displaying crucial data and marketing software. On their desk, a sleek laptop and a smartphone are meticulously organized, the latter constantly buzzing with team communications and social media updates. Nearby, open workspace areas and creative spaces like design studios buzz with the collaborative energy of the marketing and sales teams. A meeting room, where regular discussions with the finance team and other departments take place, is just a few strides away. In this environment, the Marketing Manager collects, analyzes, and reports marketing performance data on a monthly basis. They use tools like Google Analytics, CRM systems, and marketing automation platforms to track key performance indicators (KPIs) and provide actionable insights to stakeholders, senior management, and departmental heads. They also collaborate with the research and IT departments to ensure accurate and secure data systems. The process is both challenging and rewarding, requiring a deep analytical understanding and the ability to translate complex data into strategic insights.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 99306.05 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123723.99 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79311.82 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Cement Mason & Concrete Finisher', 'process': 'Leveling Concrete', 'situation': 'Five concrete finishers work diligently on a large, open-air construction site. The air is filled with the rumble of a nearby concrete plant, the distant chatter of construction workers, and the occasional whir of a safety sign spinning in the wind. To the east, a safety area is set up with comfortable seating and shade for breaks, while to the north, a storage area houses various tools, equipment, and materials, including a dozen trowels of varying sizes and cleanliness, three freshly washed bull floats, two wheelbarrows, and one mechanical concrete finishing machine. The workers are focused on a single, enormous concrete slab, which they are leveling, smoothing, and brushing to create a non-slip texture. The process requires precision and teamwork, with each worker contributing their skills and tools to the task. They work diligently for nearly two hours, stopping only for a brief break to check their hard hats, safety glasses, gloves, and non-slip shoes. The sun beats down on them, and the work is physically demanding, but they continue, knowing that their efforts will result in a smooth and even surface for building construction.', 'situation_json': '{\"number_of_workers\": 5, \"location\": \"large, open-air construction site\", \"background_noise\": [\"rumble of a nearby concrete plant\", \"distant chatter of construction workers\", \"occasional whir of a safety sign spinning in the wind\"], \"break_area\": \"safety area set up with comfortable seating and shade for breaks to the east\", \"storage_area\": \"storage area housing various tools, equipment, and materials to the north\", \"tool_equipment_material\": {\"trowels\": {\"quantity\": 12, \"size\": \"varying\", \"cleanliness\": \"varying\"}, \"bull floats\": {\"quantity\": 3, \"cleanliness\": \"freshly washed\"}, \"wheelbarrows\": {\"quantity\": 2}, \"mechanical_concrete_finishing_machine\": {\"quantity\": 1}}, \"task\": \"leveling, smoothing, and brushing a non-slip texture\", \"teamwork_required\": true, \"physical_demand\": true, \"duration\": \"nearly two hours\", \"break_frequency\": \"brief\", \"break_checklist\": [\"hard hats\", \"safety glasses\", \"gloves\", \"non-slip shoes\"], \"sun_exposure\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  27%|██▋       | 192/723 [23:45<08:10,  1.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Administrative Assistant', 'process': 'Expense Reporting', 'situation': \"The Administrative Assistant, ensconced in their indoor, sunlit office, begins their weekly expense reporting process. Their office, a sanctuary of administrative efficiency, is adorned with meticulously organized filing cabinets, their faces gleaming under the soft hum of fluorescent lights. The room is filled with the quiet hum of the printer, a loyal workhorse, tirelessly preparing statements and receipts, its tray neatly stacked with an armory of crisp, white paper, ready for battle. The computer, a sleek black battle station, sits atop the desk, its screen a portal into the digital labyrinth of expense claims. The keyboard, a well-worn warrior, bears the scars of countless expense reports, each key a testament to the Assistant's diligence. The mouse, a silent sentinel, guards the scroll wheel, ready to navigate the treacherous seas of spreadsheet data. The Administrative Assistant's chair, a plush throne of administrative power, is positioned perfectly, allowing for hours of comfortable, focused work. The room is filled with the faint scent of ink and paper, a symphony of administrative accomplishment. The walls are adorned with charts and graphs, a visual representation of the Assistant's relentless pursuit of expense reporting excellence. The window, a portal to the outside world, offers a glimpse of the bustling office space, where colleagues, ensconced in their own administrative sanctuaries, are engaged in their own battles of administrative efficiency. The phone, a silent observer, rests on the desk, ready to receive calls from employees with queries about their expense claims. The Administrative Assistant takes a deep breath, their fingers poised over the keyboard, ready to dive into the weekly expense reporting process. The office, a bastion of administrative order, is ready for another week of expense reporting.\", 'situation_json': '{\"office\": {\"lighting\": \"fluorescent\", \"organization\": \"meticulous\", \"humnoise\": \"soft\"}, \"furniture\": {\"filing_cabinets\": {\"state\": \"gleaming\"}, \"desk\": {\"computer\": {\"state\": \"sleek\", \"color\": \"black\"}, \"keyboard\": {\"state\": \"well-worn\"}, \"mouse\": {\"state\": \"silent\"}, \"chair\": {\"comfort\": \"plush\", \"position\": \"perfect\"}}, \"printer\": {\"state\": \"loyal\", \"tray\": \"neatly stacked\"}}, \"scents\": {\"ink_and_paper\": \"faint\"}, \"wall_decor\": \"charts and graphs\", \"window\": {\"view\": \"bustling office space\"}, \"phone\": {\"state\": \"silent\"}, \"assistant\": {\"mood\": \"ready\", \"position\": \"fingers poised over keyboard\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  27%|██▋       | 193/723 [23:48<13:24,  1.52s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Restaurant Cook', 'process': 'Order Processing', 'situation': \"In the bustling, indoor restaurant kitchen, the Restaurant Cook, a seasoned chef with a tall, white hat and a crisp, double-breasted jacket, stands at the helm of the cooking line, a sprawling, stainless-steel counter stretching out before them like a command bridge. The kitchen, a symphony of clattering pans and hissing flames, is a well-oiled machine, each cook, their faces glistening with sweat and concentration, working in harmony to fulfill the relentless stream of orders pouring in from the open kitchen, visible to the guests in the dining room. The chef's eyes flit from the orders scrawled on the tickets spitting out from the printer to the prep area, where a team of line cooks, their knives flashing like extensions of their hands, transform mountains of fresh ingredients into something extraordinary. The air is thick with the aroma of garlic, searing meat, and the faint tang of cleaning solution, the latter a testament to the strict cleanliness standards enforced in this kitchen. The chef's hands, calloused and stained, deftly wield a gleaming spatula, pushing a perfectly cooked steak around the grill, while their other hand hovers over the thermometer, ensuring every morsel leaves the kitchen at the optimal temperature. The oven, a roaring beast of cast iron and fire, glows like a jewel behind the chef, its door swinging open to reveal trays of golden-brown pastries, their buttery scent promising delight to the diners in the next room. The chef's gaze sweeps across the cooking line, taking in the sizzling pans, the bubbling sauces, the precise choreography of each cook, before landing on the dishwasher, a towering machine churning out clean plates with mechanical efficiency. The chef nods, satisfied, before turning their attention back to the orders, their mind a whirlwind of recipe formulas, cooking times, and presentation ideas. The kitchen, their domain, is a dance floor, and they are the dance director, orchestrating each step with precision and passion. The chef's eyes crinkle at the corners, a smile tugging at their lips as they survey their kingdom, the heart of the restaurant, where every plate tells a story, and every story ends with a satisfied customer.\", 'situation_json': '{\"kitchen_type\": \"indoor\", \"chef_attire\": {\"hat\": \"white\", \"hat_tallness\": true, \"jacket\": \"double-breasted\", \"jacket_crispness\": true}, \"chef_skill_level\": \"seasoned\", \"chef_hand_state\": \"calloused, stained\", \"chef_eyes\": \"flitting\", \"chef_mind_state\": \"whirlwind of recipe formulas, cooking times, presentation ideas\", \"chef_expression\": \"smile tugging at their lips, eyes crinkling at the corners\", \"chef_role\": \"orchestrating\", \"chef_domain\": \"kitchen\", \"kitchen_state\": \"well-oiled machine\", \"kitchen_noise\": \"clattering pans, hissing flames\", \"kitchen_aroma\": [\"garlic\", \"searing meat\", \"cleaning solution\"], \"oven_state\": \"roaring beast\", \"oven_material\": \"cast iron, fire\", \"oven_door_state\": \"swinging open\", \"oven_contents\": \"trays of golden-brown pastries\", \"dishwasher_state\": \"churning out clean plates\", \"dishwasher_efficiency\": \"mechanical\", \"order_state\": \"relentless stream\", \"order_visibility\": \"visible to guests in dining room\", \"order_processing\": \"transforming mountains of fresh ingredients into something extraordinary\", \"order_fulfillment\": \"every plate tells a story, every story ends with a satisfied customer\", \"temperature_control\": \"ensuring every morsel leaves the kitchen at optimal temperature\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  27%|██▋       | 194/723 [23:49<13:07,  1.49s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Compliance Officer', 'process': 'Stakeholder Communication', 'situation': 'The Compliance Officer is responsible for maintaining a good relationship with stakeholders by communicating effectively about regulatory compliance issues. This involves regular meetings, reports, and updates to keep stakeholders informed and involved in the decision-making process.', 'situation_json': '{\"description\": \"A Compliance Officer situation in the Stakeholder Communication process.\", \"compliance_issues\": {\"regulatory_updates\": true, \"policy_changes\": true}, \"communication_methods\": {\"meetings\": \"regular\", \"reports\": true, \"updates\": true}, \"stakeholder_involvement\": {\"informed\": true, \"decision_making_process\": true}, \"meeting_frequency\": \"weekly\", \"stakeholder_interaction\": {\"direct\": true, \"indirect\": false}, \"reporting_frequency\": \"monthly\", \"update_frequency\": \"daily\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125017.52 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134738.38 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86266.78 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Brickmason & Blockmason', 'process': 'Blueprint Reading', 'situation': 'The Brickmason & Blockmason is meticulously studying the blueprint at the outdoor construction site, a location bustling with activity. The blueprint shows the dimensions and specifications for a structure made of bricks or blocks. Nearby, a temporary structure of scaffolding supports the mason as they work at different heights, providing a stable platform for them to build the structure. The Brickmason & Blockmason looks around and sees a laborer nearby, assisting by carrying materials and mixing mortar. They also spot a wheelbarrow and a concrete mixer nearby, the latter used to prepare the mortar mixture. The Brickmason & Blockmason knows that understanding the blueprint is crucial. It ensures that the structure is built according to the plan, meets all safety and aesthetic standards, and keeps the project within budget. The Brickmason & Blockmason continues studying the blueprint, making sure to take note of every detail as they prepare to build.', 'situation_json': '{\"location\": \"outdoor construction site\", \"activity_level\": \"bustling\", \"blueprint_present\": true, \"blueprint_details\": \"dimensions and specifications for a structure made of bricks or blocks\", \"scaffolding_present\": true, \"scaffolding_purpose\": \"stable platform for building structure\", \"laborer_present\": true, \"laborer_role\": \"carrying materials and mixing mortar\", \"wheelbarrow_present\": true, \"concrete_mixer_present\": true, \"concrete_mixer_purpose\": \"preparing mortar mixture\", \"understanding_blueprint_crucial\": true, \"purpose_of_understanding_blueprint\": \"build structure according to plan, meet safety and aesthetic standards, keep project within budget\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  27%|██▋       | 196/723 [23:53<14:46,  1.68s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Interpreter & Translator', 'process': 'Transcription Services', 'situation': \"Situated in a quiet indoor environment, a dedicated interpreter and translator carries out transcription services within a translation agency. Fitted with several tools essential for the job, the interpreter and translator's office is a well-equipped workspace. A state-of-the-art computer with a reliable internet connection sits on the desk, alongside a comprehensive dictionary and specialized translation software. A comfortable headset rests nearby, used for both listening to audio materials and communicating with clients. Further down the hallway, a hushed library offers a wealth of reference materials for quick consultation. After researching complex terminologies, the interpreter and translator can switch to the audio recording room, ensuring precise transcriptions of audio materials. In the waiting room, a couple of clients patiently await their turn for interpretation services, demonstrating the high demand for accurate language conversion.\", 'situation_json': '{\"environment\": \"indoor\", \"environment_description\": \"quiet\", \"equipment\": {\"computer\": {\"type\": \"state_of_the_art\", \"status\": \"on\"}, \"internet_connection\": {\"status\": \"reliable\"}, \"dictionary\": {\"description\": \"comprehensive\"}, \"translation_software\": {\"description\": \"specialized\"}, \"headset\": {\"status\": \"comfortable\", \"purpose\": [\"listening\", \"communication\"]}, \"library\": {\"status\": \"well-stocked\", \"environment\": \"hushed\", \"location\": \"hallway\", \"purpose\": \"research\"}, \"audio_recording_room\": {\"purpose\": \"transcription\"}, \"waiting_room\": {\"status\": \"occupied\", \"number_of_clients\": 2, \"demand\": \"high\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 84746.22 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 115249.93 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81739.31 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Maid & Housekeeper', 'process': 'Bathroom Cleaning', 'situation': 'In the early morning hours, the Maid & Housekeeper, dressed in a neat uniform, begins the daily bathroom cleaning process in a spacious home. As they prepare for the task at hand, the maid & housekeeper carefully lines up their gleaming cleaning equipment on the bathroom vanity - a sponge, mop, vacuum cleaner, cleaning solutions, and rubber gloves, all ready for use. They can hear the soft footsteps of the homeowner/tenant, knowing they expect a clean, hygenic, and well-maintained bathroom, a sense of responsibility swelling within them. In the corner, the ventilation fan hums quietly, ensuring excess moisture and odors are kept at bay. As they start with the sink, meticulously scrubbing away any dirt and grime, a sense of satisfaction spreads through them, knowing their work contributes to the overall cleanliness and order within this very home or commercial building.', 'situation_json': '{\"time_of_day\": \"early_morning\", \"location\": \"spacious_home\", \"uniform\": \"neat\", \"vacuum_cleaner_state\": \"ready_for_use\", \"cleaning_solutions_state\": \"ready_for_use\", \"homeowner_presence\": true, \"ventilation_fan_state\": \"on\", \"bathroom_cleanliness\": \"to_be_cleaned\", \"homeowner_expectation\": \"clean_hygenic_maintained_bathroom\", \"maid_responsibility\": \"uphold_responsibility\", \"sink_state\": \"dirty\", \"sink_cleaned\": false, \"home_building_type\": \"home_or_commercial_building\", \"overall_cleanliness\": \"to_be_maintained\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 89541.14 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137140.74 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 66417.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Hairdresser', 'process': 'Hair Cutting', 'situation': 'Inside the bustling hair salon, the hairdresser is preparing for their next 30-minute hair cutting appointment. The hair cutting station, illuminated by warm ambient lighting, is adorned with a polished mirror, a plush swivel chair, and a black leather-topped counter. On the counter, there are five gleaming pairs of scissors, two razors, a single pair of clippers, and three combs with teeth varying in width. As the hairdresser sanitizes their tools, the waiting area around the corner buzzes with anticipation. Four clients are scattered across the comfortable seating, flipping through the latest fashion magazines. The air swirls lightly with the fragrance of lavender, emanating from the nearby retail shelves. The retail area, filled with a multitude of hair care products, is frequently visited and admired by the waiting clients. A colleague, hairdresser in training, is restocking the shelves with shampoos, conditioners, and hairsprays to ensure they stay well-stocked. The reception area, manned by an assistant, constantly hums with the quiet chatter of clients checking in and out.', 'situation_json': '{\"profession\": \"Hairdresser\", \"process\": \"Hair Cutting\", \"equipment_states\": {\"scissors\": 5, \"razors\": 2, \"clippers\": 1, \"combs\": 3}, \"observable_details\": {\"ambient_lighting\": true, \"mirror_polished\": true, \"chair_swivel\": true, \"counter_leather\": true, \"waiting_area_occupied\": 4, \"magazines_present\": true, \"lavender_fragrance\": true, \"retail_shelves_stocked\": true, \"reception_area_active\": true, \"colleague_available\": true}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 118132.04 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 110861.40 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83345.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Cost Estimator', 'process': 'Cost Analysis', 'situation': \"In the spacious and well-lit construction company office, the Cost Estimator is seated in a comfortable office chair, leaning over a cluttered but organized desk. The large computer screen displays a complex spreadsheet, filled with rows and columns of data. The room is quiet, broken only by the occasional hum of the air conditioning and the soft tapping of keys on the keyboard. To the left of the desk, a stack of blueprints sits neatly, providing detailed information about the proposed project. The Cost Estimator often refers to them while working on the cost estimates. Nearby, a team of engineers and project managers are seen gathered around a table, engaged in a heated discussion about the project's timeline and resources. The meeting room, separated by a glass wall, provides a glimpse of this interaction. The office has a peaceful environment, necessary for the Cost Estimator to concentrate and perform their tasks accurately. Occasionally, the Cost Estimator may visit a nearby library to research industry trends and gather data for their estimates. The expected duration of this process is between 1 day to 10 days, occurring on a monthly frequency. The main challenge is mental, ensuring accuracy in the estimates and avoiding underestimating high-risk aspects such as labor, materials, and equipment costs.\", 'situation_json': '{\"office_size\": \"spacious\", \"office_lighting\": \"well-lit\", \"protagonist_seat\": \"comfortable office chair\", \"desk_state\": \"cluttered but organized\", \"computer_screen_display\": \"complex spreadsheet\", \"data_format\": \"rows and columns\", \"office_noise_level\": \"quiet\", \"air_conditioning_state\": \"humming\", \"keyboard_state\": \"soft tapping\", \"blueprint_location\": \"left of the desk\", \"blueprint_state\": \"neatly stacked\", \"blueprint_information\": \"detailed\", \"engineer_location\": \"nearby\", \"engineer_activity\": \"discussing project timeline and resources\", \"meeting_room_visibility\": \"glass wall\", \"office_environment\": \"peaceful\", \"research_location\": \"library\", \"research_topic\": \"industry trends\", \"research_frequency\": \"monthly\", \"process_duration\": \"1-10 days\", \"process_challenge\": \"ensuring accuracy in estimates\", \"high_risk_aspects\": [\"labor\", \"materials\", \"equipment costs\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 140553.58 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133507.27 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87375.69 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Telemarketer', 'process': 'Product Presentation', 'situation': \"A telemarketer's job involves making phone calls to potential customers, introducing products or services, and persuading them to make a purchase or schedule a follow-up appointment. This process is crucial in generating leads and increasing sales. It requires excellent communication skills, product knowledge, and the ability to handle objections.\", 'situation_json': '{\"situation\": \"A telemarketer\\'s job involves making phone calls to potential customers, introducing products or services, and persuading them to make a purchase or schedule a follow-up appointment. This process is crucial in generating leads and increasing sales. It requires excellent communication skills, product knowledge, and the ability to handle objections.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 118930.61 examples/s]ples]\n",
      "Filter:   0%|          | 0/4271 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Occupational Therapist', 'process': 'Collaboration with Other Healthcare Professionals', 'situation': \"In a spacious private indoor clinic, an experienced Occupational Therapist prepares for their hourly collaboration meeting with other healthcare professionals. The office, furnished with a comfortable ergonomic chair and a large modern computer, is neatly organized, with medical books stacked neatly on the shelf. The room exudes a sense of calmness and professionalism, with a subtle fragrance of lavender emanating from a small potted plant sitting on the windowsill. On the sturdy desk, there are several orthotics and prosthetics, a few pieces of adaptive equipment, and a wheelchair. Each piece of equipment is meticulously organized, well-maintained, and ready for use. The occupational therapist's computer screen displays the electronic health records of several patients, with detailed notes on their progress. The doctor, nurse, and physical therapist wait patiently in the nearby waiting room of the clinic, a bright and cheerful area bustling with activity. The area is decorated with colorful posters illustrating the importance of health and well-being, and the low hum of conversation creates a lively yet professional atmosphere. With the plan to review and adjust the treatment plans for each patient, the mental health professionals will gather in a meeting room nearby, discussing the challenges and successes of each case.\", 'situation_json': '{\"clinic_type\": \"private\", \"clinic_location\": \"indoor\", \"room_size\": \"spacious\", \"clinic_area\": \"neatly organized\", \"chair_condition\": \"comfortable ergonomic\", \"chair_quantity\": 1, \"computer_type\": \"large modern\", \"shelf_condition\": \"natively organized\", \"shelf_content\": \"medical books\", \"shelf_content_quantity\": \"several\", \"plant_condition\": \"small potted\", \"plant_location\": \"windowsill\", \"plant_scent\": \"lavender\", \"desk_condition\": \"sturdy\", \"desk_content\": [\"orthotics and prosthetics\", \"adaptive equipment\", \"wheelchair\"], \"desk_content_quantity\": {\"orthotics and prosthetics\": \"several\", \"adaptive equipment\": \"a few\", \"wheelchair\": 1}, \"equipment_maintenance\": \"meticulously well-maintained\", \"OT_computer_screen_display\": \"electronic health records\", \"OT_computer_screen_display_content\": \"several patients progress\", \"OT_computer_screen_display_content_notes\": \"detailed\", \"clinic_waiting_room\": \"bright and cheerful area bustling with activity\", \"waiting_room_decor\": \"colored posters\", \"waiting_room_decor_illustration\": \"health and well-being\", \"waiting_room_ambiance_noise\": \"low hum of conversation\", \"professional_ambiance\": \"lively yet professional\", \"meeting_room_location\": \"nearby\", \"meeting_objective\": \"review and adjust treatment plans for each patient\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 102081.49 examples/s]ples]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 47888.66 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 100485.60 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 129667.85 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79230.52 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Financial Analyst', 'process': 'Budget Planning', 'situation': 'The financial analyst sits at a large mahogany desk, surrounded by stacks of neatly organized documents. The desk is equipped with multiple computer monitors displaying complex spreadsheets and financial modeling software. The office is filled with the hum of quiet concentration as account executives manage client relationships and provide the necessary inputs for budgeting and financial planning. Finance managers are nearby, planning, coordinating, and managing the financial activities of the company. They provide direction and guidance to financial analysts. Internal auditors oversee internal controls, risk management, and governance processes within the company, assisting financial analysts in verifying financial data and ensuring accuracy. The office setting provides a conducive environment for financial tasks ensuring confidentiality and facilitating teamwork. Meeting rooms with sleek marble tables are available for discussions and presentations with colleagues and superiors.', 'situation_json': '{\"desk_material\": \"mahogany\", \"desk_status\": \"occupied\", \"document_organization\": \"neat\", \"computer_monitors\": 3, \"displayed_software\": [\"spreadsheets\", \"financial modeling software\"], \"office_noise\": \"quiet concentration\", \"office_environment\": \"conducive for financial tasks\", \"confidentiality\": true, \"teamwork_facilitation\": true, \"meeting_room_tables\": \"marble\", \"meeting_room_purposes\": [\"discussions\", \"presentations\"], \"meeting_room_participants\": [\"colleagues\", \"superiors\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 98099.90 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146470.05 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86390.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Software Developer', 'process': 'Documentation', 'situation': 'Software developers design, code, test, and maintain software applications, frameworks, or systems. The job involves writing clean, efficient code based on specifications. Their role is crucial in the software development life cycle. Alongside technical tasks, software developers collaborate with various stakeholders, including project managers, designers, and other developers, to understand requirements and deliver solutions that meet user needs. They also troubleshoot, debug, and upgrade existing systems. Additionally, they stay updated with the latest programming languages and technologies to keep their skills relevant.', 'situation_json': '{\"job_details\": {\"design\": true, \"code\": true, \"test\": true, \"maintain\": true, \"frameworks\": true, \"systems\": true, \"write_code\": true, \"technical_tasks\": true, \"collaboration\": true, \"project_managers\": true, \"designers\": true, \"other_developers\": true, \"requirements\": true, \"deliver_solutions\": true, \"troubleshoot\": true, \"debug\": true, \"upgrade_systems\": true, \"latest_programming_languages\": true, \"technologies\": true}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  28%|██▊       | 204/723 [24:35<21:44,  2.51s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Plumber', 'process': 'Maintain Water Heaters', 'situation': \"In the dimly lit, damp basement, the air is thick with the scent of earth and the faint hum of distant machinery. The water heater, a towering, olive-green behemoth, looms in the corner, its surface speckled with rust and condensation. A rusty, worn-out wrench lies on the concrete floor, a testament to the age and neglect of the appliance. The pipes connected to the water heater are a maze of copper and steel, some gleaming, others encrusted with mineral deposits. The plumber, dressed in overalls stained with grease and grime, is on their hands and knees, a flashlight clenched between their teeth, as they scrutinize the labyrinthine network, listening intently with a stethoscope for any telltale hisses or rattles. The sound of dripping water echoes through the basement, a reminder of the constant battle against leaks and corrosion. The plumber's bucket, a chipped and battered yellow plastic, sits nearby, ready to catch any sudden gushes. In the utility room upstairs, the homeowner, a middle-aged man with a worried expression, paces back and forth, occasionally casting a glance at the closed basement door, no doubt anxious about the state of their water heater.\", 'situation_json': '{\"location\": \"basement\", \"ambient_air\": \"thick\", \"smells\": [\"earth\", \"faint machinery\"], \"sounds\": [\"dripping water\"], \"water_heater\": {\"color\": \"olive-green\", \"condition\": \"towering\", \"surface\": \"speckled with rust and condensation\"}, \"floor\": \"concrete\", \"floor_items\": [{\"item\": \"wrench\", \"material\": \"rusty, worn-out\", \"condition\": \"stained with grease and grime\"}], \"pipes\": {\"materials\": [\"copper\", \"steel\"], \"conditions\": [\"gleaming\", \"encrusted with mineral deposits\"]}, \"plumber\": {\"position\": \"on their hands and knees\", \"tools\": [\"flashlight\", \"stethoscope\"]}, \"utility_room\": {\"occupant\": \"middle-aged man\", \"expression\": \"worried\", \"activity\": \"pacing back and forth\", \"glances\": \"closed basement door\", \"anxiety\": \"state of their water heater\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]2,  1.86s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Elementary School Teacher', 'process': 'Classroom Management', 'situation': \"Elementary school teachers are responsible for creating a safe, inclusive, and engaging learning environment for students aged 5 to 11. Classroom management is a critical aspect of this role, involving various tasks to maintain a productive and positive learning atmosphere. This includes lesson planning, teaching, assessing student progress, and managing classroom behavior. Teachers must be skilled in classroom organization, time management, and effective communication to successfully manage their classroom.\\n\\nIn this classroom, it is a bright and sunny morning, with the gleaming rays of the sun peeking through the half-open blinds of the classroom windows. There are 24 students present, all seated at their respective desks arranged neatly in rows. The classroom is adorned with vibrant posters and educational charts, adding a splash of color and life to the space.\\n\\nAt the front of the room sits the teacher's desk, where a laptop and a stack of textbooks are carefully arranged. The teacher, Ms. Thompson, is standing by the whiteboard, meticulously writing the day's agenda and objectives. Behind her, the whiteboard is divided into sections, one for the day's schedule, another for important announcements, and a third section dedicated to highlighting outstanding student achievements.\\n\\nOn the teacher's desk, there is a cup of steaming coffee, emitting a comforting aroma that fills the room. Beside the coffee, there is a neatly organized pile of art supplies, ready for the upcoming art class. The computers in the classroom are switched on, their screens displaying the school's welcome page, ready for the day's lessons.\\n\\nThe classroom is quiet, but there is an underlying buzz of anticipation as students await the start of the day's activities. The playground outside is visible from the classroom windows, where a few students are running around, enjoying their morning recess.\\n\\nMs. Thompson, with a warm smile, turns to face the class, ready to begin the day's lesson, confident in her ability to manage and guide the young minds before her.\", 'situation_json': '{\"setting\": {\"time_of_day\": \"morning\", \"weather\": \"sunny\"}, \"classroom\": {\"lighting\": \"bright\", \"windows\": {\"state\": \"half_open\", \"blinds\": \"partially_closed\"}, \"number_of_students\": 24, \"seating_arrangement\": \"rows\", \"decorations\": [\"vibrant_posters\", \"educational_charts\"], \"teacher_desk\": {\"items\": [\"laptop\", \"stack_of_textbooks\", \"cup_of_coffe\", \"art_supplies\"], \"computer_state\": \"on\", \"screen_display\": \"school_welcome_page\"}, \"whiteboard\": {\"sections\": [\"day_schedule\", \"important_announcements\", \"student_achievements\"]}, \"atmosphere\": {\"sound_level\": \"quiet\", \"student_mood\": \"anticipation\"}}, \"surroundings\": {\"playground\": {\"activity\": \"students_playing\", \"time\": \"morning_recess\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129780.30 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 129587.18 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 41972.97 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 94590.39 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133101.56 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93820.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Real Estate Agent', 'process': 'Property Inspections', 'situation': \"In the bustling heart of the city, nestled amidst towering skyscrapers, stands a quaint building, the focus of today's endeavor for a seasoned real estate agent. Armed with a well-worn clipboard, a sophisticated camera, and a sleek laptop, the agent embarks on the process of property inspections. The clipboard, cluttered with inspection forms and hand-scribbled notes from previous inspections, is a testament to the meticulousness of the agent. The camera, a state-of-the-art device, is primed to capture every nook and cranny of the property, ensuring no detail goes unnoticed. The laptop, gleaming and efficient, awaits the influx of information and visuals that will inevitably paint a vivid picture of the property. As the agent steps into the property, they are greeted by the sight of a compact but well-maintained kitchen. The appliances, gleaming in the soft light, are in perfect working order. The cabinets, a deep mahogany, stand tall and proud, showing no signs of wear. The countertops, a pristine white, stretch out invitingly, offering a glimpse into the heart of the home. The agent, with a keen eye and a steady hand, begins the inspection, their clipboard at the ready. The camera whirs softly as it captures the intricate details of the kitchen, while the laptop hums quietly in anticipation of the data that is about to be entered. As the inspection continues, the agent is acutely aware of the importance of their task. They are not just inspecting a property, but laying the groundwork for a potential home. Surrounded by the hum of the city and the quiet stillness of the property, the agent continues their meticulous work, armed with tools of their trade and a relentless pursuit of accuracy and thoroughness.\", 'situation_json': '{\"Location\": \"city\", \"Building\": \"quaint building\", \"Property_Condition\": \"well-maintained\", \"Kitchen_Condition\": \"compact but well-maintained\", \"Kitchen_Appliances\": \"perfect working order\", \"Cabinets_Condition\": \"no signs of wear\", \"Countertops_Color\": \"white\", \"Countertops_Condition\": \"pristine\", \"Intent\": \"property inspection\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n",
      "{'profession': 'Dental Assistant', 'process': 'Dental Equipment Sterilization', 'situation': \"The sterilization room of the dental clinic is a stark contrast to the bustling clinical spaces nearby. It's filled with a smooth hum, the ultrasonic cleaner gently vibrating as it agitates the dental instruments in a bath of sparkling, clear disinfectant solution. The instruments, notably six dental mirrors with reflective surfaces glinting under the fluorescent lights, lie submerged in the cleaner, their original purpose temporarily suspended while the machine works its cleaning magic. Next to this, the autoclave stands tall and commanding, its stainless-steel exterior reflecting the clinical efficiency of the room. With the temperature gauge reading a consistent 275°F (135°C), it's a formidable ally in the quest for sterility.\", 'situation_json': '{}'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  29%|██▊       | 207/723 [24:38<12:40,  1.47s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 103314.32 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 97565.63 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 117867.61 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 125966.85 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86173.35 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78306.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Personal Care Aide', 'process': 'Mobility Assistance', 'situation': 'In the heart of a bustling clinic, a dedicated Personal Care Aide diligently attends to her daily tasks. The treatment room, her primary workplace, is a symphony of activity and compassion. The room, bathed in warm, natural light filtering through large windows, is filled with a variety of mobility equipment. Two sturdy wheelchairs, a well-maintained walker, and a couple of transfer belts are neatly arranged, ready for use. The wheelchairs, with their gleaming silver frames and plush navy blue seats, provide comfort and safety for those in need. The walker, with its four sturdy legs and ergonomic handles, offers stability and independence. The transfer belts, with their secure fasteners and wide straps, ensure safe and dignified transfers. Nearby, a group of family members and healthcare professionals are gathered, their expressions a mix of anticipation and concern. They are here to support their loved ones and ensure they receive the best possible care. The Personal Care Aide, with her calm demeanor and gentle approach, navigates this complex environment with grace. She is a beacon of support and comfort for her clients, ensuring their mobility needs are met with respect and dignity.', 'situation_json': '{\"lighting\": \"natural\", \"number_of_wheelchairs\": 2, \"wheelchair_color\": \"silver and navy blue\", \"wheelchair_condition\": \"well-maintained\", \"number_of_walkers\": 1, \"walker_color\": \"unspecified\", \"walker_condition\": \"well-maintained\", \"number_of_transfer_belts\": 2, \"transfer_belt_color\": \"unspecified\", \"transfer_belt_condition\": \"well-maintained\", \"number_of_people_present\": \"group\", \"people_relationships\": [\"family members\", \"healthcare professionals\"], \"people_emotions\": [\"anticipation\", \"concern\"], \"aide_demeanor\": \"calm\", \"aide_approach\": \"gentle\", \"environment_complexity\": \"complex\", \"aide_emotional_support\": \"high\", \"aide_respect\": \"high\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  29%|██▉       | 209/723 [24:39<08:58,  1.05s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Medical Secretary', 'process': 'Reporting', 'situation': \"In a bustling hospital clinic, the Medical Secretary, donning a crisp white shirt and neatly organized tie, is situated in their tidy office cubicle. The office is adorned with calming shades of blue and grey, with a neat row of diplomas and certifications framed on the wall. A large computer monitor dominates the desk, surrounded by neatly stacked folders and a sleek black telephone. The Medical Secretary is currently in the process of Reporting, where they use their expertise to maintain accurate and complete medical records for all patients. Their computer screen flickers with data as they meticulously type correspondence, reports, and other documentation. The Medical Secretary is multitasking, answering phone calls from both physicians and patients, handling each with a professional and empathetic tone. The nearby filing room holds a wealth of information, its rows of manila folders neatly organized by patient name and date. Several colleagues are also busy at their desks, the hum of their activity a constant backdrop to the Medical Secretary's tasks. The Medical Secretary's work is frequently interrupted by the need to retrieve files from the filing room, but they return to their desk with an unwavering focus. The Medical Secretary is also responsible for composing and editing clinical correspondence and preparing professional reports, presentations, brochures, and other materials, their creativity and eye for detail evident in their work. The Medical Secretary's mental focus is tested daily as they handle the challenges of maintaining a high degree of accuracy and efficiency in their work.\", 'situation_json': '{\"office_description\": {\"colour_scheme\": {\"primary\": \"blue\", \"secondary\": \"grey\"}, \"wall_decoration\": \"calm shades of blue and grey\", \"wall_content\": [\"row of diplomas\", \"certifications\"], \"furniture\": [\"desk\", \"large computer monitor\", \"folders\", \"black telephone\"], \"furniture_condition\": [\"neatly stacked\", \"meticulously typed\", \"sleek\"], \"equipment\": [\"computer\"], \"equipment_state\": [\"flickering data\"], \"other_office_equipment\": [\"filing room\", \"manila folders\", \"colleagues\"], \"other_office_equipment_state\": [\"neatly organized\", \"hum of activity\", \"professional task handling\"]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 93472.90 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 129553.44 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 76814.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Cement Mason & Concrete Finisher', 'process': 'Repairing Concrete', 'situation': 'In the bustling heart of the construction site, the Cement Mason and his team are hard at work repairing a damaged concrete surface. The sun beats down mercilessly on the outdoor site, casting long shadows over the tools and equipment scattered around. The concrete mixer roars to life, its grumbling reverberating across the site as it churns out a fresh batch of concrete, while the wheelbarrows stand by, patiently waiting to transport the mixture. The team dons their protective gear - hard hats, safety glasses, and gloves - with the dexterity of seasoned professionals. The cement mason picks up his trowel, the tool looking well-used yet maintained, its surface still gleaming from the rigorous cleaning it received post the last repair job. Other team members armed with wire brushes and water hoses stand nearby, ready to clean tools and equipment throughout the process. Nearby, the foreman keeps a sharp eye on the progress, ensuring everything proceeds according to plan. The buzz of activity and the camaraderie among the workers under the hot sun make the process of repairing concrete a dynamic and engaging spectacle.', 'situation_json': '{\"weather\": {\"temperature\": \"hot\", \"location\": \"outdoor\", \"sunlight\": \"bright\"}, \"equipment\": {\"concrete_mixer\": {\"state\": \"running\", \"sound_level\": \"high\", \"output\": \"fresh_batch_of_concrete\"}, \"trowel\": {\"state\": \"ready_to_use\", \"condition\": \"well-used_but_maintained\", \"recent_cleaning\": \"rigorous\"}, \"wheelbarrows\": {\"state\": \"ready\", \"function\": \"transport_concrete_mixture\"}, \"wire_brushes\": {\"state\": \"ready_to_use\", \"function\": \"clean_tools_and_equipment\"}, \"water_hoses\": {\"state\": \"ready_to_use\", \"function\": \"clean_tools_and_equipment\"}}, \"team\": {\"protective_gear\": {\"list\": [\"hard_hats\", \"safety_glasses\", \"gloves\"]}, \"action\": \"donning\", \"proficiency\": \"seasoned_professionals\"}, \"leadership\": {\"foreman\": {\"action\": \"monitoring_progress\", \"degree_of_strictness\": \"ensuring_plan_followed\"}}, \"atmosphere\": {\"activity_level\": \"bustling\", \"team_camaraderie\": \"engaging\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  29%|██▉       | 211/723 [24:41<09:24,  1.10s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Marketing Manager', 'process': 'SEO Optimization', 'situation': \"In the heart of a bustling corporate headquarters, the Marketing Manager sits in their cubicle, the walls adorned with an eclectic mix of marketing campaign posters, brainstorming notes, and framed certifications. The room hums with the quiet buzz of a high-performance machine, with three sleek, black computers arranged neatly on the expansive desk, their screens glowing with arrays of data and analytics tools like Google Analytics and SEMrush. To the left, a tall bookshelf stands laden with an impressive collection of marketing tomes and industry reports, while on the right, a vibrant green plant adds a touch of natural energy to the otherwise tech-centric environment. The marketing manager's comfortable, adjustable chair creaks slightly as they lean back, eyes scanning the newest keyword research findings displayed on a large, wall-mounted monitor. Surrounding them, the marketing department is a hive of activity. The content creators are scattered across the open-plan space, hunched over laptops, furiously typing away to craft the next viral blog post. Sitting five desks away, the web developers are huddled together, deep in conversation about the latest site update optimizing load speeds. In the background, the soft murmur of voices in the meeting rooms can be heard as the team strategizes, occasionally punctuated by the excited whoops when a campaign metric exceeds its target. In the nearby boardroom, senior management awaits the next performance report, eyes fixed on the large screen displaying the latest data visualizations. The air is filled with the ubiquitous scent of freshly brewed coffee, the constant hum of the espresso machine in the nearby pantry providing a comforting backdrop to the day's intense activities. Beyond the department, the sales team is likely engaged in their own meeting, planning their next moves based on the insights provided by the marketing team. Outside, the city's skyline glints through the floor-to-ceiling windows, a constant reminder of the competitive market they operate in. The journey of SEO optimization is a continuous, daily dance with the ever-evolving algorithms of search engines, where staying agile and informed is paramount. For the Marketing Manager, it’s another day in the race to maintain and improve the website's ranking, yet another task seamlessly blended into the frenetic, dynamic world of a corporate marketing hub.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139324.87 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143866.88 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92328.80 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Administrative Assistant', 'process': 'Meeting Coordination', 'situation': \"The Administrative Assistant is meticulously preparing for the upcoming meeting in the vast, rectangular conference room of the corporate office, bathed in the soft, warm glow of the overhead fluorescent lights. The conference room is aptly designed for productivity, equipped with a long, oblong table made of polished dark mahogany, surrounded by twelve ergonomic leather chairs, each upholstered in a vibrant, earthy green, arranged evenly in a circular configuration. At the head of the table stands a sleek, black projector, its glass lens reflecting the ambient light, ready to display any important documents or presentations during the meeting. Protected from prying eyes by a screen of sleek, frosted glass, the conference room offers a sanctuary of quietude, where theonly sound is the faint hum of the air conditioner, diligently maintaining a comfortable temperature. Outside, the bustling office environment hints at the busyness beyond, but inside the conference room, it's a peaceful oasis of focus and preparation. In one corner, a tumbling waterfall of colorful post-it notes cascades down from a whiteboard, each one a reminder of an important task or agenda item that needs to be addressed. The Administrative Assistant diligently ensures that every detail is in order, double-checking the agenda on their state-of-the-art laptop, its screen displaying a snappy and organized list of topics. Their fingers dance across the keyboard, adjusting timings and ensuring that all virtual attendees have the necessary login credentials. As they work, they subtly acknowledge the beeps from their smartwatch, reminding them of the next task on their tightly packed schedule. Across the hallway, in the well-organized reception area, a small group of colleagues and clients patiently wait, their eyes occasionally flicking to the large digital clock hanging above the reception desk. A laptop on the desk softly pings, signaling the arrival of an email—likely another agenda item or a confirmation from a remote attendee. The Administrative Assistant’s supervisor, engrossed in their work in an adjacent office, periodically glances up from their laptop, assured that every aspect of the meeting is being meticulously handled. In the quiet workspace nearby, another administrative assistant is busily printing the meeting materials, the steady whirr of the printer practically the only sound in the otherwise silent room. The hum of the office printer itself is a reassuring testament to the preparation underway. In the office kitchen, the aroma of freshly brewed coffee wafts through the air, a subtle promise of the refreshments that will later be served during the meeting break. Behind the scenes, the Administrative Assistant is also coordinating with the project management software to ensure that all team members have access to the needed documents and resources. Their smartphone, never far from their side, is a tool that keeps them connected to the pulse of the office, allowing them to respond swiftly to any last-minute changes or requests. As the hands of the clock edge closer to the meeting time, the Administrative Assistant takes a deep breath, offering a final look around the conference room to ensure that everything is flawlessly arranged for a productive and engaging session.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  29%|██▉       | 213/723 [24:44<12:12,  1.44s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Restaurant Cook', 'process': 'Recipe Development', 'situation': \"In the heart of the bustling kitchen, a culinary symphony unfolds as the Restaurant Cook, a maestro in their own right, orchestrates the intricate dance of Recipe Development. The air is filled with the symphonic hum of a dozen knives, each a different size and shape, tapping out a rhythm against their respective cutting boards. The cook, a vision in their pristine whites, moves with grace and precision, their hands dancing with the familiarity of long practice. They wield a chef's knife, its blade glinting menacingly under the bright kitchen lights, as they reduce a mountain of vibrant vegetables to uniform dice with swift, sure strokes. nearby, a line cook, their face flushed with concentration, tends to the stove, a symphony of sizzles and pops emanating from the half dozen pans dancing across the flames. The oven, a monstrous steel beast, groans and clicks as it works to maintain a steady temperature, its door propped open by a well-worn spatula, releasing clouds of fragrant steam into the air. The cook's eyes, sharp and focused, flit from pan to oven to knife, their mind a whirl of temperatures, timings, and tastes. They pause, a pinch of salt mid-air, to taste a spoonful of sauce, their brows furrowing in concentration. A nod of satisfaction, and the sauce is poured, a river of gold flowing across the plate, adorned with a sprinkle of fresh herbs from the pot by the window, bursting with life and greenery. The cook steps back, surveying their handiwork with a critical eye, before reaching for their notebook, the pages filled with scrawled notes and sketches, a testament to their creative journey. The kitchen, a sprawling labyrinth of steel and fire, is their canvas, and the recipe, their masterpiece. Yet, it's not just the cook in this kitchen. A team of cooks, each with their own role, dance around them, a well-oiled machine working in harmony. The sous chef, a tower of calm amidst the chaos, oversees the line, their eyes missing nothing, their voice a steady stream of instructions and encouragement. The dishwasher, a unsung hero, works tirelessly in the background, ensuring a steady supply of clean tools, their hands red and raw from the hot water and soap. Even the pantry, a vast, organized cave filled with the scent of spices and the cool hum of refrigeration, plays its part, a silent sentinel standing ready with its stores of ingredients. The kitchen, a living, breathing entity, pulses with life and energy, a testament to the cook's artistry and the team's harmony. The cook, at the heart of it all, takes a deep breath, steeling themselves for the next challenge, the next recipe, the next masterpiece. For in this kitchen, the symphony never ends.\", 'situation_json': '{\"kitchen_atmosphere\": \"busy\", \"cook_apparel\": \"pristine whites\", \"cook_movement\": \"graceful and precise\", \"cook_tool\": \"chef\\'s knife\", \"cook_task\": \"reducing vegetables to uniform dice\", \"line_cook_task\": \"tending to the stove\", \"stove_state\": \"dancing with flames\", \"oven_state\": \"groaning and clicking\", \"oven_door_state\": \"propped open\", \"cook_expression\": \"concentrated\", \"cook_activity\": \"tasting sauce\", \"sauce_state\": \"satisfying\", \"plate_adornment\": \"fresh herbs\", \"cook_document\": \"notebook with scrawled notes and sketches\", \"team_roles\": [\"cooks\", \"sous chef\", \"dishwasher\", \"pantry\"], \"kitchen_description\": \"sprawling labyrinth of steel and fire\", \"kitchen_role\": \"canvas\", \"recipe_role\": \"masterpiece\", \"kitchen_pulse\": \"living, breathing entity\", \"cook_preparation\": \"steeling themselves for the next challenge\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  30%|██▉       | 214/723 [24:45<10:46,  1.27s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Compliance Officer', 'process': 'Training and Education', 'situation': \"In the bustling environment of the business office, the Compliance Officer diligently oversees the process of Training and Education. The officer is surrounded by a plethora of equipment, including a sleek, high-performance computer humming on the polished mahogany desk, a state-of-the-art projector resting on a sturdy stand, and a neatly organized stack of course materials waiting to be distributed. The office is a hub of activity, with employees and management constantly in motion, their expressions a mix of concentration and determination. A group of employees, who are involved in the incident, or may be affected by it, huddle in a corner, engrossed in an intense discussion. Department heads work closely with the Compliance Officer, their faces etched with concern as they strive to resolve incidents and prevent similar ones from happening in the future. In the training room, desks and chairs are arranged in a classroom-style, awaiting the next in-person training session. The room is filled with a sense of anticipation and eagerness to learn. Outside the window, the city's skyline stretches out, a testament to the organization's commitment to regulatory compliance and ethical conduct.\", 'situation_json': '{\"description\": \"In the bustling environment of the business office, the Compliance Officer diligently oversees the process of Training and Education. The officer is surrounded by a plethora of equipment, including a sleek, high-performance computer humming on the polished mahogany desk, a state-of-the-art projector resting on a sturdy stand, and a neatly organized stack of course materials waiting to be distributed. The office is a hub of activity, with employees and management constantly in motion, their expressions a mix of concentration and determination. A group of employees, who are involved in the incident, or may be affected by it, huddle in a corner, engrossed in an intense discussion. Department heads work closely with the Compliance Officer, their faces etched with concern as they strive to resolve incidents and prevent similar ones from happening in the future. In the training room, desks and chairs are arranged in a classroom-style, awaiting the next in-person training session. The room is filled with a sense of anticipation and eagerness to learn. Outside the window, the citys skyline stretches out, a testament to the organizations commitment to regulatory compliance and ethical conduct.\", \"environment\": \"business office\", \"equipment\": [\"high-performance computer\", \"state-of-the-art projector\", \"stack of course materials\"], \"activities\": [\"employees and management in motion\", \"group of employees discussing\", \"department heads working with Compliance Officer\", \"in-person training session awaiting\"], \"atmosphere\": [\"hub of activity\", \"concentration and determination\", \"anticipation and eagerness to learn\"], \"location\": \"office and training room\", \"time_of_day\": \"not mentioned\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130228.70 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 110277.90 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84128.68 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Brickmason & Blockmason', 'process': 'Brick Cutting', 'situation': \"The mid-morning sun bathes the sprawling construction site in a warm, golden glow, as the clock ticks past 10 a.m. At the center of this bustling tableau stands the meticulous figure of a brickmason, clad in protective gear from head to toe. The brickmason, a seasoned professional with calloused hands and a determination etched into every line of their face, is surrounded by an array of specialized tools and equipment. A powerful brick saw, its cutting blade glinting menacingly under the sun, sits on a sturdy workbench, awaiting its next command. Beside it, a well-worn trowel and a level rest neatly, their importance underscored by the meticulous care with which they are arranged. The hammer, chisel, and a selection of masonry blades line up in ordered precision, each tool bearing witness to their role in countless projects. Safety is paramount here; a pair of safety glasses, a dust mask, and ear protection lie at the ready, ensuring the mason's well-being amidst the activities. To their left, a mixing tub brims with the fresh mortar mix, a vital component in today's tasks, while a nearby brick pile stands tall, each unit awaiting its transformation under the mason's expert touch. Scaffoldings, sturdy and towering, loom in the background, providing the necessary elevation for the brickmason as they climb higher, their movements precise and graceful. A helper, diligent and quick, hovers nearby, ready to assist with materials and cleaning. The symphony of construction echoes around them—the whirr of the brick saw, the steady thud of trowels against bricks, the friendly banter of laborers and supervisors who oversee the work, each voice blending into the operational melody. The nearby storage area is a beehive of activity, with laborers carting bricks and blocks in sturdy wheelbarrows, while concrete mixers churn steadily, the aroma of fresh cement filling the air. The architect and engineer confer nearby, blueprints spread out, their conversations a blend of technical jargon and enthusiastic vision. This is more than just a construction site; it is a symphony of precision, a ballet of skill, a testament to the human capacity to build and create.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  30%|██▉       | 216/723 [24:49<12:47,  1.51s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Janitor', 'process': 'Carpet Cleaning', 'situation': \"In the heart of a bustling office building, a dedicated janitor is preparing for their weekly carpet cleaning routine. The large office space, filled with rows of desks and office chairs, is a beehive of activity. Nearby, a group of office workers are engrossed in a lively discussion. The janitor has already blocked off the main hallways and stairways leading to this area to prevent any accidents during the cleaning process. In a nearby storage closet, various cleaning equipment and supplies are neatly arranged. The janitor pulls out a commercial-grade vacuum cleaner, its powerful motor humming as it's switched on. This is a crucial step in the carpet cleaning process, as it helps to remove loose dirt and dust particles. After vacuuming, the janitor carefully applies a cleaning agent, a potent blend of detergents and solvents, onto the carpet. They use a large rotary machine to agitate the cleaning solution into the carpet fibers, breaking down any stubborn stains and embedded soil. Next, they rinse the carpet with hot water using a high-pressure hot water extractor, removing the cleaning solution and any remaining dirt. Finally, they turn on the air movers, powerful fans that help to dry the carpet quickly, preventing any mold or mildew growth. During this process, the janitor works diligently to ensure the office space remains clean and hygienic, despite the frequent foot traffic and inevitable spills.\", 'situation_json': '{\"office_space\": {\"activity_level\": \"high\", \"furniture\": [\"desks\", \"office chairs\"]}, \"office_workers\": {\"engrossed_in\": \"discussion\"}, \"janitor_actions\": {\"blocked_off\": [\"main hallways\", \"stairways\"], \"cleaning_process\": {\"vacuuming\": {\"equipment\": \"commercial-grade vacuum cleaner\", \"motor_state\": \"humming\", \"switch_state\": \"on\"}, \"cleaning_agent_application\": {\"agent_type\": \"potent blend of detergents and solvents\"}, \"rotary_machine_usage\": {\"purpose\": \"agitate cleaning solution into carpet fibers\", \"effect\": \"break down stubborn stains and embedded soil\"}, \"hot_water_extraction\": {\"purpose\": \"rinse carpet with hot water\", \"equipment\": \"high-pressure hot water extractor\"}, \"air_movers_usage\": {\"purpose\": \"dry the carpet quickly\", \"equipment\": \"powerful fans\"}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': {'message': 'You are either out of credits, or requesting a resource that requires owning at least a few. Please visit https://openrouter.ai/credits to add more.', 'code': 402}, 'user_id': 'user_2U7ChXa8UHwNIfm1TPiVx8jWFnz'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 88688.39 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 122228.93 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96450.00 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138640.41 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146091.39 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 72888.41 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146472.90 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139363.10 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79263.02 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120526.59 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 88607.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 97591.22 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136347.03 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137206.92 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90749.26 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 153994.91 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136867.27 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 76688.10 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131998.86 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143348.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 97778.16 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136446.86 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133667.66 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88219.07 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131399.86 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142101.41 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90880.34 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 140769.48 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 125281.47 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91417.77 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139493.25 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139657.54 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91137.52 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121456.06 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133588.91 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95328.45 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 148377.98 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139383.70 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88464.28 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125350.13 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131075.84 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87786.81 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145675.24 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134602.72 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 97355.91 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145966.56 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132963.25 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96388.15 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122851.67 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141149.69 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89752.71 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 149198.26 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137403.72 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94754.16 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 148084.20 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140968.64 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94664.64 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133095.40 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 148448.48 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86734.19 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127866.49 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142429.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86631.42 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145478.93 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 129432.69 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94697.78 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128333.34 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141744.98 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89093.56 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131309.34 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146337.23 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96757.01 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127204.33 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132463.78 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96357.25 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133712.67 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 115979.67 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93912.11 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125483.11 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 102724.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95017.07 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132771.18 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146909.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95382.23 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142979.06 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143703.00 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91936.59 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 144919.58 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146186.77 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91485.78 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136375.45 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134564.30 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90843.72 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131113.73 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131426.84 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95358.69 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127523.83 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128798.02 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89500.32 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 141481.78 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138805.89 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78962.26 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130215.48 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143791.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92648.15 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131004.05 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133144.10 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84346.39 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143175.44 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146385.07 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86357.65 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136938.66 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137442.72 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 97373.43 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132178.79 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143671.88 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 97271.90 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 141588.67 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145586.79 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92686.24 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137381.95 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143664.97 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90779.71 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143608.14 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139945.57 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95777.32 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136338.67 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139586.80 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89740.80 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 141584.46 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139714.18 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88147.21 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129850.52 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 148782.61 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89040.78 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132332.43 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144282.87 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 76056.40 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133753.42 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123200.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92515.08 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 149164.90 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138653.34 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96439.69 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121694.45 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124846.66 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92420.27 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146313.57 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143305.25 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85927.01 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 123210.15 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128065.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87181.40 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143840.98 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147486.62 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 80350.65 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 109992.45 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145049.25 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 69854.53 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145287.57 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145733.66 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94176.92 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114635.02 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130376.58 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90965.91 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132729.98 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130950.32 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87201.07 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122340.28 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144615.99 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81954.74 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 149527.98 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130688.56 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87257.32 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130057.59 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124010.05 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90331.10 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142558.66 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144895.56 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91983.48 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 113351.86 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140985.29 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85910.64 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 123034.28 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132016.69 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90560.91 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131217.91 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131832.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93267.81 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 115422.78 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145521.75 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93970.82 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 126213.33 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 85662.30 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 74584.42 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 141479.98 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123816.34 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85998.03 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138220.47 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141806.69 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87355.94 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 158991.92 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133673.64 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89937.70 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 151134.28 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145622.30 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92262.67 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130848.35 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142373.59 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95841.79 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119517.38 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123709.46 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93567.81 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146624.85 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 121878.00 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91448.67 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127999.95 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 108584.72 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86484.64 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129780.30 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137283.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89779.51 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 140301.74 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137598.97 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92256.38 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146905.10 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128892.54 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96677.49 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 148273.78 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136659.49 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 80961.43 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138658.86 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142031.56 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90111.45 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130238.36 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136733.55 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89175.79 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137845.21 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 121381.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91504.35 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124368.23 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 119881.37 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90871.19 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122094.89 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 121608.28 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92130.71 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114928.47 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 117045.88 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 67219.75 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 147990.91 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 135309.33 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86700.83 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 141469.18 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136101.93 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84801.14 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143689.80 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147602.07 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88699.22 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 144361.40 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138389.84 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94055.77 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134271.35 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132149.13 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90078.45 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112525.55 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 120997.98 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91631.42 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131101.88 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123208.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93889.29 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138554.04 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139358.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86901.35 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134218.40 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143684.56 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93357.93 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 144617.38 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 118413.77 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89749.73 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 150365.80 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142139.75 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92822.99 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 153329.53 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131946.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86996.37 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135639.03 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140367.75 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73877.66 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 147363.28 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134420.92 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87471.74 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 147374.35 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 104984.81 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93886.03 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110482.07 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 125399.87 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91886.63 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 126141.74 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144357.28 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93267.81 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 158415.05 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142874.36 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93856.72 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136131.13 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 117344.13 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 47379.57 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 141376.84 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143352.26 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85592.62 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 150980.36 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 82052.53 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 46891.76 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143093.14 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144965.91 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89892.88 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 140737.41 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132080.93 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85473.64 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 123903.96 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123885.70 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88935.40 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 144746.65 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134839.80 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85701.08 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131350.71 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144637.01 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95351.97 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134243.79 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138932.92 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89331.86 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 153218.26 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 91529.00 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 47215.02 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 153709.65 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 100075.26 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89687.25 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138663.47 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136507.45 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88789.46 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143565.50 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130257.13 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94036.15 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121005.34 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133899.45 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 66010.93 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136040.63 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 114692.83 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88308.34 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122512.37 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142568.48 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 80949.31 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145840.84 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 86872.83 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 51658.92 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 115974.56 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147521.84 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82461.86 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146441.40 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 115294.43 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94631.53 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142370.64 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143743.36 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 47426.08 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124151.14 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 116922.12 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 76635.96 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 126170.37 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141630.67 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87641.77 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138364.38 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134763.72 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89734.84 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142091.07 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 116489.50 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86006.23 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137218.63 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144244.53 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83839.29 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112105.41 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132209.60 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91039.38 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 156059.00 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 109587.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89178.73 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 152290.71 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 135694.71 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92376.09 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136282.96 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145845.19 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88377.58 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124748.69 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 117523.50 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92683.07 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134984.22 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 108955.22 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90291.91 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138651.36 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133031.38 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94621.60 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 91192.24 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 127498.15 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81002.64 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142287.45 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128088.89 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91448.67 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 145042.46 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147536.42 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91637.63 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137383.65 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150928.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85641.40 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128009.78 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145239.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90382.40 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134701.86 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131162.21 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86575.98 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137229.35 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 111300.85 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86159.63 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137341.23 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 84411.80 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91653.15 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133621.61 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 114796.46 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86222.78 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134157.41 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134067.81 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88322.76 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135280.38 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 109153.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92673.54 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112000.01 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138938.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95003.73 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139730.48 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131646.08 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89854.06 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136483.15 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 114933.45 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84238.71 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 106171.22 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 111622.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95409.14 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127512.13 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137587.35 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83870.48 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134795.49 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142817.40 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89061.30 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110272.43 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138001.77 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81204.44 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 123104.66 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140538.44 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85782.61 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131260.77 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142167.95 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91793.09 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 144367.02 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 110529.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82051.68 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129202.72 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124718.02 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86948.84 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 111854.67 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131204.48 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96979.00 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134707.85 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128245.70 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92641.81 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133288.45 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 135283.78 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84716.17 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110631.21 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144184.16 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84011.12 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 118317.67 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133845.43 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92376.09 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 123681.15 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 106481.88 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 67472.90 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128759.35 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 109446.49 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93319.29 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139231.24 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144541.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86376.95 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 156077.26 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 109317.58 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92740.26 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119310.05 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 149560.20 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91587.99 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142057.79 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144787.81 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89370.22 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 155763.14 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141720.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92319.34 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127754.84 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133512.25 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92988.90 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 150821.31 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133256.01 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84536.16 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 153874.15 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124395.84 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91168.23 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 98277.35 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 116135.32 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73578.28 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136989.28 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 108768.00 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88914.94 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 117048.91 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 81386.37 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91678.00 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139869.93 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 135367.61 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85379.22 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128104.16 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139943.38 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89231.68 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 153491.81 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140331.46 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90325.07 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 153262.61 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134490.55 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88973.43 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132509.06 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 87109.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92426.58 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 152309.48 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124207.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85443.94 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 98349.21 examples/s]mples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 117101.74 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79956.44 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 117461.90 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137311.04 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81544.67 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 126778.40 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 122426.07 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84607.54 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135864.43 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 125684.04 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89746.75 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146892.16 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 114428.35 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 75879.34 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 156201.50 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 127980.00 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82014.37 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124137.28 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140776.99 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89193.44 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125551.59 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137628.57 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79563.73 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 116895.91 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124705.86 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89538.83 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114949.86 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 98491.19 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93238.88 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 111689.88 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 99135.44 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83110.38 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 113469.47 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 108047.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86382.47 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110168.63 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134003.62 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91365.28 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 126196.14 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 89108.23 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90285.88 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128508.36 examples/s]ples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132615.78 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95868.96 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 102994.68 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137769.34 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87142.09 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112708.43 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 125909.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 74547.43 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127415.69 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 107441.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77472.11 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135027.93 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 126172.69 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73398.61 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135678.75 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145559.58 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73756.81 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 152484.24 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136265.51 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 75413.99 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129504.19 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 102683.01 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85003.65 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130061.14 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 98638.15 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 84374.74 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 66632.01 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 116511.48 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77819.76 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124184.41 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142942.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89538.83 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129743.95 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 101686.30 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93181.07 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 144019.22 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 90159.91 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 53211.50 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139442.52 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128499.60 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88652.71 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 148071.71 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138205.13 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89476.64 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 102252.43 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 85544.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79949.35 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142198.28 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137160.69 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94337.83 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 161087.23 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 107271.27 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87786.81 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112639.92 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 97862.74 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86556.59 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146579.75 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139450.98 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93014.48 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 109445.35 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 88862.02 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92600.58 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 126337.14 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131538.78 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91622.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dental Hygienist', 'process': 'Teeth Cleaning', 'situation': \"A dental hygienist, clad in a crisp, blue scrub uniform, is performing a routine teeth cleaning in a meticulously organized treatment room within the bustling dental clinic. On the gleaming, stainless steel tray situated beside them, an array of six precision dental mirrors reflect the light, alongside an assortment of scalers, polishers, and fluoride treatment supplies. The patient, comfortably reclined in the specialized dental chair, gazes up at the ceiling, while the sound of low, calming music fills the air. The dental hygienist's deft hands are swiftly gliding over the patient's teeth, meticulously removing plaque and tartar with their expertly-wielded tools. In the waiting room adjacent, a total of seven patients are patiently seated, three of them engrossed in magazines, while the others are engaged in quiet conversation. Adjacent to this space, the sterilization room hums with activity as dental instruments undergo rigorous cleaning and sterilization prior to their next use. The waiting room is adorned with lush plants that add a touch of nature to the otherwise clinical setting. The dentist, nearby, observes the procedure through the open door, ready to provide expertise and support as needed.\", 'situation_json': '{\"profession\": \"Dental Hygienist\", \"process\": \"Teeth Cleaning\", \"description\": \"A dental hygienist, clad in a crisp, blue scrub uniform, is performing a routine teeth cleaning in a meticulously organized treatment room within the bustling dental clinic. On the gleaming, stainless steel tray situated beside them, an array of six precision dental mirrors reflect the light, alongside an assortment of scalers, polishers, and fluoride treatment supplies. The patient, comfortably reclined in the specialized dental chair, gazes up at the ceiling, while the sound of low, calming music fills the air. The dental hygienist\\'s deft hands are swiftly gliding over the patient\\'s teeth, meticulously removing plaque and tartar with their expertly-wielded tools. In the waiting room adjacent, a total of seven patients are patiently seated, three of them engrossed in magazines, while the others are engaged in quiet conversation. Adjacent to this space, the sterilization room hums with activity as dental instruments undergo rigorous cleaning and sterilization prior to their next use. The waiting room is adorned with lush plants that add a touch of nature to the otherwise clinical setting. The dentist, nearby, observes the procedure through the open door, ready to provide expertise and support as needed.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 230, in generate_covas_commentary\n",
      "    raise Exception(\"Too many runs\")\n",
      "Exception: Too many runs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 99772.68 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 113673.92 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93603.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Veterinarian', 'process': 'Vaccination', 'situation': \"In the heart of the bustling Veterinary Clinic, a tranquil treatment room awaits the arrival of a canine patient for its annual vaccination. The room, bathed in the warm glow of soft, indirect lighting, is fully equipped with all the necessary tools for the procedure. The sterilized stainless-steel tray gleams with an array of instruments: two gleaming dental mirrors, a pair of sharp surgical scissors, and three syringes of varying sizes, all neatly arranged for easy access. The walls are adorned with several informative posters detailing the importance of vaccinations for pets. Nearby, the reception area is filled with pet owners of various ages and occupations, silently engrossed in their phones or engrossed in conversations about their beloved pets. In the opposite corner, the clinic's head veterinarian is engrossed in paperwork, while a vet tech is skillfully handling an ornery feline patient in the adjacent examination room. As the waiting pet-owner glances at their watch, the pace quickens, anticipation builds, and the stage is set for the timely 10-minute task.\", 'situation_json': '{\"lighting\": \"soft indirect\", \"equipment_present\": [\"sterilized stainless-steel tray\", \"dental mirrors\", \"surgical scissors\", \"syringes\"], \"number_of_dental_mirrors\": 2, \"number_of_surgical_scissors\": 1, \"number_of_syringes\": 3, \"syringe_sizes\": [\"small\", \"medium\", \"large\"], \"wall_decorations\": [\"informative posters\"], \"number_of_posters\": \"several\", \"topic_of_posters\": \"importance of vaccinations for pets\", \"waiting_room\": \"reception area\", \"occupants_of_waiting_room\": [\"pet owners of various ages and occupations\"], \"waiting_room_activities\": [\"engrossed in phones\", \"engrossed in conversations\"], \"head_veterinarian_status\": \"engrossed in paperwork\", \"adjacent_examination_room_activity\": \"vet tech handling an ornery feline patient\", \"waiting_time_of_pet_owner\": \"glances at their watch\", \"pace_of_waiting\": \"quickens\", \"anticipation_level\": \"builds\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 230, in generate_covas_commentary\n",
      "    raise Exception(\"Too many runs\")\n",
      "Exception: Too many runs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122172.25 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136498.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85204.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Massage Therapist', 'process': 'Client Follow-up', 'situation': \"In the serene, dimly-lit **treatment room**, the **massage table** stands as the focal point, its warm, polished surface a testament to the countless clients who have found solace and relief upon it. The room is a sanctuary of tranquility, the soft hum of the **heating pad** beneath the table's surface the only sound breaking the silence, save for the occasional distant murmur of the clinic's **reception area**. The air is thick with the scent of **eucalyptus and lavender**, the essential oils diffusing gently into the atmosphere, their calming effects amplified by the soft, **indigo glow** of the salt lamp in the corner. The **towels** and **sheets** are meticulously folded, their crisp edges a stark contrast to the plush, inviting **cushions** scattered around the room. The **computer** on the nearby desk hums softly, its screen displaying the client's file, ready for the therapist to update with today's progress. The **phone** lies nearby, its silent ringer a promise of connection to the world outside, should the need arise. The **therapist's** hands, already gloved in anticipation, rest lightly on the table, their warmth a silent invitation for the client to lie down and let go of their worries. The **client**, wrapped in a **plus Robe**, their **socks** tucked neatly into the pockets, takes a deep breath, ready to surrender to the therapist's skilled touch. The **clock** on the wall ticks softly, each second a gentle reminder of the time passing, the tension ebbing away with every tick. The **therapist's office**, just a few steps away, is a beacon of organization, the **appointment book** open to today's date, the **computer** screen displaying the day's schedule. The **classroom**, a short walk down the hall, is a hub of learning, the **whiteboard** filled with notes from the latest lecture, the **laptop** on the instructor's desk a portal to a wealth of knowledge. The **massage clinic** itself is a haven of healing, the **reception area** a welcoming space, the **waiting room** a comfortable retreat for clients to relax before and after their sessions. The **office**, tucked away in the corner, is a model of efficiency, the **billing software** open on the **computer**, the **printer** humming softly as it spits out receipts and invoices. The **therapist** takes a deep breath, their eyes meeting the client's, a silent promise of relief and relaxation. The follow-up begins.\", 'situation_json': '{\"treatment_room_light_intensity\": \"dim\", \"massage_table_cover_state\": \"polished\", \"heating_pad_state\": \"on\", \"reception_area_audio_level\": \"low\", \"essential_oils_diffuser_state\": \"on\", \"essential_oils_diffused\": [\"eucalyptus\", \"lavender\"], \"salt_lamp_state\": \"on\", \"salt_lamp_glow_color\": \"indigo\", \"towels_folding_state\": \"meticulous\", \"sheets_folding_state\": \"meticulous\", \"cushions_state\": \"inviting\", \"computer_state\": \"on\", \"computer_display\": \"client\\'s file\", \"phone_ringer_state\": \"silent\", \"therapist_gloves_state\": \"on\", \"client_rob_state\": \"on\", \"client_socks_state\": \"tucked\", \"clock_ticking_state\": \"on\", \"appointment_book_state\": \"open\", \"computer_schedule_display\": \"day\\'s schedule\", \"whiteboard_state\": \"filled\", \"laptop_state\": \"on\", \"reception_area_state\": \"welcoming\", \"waiting_room_state\": \"comfortable\", \"billing_software_state\": \"open\", \"printer_state\": \"working\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124406.73 examples/s]amples]\n",
      "Filter:   0%|          | 0/4271 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Recreation & Fitness Worker', 'process': 'Equipment Maintenance', 'situation': 'In the heart of a bustling gym, the Recreation & Fitness Worker can be found diligently tending to the equipment maintenance in a room aptly named the equipment maintenance dungeon. The room is filled with the scent of metal and the faint hum of machines. On a large workbench, a collection of tools awaits their use - a variety of screwdrivers in different sizes, wrenches, a bottle of lubricant, and an assortment of cleaning supplies. The worker meticulously inspects each piece of equipment, their hands moving with practiced ease as they tighten loose bolts and screws with a screwdriver, adjust tension with a wrench, and lubricate moving parts to ensure smooth operation. They pay close attention to every detail, their eyes scanning for any signs of wear and tear. A particularly worn-out treadmill catches their attention, and they make a mental note to schedule a professional repair. As they work, the distant echoes of weights clinking and the muffled cheers from the nearby workout room serve as a reminder of the importance of their task - to ensure the safety and functionality of the equipment, and ultimately, the satisfaction of the gym members.', 'situation_json': '{\"location\": \"equipment maintenance room\", \"tools\": [\"screwdrivers\", \"wrenches\", \"lubricant\", \"cleaning supplies\"], \"equipment_condition\": [{\"type\": \"treadmill\", \"condition\": \"heavily worn-out\", \"action_required\": \"professional repair\"}], \"odor\": \"metal\", \"sounds\": \"faint hum of machines\", \"distant_sounds\": [\"weights clinking\", \"muffled cheers\"], \"work_bench\": \"large\", \"worker_tasks\": [\"tightening loose bolts and screws\", \"adjusting tension\", \"lubricating moving parts\"], \"worker_approach\": \"meticulous\", \"goal\": \"ensure safety and functionality\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 90070.60 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 61295.23 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 93459.02 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140081.27 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91470.32 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Epidemiologist', 'process': 'Epidemiological Modeling', 'situation': 'In the quiet, climate-controlled indoor office, an epidemiologist sits at their desk, eyes focused intently on the large computer monitor in front of them. The familiar hum of the computer fan and the soft buzz of the LED lights overhead provide a subtle backdrop to their work. Their desk, while functional, is far from bare - in fact, it is a testament to the intellectual challenges of epidemiological modeling. On one side, several thick textbooks on mathematics, statistics, and epidemiology are stacked neatly, a constant reminder of the complexities of their work. On the other side, a high-powered laptop sits closed for now, but ready to be opened and filled with statistical software required for data analysis and creating models. A large mug of coffee, now empty, stands sentinel over the desk, evidence of hours spent immersed in their work. In the distance, the soft murmur of colleagues can be heard, other epidemiologists and public health professionals also engaged in their respective tasks. The epidemiologist knows they can rely on them for collaboration and feedback when needed. Despite the seemingly isolated nature of their work, they are never truly alone in their mission to understand, predict, and prevent the spread of infectious diseases.', 'situation_json': '{\"location\": \"indoor office\", \"climate\": \"controlled\", \"noise_level\": \"quiet\", \"illumination_state\": \"LED lights overhead\", \"background_noise\": \"hum of the computer fan and soft buzz of LED lights\", \"colleagues_in_proximity\": true, \"computer_monitor_state\": \"large\", \"laptop_state\": \"closed for now\", \"coffee_mug_state\": \"empty\", \"reference_material_state\": \"stacked neatly\", \"collaboration_availability\": \"yes\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 80806.63 examples/s]mples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 116883.22 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81148.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Billing', 'situation': \"The billing process in the legal profession involves accurately tracking the time spent on various tasks related to a client's case, calculating the total amount due, and preparing an invoice that clearly details the work done. Billing is done in an office setting, typically at a lawyer's desk. The main challenge is ensuring that all billable hours are accurately recorded and that the client understands the value of the services provided. The duration of this process varies depending on the case and workload, but it is typically done on a monthly basis. The risks associated with this process include inaccurate billing or misunderstandings with clients about the charges. Equipment used includes time tracking software, word processing software, and billing software. The localities involved are the lawyer's office and the client's location. Other people involved in this process are the lawyer's staff, clients, and potentially other legal professionals.\", 'situation_json': '{\"parameters\": {\"localities\": [\"office\", \"client\"], \"equipment\": {\"time_tracking_software\": {\"state\": \"running\"}, \"word_processing_software\": {\"state\": \"idle\"}, \"billing_software\": {\"state\": \"open\"}}, \"people\": [\"staff\", \"client\", \"legal_professionals\"], \"frequency\": \"monthly\", \"process_duration\": \"variable\", \"challenges\": [\"accurately tracking time\", \"ensuring clients understand value\"], \"risks\": [\"inaccurate billing\", \"misunderstandings with clients\"]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]3,  6.42s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Pharmacy Technician', 'process': 'Insurance Verification', 'situation': \"In the heart of the bustling pharmacy store, a Pharmacy Technician dons their white lab coat, preparing to verify the insurance of a patient. The technician grabs a nearby computer, its screen illuminating the dimly-lit pharmacy counter, and proceeds to access the patient's insurance information. The computer, equipped with a sleek keyboard and mouse, whirrs softly as the technician navigates through the online insurance portal. Meanwhile, a group of eager patients wait in the spacious waiting area, anticipating their turn at the counter. The pharmacy store, filled with an array of medications, provides a controlled environment for Pharmacy Technicians to work in, where necessary equipment, medication inventory, and workspace are readily available. The technician's workstation houses the pharmacy's medication dispensing system, a sophisticated piece of machinery with safety features to ensure accurate prescription dosing. The technician, ever-focused, dials a phone number to contact the insurance company, a task repeated every hour. The ultimate goal of this process is to ensure that the pharmacy provides patients with the prescriptions they need while also receiving appropriate insurance reimbursement, a typically mundane yet essential task taking up to 10 minutes to complete.\", 'situation_json': '{\"location_description\": \"heart of the bustling pharmacy store\", \"equipment\": {\"presence\": true, \"condition\": \"working\", \"type\": \"computer\", \"screen_state\": \"illuminated\", \"keyboard_state\": \"sleek\", \"mouse_state\": \"sleek\"}, \"ambient_conditions\": {\"light_level\": \"dimly-lit\", \"waiting_area\": \"spacious\", \"patient_population\": \"group of eager patients\", \"medication_availability\": \"array\", \"environment_controlled\": true}, \"technician_workstation\": {\"presence\": true, \"medication_dispensing_system\": \"sophisticated machinery\", \"safety_features\": true, \"accurate_prescription_dosing\": true}, \"communication_methods\": {\"phone\": true}, \"frequency_of_task\": \"repeated every hour\", \"typical_time_to_complete\": \"up to 10 minutes\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 106540.85 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 107340.00 examples/s]\n",
      "Filter:   0%|          | 0/4271 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Change Management', 'situation': \"In the heart of the bustling corporate office, a Management Analyst is meticulously handling the intricacies of change management. The spacious office, bathed in the soft glow of LED lights, is a testament to modern minimalism, with sleek, black desks and ergonomic chairs designed to maximize comfort and productivity. The analyst sits at the epicenter of this workspace, surrounded by a multitude of sophisticated electronic devices that hum gently, awaiting their next command. To their left, a state-of-the-art computer sits adjacent to an articulated laptop, both critical tools for research, data analysis, and strategy development. A high-definition monitor extends from the desktop, displaying a myriad of charts and graphs that reflect the complexity of the task at hand. Directly in front of them, an additional computer is open, its screen occupied by a project management software interface that tracks a multitude of projects, each color-coded and meticulously organized. The software is the analyst's digital compass, guiding them through the labyrinthine process of change management. On the right, an array of specialized software programs are open, each dedicated to a unique aspect of the task, from financial analysis to risk management. The air is filled with a faint, rhythmic ticking, emanating from several nested keyboards that are being diligently tapped to input data and spawn insights. The analyst's fingers dance over the keys, their eyes scanning the data with the precision of a hawk. Nearby, the office hums with activity. In one of the adjacent meeting rooms, a training session is underway, with employees engaged in lively discussions about the new processes. Through the glass wall, the analyst can see the trainer, marker in hand, conducting an interactive workshop. Outside, in the broad, open-plan workspace, colleagues are deeply focused on their tasks, the occasional murmured conversation punctuating the focus. In another corner, a quick brainstorming session is taking place, with three colleagues huddled together, whiteboard markers in hand, their animated discussion punctuated by laughter. The analyst is not alone in their mission; outsiders offer valuable data and perspectives. Management, employees, and stakeholders alike chime in with insights, each voice contributing to the collective understanding needed to navigate the complexities of change. The walls are adorned with a patchwork of post-it notes, each bearing a scrap of information or an idea, a visible testament to the collaborative nature of the work. The office, a beehive of activity, is designed to foster creativity and efficiency, with spaces for both focused work and casual collaboration. As the day progresses, the analyst continues their delicate dance with data and strategy, steering the organization toward a more efficient and profitable future.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 97965.49 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 102700.67 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 55832.87 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 41363.94 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 95032.06 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136754.42 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90261.78 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Customer Service Representative', 'process': 'Updating Customer Records', 'situation': 'In the heart of the bustling customer service department, a customer service representative sits diligently at their desk. Their worn, yet comfortable leather chair contrasting with the sleek, modern design of their computer setup. Adorned with various sticky notes and reminders, the monitor glows with the customer records software open, the cursor patiently awaiting input. To their right, a well-used headset rests, its microphone adjusted with care, while the accompanying phone sits quietly aside, waiting for the next call ring. The office hums with the subtle sounds of other representatives working, keyboards clicking rhythmically, the occasional murmur of polite conversation wafting through the air. Outside their window, the IT department buzzes with activity as technicians diligently maintain operational systems, while the sales department bustles with updates on customer orders and transactions. The process of updating customer records is about to begin, as the representative takes a deep breath, ready to provide the best possible service to those on the other end of the line.', 'situation_json': '{\"description\": \"Detailed description of the situation.\", \"chair_condition\": \"worn, yet comfortable\", \"chair_type\": \"leather\", \"monitor_notes\": \"various sticky notes and reminders\", \"headset_usage\": \"well-used\", \"headset_microphone_adjustment\": \"adjusted with care\", \"phone_usage\": \"queitly aside\", \"environment_sound\": \"keyboards clicking rhythmically, the occasional murmur of polite conversation\", \"it_department_activity\": \"buzzes with activity\", \"technician_task\": \"maintain operational systems\", \"sales_department_activity\": \"bustles with updates on customer orders and transactions\", \"process_start\": \"about to begin\", \"representative_readiness\": \"ready to provide the best possible service\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]0,  3.17s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Brand Management', 'situation': \"You sit in the heart of the bustling corporate office, the echoes of your keyboard clicks filling the air as you craft the latest press release. The room hums with a mix of tension and focus, as your teammates huddle over their laptops, furiously typing reports and speeches. The walls, adorned with screen prints of past media successes and framed headlines, serve as both a testament to your team's efforts and a constant reminder of the reputation you all strive to uphold. Your desk, bathed in the warm glow of your computer screen, is a landscape of organized chaos: stacks of notepads scribbled with ideas, a mug with a bureau slogan half-drunk, and a phone that hasn’t stopped buzzing since the start of the workday. Despite the intensity, the coffee break area just down the hall beckons, promising a moment of respite and a chance to brainstorm over steaming cups of caffeine. Outside, beyond the glass walls of the boardroom where senior management strategizes, the city pulses with life, a stark contrast to the focused calm within your office. The day is a marathon of crafting messages, liaising with journalists, and navigating the delicate dance of public relations.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Home Health Aide', 'process': 'Medication Management', 'situation': \"In the cozy and comforting atmosphere of a patient's residence, a Home Health Aide diligently carries out the critical task of Medication Management. The house, adorned with soft yellow walls and warm wooden floors that creak gently underfoot, feels both familiar and invitingly homey. In the midst of the living room, a serene space filled with a plush couch and mismatched armchairs, the Home Health Aide stands attentively beside the patient. The patient, nestled comfortably on the couch with a fleece blanket draped over their lap, watches the meticulous process unfold with trusting eyes.\\n\\nThe Home Health Aide, dressed in professional attire including a crisp white polo and khaki pants, approaches the task with a gentle smile that instills confidence and calm. Nearby, an old wooden coffee table supports a neatly organized tray containing a multitude of medications. The tray, a humble plastic rectangle, houses an array of ten different pill bottles, each distinct with varying colors and shapes. The colors range from the pristine white of antibiotics to the striking reds of heart medications, all arranged in a precise order that seems almost artistic.\\n\\nBeside the tray, a compact laptop sits open, its screen glowing softly with a log book template that dutifully records the details of each medication administration. The log book is an essential tool, its digital pages filled with meticulous notes that ensure accuracy and consistency in the patient's care. The laptop’s subtle hum fills the quiet room, a steady rhythm that accompanies the careful work.\\n\\nOutside the living room, the rest of the house buzzes with the faint hum of daily life. A family member, perhaps a caregiver, putters in the kitchen, the clinking of dishes and the soft whir of a mixer suggesting the preparation of a nourishing meal. A gentle breeze wafts through an open window, carrying the faint scent of fresh laundry from a nearby room, hinting at the continuous cycle of care and support that permeates the household. Back in the living room, the Home Health Aide, with a final glance at the meticulously organized tray, proceeds to assist the patient with their medication, ensuring that each pill is taken with the utmost care and precision.\", 'situation_json': '{\"situation\": \"{\\\\n    \\\\\"environment\\\\\": {\\\\n        \\\\\"type\\\\\": \\\\\"residence\\\\\",\\\\n        \\\\\"atmosphere\\\\\": \\\\\"cozy and comforting\\\\\",\\\\n        \\\\\"walls\\\\\": \\\\\"soft yellow\\\\\",\\\\n        \\\\\"floors\\\\\": \\\\\"warm wooden\\\\\",\\\\n        \\\\\"floors_creak\\\\\": true\\\\n    },\\\\n    \\\\\"living_room\\\\\": {\\\\n        \\\\\"space\\\\\": \\\\\"serene\\\\\",\\\\n        \\\\\"furniture\\\\\": [\\\\n            \\\\\"plush couch\\\\\",\\\\n            \\\\\"mismatched armchairs\\\\\",\\\\n            \\\\\"old wooden coffee table\\\\\"\\\\n        ],\\\\n        \\\\\"patient\\\\\": {\\\\n            \\\\\"position\\\\\": \\\\\"nestled comfortably on the couch\\\\\",\\\\n            \\\\\"blanket\\\\\": \\\\\"fleece\\\\\",\\\\n            \\\\\"blanket_position\\\\\": \\\\\"draped over lap\\\\\",\\\\n            \\\\\"eyes\\\\\": \\\\\"trusting\\\\\"\\\\n        },\\\\n        \\\\\"tray\\\\\": {\\\\n            \\\\\"material\\\\\": \\\\\"plastic\\\\\",\\\\n            \\\\\"shape\\\\\": \\\\\"rectangle\\\\\",\\\\n            \\\\\"contents\\\\\": [\\\\n                {\\\\n                    \\\\\"item\\\\\": \\\\\"pill bottles\\\\\",\\\\n                    \\\\\"quantity\\\\\": 10,\\\\n                    \\\\\"colors\\\\\": [\\\\n                        \\\\\"white\\\\\",\\\\n                        \\\\\"red\\\\\"\\\\n                    ],\\\\n                    \\\\\"shapes\\\\\": \\\\\"varying\\\\\"\\\\n                }\\\\n            ],\\\\n            \\\\\"organization\\\\\": \\\\\"precise order\\\\\"\\\\n        },\\\\n        \\\\\"laptop\\\\\": {\\\\n            \\\\\"state\\\\\": \\\\\"open\\\\\",\\\\n            \\\\\"screen\\\\\": \\\\\"glowing softly\\\\\",\\\\n            \\\\\"function\\\\\": \\\\\"log book template\\\\\",\\\\n            \\\\\"hum\\\\\": true\\\\n        },\\\\n        \\\\\"log_book\\\\\": {\\\\n            \\\\\"pages\\\\\": \\\\\"digital\\\\\",\\\\n            \\\\\"notes\\\\\": \\\\\"meticulous\\\\\"\\\\n        }\\\\n    },\\\\n    \\\\\"rest_of_the_house\\\\\": {\\\\n        \\\\\"kitchen\\\\\": {\\\\n            \\\\\"activity\\\\\": \\\\\"preparation of a meal\\\\\",\\\\n            \\\\\"sounds\\\\\": [\\\\n                \\\\\"clinking of dishes\\\\\",\\\\n                \\\\\"whir of a mixer\\\\\"\\\\n            ]\\\\n        },\\\\n        \\\\\"window\\\\\": {\\\\n            \\\\\"state\\\\\": \\\\\"open\\\\\",\\\\n            \\\\\"breeze\\\\\": \\\\\"gentle\\\\\",\\\\n            \\\\\"smell\\\\\": \\\\\"fresh laundry\\\\\"\\\\n        }\\\\n    },\\\\n    \\\\\"patient_care\\\\\": {\\\\n        \\\\\"task\\\\\": \\\\\"assist with medication\\\\\",\\\\n        \\\\\"care\\\\\": \\\\\"utmost\\\\\"\\\\n    }\\\\n}\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 89432.64 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 119426.61 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 60388.09 examples/s]s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 75947.89 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 72180.39 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 97964.96 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 60873.18 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 92292.93 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 67320.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sports Coach', 'process': 'Injury Management', 'situation': \"Under the crisp blue sky of a blazing hot afternoon, Coach Miller stands amidst the lush green turf of the sports field, a sprawling outdoor arena that stretches as far as the eye can see. This is the sports facility, a hub of athletic excellence where the sweet scent of freshly cut grass mingles with the invigorating aroma of sweat and determination. Coach Miller, clad in his trademark crisp white polo shirt and dark blue shorts, observes his team with a keen, watchful eye. The training field, a vast expanse of meticulously maintained grass, is dotted with a dozen training cones of varied hues - vibrant red, electric blue, and neon green - set up in intricate patterns to challenge the athletes' agility and speed. A clipboard, securely tucked under his right arm, bears the coach's meticulous notes and drill plans, each jotting and line indicative of his relentless dedication to perfecting each player's performance.\\n\\nIn the distance, the medical room, a sanctuary of healing and recovery, is adorned with advanced medical equipment. The sports facility also hosts a well-equipped gymnasium, where the clanking sounds of weights and the rhythmic hum of conditioning machines serve as a symphony of physical prowess. The locker rooms, with their rows of gleaming lockers and pungent odor of disinfectant and sweat, offer a sanctuary for the athletes to prepare mentally and physically before each session. An array of sports equipment - an array of colorful footballs, soccer balls, and basketballs - are scattered around the facility, each item showing signs of wear and tear, testament to the relentless drive of the athletes.\\n\\nNearby, the training room, a space abuzz with the energy of young athletes honing their skills, is filled with advanced training equipment. The gym, with its state-of-the-art machinery, is a beehive of activity where athletes perform strength training exercises, the sound of grunting and the clanking of weights filling the air. The athletes, a diverse group of individuals, are clad in their training gear, their bodies glistening with sweat under the harsh glare of the afternoon sun. They execute drills with precision, lunging, sprinting, and dribbling, under the watchful eyes of Coach Miller and his Assistant Coach. The assistant coach, dressed in a similar attire, furiously scribbles notes on a clipboard, his eyes flickering between the athletes and his notes.\\n\\nThe coaching box, a elevated platform just off the field, offers Coach Miller a strategic vantage point from where he can observe the entire field and shout instructions to his players. In the spectator stands, a sea of supporters cheer on the athletes, their energetic voices filling the air and serving as an inspiration for the players. The atmosphere is electric, a mix of determination, adrenaline, and the constant hum of competitive spirit. The coaching office, a cozy space adorned with trophies, photos, and inspirational quotes, serves as a sanctuary where Coach Miller strategizes and develops plans to propel his team to victory.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 79785.93 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146525.15 examples/s]\n",
      "Filter:   0%|          | 0/645 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Painter', 'process': 'Quality Control', 'situation': 'In the heart of the workspace, the painter, clad in a paint-splattered apron, meticulously scrutinizes the freshly painted surface, her eyes as focused as a hawk. Four brushes of varying sizes rest on her right, the bristles still damp from use, while a couple of rollers lie nearby, their cylindrical bodies smattered with a kaleidoscope of colors. A meter-long tape measure, its yellow body gleaming under the studio lights, is coiled neatly beside them. In her left hand, she holds a magnifying glass, its lens revealing the tiniest imperfections in the paint job. Her assistant, a novice painter with an eager expression, watches intently from a few paces away, his notepad and pen at the ready to jot down any observations. In the corner of the room, a table is strewn with color charts, each sheet a vibrant palette of potential hues. Just beyond, a pair of clients, the soon-to-be residents of this newly painted abode, stand in anticipation, their eyes flickering between the painter and the painted wall. The atmosphere is tense yet hopeful, as the painter prepares to deliver her verdict.', 'situation_json': '{\"paint_state\": \"meticulously scrutinizes the freshly painted surface\", \"equipment\": [{\"type\": \"brush\", \"quantity\": 4, \"size\": [\"varying\", \"small\", \"medium\", \"large\"], \"bristle_state\": \"damp\", \"color\": \"paint-splattered\"}, {\"type\": \"roller\", \"quantity\": 2, \"body_state\": \"smattered\", \"color\": \"kaleidoscope of colors\"}, {\"type\": \"tape measure\", \"length\": \"meter-long\", \"color\": \"yellow\", \"position\": \"coiled neatly\"}, {\"type\": \"magnifying glass\", \"position\": \"held in left hand\", \"lens_state\": \"reveals imperfections\"}], \"assistant_present\": true, \"assistant_state\": \"intently watching\", \"assistant_equipment\": [{\"type\": \"notepad\", \"position\": \"ready to jot observations\"}, {\"type\": \"pen\", \"position\": \"ready to jot observations\"}], \"color_charts_present\": true, \"color_charts_state\": \"table strewn\", \"client_present\": true, \"client_count\": 2, \"client_state\": \"stand in anticipation\", \"client_focus\": [\"painter\", \"painted wall\"], \"atmosphere\": \"tense yet hopeful\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78283.64 examples/s]xamples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Business Operations Manager', 'process': 'Resource Allocation', 'situation': \"Business Operations Manager is responsible for overseeing the daily operations of a company, ensuring that they are running efficiently and effectively. This includes managing resources, setting goals, and identifying areas for improvement. They work closely with other departments, such as finance, human resources, and IT, to ensure that all processes are aligned with the company's strategic objectives. They also ensure that all staff members are equipped with the necessary resources to perform their job tasks, and monitor the performance of these resources to ensure optimal usage. In addition, they develop and implement policies and procedures to streamline operations and minimize risk. The ultimate goal of a Business Operations Manager is to improve productivity, reduce costs, and enhance overall business performance. The process of Resource Allocation involves identifying and managing the allocation of resources, such as people, money, and equipment, to ensure that they are used effectively and efficiently to achieve the company's goals. This process is done primarily in an office or cubicle, in a business or corporate environment, and the main challenge is to effectively manage and allocate resources to meet the company's goals and objectives.\", 'situation_json': '{\"environment\": {\"type\": \"Office or Cubicle\", \"business_type\": \"Business or Corporate\"}, \"resources\": [\"Personnel\", \"Equipment\", \"Funds\"], \"equipment_states\": {\"Personnel\": {\"status\": \"Equipped\"}, \"Equipment\": {\"status\": \"Optimal Usage\"}, \"Funds\": {\"status\": \"Adequately Allocated\"}}, \"goals\": [\"Improve Productivity\", \"Reduce Costs\", \"Enhance Business Performance\"], \"challenges\": [\"Effective Resource Management and Allocation\"]}'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 106844.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 84484.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 50262.45 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 91621.55 examples/s]\n",
      "Filter:   0%|          | 0/4271 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sales Representative', 'process': 'Customer Follow-ups', 'situation': \"Once a week, the Sales Representative is found diligently working away at their indoor sales office, a place filled with vibrant natural light filtering in through large windows overlooking a bustling cityscape. The sales office is adorned with motivational posters that inspire productivity, but today, it is particularly quiet with only a few colleagues in their cubicles, engrossed in their laptops, reviewing contracts, and researching about clients. In a corner of the room, an empty meeting room with its glass walls reflects the hustle bustle of the office, set and ready for a client presentation next door. The Sales Representative sits at their desk, surrounded by stacks of brochures and product samples showcasing the latest offerings. Their indigo-colored laptop projects a dazzling presentation of sales reports on the screen, powered by the latest CRM software. Their white-colored, sleek, smartphone lies nearby, vibrating intermittently with customer follow-up reminders. The phone is crucial for their CRM software, which also aids in tracking sales progress and managing client information, alongside their computer. Their email's inbox is an organized hub, filled with weekly customer follow-ups. Today, the Sales Representative is reaching out to a customer to upsell a service. The Sales Manager hovers nearby, overseeing the Representative's work and offering guidance whenever needed. The Sales Representative's task is a challenging yet rewarding one, requiring excellent verbal communication skills to understand customer needs and clinch the deal.\", 'situation_json': '{\"location\": \"indoor sales office\", \"lighting\": \"natural light\", \"view\": \"cityscape\", \"ambiance\": \"quiet\", \"number_of_colleagues\": \"few\", \"colleague_activities\": [\"reviewing contracts\", \"researching about clients\"], \"meeting_room\": \"empty\", \"meeting_room_preparation\": \"ready for client presentation\", \"sales_representative_equipment\": [\"indigo-colored laptop\", \"white-colored smartphone\"], \"laptop_activity\": \"projecting sales reports\", \"software_used\": \"CRM software\", \"smartphone_activity\": \"vibrating intermittently\", \"smartphone_purpose\": \"customer follow-up reminders\", \"smartphone_integration\": \"CRM software\", \"sales_representative_task\": \"upselling a service\", \"sales_manager_presence\": \"yes\", \"sales_manager_role\": \"overseeing and guiding\", \"skills_required\": \"excellent verbal communication\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 117007.66 examples/s]ples]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 52802.30 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 104915.31 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 121139.54 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94229.40 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mental Health Counselor', 'process': 'Continuing Education', 'situation': \"In a sparsely furnished yet serene counseling office, the mental health counselor sits poised at a polished mahogany desk. The room is bathed in soft natural light streaming through tall, sheer-curtained windows, casting a warm, comforting glow on the place. The counselor's laptop, humming quietly, is flanked by neatly arranged stacks of textbooks and journals, the colorful spines neatly facing out, each marked with the latest findings and methodologies. A pair of high-quality headphones lies next to a notepad filled with meticulously penned notes from previous webinars and sessions.\\n\\nThe room itself is an embodiment of tranquility, with soothing beige walls adorned with abstract art that invites contemplation. A plush couch with soft, inviting cushions awaits clients, fostering an atmosphere of comfort and trust. Potted plants thrive in the corners, adding a touch of nature and freshness to the environment.\\n\\nIn the adjacent room, the waiting area is equally well-designed. Comfortable armchairs in various hues of calming blue and green dot the space, while a coffee table holds a variety of magazines and books for clients to peruse. A small coffee bar offers refreshments—hot coffee and a selection of teas, complete with an assortment of mugs in different styles, providing a level of personalization and warmth.\\n\\nBack in the counseling office, the counselor's desk includes a small tray with an array of pens in various colors, symbolizing the multifaceted nature of their work. Behind the counselor, a bookshelf teems with psychological tests and diagnostic resources, carefully organized and ready to be deployed as needed. A soft, long-lasting desk lamp sits on one corner of the desk, providing focused light for reading or note-taking.\\n\\nSurrounding this main workspace, the broader office area includes a library brimming with books and journals, providing ample resources for continued education. A quiet staff lounge provides a place for breaks and collegial discussions, equipped with comfortable chairs and a small kitchenette. Administrative staff can be seen working diligently in a nearby office, handling scheduling, billing, and other logistical concerns. Their workspace is tidy and efficiently organized, with multiple computer monitors and stacks of neatly filed documents.\\n\\nJust outside the office, a cozy coffee shop offers a peaceful haven for reflection and relaxation after a busy day of counseling sessions. While in the office, colleagues and peers engage in lively but hushed discussions within the conference room, which is adorned with whiteboards filled with ideas and concepts from recent seminars and professional development sessions.\\n\\nThis interconnected array of spaces and elements paints a comprehensive picture of a mental health counselor's professional ecosystem, where every detail is designed to support the holistic well-being of both the counselor and their clients.\", 'situation_json': '{\"properties\": {\"counseling_office\": {\"furnishing\": \"sparsely\", \"atmosphere\": \"serene\"}, \"desk\": {\"type\": \"mahogany\", \"condition\": \"polished\"}, \"lighting\": {\"type\": \"natural\", \"intensity\": \"soft\"}, \"windows\": {\"size\": \"tall\", \"coverings\": \"sheer curtains\"}, \"laptop\": {\"state\": \"on\", \"noise\": \"humming quietly\"}, \"literature\": {\"type\": [\"textbooks\", \"journals\"], \"arrangement\": \"neat\", \"color\": \"colorful\", \"orientation\": \"spines facing out\", \"content\": \"latest findings and methodologies\"}, \"headphones\": {\"quality\": \"high\", \"position\": \"next to notepad\"}, \"notepad\": {\"content\": \"notes from webinars and sessions\", \"writing\": \"meticulously penned\"}, \"walls\": {\"color\": \"beige\", \"decoration\": \"abstract art\"}, \"couch\": {\"type\": \"plush\", \"cushions\": \"soft and inviting\"}, \"plants\": {\"type\": \"potted\", \"condition\": \"thriving\", \"location\": \"corners\"}, \"waiting_area\": {\"chairs\": {\"type\": \"armchairs\", \"colors\": [\"blue\", \"green\"], \"comfort\": \"comfortable\"}, \"table\": {\"type\": \"coffee table\", \"content\": [\"magazines\", \"books\"]}, \"coffee_bar\": {\"offerings\": [\"hot coffee\", \"teas\"], \"mugs\": {\"variety\": \"assortment\", \"styles\": \"different\"}}}, \"counselor_desk\": {\"tray\": {\"item\": \"pens\", \"colors\": \"various\"}, \"bookshelf\": {\"content\": [\"psychological tests\", \"diagnostic resources\"], \"organization\": \"carefully organized\"}, \"lamp\": {\"type\": \"desk lamp\", \"brightness\": \"soft\", \"duration\": \"long-lasting\"}}, \"broader_office_area\": {\"library\": {\"content\": [\"books\", \"journals\"], \"resources\": \"ample\"}, \"staff_lounge\": {\"purpose\": [\"breaks\", \"collegial discussions\"], \"amenities\": [\"comfortable chairs\", \"kitchenette\"]}, \"administrative_office\": {\"staff_activity\": \"working diligently\", \"workspace\": {\"condition\": \"tidy\", \"organization\": \"efficient\"}, \"equipment\": [\"multiple computer monitors\"], \"documents\": {\"arrangement\": \"neatly filed\"}}}, \"coffee_shop\": {\"atmosphere\": \"cozy\", \"purpose\": \"reflection and relaxation\", \"timing\": \"after sessions\"}, \"conference_room\": {\"discussions\": {\"type\": \"lively but hushed\"}, \"decoration\": {\"type\": \"whiteboards\", \"content\": [\"ideas\", \"concepts from seminars and professional development sessions\"]}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114543.30 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138167.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96093.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Computer Systems Analyst', 'process': 'Software Development', 'situation': \"In the heart of a bustling software development firm, a Computer Systems Analyst begins their daily 8-hour journey. Their office, an indoor sanctuary of productivity, is equipped with two computers adorned with state-of-the-art software applications, including project management tools and testing software. The air is filled with the faint hum of a nearby white printer, spewing out project proposals and client reports. The walls of the office are adorned with four whiteboards, each one a canvas of colorful markers, filled with brainstorming ideas, system designs, and project timelines.\\n\\nThe analyst is surrounded by a symphony of productivity. To their left, a group of other analysts huddle around a laptop, fervently discussing a project design. To their right, the IT department buzzes with the sounds of keyboards clicking and muffled conversations about system updates and network configurations. In the far corner, the business department is a hive of activity, with team members engrossed in discussions about new system requirements and specifications.\\n\\nThe office is a labyrinth of meeting rooms, each one a hub of collaboration between the analyst, management, and stakeholders. The rooms are equipped with large screens for presentations and video conferencing, ensuring seamless communication regardless of the participants' locations.\\n\\nNearby, a testing environment houses several systems, their lights flickering as they undergo rigorous testing. The server room, a haven of technology, is a short walk from the office. It is constantly monitored by the IT department, ensuring the smooth running of all systems.\\n\\nThe analyst's role is a delicate dance of mental problem-solving and strategic decisions. They consult with managers to identify areas of improvement, research and evaluate new technologies, and implement systems and software applications that align with the company's goals. Their responsibilities are as diverse as the people they interact with daily - from managers and end-users to software developers and project managers.\", 'situation_json': '{\"office\": \"indoor\", \"office_devices\": [\"computer1\", \"computer2\"], \"software_applications\": [\"project management tools\", \"testing software\"], \"printer_state\": \"active\", \"whiteboards\": 4, \"analyst_left\": \"other analysts\", \"analyst_right\": \"IT department\", \"analyst_far_corner\": \"business department\", \"meeting_rooms\": true, \"presentation_screens\": true, \"video_conferencing\": true, \"testing_environments\": true, \"server_room\": true, \"server_room_monitoring\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112306.58 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 112791.42 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88993.92 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Clinical Laboratory Technician', 'process': 'Continuing Education', 'situation': 'In the bustling, indoor clinic laboratory, a clinical laboratory technician embarks on a vital process of Continuing Education. Amidst the sterile area and the main laboratory area where most of the equipment is located and maintained, they can be found surrounded by meticulously cleaned equipment. The microscope, a scientific instrument used to view objects too small for the naked eye, is shined to a reflective gloss. The centrifuge, a device used to separate fluids of different densities, hums with a consistent, low-pitched whir, indicating its steady operation. The hemocytometer, an instrument used for counting blood cells, sits nearby, its grid meticulously cleaned and ready for use. The laboratory, predominantly white, is contrasted by the colorful biohazardous waste disposal area. The technician is joined by colleagues, the laboratory manager and other laboratory technicians, all dressed in their lab coats, safety goggles and gloves, as is the requirement for all individuals in this controlled environment with strict safety protocols and procedures.', 'situation_json': '{\"location\": \"indoor clinic laboratory\", \"environment\": \"sterile area and main laboratory area\", \"equipment\": {\"microscope\": {\"state\": \"shined to a reflective gloss\", \"usage\": \"view objects too small for the naked eye\"}, \"centrifuge\": {\"state\": \"humming with a consistent, low-pitched whir\", \"usage\": \"separate fluids of different densities\"}, \"hemocytometer\": {\"state\": \"meticulously cleaned and ready for use\", \"usage\": \"counting blood cells\"}}, \"color_scheme\": {\"laboratory\": \"predominantly white\", \"biohazardous_waste_disposal_area\": \"colorful\"}, \"present_individuals\": {\"colleagues\": true, \"laboratory_manager\": true, \"other_laboratory_technicians\": true}, \"dress_code\": {\"lab_coats\": true, \"safety_goggles\": true, \"gloves\": true}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132137.95 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134639.14 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89026.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Financial Manager', 'process': 'Financial Reporting', 'situation': 'In the heart of the Finance Department, the Financial Manager can be found meticulously preparing financial statements and reports. Their spacious office is adorned with a sleek, modern computer and a laptop, both essential tools for running complex financial software. The computer, slightly elevated on a glass desk, is connected to a high-resolution monitor that displays various spreadsheets and financial data. A calculator is neatly placed beside the computer, ready for quick calculations. The laptop, resting on a compact black stand, is used for budgeting, forecasting, and creating presentations for stakeholders. Next to the laptop, a set of tax law books are stacked, serving as a daily reference for the latest tax regulations. The Financial Manager is also supported by a dedicated financial team, who contribute to the data analysis and reporting tasks. In the nearby meeting room, the management team is reviewing the budget plans, while the CEOs office is a frequent stop for the Financial Manager to discuss financial strategies and budgets. The archive room, a secure area within the department, is where all financial records and documents are stored for future reference. Regular visits to clients and the taxation office are also part of the Financial Managers routine, to understand their financial situations and submit tax documents. The challenge in this process lies in ensuring the accuracy, compliance, and timely delivery of financial statements and reports, all while keeping pace with the ever-changing financial landscape.', 'situation_json': '{\"location\": \"Finance Department\", \"equipment\": {\"computer\": \"modern, connected to high-resolution monitor, running complex financial software\", \"laptop\": \"used for budgeting, forecasting, presentations\", \"calculator\": \"for quick calculations\", \"tax law books\": \"daily reference\"}, \"offices\": {\"meeting room\": \"budget reviews\", \"CEOs office\": \"financial strategy discussions\"}, \"rooms\": {\"archive room\": \"secure area for financial records\"}, \"routines\": {\"client visits\": true, \"taxation office visits\": true, \"financial report compliance\": \"accuracy, timeliness, compliance\", \"market pace\": \"keeping pace with changing financial landscape\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131202.95 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140584.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96008.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Art Director', 'process': 'Client Meetings', 'situation': 'In the heart of a bustling design studio, the air is filled with a palpable sense of anticipation as the Art Director prepares for a crucial client meeting. The studio is bathed in the soft glow of overhead lights, their warm hue casting long shadows across the polished wooden floor. The walls are adorned with an eclectic mix of artwork, each piece a testament to the team’s creative prowess. The Art Director sits at a sleek, modern desk, their laptop open, ready to display a carefully curated portfolio of designs, budgeting software humming quietly in the background. To their left, a notepad lies open, its crisp pages awaiting the sketches and notes that will inevitably flow from the upcoming discussion. The desk is spotlessly clean, save for a striking arrangement of five high-quality pens and a sleek drawing tablet, their glossy surfaces reflecting the dimmed studio lights. Behind them, a vast drawing board stands, its surface speckled with the remnants of previous projects – a visual timeline of ideas that have since come to fruition. The Art Director’s colleagues are similarly engaged in preparations. In the adjacent room, which serves as the meeting space, the designer team is setting up a projection screen, its white surface already glowing with the introductory slides. The room is filled with six ergonomic chairs, each upholstered in a vibrant teal fabric that pops against the stark white walls. A coffee maker hums in the corner, its aroma wafting through the air, promising a much-needed lifeline during what will undoubtedly be an intensive meeting. The Art Director glances at the reception area, where five people, a mix of clients and account managers, are engaged in casual conversation, their muted tones a prelude to the more focused discussion to come. The atmosphere is one of professional camaraderie, with every individual aware of the significance of the meeting about to commence.', 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136625.13 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 103336.35 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90570.01 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dental Hygienist', 'process': 'X-Ray Imaging', 'situation': \"In the heart of a bustling dental clinic, a meticulous Dental Hygienist begins the process of X-Ray Imaging. The procedure, which lasts about 15 minutes, is conducted in a dedicated X-ray room. Inside this room, the air is filled with the hum of the X-ray machine, a large, sophisticated device positioned next to a dental chair. On the small, stainless steel tray beside it, a collection of four dental mirrors gleam, their reflective surfaces meticulously cleaned and sterilized. The hygienist dons a lead apron and thyroid collar, a precautionary measure to minimize radiation exposure. Meanwhile, in the nearby waiting room, three patients sit in comfortable chairs, leafing through magazines as they anticipate their appointments. The walls of the waiting room are adorned with informative posters about oral hygiene, casting a warm glow in the soft, ambient lighting. Back in the treatment room, the hygienist's colleague, another skilled Dental Hygienist, is engrossed in patient education, demonstrating proper brushing and flossing techniques using a tooth model and a dental mirror. The atmosphere is a blend of professionalism and care, a testament to the dedication of the dental clinic's team.\", 'situation_json': '{\"room_type\": \"dedicated X-ray room\", \"duration\": 15, \"x_ray_machine_status\": \"humming\", \"x_ray_machine_size\": \"large\", \"x_ray_machine_complexity\": \"sophisticated\", \"dental_chair_proximity\": \"next to\", \"dental_mirror_count\": 4, \"dental_mirror_material\": \"stainless steel\", \"dental_mirror_state\": \"clean and sterilized\", \"hygienist_protective_gear\": \"lead apron and thyroid collar\", \"waiting_room_patient_count\": 3, \"waiting_room_material\": \"comfortable chairs and magazines\", \"waiting_room_walls\": \"informative posters\", \"waiting_room_lighting\": \"ambient\", \"colleague_activity\": \"patient education\", \"colleague_demonstrating_with\": \"tooth model and dental mirror\", \"clinic_atmosphere\": \"blend of professionalism and care\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131435.58 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 135045.14 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87451.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Veterinary Technologist & Technician', 'process': 'Emergency Care', 'situation': \"In the heart of the bustling clinic, the air hums with anticipation and a subtle tension hangs like a veil over the emergency care area. The treatment room, bathed in the sterile glow of overhead lights, is a sanctuary of organized chaos. Gleaming instruments lay scattered in meticulous arrays around the examination table, a symphony of stainless steel that whispers of dedicated service to those unable to speak. Among these, three stethoscopes coil like serpents at rest, their diaphragms awaiting the gentle press against furred or feathered skin. Nearby, a detailed array of surgical instruments glints, their exacting edges and handles evoking a sense of precision in service to life's most fragile moments. The obligatory latex gloves, thermometer, and two stethoscopes are prominent on the tray, ready to serve the dual need for hygiene and essential diagnostics. A neat row of dental mirrors, five in total, spreads across one corner, reflecting isolates of light that dance on the wall, hinting at thorough checks and care. A microscope, centrifuge, and blood analyzer form an unwavering trio at the far end, their cold, unblinking eyes promising answers hidden in infinitesimal samples. The reassuring clicks and hums of their duties fill the air, a quiet testament to their relentless vigilance. Collected in an adjoining space, 12 clinical bottles cast long, ominous shadows on the floor, containing the pharmaceutical arsenal prepared to wage war on ailments both known and yet undiagnosed. Outside, the waiting room swells with a calendar's worth of lives on pause, 40 anxious eyes flitting between the clock and the door, each heartbeat echoing the unspoken prayers for their beloved companions' swift recovery. Colleagues bustle in and out, their sleeves rolled up, faces stern with purpose yet softened by empathy. The scene is one of choreographed urgency, where every step, every sigh, and every whispered instruction leads inexorably towards the central mission of care and healing.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120218.62 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141958.40 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93853.46 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Massage Therapist', 'process': 'Continuing Education', 'situation': 'In a spacious and well-lit classroom nestled within the confines of a modern school, a skilled massage therapist embarks on their annual journey of continuing education. The room, one of several breakout spaces within the convention center, is furnished with 12 sturdy massage tables, each draped with pristine white towels. The room hums with an air of contemplative silence, broken intermittently by the soft click-clack of laptop keyboards as therapists take notes. A few massage therapists huddle around a shared table, their heated discussions on various massage techniques punctuated by the occasional chuckle or nod. Meanwhile, three comfortably cushioned chairs lie vacant near the entrance, awaiting the arrival of the instructor. The atmosphere is one of focused learning, with the quiet workspace permitting clear communication and effective data entry, while also providing ample space for practical sessions. Nearby, a bustling reception area and quiet waiting room are home to 4 other massage therapists, patiently awaiting their turn for the practical session. The waiting room, bedecked in calm blues and greens, exudes an aura of tranquility, with a handful of magazines neatly arranged on a central coffee table, flanked by two potted plants.', 'situation_json': '{\"room_description\": \"spacious and well-lit classroom\", \"room_location\": \"within the confines of a modern school\", \"number_of_tables\": 12, \"table_condition\": \"sturdy\", \"table_coverings\": \"pristine white towels\", \"ambient_noise\": \"contemplative silence, broken intermittently by the soft click-clack of laptop keyboards\", \"number_of_therapists_in_room\": 9, \"interaction_among_therapists\": true, \"instructor_arrival_status\": \"awaiting arrival\", \"comfortable_seating_availability\": 3, \"waiting_area_population\": 4, \"waiting_area_atmosphere\": \"calm blues and greens\", \"waiting_area_reading_material\": true, \"waiting_area_plants\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137943.82 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146609.10 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82751.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Recreation & Fitness Worker', 'process': 'Leading Fitness Classes', 'situation': 'In the heart of the bustling gym, the recreation and fitness worker prepares to lead their daily fitness class. The fitness studio is filled with an array of equipment, from the vibrant, red and blue exercise mats neatly stacked in the corner, to the gleaming free weights ranging from 5 to 50 pounds. The resistance bands, a mix of light and heavy, are meticulously arranged on a nearby rack. The studio is a flurry of activity as the assistant helps set up the space, ensuring each station is ready for the impending class. The participants, a diverse mix of ages and fitness levels, begin to trickle in, their numbers steadily growing, filling the locker rooms with the hum of excited chatter. The recreation and fitness worker, radiating energy and excitement, greets each person with a warm smile, their positive attitude contagious. The clock ticks down to the start of the class, and anticipation hangs in the air, a palpable energy of determination and camaraderie.', 'situation_json': '{\"studio_setting\": \"heart of a bustling gym\", \"equipment\": {\"exercise_mats\": {\"color\": [\"red\", \"blue\"], \"quantity\": \"numerous\", \"arrangement\": \"neatly stacked\", \"location\": \"corner\"}, \"free_weights\": {\"weight_range_lb\": \"5-50\", \"quantity\": \"various\", \"condition\": \"gleaming\"}, \"resistance_bands\": {\"weight_range\": [\"light\", \"heavy\"], \"quantity\": \"various\", \"arrangement\": \"meticulously arranged\", \"location\": \"rack nearby\"}}, \"studio_activity\": \"flurry of activity\", \"assistant_present\": true, \"assistant_task\": \"setting up stations\", \"participant_description\": {\"age\": \"diverse\", \"fitness_level\": \"diverse\", \"number\": \"numerous\", \"location\": \"locker rooms\", \"chatter\": \"excited\"}, \"protagonist_presence\": true, \"protagonist_disposition\": \"radiating energy and excitement\", \"greeting_style\": \"warm smile\", \"protagonist_effect\": \"positive attitude contagious\", \"clock_status\": \"ticking down\", \"class_start_anticipation\": true, \"locker_room_atmosphere\": \"determination and camaraderie\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 144980.05 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141786.49 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89764.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Epidemiologist', 'process': 'Literature Review', 'situation': 'An Epidemiologist is nestled in their office within a bustling Health Department or Research Institution. The room, a harmonious blend of comfort and functionality, is brimming with books and papers scattered across a large, oak wood desk. A high-performance laptop, adorned with sticky notes, sits at the heart of the desk, humming with the latest statistical software busily crunching data. Nearby, a sleek, black microscope stands ready for detailed analysis, its eyepiece gleaming in the soft glow of a nearby desk lamp. In one corner of the room, a floor-to-ceiling bookshelf is packed with medical journals and research papers collected over years of study. The room is a testament to a life dedicated to the understanding and prevention of diseases. Occasionally, the Epidemiologist engages in meetings with other healthcare professionals, discussing the progress of their research and the implications of their findings. They also make field visits, collecting data and observing patients in their natural environments. The frequency of these tasks varies, but the dedication remains constant.', 'situation_json': '{\"description\": \"An Epidemiologist is nestled in their office within a bustling Health Department or Research Institution. The room, a harmonious blend of comfort and functionality, is brimming with books and papers scattered across a large, oak wood desk. A high-performance laptop, adorned with sticky notes, sits at the heart of the desk, humming with the latest statistical software busily crunching data. Nearby, a sleek, black microscope stands ready for detailed analysis, its eyepiece gleaming in the soft glow of a nearby desk lamp. In one corner of the room, a floor-to-ceiling bookshelf is packed with medical journals and research papers collected over years of study. The room is a testament to a life dedicated to the understanding and prevention of diseases. Occasionally, the Epidemiologist engages in meetings with other healthcare professionals, discussing the progress of their research and the implications of their findings. They also make field visits, collecting data and observing patients in their natural environments. The frequency of these tasks varies, but the dedication remains constant.\", \"office_location\": \"Health Department or Research Institution\", \"room_description\": {\"size\": \"large\", \"desk_size\": \"large\", \"desk_material\": \"oak wood\", \"book_quantity\": \"many\", \"paper_quantity\": \"many\", \"laptop_description\": {\"performance\": \"high\", \"sticky_notes\": true, \"statistical_software\": true}, \"microscope_description\": {\"color\": \"black\", \"style\": \"sleek\", \"status\": \"ready\", \"eyepiece_condition\": \"gleaming\", \"lamp_status\": true, \"lamp_glow\": \"soft\"}, \"bookshelf_description\": {\"height\": \"floor-to-ceiling\", \"journal_quantity\": \"many\", \"research_papers\": \"many\", \"collection_time_span\": \"years\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119324.99 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145015.20 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92641.81 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Case Management', 'situation': 'In the heart of a bustling law firm office, a lawyer is engrossed in the intricate process of case management. The lawyer sits at a tidy mahogany desk, a sleek silver laptop humming with activity, as legal research tools and word processing software flicker on the screen. To the left of the laptop, a towering stack of legal documents awaits review, their edges neatly aligned and tagged with color-coded sticky notes. The room echoes with a hushed silence, only occasionally broken by the low murmur of dialogue from the nearby conference room, where colleagues discuss pending cases.', 'situation_json': '{\"office_description\": \"The office is bustling, but the lawyer\\'s immediate area is neat and tidy.\", \"desk\": \"mahogany\", \"desk_state\": \"tidy\", \"laptop\": \"silver\", \"laptop_state\": \"humming with activity\", \"legal_research_tools\": \"present on the screen\", \"word_processing_software\": \"present on the screen\", \"legal_documents\": \"present in a towering stack to the left of the laptop\", \"document_edges\": \"neatly aligned\", \"document_tags\": \"color-coded sticky notes\", \"office_noise_level\": \"hushed\", \"murmur_from_conference_room\": \"present, but low\"}'}{'profession': 'Pharmacy Technician', 'process': 'Patient Counseling', 'situation': \"The Pharmacy Technician is situated in the cozy counseling room of the pharmacy, a private space designed for confidentiality and comfort. The well-lit room is furnished with a sleek computer, a sturdy desk to accommodate the medication dispensing system, and a comfortable chair for the patient. A neat stack of medication leaflets is placed on the desk, ready for reference. The computer is used to access the patient's medical records and enter notes about the counseling session. The medication dispensing system, with its advanced safety features, is ready to accurately dispense prescription medications to customers. Nearby, the reception area buzzes with activity as other pharmacy staff greet and register patients. The pharmacist, the technician's supervisor, is in close proximity, ready to provide guidance and support. The pharmacy counter is just a few steps away, where patients receive their prescriptions and ask questions about their medications. In the pharmacy storage area, the inventory is kept clean, organized, and secure. The pharmacy technician, with a calm and patient demeanor, interacts with patients, providing education and support regarding medications in this 30-minute patient counseling process.\", 'situation_json': '{\"location\": \"counseling room\", \"room_characteristics\": {\"lighting\": \"well-lit\", \"design\": \"private space designed for confidentiality and comfort\"}, \"equipment\": {\"computer\": {\"state\": \"on\", \"purpose\": \"access patient medical records and take notes\"}, \"desk\": {\"state\": \"sturdy\", \"purpose\": \"accommodate medication dispensing system\"}, \"medication dispensing system\": {\"state\": \"ready with advanced safety features\", \"purpose\": \"accurately dispense prescription medications\"}, \"patient chair\": {\"state\": \"comfortable\", \"purpose\": \"seat patients\"}, \"medication leaflet stack\": {\"state\": \"neat\", \"purpose\": \"provide medication references\"}}, \"additional_features\": {\"nearby reception area\": \"buzzes with activity\", \"pharmacist supervisor\": \"in close proximity\", \"pharmacy counter\": \"few steps away\", \"pharmacy storage area\": \"kept clean, organized, and secure\"}, \"process_characteristics\": {\"duration\": 30, \"technician demeanor\": \"calm and patient\"}}'}\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 86896.71 examples/s]mples]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 85202.52 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134263.75 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 119597.24 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84380.59 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81776.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Data Analysis', 'situation': \"In the indoor surroundings of the headquarters, a Management Analyst occupies their office space, ensconced within a cubical that provides a secluded atmosphere conducive to focused productivity. The office environment reverberates with a subdued hum of activity, as nearby meeting rooms host discussions between management and other stakeholders, their voices occasionally escaping into the shared space. The analyst's laptop, a sleek, glossy device, lies open on the desk, its screen emitting a soft blue-white glow, filled with financial data and analytical software. Nestled beside it are presentation tools, ready to be utilized when the analyst's findings are presented to clients. Through the rectangular window of their cubical, the analyst can glimpse the bustling corporate office, and the headquarters, where various departments operate in harmony, contributing to the overall success of the company.\", 'situation_json': '{\"Location\": \"Indoor\", \"Specific_Location\": \"Headquarters\", \"Sub_Location\": \"Office Space\", \"Sub_Sub_Location\": \"Cubical\", \"Atmosphere\": \"Focused Productivity\", \"Device_Presence\": \"Laptop\", \"Device_State\": \"Open\", \"Device_Details\": {\"Type\": \"Laptop\", \"Appearance\": \"sleek, glossy\", \"Light_State\": \"Glowing\", \"Light_Color\": \"blue-white\", \"Screen_Content\": \"Financial data and analytical software\"}, \"Surrounding_Activity\": \"Subdued hum\", \"Source_of_Activity\": \"Meeting rooms discussions\", \"Presentation_Tools_Presence\": true, \"Presentation_Tools_Details\": \"Besides the laptop\", \"Presentation_Tools_State\": \"Ready\", \"Office_View_Presence\": true, \"Office_View_Details\": \"Bustling corporate office\", \"Office_View_Source\": \"Headquarters\", \"Office_View_Departments\": \"Various\", \"Office_View_Department_Harmony\": true, \"Office_View_Department_Contribution\": \"Overall success\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125230.60 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130299.77 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92851.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Home Health Aide', 'process': 'Patient Assessment', 'situation': \"In the warm, cozy atmosphere of the patient's residence, where the faint scent of jasmine lingers in the air, a dedicated Home Health Aide diligently performs her daily Patient Assessment routine. The morning sunlight streams through the windowpanes of the living room, casting a golden hue on the neatly arranged furniture, as well as the crisp white medical equipment set on the table. The blood pressure monitor, thermometer, and pulse oximeter look pristine and well-maintained, gleaming under the natural light. The aide meticulously conducts the patient assessment process; her gloved hands skillfully take the patient's vital signs, her eyes observing every nuance of the patient's condition with utmost care and precision. The patient, a kind elderly individual, occasionally gazes around their residence, their eyes briefly resting on the family portraits hanging on the walls. Outside the window, the sound of birds chirping creates a serene and comforting ambiance, while the Home Health Aide efficiently records the patient's health information in a meticulous logbook. Later on, the aide gently heads to the kitchen, where she thoughtfully prepares the patient's meals using fresh, wholesome ingredients. She employs various cooking utensils and appliances such as pots, pans, knives, stove, oven, and microwave with great dexterity, ensuring that the meal not only tastes great but also meets the patient's special dietary needs. A slight smile appears on the patient's face as they perceive the aroma of their favorite dish wafting through the residence. As the Home Health Aide continues to execute her role with expertise, compassion, and professionalism, she contributes significantly in enhancing the overall well-being of the patient in a safe, nurturing, and comfortable environment.\", 'situation_json': '{\"room_atmosphere\": \"warm and cozy\", \"room_scent\": \"jasmine\", \"time_of_day\": \"morning\", \"natural_light\": \"present\", \"medical_equipment\": [\"blood pressure monitor\", \"thermometer\", \"pulse oximeter\"], \"medical_equipment_state\": \"pristine and well-maintained\", \"cooking_utensils_and_appliances\": [\"pots\", \"pans\", \"knives\", \"stove\", \"oven\", \"microwave\"], \"special_dietary_needs\": \"present\", \"patient_mood\": \"content\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]6,  1.38s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Content Creation', 'situation': 'In the bustling heart of the city, nestled within a towering office building, sits the stylish office of a Public Relations Specialist. Every corner of this modern workspace emanates a sense of purpose, creativity, and professionalism. The main room, bathed in the warm glow of sleek LED lights, is dotted with ergonomic workstations. At each station, a top-of-the-line laptop rests, its keyboard teeming with the keystrokes of a dedicated professional. Here, the PR Specialist and their team work diligently on their weekly task - content creation. The room is abuzz with the hum of active minds, as they meticulously craft press releases, speeches, and media kits, aiming to keep their clients in the best possible light. Surrounded by walls adorned with the latest digital tools, the professionals brainstorm, discuss strategies, and monitor media coverage, all in their quest to build and maintain a positive public image for their clients. Adjoining the main room is a smaller, glass-walled conference room where strategic meetings take place, the air charged with ideas and innovation. Outside, the city thrives with activity, but inside the office of this PR Specialist, focus, creativity, and a commitment to excellence reign supreme.', 'situation_json': '{\"location\": \"urban office building\", \"room_description\": \"stylish office\", \"lighting\": \"LED lights\", \"workstations\": \"ergonomic workstations\", \"laptops\": \"top-of-the-line\", \"tasks\": \"content creation\", \"room_atmosphere\": \"abuzz with activity\", \"tasks_details\": [\"press releases\", \"speeches\", \"media kits\"], \"tools\": \"digital tools\", \"activities\": [\"brainstorming\", \"strategy discussions\", \"media coverage monitoring\"], \"goal\": \"positive public image\", \"adjacent_rooms\": [\"glass-walled conference room\"], \"outside_environment\": \"city thriving with activity\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paralegal', 'process': 'Billing and Invoicing', 'situation': 'A paralegal is tasked with assisting lawyers in preparing for trials, hearings, and corporate meetings. They investigate facts, prepare legal documents, and research law. A competent paralegal is detail-oriented, possesses strong research and writing skills, and practices superb organization and communication abilities.', 'situation_json': '{\"details\": {\"roles\": [\"assisting lawyers\"], \"activities\": [\"tasks with trials\", \"hearings\", \"corporate meetings\", \"investigate facts\", \"prepare legal documents\", \"research law\"], \"skills\": {\"detail-oriented\": true, \"research\": true, \"writing\": true, \"organization\": true, \"communication\": true}, \"type\": \"paralegal\", \"process\": \"billing and invoicing\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 96377.46 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 91027.50 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 90708.66 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 95898.95 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 76648.99 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 105531.53 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 117895.53 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78835.71 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 65516.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Database Administrator', 'process': 'Backup and Recovery', 'situation': 'A Database Administrator (DBA) is responsible for maintaining, securing, and ensuring the performance of the database systems in an organization. They also backup and recovery the database to ensure data is protected and can be restored in case of any data loss or corruption. The process of backup and recovery includes creating a copy of the database at regular intervals and storing it in a secure location. In case of data loss or corruption, the DBA will restore the database from the backup. This process is crucial for ensuring business continuity and data integrity.', 'situation_json': '{\"situation\": \"{\\\\n  \\\\\"database_status\\\\\": \\\\\"active\\\\\",\\\\n  \\\\\"backup_frequency\\\\\": \\\\\"daily\\\\\",\\\\n  \\\\\"backup_location\\\\\": \\\\\"secure server\\\\\",\\\\n  \\\\\"data_loss\\\\\": false,\\\\n  \\\\\"data_corruption\\\\\": false,\\\\n  \\\\\"backup_restoration\\\\\": false,\\\\n  \\\\\"business_continuity\\\\\": true,\\\\n  \\\\\"data_integrity\\\\\": true\\\\n}\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 146203.91 examples/s]es/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sports Coach', 'process': 'Liaising with Other Coaches', 'situation': 'Nestled within the heart of the bustling training facility, the meeting room buzzes with a quiet energy. The air is filled with the soft hum of conversation and the faint scent of fresh coffee wafting from the nearby break room. The walls are adorned with motivational posters and team photos, each one a testament to the shared experiences and achievements of the coaching staff. Teak-brown wooden tables, arranged in a horseshoe shape, stand at the center of the room, their glossy surfaces gleaming under the soft glow of overhead lights. Seven comfortable leather chairs are nestled around the tables, each occupied by a fellow coach, their heads bent together in earnest discussion. The coaches, a diverse group, are dressed in an assortment of casual attire — jeans, polo shirts, and sneakers — reflecting the informal yet focused atmosphere of the meeting. On the tables lie various pieces of equipment: four sleek mobile phones, two laptops with open email accounts, and a state-of-the-art desktop computer with a video conferencing software window open, displaying the faces of three more coaches joining virtually from different locations. The meeting room is bathed in a warm, welcoming light, with four recessed LED lights casting a soft glow around the room, creating an inviting ambiance. The large windows to the west illuminate the space with natural light, providing a glimpse of the lush training ground outside, where a dozen athletes are engaged in rigorous drills, their athletic bodies moving in synchronized harmony. The coaches, with their notebooks and pens scattered on the tables, are in the midst of a lively exchange, their voices animated as they debate various training strategies, player development plans, and upcoming match schedules. In the background, the low murmur of the other coaches creates a gentle melodic undercurrent, a symphony of expertise and collaboration. The door to the meeting room is slightly ajar, revealing glimpses of the bustling hallway beyond, where team managers and players pass by, engaged in their own preparatory tasks. The atmosphere is one of shared purpose and mutual respect, as each coach contributes their unique insights and experiences to the collective goal of propelling the team to new heights of excellence.', 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130027.38 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 42736.82 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 79216.74 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 126033.32 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 51294.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Business Operations Manager', 'process': 'Staff Supervision', 'situation': \"In the heart of a bustling company office, a Business Operations Manager begins their daily routine. Their office is a symphony of modernity and functionality, with a sleek, ergonomic desk supporting a high-performance computer and a state-of-the-art phone system. The room is adorned with a vibrant array of houseplants, lending a touch of nature to the otherwise industrial space. The nearby break room hums with the murmur of staff members, while the corporate lobby is alive with the comings and goings of colleagues and external stakeholders. On the manager's computer screen, rows of data dance in a well-organized spreadsheet. This is the beginning of another day spent supervising staff members, coordinating operations, reviewing work for quality and efficiency, and striving to achieve the company's business objectives.\", 'situation_json': '{\"location\": \"office\", \"environment\": \"bustling company office\", \"time\": \"daily routine\", \"equipment\": {\"computer\": \"high-performance computer\", \"phone_system\": \"state-of-the-art phone system\", \"desk\": \"ergonomic desk\"}, \"office_decor\": {\"plants\": \"vibrant array of houseplants\"}, \"surrounding_areas\": {\"break_room\": \"humming with staff murmurs\", \"lobby\": \"alive with comings and goings of colleagues and stakeholders\"}, \"computer_screen\": {\"data\": \"well-organized spreadsheet\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122125.73 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 129097.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84267.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sales Representative', 'process': 'Product Demonstrations', 'situation': 'In the heart of a bustling clinic, a Sales Representative meticulously prepares for a daily routine - a 1-hour product demonstration. The scene unfolds in a spacious conference room, filled with a comfortable assortment of chairs and tables, designed to accommodate up to 20 potential customers. The room is softly lit, with a warm, inviting ambience, created by the soft glow of the overhead lights reflecting off the cream-colored walls. \\n\\nThe Sales Representative, a polished professional, is dressed in a crisp, dark blue suit, with a vibrant red tie standing out against the neutral backdrop. He is surrounded by a neat array of tools, essential for the task ahead. To his left is a sleek, silver laptop, its screen glowing with the first slide of a meticulously crafted presentation. Next to it, a stack of 50 pristine, white brochures, neatly bound together with a navy blue ribbon. \\n\\nHis right side is occupied by a collection of product samples, each nestled in its own padded, black box. A total of 10, they range from small to large, each representing a different product in the company’s extensive range. \\n\\nIn the background, the quiet murmur of the waiting room can be heard, filled with a diverse crowd - children flipping through comic books, adults engrossed in magazines, and seniors in quiet conversation. The Sales Representative takes one final look around, ensuring everything is in place, before the first potential customer arrives. The stage is set for a successful product demonstration, aiming to increase sales and ensure customer satisfaction.', 'situation_json': '{\"room_description\": {\"size\": \"spacious\", \"max_capacity\": 20, \"lighting\": \"softly lit\", \"ambience\": \"warm, inviting\", \"wall_color\": \"cream-colored\", \"background_noise\": \"quiet murmur of waiting room\"}, \"sales_representative_description\": {\"clothing\": \"dark blue suit, vibrant red tie\", \"tools\": {\"laptop\": {\"color\": \"silver, sleek\", \"presentation_status\": \"first slide\", \"brochures\": {\"quantity\": 50, \"color\": \"pristine white\", \"binding\": \"navy blue ribbon\"}, \"product_samples\": {\"quantity\": 10, \"size_range\": \"small to large\", \"color\": \"black\", \"packaging\": \"padded\"}}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136143.91 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144860.41 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85148.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mental Health Counselor', 'process': 'Crisis Intervention', 'situation': \"Crisis Intervention is a short-term therapeutic process provided by Mental Health Counselors to help individuals in a state of psychological crisis stabilize and regain their ability to function. The process is done by first assessing the individual's mental and emotional state, then using various therapeutic techniques to help them cope with their current situation. The ultimate goal of Crisis Intervention is to prevent the individual from causing harm to themselves or others and to help them return to their usual level of functioning. The counseling room, a quiet and private space adorned with comfortable chairs, thus becomes the sanctuary where the Mental Health Counselor, equipped with a cream-colored notebook and an array of therapeutic techniques, meets with the Individual in crisis. The counselor’s hands swiftly turn the soft pages of the notebook, diligently scribbling observations and insights with a black ink pen. On a nearby desk, a laptop hums quietly, its screen displaying the patient’s records, ready to be updated as the session unfolds. The room is bathed in a gentle, warm light, filtered through the soft green leaves of a potted plant standing tall in the corner. Scattered throughout the space are various mental health resources, plush cushions, and tasteful paintings that complete the calming ambiance. In the adjacent waiting room, ten individuals quietly thumb through magazines, their faces a mix of anxiety and anticipation, while in the staff lounge, colleagues diligently prepare for their own sessions, sipping coffee and sharing insights over hushed conversations.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135974.64 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136403.51 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93171.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Computer Systems Analyst', 'process': 'System Analysis', 'situation': 'In the bustling indoor IT department, the Computer Systems Analyst sits at their spacious office desk. The desk is adorned with a top-of-the-line laptop, its sleek silver body contrasting with the white surface of the desk. A myriad of software tools, including project management software and design tools, are neatly arranged on the screen. Nearby, a high-speed printer hums quietly, ready to print the numerous documents that the analyst will need for their daily tasks. The analyst looks up from their laptop and glances around the room. In the corner, a large whiteboard stands, filled with colorful diagrams and charts from the previous brainstorming session. The analyst is surrounded by other analysts, each engrossed in their own tasks, creating a symphony of clicking keyboards and hushed conversations. The IT department is a hive of activity, with the constant buzz of discussions between analysts and management, all working towards the common goal of improving the company’s technological capabilities. The analyst turns their attention back to their laptop, ready to delve into another day of system analysis.', 'situation_json': '{\"location\": \"indoor IT department\", \"equipment\": {\"desk\": \"spacious office desk\", \"laptop\": \"top-of-the-line laptop\", \"printer\": \"high-speed printer\", \"whiteboard\": \"large whiteboard\"}, \"equipment_states\": {\"laptop\": {\"color\": \"sleek silver\", \"screen_contents\": [\"myriad of software tools\", \"project management software\", \"design tools\"]}, \"printer\": \"humming quietly\", \"whiteboard\": {\"contents\": [\"colorful diagrams and charts\"]}}, \"environment\": {\"noise_level\": \"symphony of clicking keyboards and hushed conversations\", \"co-workers_activity\": \"each engrossed in their own tasks\", \"bustling_level\": \"hive of activity\", \"discussion_level\": \"constant buzz of discussions\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138163.80 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140065.93 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90243.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Clinical Laboratory Technician', 'process': 'Equipment Maintenance', 'situation': 'In the sterile, immaculately organized laboratory, a Clinical Laboratory Technician meticulously attends to the equipment maintenance tasks. The space buzzes with a muted, purposeful energy, as the technician oversees the sterilization and calibration of equipment. A shiny, spotless microscope sits on the counter, its lens glinting under the harsh fluorescent lights, while nearby, the centrifuge hums steadily. The technician, clad in personal protective equipment, moves efficiently between tasks, ensuring every piece of equipment is in optimal condition. Each microscope, centrifuge, and biosafety cabinet is cleaned and inspected with meticulous attention to detail. Nearby, in the equipment storage area, rows of spare parts and cleaning supplies are carefully organized, ready for use. The biohazard waste area is a stark contrast, with bright yellow caution signs and sealed waste bins, a stark reminder of the importance of safety in this environment. Amidst this, the lab manager provides oversight, collaborating with the technician on workflow and safety protocols. Other technicians occasionally drop by, offering assistance and sharing resources. The doctor, engagement in consultations, and the nurse, preparing medical implements, occasionally cross paths with the technician, their professional duties intertwining seamlessly. The lab is a symphony of caution and precision, where every act is underpinned by the critical need for accuracy and reliability in medical testing.', 'situation_json': '{\"Equipment\": {\"Microscope\": {\"Cleanliness\": \"Spotless\", \"Condition\": \"Shiny\", \"Lens Appearance\": \"Glinting\", \"Location\": \"Counter\"}, \"Centrifuge\": {\"Operating State\": \"Humming Steadily\"}}, \"Lighting\": {\"Type\": \"Fluorescent\", \"Brightness\": \"Harsh\"}, \"Protective Clothing\": {\"Usage\": true}, \"Storage Area\": {\"Organization Level\": \"Carefully Organized\", \"Contents\": [\"Spare Parts\", \"Cleaning Supplies\"]}, \"Biohazard Waste Area\": {\"Signage\": {\"Color\": \"Bright Yellow\", \"Type\": \"Caution Signs\"}, \"Waste Bins\": {\"State\": \"Sealed\"}}, \"Professional Interaction\": {\"LabManager Oversight\": true, \"Technician Assistance\": true, \"Resource Sharing\": true, \"Doctor Consultation\": true, \"Nurse Preparation\": true}, \"Lab Environment\": {\"Energy\": \"Muted, Purposeful\", \"Atmosphere\": \"Symphony of Caution and Precision\", \"Importance\": \"Critical Need for Accuracy and Reliability in Medical Testing\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121516.23 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134108.96 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85295.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Financial Manager', 'process': 'Risk Management', 'situation': 'A process aimed at identifying, evaluating, and minimizing financial risk.', 'situation_json': '{\"data\": {\"Risk Type\": \"Financial\", \"Risk Level\": \"Medium\", \"Identification Status\": \"Identified\", \"Evaluation Status\": \"Evaluated\", \"Minimization Status\": \"Minimized\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120064.14 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150390.14 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 76161.32 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Art Director', 'process': 'Concept Development', 'situation': 'Nestled in the heart of the design studio, the Art Director sits at a sprawling desk, surrounded by an array of cutting-edge technology that shimmers under the soft glow of the ambient lighting. To their left, a sleek, state-of-the-art computer hums quietly, its dual monitors displaying a myriad of colorful digital designs and intricate graphics, a testament to their creator’s meticulous craftsmanship. Beside it, a Wacom drawing tablet lies ready, its smooth surface inviting the Art Director to bring their vision to life with a mere touch of their stylus. To the right, another powerful computer sits, connected to a large central monitor, all wired for the seamless creation and manipulation of digital artwork. About a dozen pristine dental mirrors adorn a nearby tray, their reflective surfaces gleaming amidst the clutter, hinting at the Art Director’s keen eye for precision and detail. The walls are adorned with an eclectic mix of vibrant posters, framed prints, and inspiring quotes that infuse the space with a creative energy. The Art Director is in constant motion, flitting between their desk and the communal design table where a diverse team of designers huddle, sketchpads and tablets scattered across the surface, engaged in lively debates and collaborative brainstorming sessions. Surrounding them, a quiet hum of activity permeates the air as the team members diligently work on their individual projects, fueled by the inspiration and guidance of the Art Director. Just outside the design studio, the meeting room buzzes with anticipation, six potential clients eagerly awaiting the unveiling of the latest project concept, while in the nearby budget meeting room, the Art Director and a handful of stakeholders gather to discuss fiscal strategies and resource allocation. The office atmosphere is a harmonious blend of focused work and vibrant exchanges, each element intertwined to foster an environment where creativity thrives and innovation flourishes.', 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 89370.82 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 120882.04 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86479.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dentist', 'process': 'Dental Examinations', 'situation': \"In the heart of a bustling city, nestled between towering skyscrapers, stands a quaint, inviting clinic. Inside, a seasoned dentist prepares for a series of dental examinations. The treatment room, bathed in soft, warm lighting, is meticulously clean and organized. The dentist's sterilized equipment, a testament to his commitment to hygiene, is neatly arranged on a stainless-steel tray. The tray is adorned with three shiny dental mirrors, their reflective surfaces ready to magnify the intricate details of the patients' teeth. Beside them, two sleek dental drills, their bits gleaming under the luminous light, stand tall, ready for any necessary procedures. A suction device, a scaler, and a dental light complete the ensemble. In the corner, an X-ray machine hums softly, its screen flickering with images of various patients' teeth. Meanwhile, the adjacent waiting room hums with activity. A group of six patients, their faces a mix of anticipation and anxiety, occupy the plush chairs, flipping through magazines to pass the time. The dental assistant, her gentle demeanor a welcome sight, attends to their needs. She guides them to their appointments, their names called out in a soothing, melodic tone.\", 'situation_json': '{\"location\": \"urban\", \"clinic_cleanliness\": \"meticulously clean\", \"number_of_dental_mirrors\": 3, \"dental_mirrors_state\": \"shiny\", \"number_of_dental_drills\": 2, \"dental_drills_state\": \"sleek with gleaming bits\", \"additional_equipment\": [\"suction device\", \"scaler\", \"dental light\"], \"x_ray_machine_state\": \"humming softly with flickering screen\", \"number_of_patients_waiting\": 6, \"patients_emotions\": [\"anticipation\", \"anxiety\"], \"waiting_room_state\": \"active\", \"magazines_state\": \"being flipped through\", \"dental_assistant_demeanor\": \"gentle\", \"dental_assistant_task\": \"attending to patients\\' needs\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131136.41 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150406.56 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94026.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Veterinary Technologist & Technician', 'process': 'Laboratory Testing', 'situation': \"In the bustling, sterile lab of a veterinary clinic, a Veterinary Technologist & Technician meticulously prepares for a day of laboratory testing. The lab is equipped with a high-powered microscope, gleaming under the bright fluorescent lights, and a humming centrifuge ready for action. A state-of-the-art blood analyzer beeps softly, awaiting the next sample. Nearby, the examination room is buzzing with activity as technicians collect specimens from various animal patients, each handled with gentle care and precise technique. The waiting area is filled with a mixture of anticipation and concern, as 10 pet owners wait patiently, hoping for answers and relief for their beloved companions. In the lab, the technician dons latex gloves and adjusts their protective gear, ensuring everything is in place before beginning the testing process. They carefully organize their equipment, including syringes, swabs, and sterile containers, all neatly lined up on the stainless-steel counter. The veterinarian, dressed in a crisp white coat, enters the lab, carrying a stack of paper charts and a laptop, ready to consult and discuss the results. In the corner, educational materials are displayed on a table, brochures and models arranged neatly for pet owners to learn more about their pets' health. The atmosphere is a blend of clinical professionalism and compassionate care, as the technician and veterinarian work together to ensure the utmost accuracy and reliability in their results, committed to providing the best possible care for their furry patients. The importance of this task is palpable as they know that the results of these tests could significantly impact the health and well-being of the animals in their care.\", 'situation_json': '{\"activity\": \"buzzing\", \"equipment\": [\"microscope\", \"centrifuge\", \"blood analyzer\", \"syringes\", \"swabs\", \"sterile containers\"], \"area\": {\"lab\": {\"lights\": \"bright fluorescent\", \"microscope\": \"high-powered\", \"centrifuge\": \"humming\", \"blood analyzer\": \"state-of-the-art\", \"surface\": \"stainless-steel\"}, \"examination_room\": {\"status\": \"buzzing with activity\"}, \"waiting_area\": {\"status\": \"filled with anticipation and concern\", \"occupancy\": 10}}, \"ambiance\": \"clinical professionalism and compassionate care\", \"safety_gear\": [\"latex gloves\", \"protective gear\"], \"materials\": {\"educational\": [\"brochures\", \"models\"]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120244.62 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144006.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 66376.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Massage Therapist', 'process': 'Inventory Management', 'situation': \"In the quiet, dimly lit massage room within the clinic, the Massage Therapist prepares for their daily inventory management task. On the sleek, sturdy massage table, six freshly laundered towels lay neatly folded, gently hugging a bottle of lavender-infused massage oil and three unopened tubes of soothing massage cream. Nearby, a sterilized set of ten needle-like tools awaits for their use in acupuncture therapy. In the office, the computer hums softly, displaying booking software that manages the therapist's busy schedule. The office administrator, a young professional in a crisp white shirt, quietly enters the room, ready to assist the therapist in this meticulous task. In the waiting room, three clients sit patiently, engrossed in magazines or staring at their phones, while soft music plays in the background.\", 'situation_json': '{\"room_settings\": {\"lighting\": \"dim\", \"background_music\": true, \"temperature\": \"not specified\"}, \"massage_table\": {\"state\": \"ready for use\", \"contains\": {\"towels\": {\"quantity\": 6, \"cleanliness\": \"freshly laundered\", \"organization\": \"neatly folded\"}, \"massage_oil\": {\"type\": \"lavender-infused\", \"quantity\": \"1 bottle\"}, \"massage_cream\": {\"quantity\": 3, \"condition\": \"unopened\"}}}, \"acupuncture_tools\": {\"quantity\": 10, \"state\": \"sterilized\"}, \"booking_software\": {\"status\": \"active\", \"location\": \"office\"}, \"office_administrator\": {\"present\": true, \"assistance_level\": \"ready to assist\"}, \"waiting_room\": {\"clients\": {\"quantity\": 3, \"patient_level\": \"patiently waiting\", \"engagement\": [\"reading magazines\", \"staring at phones\"]}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124775.75 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141748.35 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 72437.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Recreation & Fitness Worker', 'process': 'Nutritional Guidance', 'situation': \"In the heart of a bustling fitness center, surrounded by the rhythmic hum of cardio machines and the clanking of weights, a Recreation & Fitness Worker is engaged in a Nutritional Guidance session. The room, a designated consultation area, is a serene oasis amidst the flurry of activity, adorned with motivational posters and anatomical charts. The worker, a seasoned professional, is seated at a small desk, a clipboard with a pen and notes at the ready. A nutrition software glows softly on a nearby computer screen, tracking the client's food intake and analyzing their nutrient needs. The client, a dedicated gym-goer, is seated across the table, their eyes intently focused on the worker. In the corner, a basket of fresh fruits serves as a visual reminder of the importance of healthy eating. As the worker discusses the client's current diet and lifestyle, they occasionally glance at the heart rate monitor and stopwatch, visual cues of the upcoming fitness assessments. Nearby, a body composition analyzer and a set of weights stand ready, symbols of the client's commitment to their health and well-being.\", 'situation_json': '{\"room_description\": \"designated consultation area, serene oasis amidst the flurry of activity, adorned with motivational posters and anatomical charts\", \"equipment_states\": {\"nutrition_software\": \"glowing softly on a nearby computer screen, tracking the client\\'s food intake and analyzing their nutrient needs\", \"heart_rate_monitor\": \"present as a visual cue for upcoming fitness assessments\", \"stopwatch\": \"present as a visual cue for upcoming fitness assessments\", \"body_composition_analyzer\": \"present and ready for use\", \"weights\": \"present and ready for use\"}, \"other_details\": {\"fresh_fruits\": \"present in a basket\", \"clipboard_notes_pen\": \"present\", \"client_focus\": \"intently focused on the worker\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122677.27 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143227.33 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91039.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Pharmacy Technician', 'process': 'Pharmaceutical Compounding', 'situation': \"In a bustling indoor pharmacy, the Pharmacy Technician, clad in a crisp white lab coat, stands at their immaculate workstation in the compounding lab. The compounding lab, a separate and sterile area, houses various equipment, including the gleaming silver mortar and pestle on a tray, a precise digital balance, and a state-of-the-art compounding aseptic containment isolator. Nearby, the pharmacy counter, the bustling hub of the pharmacy, overflows with customers waiting to receive their prescription medications. Further back in the Storage Room, rows of medications are neatly organized and labeled, ready to be dispensed. Meanwhile, the technician's colleagues, comprised of three other Pharmacy Technicians and a supervising Pharmacist, engage in their respective tasks, adding to the hum of productivity. The Insurance Office, tucked away in the corner, is where insurance companies manage their clients' benefits and verify insurance coverage for pharmacies. The process of pharmaceutical compounding, which involves creating personalized medications, takes place approximately once an hour and lasts for about 30 minutes each time.\", 'situation_json': '{\"profession\": \"Pharmacy Technician\", \"process\": \"pharmaceutical compounding\", \"compounding lab\": {\"equipment\": [\"mortar and pestle\", \"digital balance\", \"compounding aseptic containment isolator\"], \"cleanliness\": \"sterile\", \"frequency of compounding\": {\"duration\": \"30 minutes\", \"frequency\": \"once per hour\"}}, \"pharmacy counter\": {\"activity\": \"dispensing prescription medications\", \"patient volume\": \"high\"}, \"storage room\": {\"state\": \"organized and labeled\"}, \"colleagues\": {\"number\": \"4\", \"roles\": [\"Pharmacy Technicians\", \"Pharmacist\"]}, \"insurance office\": {\"purpose\": \"managing clients\\' benefits and verifying insurance coverage\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]4,  4.52s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Epidemiologist', 'process': 'Policy Development', 'situation': 'In the heart of a bustling, urban research institution, an epidemiologist works tirelessly on policy development. Their office, a sanctuary of meticulous orderliness, houses a multitude of equipment. An imposing computer, humming with data and analysis, is flanked by a sleek laptop, its screen awash with statistical software and figures. A plethora of survey tools and data collection instruments are tactfully arranged on a nearby workbench, awaiting their turn in the process of data gathering and interpretation. The epidemiologist, donned in a crisp white lab coat, is often found here, engrossed in research papers and jotting down notes. Their colleagues, a motley crew of data analysts, public health professionals, and other epidemiologists, populate adjacent offices. They are a frequent presence, providing feedback and engaging in lively discussions. The distant murmur of a community outreach program can be heard, a testament to their collaborative efforts. Occasionally, they retreat to the tranquility of a secluded meeting room for brainstorming sessions and crucial decision-making. Amidst the constant hum of activity and the ceaseless pursuit of data, the epidemiologist is steadfast in their goal of shaping policy, a beacon of evidence-based insight in the labyrinth that is public health.', 'situation_json': '{\"location\": \"urban research institution\", \"equipment\": {\"computer\": \"imposing\", \"laptop\": \"sleek\", \"software\": [\"statistical\", \"analysis\"], \"survey tools\": \"plethora\", \"data collection instruments\": \"tactfully arranged\", \"workbench\": true}, \"personnel\": {\"epidemiologist\": true, \"lab coat\": \"white\", \"engrossed\": true, \"colleagues\": [\"data analysts\", \"public health professionals\"], \"meeting rooms\": true, \"brainstorming sessions\": true, \"policy development\": true, \"evidence-based\": true, \"community outreach program\": true}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paralegal', 'process': 'Case Management', 'situation': 'In the heart of a bustling yet serene office, nestled at a meticulously organized desk, I, a paralegal, find myself engrossed in the intricate dance of case management. The aroma of freshly brewed coffee from the room down the hall wafts intermittently through the air, while the soft hum of a nearby printer adds a rhythm to the otherwise quiet workspace. Surrounding me is a sea of legal tomes and towering stacks of documents, each whispering tales of cases past and present. The desktop, a sprawling expanse of oak, bears witness to my work: a high-definition monitor displays rows upon rows of complex legal texts, while a multi-function printer — its tray laden with an ever-shifting pile of at least fifteen documents — sits patiently nearby, ready to transform digital drafts into tangible evidence. To my left, a landline phone, its receiver cradled gently, awaits the next important call. Across the room, through the large glass window, I catch glimpses of colleagues at their own desks, their heads bent in concentration, fingers dancing on keyboards with the precision of pianists. Behind them, the law library — a sanctuary of knowledge — stands sentinel, its shelves sagging under the weight of legal precedents and statutes. The atmosphere is one of quiet efficiency, punctuated only by the occasional murmured conversation or the hushed turn of a page. This is the stage upon which I practice my craft, balancing the weight of legal research, document drafting, and client communications with the finesse of a circus act. The challenge lies in staying organized amidst the constant influx of new cases, each one bringing its own unique set of deadlines and complexities. Yet, in this environment, I thrive, fueled by the persistent quest for justice and the satisfaction of a job well done.', 'situation_json': '{}'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 84744.72 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 63463.37 examples/s]mples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 85005.82 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78365.28 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Client Communication', 'situation': \"In the heart of a bustling law firm, a lawyer is huddled over a sleek, silver laptop, its screen casting an ethereal glow upon their focused face. A pristine, white conference room lies just beyond the lawyer's private office, where a client patiently waits, their eyes drifting over the walls lined with books of case law and legal encyclopedias. The lawyer is using legal research tools on their laptop, their fingers dancing over the keyboard as they meticulously search for relevant case law, statutes, and regulations to build their case. Word processing software is also humming in the background, ready to draft persuasive legal documents and motions. The lawyer must maintain a high level of professionalism and respect, actively listening to the client's concerns and providing clear, concise legal advice while keeping them informed about the progress of their case. As the conversation unfolds, a sense of trust builds between the lawyer and the client, a crucial foundation for ensuring the client's legal needs are met.\", 'situation_json': '{\"laptop\": {\"color\": \"silver\", \"state\": \"on\", \"glow\": \"ethereal\", \"software_used\": [\"legal research tools\", \"word processing software\"]}, \"office\": {\"state\": \"private\", \"furnishing\": [\"books of case law\", \"legal encyclopedias\"], \"color\": \"pristine, white\"}, \"conference_room\": {\"state\": \"waiting\", \"client_state\": \"patient\", \"client_activity\": \"looking around\"}, \"lawyer_activity\": [\"using legal research tools\", \"typing\", \"providing legal advice\"], \"lawyer_demeanor\": \"professionalism and respect\", \"client_lawyer_interaction\": {\"type\": \"conversation\", \"building\": \"trust\"}}'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 78915.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 63794.25 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 72646.63 examples/s]mples]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 55751.18 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 82752.62 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82034.27 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 98138.86 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124256.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78024.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Database Administrator', 'process': 'Data Cleansing', 'situation': \"In the confines of a well-lit, climate-controlled server room, a dedicated Database Administrator is focused on the meticulous process of Data Cleansing. The room, designed to protect the high-end database servers from unauthorized access and environmental hazards, is the heart of the organization's data management. Nearby, the Network Operations Center (NOC) is bustling with activity, where network administrators and other database professionals work side by side to manage and monitor the organization's network performance. The Database Administrator turns their attention to the task at hand, using a powerful database management system and specialized data validation and verification tools to comb through vast data archives. They diligently identify data inconsistencies, duplications, and irregularities. Utilizing a robust set of data backup and recovery tools, the Database Administrator ensures that data integrity and consistency is maintained. The surrounding work environment is professionally quiet, punctuated only by the faint hum of server racks, as the Database Administrator continues their painstaking work, feeding crucial data into their validation tools while the clock ticks away.\", 'situation_json': '{\"environment\": \"server room\", \"environment_attributes\": {\"light\": \"well-lit\", \"climate_control\": \"enabled\"}, \"security_measures\": \"designed to protect from unauthorized access and environmental hazards\", \"equipment\": [\"database servers\", \"network operation center\"], \"equipment_states\": {\"noise_level\": \"professionally quiet\", \"server_racks\": \"faint hum\"}, \"tasks\": [\"data cleansing\", \"data validation\", \"data verification\"], \"tools_used\": [\"database management system\", \"data validation and verification tools\"], \"data_states\": [\"inconsistencies\", \"duplications\", \"irregularities\"], \"data_management_tools\": [\"data backup\", \"data recovery\", \"data validation tools\"], \"work_environment\": \"professionally quiet\", \"monitoring\": [\"network performance\", \"data integrity\", \"data consistency\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 113334.92 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134990.18 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94364.16 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Home Health Aide', 'process': 'Transportation', 'situation': \"In a cozy yet efficiently organized patient's bedroom, the Home Health Aide carefully assists the patient in preparing for transportation. The bedroom is adorned with warm, soothing colors and soft lighting, creating a comforting atmosphere. A key piece of furniture is the adjustable hospital bed, which is neatly made with crisp, clean sheets. Nearby, a bedside table holds a lamp, a small stack of books, and a glass of water, all arranged neatly.\\n\\nThe Home Health Aide uses a wheelchair for the transportation process. The wheelchair is well-maintained, with clean, grippy wheels and a comfortable, slightly worn seat cushion. The aide ensures the wheels are locked before helping the patient transfer from the bed to the wheelchair.\\n\\nIn the living room, the aide's colleague is busy preparing a light meal for the patient. The aroma of freshly cooked food wafts through the air, adding a homely touch to the scene. The living room is filled with comfortable furniture, including a plush sofa and a recliner, all arranged around a vintage coffee table. A few family members are present, engaging in quiet conversation while watching the aide's meticulous care.\\n\\nAfter securely settling the patient in the wheelchair, the aide proceeds to maneuver the wheelchair through the spacious hallway, lined with family photos and art prints, toward the living room. The hallway is well-lit with overhead lights and free of clutter, ensuring a smooth and safe ride.\\n\\nOutside, the vehicle stands ready, its interior clean and equipped for the patient's needs. The aide deftly handles the wheelchair ramp, ensuring the patient's comfortable and safe transition into the vehicle. The vehicle's interior is spacious and well-maintained, with a faint scent of lemon from a recent cleaning.\\n\\nThe entire process is carried out with the aide's gentle touch and reassuring words, ensuring the patient's comfort and ease throughout the journey.\", 'situation_json': '{\"patient_comfort\": true, \"patient_ease\": true, \"bedroom_ambience\": \"cozy\", \"bedroom_lighting\": \"soft\", \"bedroom_decor_colors\": \"warm\", \"bedroom_decor_details\": \"soothing\", \"bed_type\": \"hospital\", \"bed_state\": \"neatly made\", \"bed_sheets_state\": \"crisp and clean\", \"bedside_table_contents\": [\"lamp\", \"small stack of books\", \"glass of water\"], \"bedside_table_state\": \"neatly arranged\", \"wheelchair_state\": \"well-maintained\", \"wheelchair_wheels_state\": \"clean and grippy\", \"wheelchair_seat_cushion_state\": \"comfortable and slightly worn\", \"living_room_responsibility\": \"preparing light meal\", \"living_room_furniture\": [\"plush sofa\", \"recliner\", \"vintage coffee table\"], \"living_room_people\": \"few family members\", \"living_room_activity\": \"engaging in quiet conversation\", \"kitchen_aroma\": \"freshly cooked food\", \"hallway_state\": \"well-lit\", \"hallway_obstacles\": \"none\", \"hallway_decor\": \"family photos and art prints\", \"vehicle_interior_state\": \"clean\", \"vehicle_interior_preparation\": \"equipped for patient needs\", \"vehicle_interior_scent\": \"lemon\", \"wheelchair_ramp_state\": \"deftly handled\", \"aide_touch\": \"gentle\", \"aide_communication\": \"reassuring words\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139413.96 examples/s]ples]\n",
      "Filter:   0%|          | 0/4271 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Financial Analysis', 'situation': 'Every day, inside the financial department, a Management Analyst spends between 1 to 8 hours ensconced in their cubical, surrounded by the hues of corporate beige and grey, engaged in the process of Financial Analysis. Their high-end desktop computer, with its sleek black finish and a spectrum of analytical software programs, is the primary tool for this endeavor. The computer is supplemented by a variety of communication tools, including email, video conferencing, and instant messaging platforms, to foster collaboration with the financial analyst, manager, and IT support. The analyst also wields an arsenal of financial software, specialized tools for financial analysis, budgeting, and forecasting. Their office space houses an ergonomic chair and a clutter-free desk, upon which lies a neat row of reports and charts waiting to be deciphered. The faint hum of printers and hushed conversations filter in from the adjoining meeting rooms, where the analyst often presents their findings to the client. The break room, with its single-serve coffee machine and plush couches, is a hub for informal discussions and brainstorming sessions, while the library serves as a repository for research and accessing financial literature and databases.', 'situation_json': '{\"time_spent\": \"between 1 to 8 hours\", \"location\": \"financial department, cubical\", \"equipment\": {\"computer\": {\"description\": \"high-end desktop computer, sleek black finish\", \"software\": [\"analytical software programs\", \"email\", \"video conferencing\", \"instant messaging platforms\", \"financial software\", \"specialized tools for financial analysis, budgeting, and forecasting\"]}, \"office_space\": {\"chair\": \"ergonomic chair\", \"desk\": \"clutter-free desk\", \"materials\": [\"reports and charts\"]}, \"additional_equipment\": {\"break_room\": \"single-serve coffee machine, plush couches\", \"library\": \"research and accessing financial literature and databases\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133774.47 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77496.52 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Crisis Management', 'situation': \"In the bustling indoor headquarters of a prominent organization, a Public Relations Specialist is engrossed in the intricate process of crisis management. Amidst the hum of softly whirring computer fans, the specialist mans a sleek desktop computer, its screen adorned with spreadsheets, reports, and live updates from social media platforms. A state-of-the-art telephone, the lifeline to key stakeholders, rests nearby, its silence pregnant with anticipation. Adjacent to the workstation, the glossy conference room beckons, its wide windows offering a glimpse into the boardroom, where senior management is engaged in hushed discussions. Beyond the glass, the press room, with its podium and swarm of media personnel, buzzes with energy, a testament to the organization's commitment to transparency and effective communication. The specialist navigates this maze gracefully, crafting strategies, disseminating information, and maintaining relationships with a multitude of stakeholders, all while navigating the ever-changing landscape of the crisis.\", 'situation_json': '{\"location\": \"indoor headquarters\", \"building_description\": \"prominent organization\", \"electrical_equipment\": [{\"name\": \"desktop computer\", \"state\": \"on\", \"noise_level\": \"soft whirring\", \"activity\": \"manning\", \"user_interface\": [\"spreadsheets\", \"reports\", \"live updates\"], \"location\": \"workstation\"}, {\"name\": \"telephone\", \"state\": \"standby\", \"noise_level\": \"silent\", \"anticipation_level\": \"pregnant\", \"adjacent_location\": \"workstation\", \"connectivity\": \"key stakeholders\"}, {\"name\": \"conference_room\", \"state\": \"available\", \"features\": [\"wide windows\", \"boardroom\"], \"boardroom_activity\": \"senior management discussions\", \"noise_level\": \"hushed\", \"adjacent_location\": \"workstation\"}, {\"name\": \"press_room\", \"state\": \"buzzing\", \"features\": [\"podium\", \"media personnel\"], \"energy_level\": \"high\", \"communication\": \"transparent\", \"adjacent_location\": \"workstation\"}]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 95497.02 examples/s]les/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 92490.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73598.29 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 98749.84 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 110259.57 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89964.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sports Coach', 'process': 'Match Analysis', 'situation': \"In the grandiosity of a sprawling sports stadium, the Sports Coach meticulously prepares for the Match Analysis process. The stadium, an arena of dreams and aspirations, is filled with an air of anticipation. The outdoor location, under the canopy of the vast blue sky, offers a perfect backdrop for the post-match analysis. The duration of 2 hours is set aside for this crucial task. The coach, along with the team members, assistant coaches, and sports analysts, is surrounded by a multitude of equipment. The primary equipment, a top-of-the-line video camera, used for filming the match, stands ready on a sturdy tripod, its sleek black body gleaming in the stadium lights. The video analysis software, installed on a high-performance computer, awaits the uploading of the match footage. The computer, a state-of-the-art machine, is connected to a large, high-resolution monitor, providing a clear and detailed view of the footage. The desk on which these tools rest is neatly organized, the various cables and wires carefully arranged to avoid any potential tripping hazards. The nearby locker room, where team members are dressed in their team colors, is filled with an atmosphere of camaraderie and shared purpose. The spectator stands, though empty at this moment, bear the echoes of the cheers and jeers from the match, serving as a poignant reminder of the team's performance. The process of Match Analysis is not just about watching the match; it's about breaking down every single moment into its constituent parts, finding patterns, identifying strengths, and pinpointing weaknesses. It's a mental challenge that requires patience, critical thinking, and a deep understanding of the game. The Sports Coach, armed with the right tools, the right team, and a wealth of experience, is ready to tackle this challenge.\", 'situation_json': '{\"location\": \"outdoor\", \"location_details\": {\"stadium\": \"sports stadium\", \"sky\": \"vast blue sky\", \"locked_room\": \"nearby\", \"spectator_stands\": \"empty\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 117637.95 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 126230.48 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92105.61 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sales Representative', 'process': 'Sales Reporting', 'situation': 'In a bustling sales office filled with the focused hum of keyboards and muffled conversation, a sales representative meticulously crafts a weekly sales report. A sleek, silver laptop sits open on their well-organized desk, alongside a neat stack of brochures, some printed presentation slides, and a folder brimming with company data. The room is lined with the occasional dental mirror, their gleaming surfaces reflecting the purposeful activity of their colleagues. Just beyond the frosted glass door, a small waiting room buzzes with anticipation; a few potential clients chat casually, their eyes periodically flitting towards the meeting room. The waiting room, dotted with comfortable chairs and a well-thumbed magazine or two, is a testament to the importance of this process – Sales Reporting. This comprehensive hour-long process involves gathering and analyzing sales data, using a CRM software system, a company computer, and a work-grade phone, all geared towards identifying trends and making recommendations to improve performance. The final outcome is a detailed sales report, presented in the meeting room to the sales team and management. The sales representative deftly navigates this mental challenge, the weight of the outcome resting heavily on their shoulders.', 'situation_json': '{\"office_atmosphere\": \"bustling\", \"computing_equipment\": [\"sleek silver laptop\", \"CRM software system\", \"company computer\", \"work-grade phone\"], \"office_equipment\": [\"neat stack of brochures\", \"printed presentation slides\", \"folder brimming with company data\"], \"surrounding_area\": [\"dental mirror\", \"frosted glass door\", \"small waiting room\", \"comfortable chairs\", \"well-thumbed magazine\"], \"people_present\": [\"sales representative\", \"potential clients\", \"sales team\", \"management\"], \"time_spent_on_process\": \"hour-long process\", \"measurable_outcome\": [\"detailed sales report\"], \"mental_challenge\": true, \"importance\": \"heavily weighted outcome\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125271.52 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140176.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Business Operations Manager', 'process': 'Strategic Planning', 'situation': \"The Business Operations Manager, ensconced in their meticulously organized office, a sanctuary of order and focus, is engrossed in the intricate dance of strategic planning. The room, a symphony of polished mahogany and crisp, white walls, hums with the quiet efficiency of a well-oiled machine. The manager's eyes, reflecting the soft glow of the dual 4K monitors arrayed before them, flit between reams of data, each pixel a testament to their meticulous attention to detail. The desk, a expansive plane of gleaming wood, is a testament to their organizational prowess, with not a paper out of place amidst the sleek hum of state-of-the-art hardware. The air is filled with the faint whir of the high-end laptop, a machine of precision and power, designed to handle the complex algorithms and data analysis required for strategic planning. The room is a silent witness to the manager's intellectual rigor, a space where strategy is not merely discussed, but meticulously crafted, one data point at a time. The manager's fingers dance over the keyboard, a pianist playing a sonata of data entry, each keystroke a note in the symphony of strategic planning. The room, a temple of focus and concentration, is a stark contrast to the bustling office outside, a testament to the manager's ability to carve out a space of quietude amidst the storm of operations. The manager's phone, a sleek device of brushed metal and smooth glass, lies silent, a testament to their ability to manage expectations and maintain focus. The office, a haven of tranquility, is a reflection of the manager's inner peace, a space where they can lose themselves in the complex tapestry of strategic planning, one thread at a time.\", 'situation_json': '{\"office_decor\": \"polished mahogany, crisp white walls\", \"equipment\": {\"desk\": \"expansive mahogany desk\", \"monitors\": \"dual 4K monitors\", \"laptop\": \"high-end laptop\", \"phone\": \"sleek metal and glass phone\"}, \"ambient_noises\": [\"soft glow of monitors\", \"whir of laptop\", \"silence\"], \"manager_activities\": [\"engrossed in data\", \"attentive to detail\", \"data entry\"], \"office_atmosphere\": \"quiet efficiency\", \"contrast_with_outside\": \"bustling office\", \"manager_phone_state\": \"silent\", \"manager_mood\": \"focused\", \"planning_style\": \"meticulous\", \"data_analysis_tool\": \"complex algorithms\", \"data_entry_tool\": \"keyboard\"}'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/645 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86725.85 examples/s]mples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130971.65 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123240.52 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90904.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mental Health Counselor', 'process': 'Documentation', 'situation': 'In a cozy clinic, a Mental Health Counselor begins their daily documentation process. The counselor sits at a well-organized desk, adorned with a sleek black laptop and an array of office supplies. Next to the desk, a neat stack of five notepads and a dozen multicolored pens await usage. The counselor’s personal office, a serene and private space, is beautifully decorated with calming blue walls, comfortable seating, and a collection of plants. \\n\\nIn the waiting room just outside their office, three patients sit comfortably, engrossed in magazines or quietly engaged in their thoughts. Down the hall, in the staff lounge, three support staff enjoy their lunch break while two colleagues discuss an upcoming workshop. The counselor takes a deep breath and clicks open the laptop to begin the documentation process, reflecting on the past sessions and the progress of their clients.', 'situation_json': '{\"room_description\": {\"counselor_office\": {\"decoration\": {\"wall_color\": \"blue\", \"has_plants\": true}, \"chair_comfort\": \"comfortable\", \"equipment\": {\"laptop\": {\"on\": true}}, \"office_supplies\": {\"notepads\": 5, \"pens\": 12}}, \"waiting_room\": {\"occupancy\": 3}, \"staff_lounge\": {\"occupancy\": 5, \"meal_status\": true}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 92043.50 examples/s]les/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130224.94 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84299.08 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Computer Systems Analyst', 'process': 'System Integration', 'situation': 'In the bustling, fluorescent-lit IT department, our Computer Systems Analyst diligently works at their spacious office desk, surrounded by towering stacks of industry papers and textbooks that sprawl across the room like rolling hills. Among the equipment, a powerful laptop hums away, its pristine, brushed aluminum body reflecting the scattering of sharp, fluorescent lights that pour into the space. Punctuated among the clutter, the whiteboard is a brilliant swirl of colorful markers and notes, the result of countless brainstorming sessions and problem-solving attempts. The nearby meeting room, encased in clear, soundproof glass, awaits its next consultation with managers and users to oversee the installation and configuration of new systems. Just a few steps away, the server room stands, housing the beating heart of the computer systems, ready for essential access and maintenance. The integration journey may take between one to three months, but our systems analyst, with their mental acuity and unwavering dedication, is ready to navigate the complex challenge ahead.', 'situation_json': '{\"location\": \"IT department\", \"lighting\": \"fluorescent\", \"working_area\": \"spacious office desk\", \"surroundings\": \"stacks of industry papers and textbooks\", \"computer\": \"powerful laptop\", \"computer_color_and_material\": \"pristine, brushed aluminum\", \"whiteboard\": \"colorful with markers and notes\", \"meeting_room\": \"clear, soundproof glass\", \"server_room\": \"nearby\", \"system_integration_duration\": \"1-3 months\", \"professional_readiness\": \"mental acuity and unwavering dedication\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128638.20 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123427.33 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87582.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Clinical Laboratory Technician', 'process': 'Report Generation', 'situation': \"In the heart of a bustling clinic, within a meticulously organized laboratory, a Clinical Laboratory Technician is at work, immersed in the process of generating reports. The room is filled with an impressive array of equipment - four microscopes meticulously cleaned and calibrated, three centrifuges humming softly as they separate fluids based on density, and a biosafety cabinet standing tall, its clear glass windows offering a glimpse of the sterile environment inside. A spectrophotometer and an assortment of pipettes lie nearby, ready for use. The technician, dressed in the requisite personal protective equipment - a lab coat, gloves, safety goggles - moves with practiced ease between the equipment, occasionally glancing at the computer screen where data is being input, analyzed, and stored. Nearby localities include the sterile area, where sterile equipment is stored and handled, and the main laboratory area, where most of the equipment is located and maintained. The storage area, a room filled with shelves stacked high with sample containers, is also within view. The technician's colleagues, other laboratory technicians and a laboratory manager, are engaged in their own tasks, their focused expressions a testament to the importance of their work. The process of report generation is mentally challenging, a task that requires a keen eye for detail and a deep understanding of the laboratory procedures. Reports are generated hourly, a testament to the frequency and importance of this crucial process.\", 'situation_json': '{\"room_description\": \"meticulously organized laboratory\", \"equipment\": {\"microscopes\": 4, \"centrifuges\": 3, \"biosafety_cabinet\": 1, \"spectrophotometer\": 1, \"pipettes\": \"assortment\", \"computer\": 1, \"sterile_equipment_storage\": \"sterile area\", \"sample_container_storage\": \"storage area\"}, \"equipment_states\": {\"microscopes\": \"meticulously cleaned and calibrated\", \"centrifuges\": \"humming softly as they separate fluids based on density\", \"biosafety_cabinet\": \"clear glass windows offering a glimpse of the sterile environment inside\", \"spectrophotometer\": \"ready for use\", \"pipettes\": \"ready for use\", \"computer\": \"data being input, analyzed, and stored\", \"sterile_equipment_storage\": \"sterile equipment is stored and handled\", \"sample_container_storage\": \"shelves stacked high with sample containers\"}, \"personnel\": {\"technician\": 1, \"other_laboratory_technicians\": \"multiple\", \"laboratory_manager\": 1}, \"ppe\": {\"lab_coat\": 1, \"gloves\": 1, \"safety_goggles\": 1}, \"report_generation_frequency\": \"hourly\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127653.64 examples/s]es/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146824.19 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88475.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Financial Manager', 'process': 'Tax Planning', 'situation': \"In the hushed, fluorescent-lit confines of their office, the Financial Manager, a seasoned sage in the art of tax planning, finds themselves ensconced in their ergonomic, high-backed leather chair, the soft hum of the laptop before them breaking the silence. The laptop, a sleek, silver HP EliteBook, is open to complex tax planning software, its screen a labyrinth of charts, graphs, and intricate tax codes. Beside it, a well-thumbed, dog-eared copy of 'Mastering Tax Planning' by renowned financial expert, James J. Finkelson, lies open, a dog-eared testament to the Financial Manager's dedication to their craft. The calculator, a vintage, click-clacking Casio, sits ready for manual calculations, its surface worn smooth by years of use. The room, a sanctuary of order amidst the corporate chaos, is adorned with degrees and certifications, each frame a testament to the Financial Manager's hard-earned expertise. The clock on the wall, a sleek, modern piece, ticks away the seconds, each one bringing the Financial Manager closer to the deadline. The window, a narrow slit in the wall, offers a view of the bustling cityscape, the rain-kissed streets a stark contrast to the Financial Manager's quiet, contemplative world. The phone, a modern, sleek device, sits silent, a rare moment of peace in the usually ringing office. The Financial Manager, their glasses perched on their nose, their brow furrowed in concentration, is a picture of diligent focus, their fingers dancing on the keyboard, each keystroke bringing them one step closer to completing the intricate tax plan.\", 'situation_json': '{\"laptop_model\": \"HP EliteBook\", \"laptop_color\": \"silver\", \"software_state\": \"open, complex tax planning software\", \"book_title\": \"\\'Mastering Tax Planning\", \"book_author\": \"James J. Finkelson\", \"book_state\": \"well-thumbed, dog-eared, open\", \"calculator_model\": \"Casio\", \"calculator_state\": \"vintage, click-clacking, ready for manual calculations\", \"room_state\": \"orderly, adorned with degrees and certifications\", \"clock_model\": \"sleek, modern\", \"window_state\": \"narrow slit, view of bustling cityscape, rain-kissed streets\", \"phone_state\": \"modern, sleek, silent\", \"manager_state\": \"diligent focus, fingers dancing on keyboard\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 94232.85 examples/s]les/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 135085.87 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92002.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Art Director', 'process': 'Project Management', 'situation': \"In the quiet office environment of a bustling design agency, the Art Director sits at their clutter-free desk, a sleek computer adorned with cutting-edge design software serves as the creative hub of their operations. The surrounding team workspaces are filled with sketches, swatches, and 3D models, a testament to the ongoing project management tasks. The Art Director glances at their large digital calendar, packed with upcoming meetings in the various meeting rooms. A quick break in the nearby coffee area helps to clear their mind before delving back into the vibrant world of visual storytelling. They anticipate regular collaborative discussions with the creative team, including graphic designers and copywriters, as well as the marketing team who ensures the designs align with the brand's marketing strategy. The day-to-day tasks range from collaborative brainstorming in the brainstorming room, to presenting and discussing designs with clients in the designated client meeting rooms, all while maintaining a consistent visual direction for the project and ensuring completion within the set time and budget constraints.\", 'situation_json': '{\"environment\": \"office\", \"equipment\": {\"computer\": \"sleek\", \"software\": \"cutting-edge design software\"}, \"team_workspaces_content\": [\"sketches\", \"swatches\", \"3D models\"], \"calendar_status\": \"busy\", \"break_areas\": [\"coffee area\"], \"collaborations\": [\"graphic designers\", \"copywriters\", \"marketing team\"], \"meeting_rooms_usage\": \"regular\", \"client_meeting_rooms_usage\": \"presenting and discussing designs\", \"budget_constraints\": \"maintained\", \"time_constraints\": \"maintained\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'API key disabled. Enable it on https://openrouter.ai/keys', 'code': 401}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121099.35 examples/s]ples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144241.05 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84872.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dentist', 'process': 'Dental X-Rays', 'situation': 'In the heart of the bustling dental clinic, the intricate process of dental X-rays unfolds hourly. The main players here are the dentist, the dental assistant, and the patient. The dentist, equipped with their years of expertise, takes the lead, while the dental assistant stands close by, ready to provide support. The patient, the center of attention, tries to relax as they prepare for the procedure. The dental office plays a crucial role, providing the necessary equipment while ensuring a safe and comfortable environment. The X-ray machine, a marvel of technology, emits radiation to capture images of the teeth and gums. The dental chair, a symbol of comfort amidst the medical process, is adjusted to ensure the patient is comfortable. Nearby, a sterilization room hums with activity, the autoclave machine and chemical vapor sterilizer working tirelessly to sterilize equipment. The dental mirror, a seemingly simple tool, reflects the teeth and gums, providing a clear view for the dentist. The dental explorer, another crucial tool, detects cavities or decay, its sharp point probing for abnormalities. Meanwhile, the waiting room, a sanctuary for patients, is filled with a mix of anticipation and anxiety. The sterilization technicians meticulously follow sterilization protocols, their work ensuring the safety and wellbeing of the patients. Overall, the process of dental X-rays is a testament to the intricate dance between medical expertise, cutting-edge technology, and patient care that unfolds in the dental clinic.', 'situation_json': '{\"Dentist\": [\"expertise\", \"leading\"], \"Dental Assistant\": [\"supporting\", \"adjacent\"], \"Patient\": [\"relaxed\", \"preparing\"], \"X-ray Machine\": [\"operational\", \"emitting radiation\"], \"Dental Chair\": [\"adjusted\", \"comfortable\"], \"Autoclave Machine\": [\"operational\", \"sterilizing\"], \"Chemical Vapor Sterilizer\": [\"operational\", \"sterilizing\"], \"Dental Mirror\": [\"operational\", \"reflecting\"], \"Dental Explorer\": [\"operational\", \"probing\"], \"Waiting Room\": [\"occupied\", \"mixed emotions\"], \"Sterilization Protocols\": [\"followed\", \"meticulous\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno -2] Name or service not known\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno -2] Name or service not known\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131097.24 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144495.85 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92190.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Veterinary Technologist & Technician', 'process': 'Patient Examination', 'situation': 'In the heart of the bustling PetCare Clinic, a Veterinary Technologist & Technician is meticulously preparing for the daily patient examination process, a task they tackle with masterful precision at least thirty times a day. The examination room, bathed in the soft glow of fluorescent lights, is a symphony of organized chaos. On the gleaming stainless-steel countertop, an array of equipment lies in wait. Five dental mirrors, each polished to a brilliant shine, are laid out in a neat row on a sterile blue tray. Next to them, a pair of latex gloves and a digital thermometer are arranged, ready for use. Nearby, a stethoscope, its cool diaphragm gleaming, is poised for action. The room hums with an undercurrent of anticipation as the Veterinary Technologist & Technician dons the gloves and prepares to begin the examination.', 'situation_json': '{\"equipment\": {\"mirrors\": {\"count\": 5, \"state\": \"polished\", \"material\": \"dental\", \"position\": \"stainless-steel countertop\"}, \"gloves\": {\"count\": 1, \"material\": \"latex\"}, \"thermometer\": {\"state\": \"ready\", \"type\": \"digital\"}, \"stethoscope\": {\"state\": \"ready\", \"position\": \"nearby\"}}, \"lighting_state\": \"on\", \"lighting_type\": \"fluorescent\", \"examination_room\": \"organized chaos\", \"examination_countertop_material\": \"stainless steel\", \"examination_frequency\": 30}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134629.01 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139392.38 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94006.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Recreation & Fitness Worker', 'process': 'Personal Training Sessions', 'situation': \"In the bustling, well-equipped indoor gym, the Recreation & Fitness Worker aka the Personal Trainer, is gearing up for a 1-hour Personal Training Session. The gym is adorned with a plethora of exercise equipment neatly arranged and in pristine condition, ready for use. Weights of various sizes and colors (from a petite 2lb neon pink to a hefty 50lb deep blue) are stacked in a corner, while resistance bands in shades of green and orange hang on a nearby rack. Cardio machines, gleaming with a fresh sheen, stand at the ready - a treadmill with a wide, sturdy belt, an elliptical with grippy handles, a stationary bike with adjustable resistance levels, and a rowing machine with a smooth sliding seat. The nearby consultation room, with its soft, inviting chairs and a large desk, is where the initial assessment took place, where the client's fitness goals were determined and the customized exercise program was designed. The reception area, with its cheerful attendant, is where the client checked in, exchanging friendly banter before embarking on this fitness journey. The main challenge of the Personal Trainer throughout these Personal Training Sessions is to keep the client motivated and ensure their safety while performing exercises. The process takes place primarily in this indoor gym setting, with a regular frequency of 2-3 times a week. The equipment used in this process primarily centers around weights, resistance bands, and cardio machines to ensure a holistic fitness routine. The localities involved in this process are the workout area where the actual workout takes place, the consultation room where the initial assessment and program design take place, and the reception area where the client checks in. The overarching setting supporting this process is the fitness facility itself, which is clean, organized, and well-equipped, a true testament to the commitment to fitness and health. The people involved in this process are the Personal Trainer, guiding the client through each exercise with meticulous precision and unwavering encouragement, the client, focused and determined to reach their fitness goals, and potential other fitness staff, providing support and expert advice.\", 'situation_json': '{\"gym_condition\": \"well-equipped and clean\", \"equipment_condition\": \"pristine\", \"weights_range\": [2, 50], \"weights_colors\": [\"neon pink\", \"deep blue\"], \"resistance_bands_colors\": [\"green\", \"orange\"], \"cardio_machines\": [\"treadmill\", \"elliptical\", \"stationary bike\", \"rowing machine\"], \"treadmill_belt_condition\": \"wide and sturdy\", \"elliptical_handles_condition\": \"grippy\", \"stationary_bike_resistance\": \"adjustable\", \"rowing_machine_seat_condition\": \"smooth sliding\", \"consultation_room_furniture\": [\"soft chairs\", \"large desk\"], \"reception_area_presence\": true, \"reception_area_attendant\": true, \"personal_trainer_challenge\": \"keeping the client motivated and safe\", \"session_duration\": 60, \"session_frequency\": \"2-3 times a week\", \"equipment_used\": [\"weights\", \"resistance bands\", \"cardio machines\"], \"locality_workout_area\": true, \"locality_consultation_room\": true, \"locality_reception_area\": true, \"fitness_facility_condition\": \"clean, organized, and well-equipped\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 115737.15 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131096.94 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95007.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paralegal', 'process': 'Discovery Process', 'situation': 'As a paralegal working in the bustling office of a law firm, I am deeply engrossed in the intricate process of Discovery. This process, a cornerstone of any legal case, allows both parties to uncover and exchange vital information before the trial. My functional computer, a hub of legal research and documentation, sits on my well-organized desk. To its right is a state-of-the-art printer, a silent witness to my countless hours of drafting and editing legal documents. Nearby, a library brimming with legal tomes and updated statutes provides a rich resource for my meticulous research. In the quiet ambiance of this indoor law firm, I often meet with clients, attorneys, and witnesses in the spacious conference room, a testament to the collaborative nature of my profession. Within these walls, amidst the flurry of phone calls, emails, and document reviews, I play a crucial role in the Discovery process, helping attorneys gather and organize information, request and review documents, and draft crucial legal documents such as interrogatories and deposition notices. The mental challenge of this process, coupled with the flexible yet rigorous timelines, makes every day a new adventure in my professional journey.', 'situation_json': '{\"situation\": \"The situation is set in a law firm where the paralegal is engaged in the Discovery process. The paralegal has a functional computer on a well-organized desk, and a state-of-the-art printer to the right of it. Nearby is a library with legal tomes and updated statutes. The law firm has a spacious conference room used for meetings. Communication is done via phone calls, emails, and document reviews. Crucial legal documents such as interrogatories and deposition notices are drafted. The mental challenge and flexible yet rigorous timelines make the process adventurous.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130131.15 examples/s]examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147056.81 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88516.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Pharmacy Technician', 'process': 'Prescription Processing', 'situation': \"In the midst of the bustling pharmacy, a skilled Pharmacy Technician is diligently working at the dispensing counter. The counter is a polished, wooden surface, meticulously organized with various pieces of essential equipment. A sleek, modern computer sits prominently, its screen displaying the prescription software that the technician is using to process and track prescriptions. The computer's keyboard is slightly worn from constant use, and the mouse clicks rhythmically as the technician navigates through the software. A scanner is tucked neatly to the side, ready to process any hard-copy prescriptions that come in.\\n\\nBehind the counter, the medication dispensing system hums softly, its automated mechanisms ensuring accurate dispensing of medications. The system is equipped with advanced safety features to prevent any medication errors and ensure accurate dosing. The sound of the system's gentle hum is almost soothing amid the background noise of the pharmacy.\\n\\nThe pharmacy counter is where the technician interacts with customers, answering their queries about medications and handling transactions. The counter is tall and spacious, designed to allow easy interaction while maintaining a professional distance. A few customers are gathered in the waiting area, seated on comfortable chairs, their expressions a mix of patience and contemplation.\\n\\nBeyond the counter, the pharmacy store stretches out, filled with rows of neatly labeled shelves and storage units. These units are carefully organized to prevent mix-ups and facilitate easy access to the medications. The air is filled with a sense of orderliness and efficiency, reflecting the diligence of the Pharmacy Technician and their colleagues.\\n\\nIn the background, the Pharmacist-in-Charge oversees the entire process, ensuring the accuracy of the filled prescriptions. Their presence is reassuring, providing guidance and support to the technician. Other pharmacy technicians are busy at their workstations, their focused expressions reflecting the importance of their tasks. Each workstation is equipped with similar equipment, all working harmoniously to ensure the smooth operation of the pharmacy.\\n\\nThe atmosphere is a blend of professionalism and calm, the kind that comes with the knowledge that every detail is being meticulously handled. The Pharmacy Technician continues their work, their fingers dancing over the keyboard as they enter prescription data, their eyes scanning the screen for any discrepancies. Their dedication to the task at hand is evident, and it is clear that they take pride in their role, knowing that their work has a direct impact on the well-being of their customers.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119017.17 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130371.84 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81094.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Massage Therapist', 'process': 'Marketing and Promotion', 'situation': 'As a Massage Therapist, I am responsible for providing therapeutic massages to clients to improve their physical and emotional well-being. During the Marketing and Promotion process, I create and implement marketing strategies to attract new clients and retain existing ones. This includes identifying target markets, developing promotional materials, and utilizing social media platforms to reach potential clients.', 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 116718.80 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150099.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93941.46 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Epidemiologist', 'process': 'Public Health Education', 'situation': 'In a bustling public health department, an Epidemiologist sits at their desk surrounded by stacks of papers, files, and folders. The room is filled with the soft hum of their computer, a vital tool for the data analysis and report writing that they conduct continuously. The nearby community center, a hub for educational programs and resource distribution, is a frequent source of data and collaboration. Their focus is drawn to the screen before them, where statistical software is open, analyzing the latest wave of data. In the meeting room down the hall, they occasionally meet with colleagues - public health professionals, data analysts, and researchers - to discuss the implications of their findings and strategies for public health initiatives. The air is thick with the palpable sense of purpose, as they work tirelessly to identify patterns and understand the causes of disease and injury, in order to promote community health and prevent the spread of illness.', 'situation_json': '{\"room_description\": \"bustling\", \"computer_state\": \"humming\", \"equipment\": [\"computer\", \"statistical software\"], \"collaboration_hub\": \"community center\", \"meeting_location\": \"meeting room down the hall\", \"meeting_frequency\": \"occasionally\", \"team_members\": [\"public health professionals\", \"data analysts\", \"researchers\"], \"focus\": \"analyzing data on screen\", \"purpose\": \"promote community health and prevent the spread of illness\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130306.53 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 151089.04 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88429.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Client Consultation', 'situation': 'You are a lawyer sitting behind a sturdy mahogany desk in your plush, yet professionally equipped office. The walls are lined with towering bookshelves filled with legal tomes and case law reports, their spines worn from years of use. The room is illuminated by both the soft, natural light filtering through the large windows and the warm glow of the desk lamp, creating a cozy, studious ambiance. On your desk lies a bright yellow legal pad, with scribbled notes from your preparation, and a sleek, silver pen resting beside it. Your laptop is open, displaying the meticulously organized time tracking software, word processing software, and billing software you use to manage your cases efficiently. The cursor blinks steadily on the screen, waiting for your next command.\\n\\nAcross from you, a client sits in a comfortable leather chair, their face etched with concern. They look around the room, taking in the framed diplomas and certificates hanging on the wall, evidence of your extensive education and expertise. The air is filled with a mix of anticipation and the faint scent of old books and freshly brewed coffee from the nearby kitchen.\\n\\nBehind the closed door, the hum of activity from the rest of the law firm can be heard—phones ringing, printers whirring, and the hushed conversations of your colleagues. The support staff, including paralegals and legal assistants, are diligently working, ensuring every detail of the cases is meticulously handled. The atmosphere is one of focused, professional energy, underscored by the importance of the legal matters being handled.\\n\\nYou take a deep breath, ready to dive into the client consultation, knowing that the next hour will be crucial in understanding their needs and developing a strategic plan tailored to their unique legal situation.', 'situation_json': '{\"text\": \"You are a lawyer sitting behind a sturdy mahogany desk in your plush, yet professionally equipped office. The walls are lined with towering bookshelves filled with legal tomes and case law reports, their spines worn from years of use. The room is illuminated by both the soft, natural light filtering through the large windows and the warm glow of the desk lamp, creating a cozy, studious ambiance. On your desk lies a bright yellow legal pad, with scribbled notes from your preparation, and a sleek, silver pen resting beside it. Your laptop is open, displaying the meticulously organized time tracking software, word processing software, and billing software you use to manage your cases efficiently. The cursor blinks steadily on the screen, waiting for your next command.\\\\n\\\\nAcross from you, a client sits in a comfortable leather chair, their face etched with concern. They look around the room, taking in the framed diplomas and certificates hanging on the wall, evidence of your extensive education and expertise. The air is filled with a mix of anticipation and the faint scent of old books and freshly brewed coffee from the nearby kitchen.\\\\n\\\\nBehind the closed door, the hum of activity from the rest of the law firm can be heard\\\\u2014phones ringing, printers whirring, and the hushed conversations of your colleagues. The support staff, including paralegals and legal assistants, are diligently working, ensuring every detail of the cases is meticulously handled. The atmosphere is one of focused, professional energy, underscored by the importance of the legal matters being handled.\\\\n\\\\nYou take a deep breath, ready to dive into the client consultation, knowing that the next hour will be crucial in understanding their needs and developing a strategic plan tailored to their unique legal situation.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 91942.27 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136213.70 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81576.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Database Administrator', 'process': 'Data Migration', 'situation': 'In the heart of the bustling data center, a Database Administrator is engrossed in the intricate task of data migration. Surrounded by a symphony of humming servers, the room radiates a cool blue glow from the ample LED screens. The Database Administrator meticulously navigates through rows of equipment; database management software with its sleek black interface, backup software quietly whirring away, and powerful data migration tools poised for activation. To the left, a group of three developers huddle around a monitor, their faces a tableau of concentration as they collaborate with the Database Administrator to ensure seamless application compatibility with the new database schema. Meanwhile, two system administrators are stationed near a glass walled network operations center, their eyes scanning the fluctuating data traffic, ready to intervene if necessary to maintain the integrity of the migration. The challenge is a mental one, as the Database Administrator orchestrates this intricate dance of data, ensuring minimal disruption for the dozens of users who depend on the availability of their data.', 'situation_json': '{\"description\": \"In the heart of the bustling data center, a Database Administrator is engrossed in the intricate task of data migration. Surrounded by a symphony of humming servers, the room radiates a cool blue glow from the ample LED screens. The Database Administrator meticulously navigates through rows of equipment; database management software with its sleek black interface, backup software quietly whirring away, and powerful data migration tools poised for activation. To the left, a group of three developers huddle around a monitor, their faces a tableau of concentration as they collaborate with the Database Administrator to ensure seamless application compatibility with the new database schema. Meanwhile, two system administrators are stationed near a glass walled network operations center, their eyes scanning the fluctuating data traffic, ready to intervene if necessary to maintain the integrity of the migration. The challenge is a mental one, as the Database Administrator orchestrates this intricate dance of data, ensuring minimal disruption for the dozens of users who depend on the availability of their data.\", \"num_developers\": 3, \"num_system_administrators\": 2, \"led_screens_glow\": \"cool blue\", \"data_traffic_status\": \"fluctuating\", \"application_compatibility\": \" ensures seamless application compatibility with the new database schema\", \"backup_software_state\": \"quietly whirring away\", \"migration_tools_state\": \"poised for activation\", \"users_impact\": \"minimal disruption for the dozens of users\", \"data_center_ambiance\": \"symphony of humming servers\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129620.43 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132190.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96860.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'IT Manager', 'process': 'Data Backup', 'situation': \"IT Manager is responsible for overseeing and managing the IT department. This involves coordinating the daily operations of the IT department, ensuring that the company's IT infrastructure is up-to-date and secure, and managing the IT budget. The IT Manager also plays a strategic role in aligning IT with the company's business objectives and providing innovative IT solutions. Additionally, the IT Manager provides leadership and mentoring to the IT team and represents the IT department in company-wide projects and meetings. The outcome of the process is a well-managed and efficient IT department that supports the company's business goals.\", 'situation_json': '{\"responsibilities\": [\"Oversees and manages IT department\", \"Coordinates daily IT operations\", \"Ensures IT infrastructure is up-to-date and secure\", \"Manages IT budget\", \"Aligns IT with business objectives\", \"Provides innovative IT solutions\", \"Leads and mentors IT team\", \"Represents IT department in company-wide projects and meetings\"], \"outcome\": \"Well-managed and efficient IT department supporting business goals\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 116965.59 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134109.96 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 98275.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Market Research', 'situation': \"In the heart of a bustling corporate office, a Management Analyst is engrossed in a continuous mental challenge, conducting a meticulous market research process. They are surrounded by the indispensable tools of their trade - a sleek computer humming with data, and a set of comprehensive survey tools. The office is a symphony of efficiency, with cubicles housing the market research team, each member diligently collecting, analyzing, and interpreting data from consumers. The management is present, engaged in a constructive dialogue with the analyst about the company's strategic goals. Nearby, the waiting room is filled with a dynamic mix of consumers, clients, and colleagues, all essential elements of the research process. The office environment, while maintaining an air of professional formality, is also dotted with informal spaces, like the coffee area, where employees brainstorm and discuss industry trends.\", 'situation_json': '{\"office_environment\": \"corporate office\", \"office_activity\": \"meticulous market research process\", \"office_tools\": \"computer, survey tools\", \"office_teams\": \"market research\", \"management_present\": true, \"waiting_room\": \"active\", \"waiting_room_occupants\": \"consumers, clients, colleagues\", \"office_espaces\": [\"cubicles\", \"formal work spaces\", \"informal spaces\"], \"informal_spaces\": [\"coffee area\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 92287.71 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 122402.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92287.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sports Coach', 'process': 'Player Motivation', 'situation': 'The indoor sports stadium bustles with energy as the sports coach focuses on the task of player motivation. Perched on a desk in the corner, the coach overlooks the vast expanse of the training ground where the team practices. The desk is filled with various equipment - a clean, whiteboard stands tall, bearing yesterday’s strategies and the results of the last game. A pristine clipboard rests beside it, with scribbled notes and practice plans. \\n\\nThe coach’s computer hums softly, the screen displaying a detailed schedule of upcoming games, training sessions, and team meetings. Nearby, a phone sits, its screen illuminating with notifications about athlete performance and updates from fellow coaches. \\n\\nThe training ground is a testament to the team’s dedication, with multiple sets of weights neatly stacked on the racks, ready for strength training exercises. Bright, orange training cones are arranged in various formations, marking the boundaries for agility and speed drills. A sturdy, black stopwatch lies dormant, waiting to be activated for timing these drills. \\n\\nA first aid kit is prominently displayed on the wall, a symbol of preparedness in case of injuries. The locker room, located nearby, offers a space for athletes to prepare before training sessions, while the water station ensures they stay hydrated throughout. The training facilities themselves, well-maintained and equipped, provide a conducive environment for athletes to hone their skills and strength. \\n\\nThe spectator stands, empty at the moment, serve as a reminder of the support and pressure that will fuel the team’s motivation during games. The coach’s dedication to the process of player motivation is evident in the meticulous planning, regular feedback, and positive training environment that they strive to cultivate. They are always on the lookout for innovative ways to inspire and encourage the team, ensuring their best potential is reached.', 'situation_json': '{\"situation\": \"The indoor sports stadium bustles with energy as the sports coach focuses on the task of player motivation. Perched on a desk in the corner, the coach overlooks the vast expanse of the training ground where the team practices. The desk is filled with various equipment - a clean, whiteboard stands tall, bearing yesterdayu2019s strategies and the results of the last game. A pristine clipboard rests beside it, with scribbled notes and practice plans. The coachu2019s computer hums softly, the screen displaying a detailed schedule of upcoming games, training sessions, and team meetings. Nearby, a phone sits, its screen illuminating with notifications about athlete performance and updates from fellow coaches. The training ground is a testament to the teamu2019s dedication, with multiple sets of weights neatly stacked on the racks, ready for strength training exercises. Bright, orange training cones are arranged in various formations, marking the boundaries for agility and speed drills. A sturdy, black stopwatch lies dormant, waiting to be activated for timing these drills. A first aid kit is prominently displayed on the wall, a symbol of preparedness in case of injuries. The locker room, located nearby, offers a space for athletes to prepare before training sessions, while the water station ensures they stay hydrated throughout. The training facilities themselves, well-maintained and equipped, provide a conducive environment for athletes to hone their skills and strength. The spectator stands, empty at the moment, serve as a reminder of the support and pressure that will fuel the teamu2019s motivation during games. The coachu2019s dedication to the process of player motivation is evident in the meticulous planning, regular feedback, and positive training environment that they strive to cultivate. They are always on the lookout for innovative ways to inspire and encourage the team, ensuring their best potential is reached.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 105604.19 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130857.53 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96587.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Carpenter', 'process': 'Client Consultation', 'situation': \"In the heart of the bustling carpentry workshop, the 30-minute client consultation process unfolds. The carpenter, a skilled craftsperson, greets the client with a warm smile, ushering them into a cozy consultation room. The room, a quiet and private space, is adorned with two comfortable high-back chairs and a spacious table, its surface covered in neat stacks of sketches and designs. The air is filled with the comforting scent of freshly cut wood and varnish. On the wall, a measuring tape hangs, a testament to the meticulous precision required in the profession. Nearby, a sketch pad sits atop a small side table, its pages filled with hand-drawn diagrams and sketches of past projects. The carpenter, with a measuring tape and pencil in hand, listens intently as the client describes their vision for their home, their eyes lighting up in excitement and anticipation. The consultation process is a verbal dance, a delicate balance of active listening, communication, problem-solving, and collaboration. The goal is to create a design that not only satisfies the client's needs but also fits their budget and meets safety and quality standards. The client's satisfaction is the ultimate reward for the carpenter.\", 'situation_json': '{\"location\": \"carpentry workshop\", \"process_duration\": \"30\", \"process_location\": \"consultation room\", \"room_description\": \"quiet and private space\", \"room_furniture\": \"comfortable high-back chairs and a spacious table\", \"table_description\": \"surface covered in neat stacks of sketches and designs\", \"room_scents\": \"freshly cut wood and varnish\", \"wall_items\": \"measuring tape\", \"side_table_items\": \"sketch pad filled with hand-drawn diagrams\", \"professional_tools\": \"measuring tape and pencil\", \"consultation_purpose\": \"client describing their vision for their home\", \"professional_goals\": \"satisfy client\\'s needs, fit budget and meet safety and quality standards\", \"client_satisfaction\": \"goal\", \"professional_emotions\": \"excitement and anticipation\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131441.28 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 146006.85 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95382.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Event Planning', 'situation': 'In the heart of a bustling downtown district, the event organization office occupies the top floor of a modern, glass skyscraper, bathed in the warm glow of the setting sun. Amidst a constellation of blinking computer screens and the soft, rhythmic tap-tapping of fingers on keyboards, a Public Relations Specialist, adorned in a chic, tailored suit, meticulously crafts communication strategies for the upcoming event. Flanked by two expansive windows offering a panoramic view of the urban jungle, the specialist immerses himself in the challenge of portraying the event in the best possible light.\\n\\nThe hum of the office is punctuated by the occasional beep of the ringing phone, as the specialist connects with various media outlets, from newspapers to television stations. Dotted around the room, in neat, ergonomic chairs, sit a team of four event planners, each absorbed in their respective tasks, as a myriad of promotional posters and event banners adorn the otherwise minimalist office walls. \\n\\nThe event venue, a grand ballroom in a historic, ivy-covered hotel, is on the specialist’s mind as he navigates the complex web of coordination, promotion, and media liaison. In the midst of it all, the dreamy image of the venue’s ornate chandeliers and sumptuous velvet drapes provides a fitting inspiration for the narrative the specialist spins to the expectant public.', 'situation_json': '{\"location\": \"downtown district skyscraper\", \"office_floor\": \"top\", \"office_structure\": \"modern glass\", \"office_lighting\": \"warm glow of the setting sun\", \"number_of_computers\": \"numerous\", \"computer_status\": \"blinking\", \"keyboard_status\": \"soft, rhythmic tap-tapping of fingers\", \"specialist_appearance\": \"chic tailored suit\", \"specialist_activity\": \"crafting communication strategies\", \"specialist_view\": \"panoramic view of urban jungle\", \"number_of_phones\": \"one\", \"phone_status\": \"occasionally ringing\", \"number_of_planners\": \"four\", \"planners_activity\": \"absorbed in their respective tasks\", \"planner_chairs\": \"neat, ergonomic chairs\", \"office_decor\": \"minimalist with promotional posters and event banners\", \"venue_location\": \"grand ballroom in a historic ivy-covered hotel\", \"venue_decor\": \"ornate chandeliers and sumptuous velvet drapes\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 94545.08 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143244.51 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95889.34 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Counselor', 'process': 'Group Counseling', 'situation': 'In the heart of a bustling school, inside a cozy cubical, a seasoned School Counselor immerses themselves in the daily ritual of Group Counseling. A group of eight students, as lively and diverse as a rainbow, gather around an oval table, their bright eyes and attentive faces focused on the counselor. Used to this task, the counselor skillfully navigates the group dynamics, employing their trusty notebook and an arsenal of educational materials: worksheets, handouts, and books, neatly stacked on a corner of the table, are readily available to be used in the various group activities planned for the session. The sourroundings are quiet and serene, the classroom next door delivering only muffled sounds, ensuring the students can fully engage in the session. The counseling office, with its warm and inviting ambiance, doubles as a safe haven where students can freely express their emotions and thoughts. In this sanctuary, the counselor, like a conductor guiding an orchestra, guides the students through a myriad of role-playing exercises, group discussions, and team-building activities, skillfully balancing the need to address personal challenges and improve academic performance. As they step up to this daily challenge, their ultimate goal is to foster a sense of community and trust among the students, enhancing their self-awareness, self-esteem, and coping skills, while also promoting positive peer relationships.', 'situation_json': '{\"location\": \"counseling office\", \"environment\": \"quiet and serene\", \"table_shape\": \"oval\", \"number_of_students\": 8, \"counselor_materials\": [\"notebook\", \"worksheets\", \"handouts\", \"books\"], \"classroom_sounds\": \"muffled\", \"classroom_distance\": \"next door\", \"office_ambiance\": \"warm and inviting\", \"group_activities\": [\"role-playing exercises\", \"group discussions\", \"team-building activities\"], \"session_goals\": [\"foster a sense of community\", \"enhance self-awareness\", \"improve academic performance\", \"promote positive peer relationships\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 118464.31 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 151626.16 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83361.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mental Health Counselor', 'process': 'Initial Assessment', 'situation': \"In the heart of the bustling clinic, the Mental Health Counselor's office stands as a sanctuary of calm, a stark contrast to the hum outside its doors. The office, adorned with warm, earthy tones, exudes an aura of tranquility, inviting clients to shed their anxieties and open up. The counselor, a master of their craft, sits attentively, their eyes reflecting a profound empathy that puts even the most hesitant souls at ease. Their desk, a testament to their organized mind, bears a laptop, its screen displaying the client's file, and a notepad, its pages filled with neat, insightful scribbles. A box of tissues, a small, considerate detail, sits within arm's reach, ready to catch the tears that sometimes flow in this sacred space. The room's only adornment is a bookshelf, filled with tomes of psychology, their spines bearing the names of the greats - Freud, Jung, Rogers - a silent testament to the counselor's intellectual journey. The clock's steady tick echoes through the room, each second marking a progress in the client's journey towards healing. The waiting room, a mere step away, is a symphony of soft chatter and the rustling of magazines. A handful of clients, each lost in their own thoughts, await their turn. The staff lounge, a haven for counselors to recharge, is filled with the aroma of freshly brewed coffee and the low hum of hushed conversations. Here, they share stories, exchange insights, and support each other, a testament to the camaraderie in this profession of healers. The administrative office, a hub of activity, is where the counselor spends hours, their fingers dancing on the keyboard as they update records, their eyes scanning documents as they ensure the smooth running of the clinic. The library, a treasure trove of knowledge, is where the counselor retreats when they need to immerse themselves in a new perspective, a new theory, a new way to help. The coffee shop, a quiet nook, is where they reflect, where they process the day's sessions, where they find solace in the simple act of sipping a cup of coffee. The therapy room, the heart of the clinic, is where the magic happens. It's a space filled with plush cushions, soft lighting, and a counselor who is ready to listen, to understand, to heal. The client, a person with their own unique story, their own unique struggles, sits across from the counselor, ready to take the first step towards healing. The counselor, with their notepad and pen, is ready to listen, to understand, to support. The room is filled with a sense of anticipation, a sense of hope, a sense of a new beginning. The clock on the wall ticks away the seconds, each one bringing the client one step closer to their journey of healing and self-discovery.\", 'situation_json': '{\"office_decoration\": \"warm, earthy tones\", \"office_atmosphere\": \"calm, inviting\", \"counselor_attitude\": \"attentive, empathetic\", \"desk_items\": [\"laptop\", \"notepad\", \"tissues\"], \"bookshelf_contents\": \"psychology tomes\", \"clock_ticking\": \"steady\", \"waiting_room_sounds\": \"soft chatter, magazine rustling\", \"staff_lounge_aroma\": \"freshly brewed coffee\", \"admin_office_activity\": \"updating records, scanning documents\", \"library_purpose\": \"immersion in new perspectives\", \"coffee_shop_purpose\": \"reflection, processing\", \"therapy_room_atmosphere\": \"soft lighting, plush cushions\", \"client_readiness\": \"ready to take the first step\", \"counselor_readiness\": \"ready to listen, understand, support\", \"therapy_room_sensations\": \"sense of anticipation, hope, new beginning\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134025.34 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142557.14 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85608.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Computer Systems Analyst', 'process': 'Technology Research', 'situation': 'In the bustling indoor environment of the technology company, the Computer Systems Analyst sits at their spacious office desk, illuminated by the cool glow of their high-powered laptop. The desk is a testament to their daily 8-hour grind, cluttered yet organized with stacks of research papers, client reports, and project proposals printed from the nearby high-speed printer. A whiteboard stands nearby, filled with scribbled diagrams and flowcharts, a stark visualization of their mental challenges. The office is often filled with the hum of discussion from meeting rooms where they frequently engage with clients, project managers, developers, and end-users, understanding their needs and resolving their issues. Amidst the serene humdrum of the office, they occasionally step into the sterile server room, a stark contrast to their office, filled with the gentle hum of servers and networking equipment. Here, they access and maintain the main systems, their lifeline for effective solutions. Their laptop, equipped with project management software and testing tools, is their constant companion, aiding them in their daily tasks of designing, testing, and debugging systems.', 'situation_json': '{\"location\": \"indoor environment of a technology company\", \"equipment_state\": {\"laptop\": \"high-powered, illuminated\", \"desk\": \"spacious and cluttered yet organized\", \"research papers\": \"stacks of\", \"client reports\": \"stacks of\", \"project proposals\": \"stacks of\", \"printer\": \"high-speed\", \"whiteboard\": \"filled with scribbled diagrams and flowcharts\", \"server room\": \"sterile, filled with the gentle hum of servers and networking equipment\", \"servers\": \"access and maintain\", \"laptop_software\": \"equipped with project management software and testing tools\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131538.21 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 148855.55 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84694.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Clinical Laboratory Technician', 'process': 'Safety Compliance', 'situation': 'In the sterile, controlled environment of the hospital laboratory, Clinical Laboratory Technicians diligently follow safety protocols and guidelines to ensure the safe handling, storage, and disposal of hazardous materials. The laboratory is a bustling hub of activity, filled with the hum of centrifuges and the occasional beep of a spectrophotometer. The main laboratory area is lined with gleaming microscopes, essential for examining specimens at a microscopic level. There are five high-powered microscopes, each meticulously cleaned and calibrated, standing tall on the stainless-steel countertops. Nearby, three centrifuges spin silently, their movements barely perceptible yet crucial for separating components of samples based on density. A biosafety cabinet, essential for protecting the technicians and the environment from hazardous biological materials, stands in the corner, its glass frontage reflecting the fluorescent lights overhead. The lab technician, garbed in full personal protective equipment (PPE), including gloves, a lab coat, and safety goggles, moves methodically through the space, ensuring that all lab personnel adhere to safety regulations and procedures. The sterile area, a dedicated space for handling and storing sterile equipment, is immaculately organized, with shelves stocked with carefully labeled vials and containers. Beside it, the preparation area is a hive of activity, where reagents and control samples are meticulously prepared. The technician carefully measures out liquids using pipettes, which are crucial for accurate dispensing. In the corner, a spectrophotometer sits, its modern design contrasting with the more traditional equipment, used to measure the absorbance of light by a sample for quantitative analysis. The biohazard waste disposal area, where hazardous materials such as biohazardous waste, chemical waste, and radioactive waste are disposed of, is clearly marked and maintained with rigorous standards. Nearby, the decontamination room is functional, with various medical instruments being cleaned, recycled, and disinfected for further use. The laboratory manager, overseeing the operations, provides guidance and ensures that all safety protocols are followed to the letter. Surrounding the technician are other laboratory technicians, each focused on their tasks, collaborating on daily tasks and sharing resources efficiently. The technicians move with practiced ease, their training and knowledge evident in their precise and coordinated actions. Outside the laboratory, the corridor is quiet, contrasting with the focused energy within. The hospital laboratory is a place where precision meets safety, where every action is guided by protocols designed to ensure the well-being of all involved.', 'situation_json': '{\"main_area_environment\": \"sterile\", \"main_area_equipment\": {\"microscopes\": {\"present\": true, \"types\": [\"high-powered\"], \"count\": 5, \"state\": \"cleaned\", \"position\": \"stainless-steel countertops\"}, \"centrifuges\": {\"present\": true, \"count\": 3, \"state\": \"spinning silently\"}}, \"biosafety_cabinet\": {\"present\": true, \"protection_level\": 3, \"position\": \"corner\", \"state\": \"active\"}, \"sterile_area\": {\"present\": true, \"state\": \"organized\", \"contents\": {\"vials_and_containers\": {\"present\": true, \"labeled\": true}}}, \"preparation_area\": {\"present\": true, \"state\": \"active\", \"tools\": {\"pipettes\": {\"present\": true, \"state\": \"active\"}}}, \"spectrophotometer\": {\"present\": true, \"layout\": \"modern\", \"position\": \"corner\", \"state\": \"active\"}, \"biohazard_waste_disposal_area\": {\"present\": true, \"state\": \"maintained\", \"types\": [\"biohazardous waste\", \"chemical waste\", \"radioactive waste\"]}, \"decontamination_room\": {\"present\": true, \"state\": \"functional\", \"contents\": {\"medical_instruments\": {\"cleaned\": true, \"cycled\": true, \"disinfected\": true}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114028.80 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142135.24 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92140.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Glazier', 'process': 'Customer Consultation', 'situation': \"A 30-minute customer consultation is taking place in the customer's office, an indoor location replete with a sea of paper-strewn desks and framed landscapes on its sun-drenched walls. The glazier, a tall, muscular individual with a workman's tan, is seated across from the customer, a clean-shaven middle-aged man in a tailored suit. Two laptops, one belonging to each of them, sit open on the desk, displaying a kaleidoscope of glazing options. A measuring tape, with its cold metallic sheen, lies coiled in front of the glazier, ready for action. Behind the glazier stands a ladder, a silent sentinel of a dozen rungs, waiting patiently for the moment it will be needed. The soporific hum of the air conditioner in the corner, churning out a steady stream of chilled air, is the only sound in the otherwise quiet room, lending a soothing ambience to the scene. The glazier, with a confident air, alternates between typing on his laptop and clicking his pen, a well-worn accessory that he uses to scratch notes on a yellow legal pad. Occasionally, his gaze flickers towards the customer, who looks on with rapt attention, his fingers steepled in front of him, as if in deep thought.\", 'situation_json': '{\"location\": \"indoor office\", \"duration\": \"30 minutes\", \"participants\": [\"customer\", \"glazier\"], \"description\": {\"office\": {\"desks\": \"paper-strewn\", \"walls\": \"sun-drenched\", \"decorations\": [\"framed landscapes\"]}, \"lighting\": \"sun-drenched\", \"equipment\": {\"laptops\": 2, \"ladders\": 1, \"measuring_tape\": true, \"air_conditioner\": true, \"pen\": true, \"legal_pad\": true}, \"sounds\": [\"soporific hum of air conditioner\"], \"atmosphere\": \"soothing\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 90309.61 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142674.08 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92870.79 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Art Director', 'process': 'Quality Control', 'situation': 'An Art Director is an expert in the creative process of producing artwork and directing others to produce artwork. In Quality Control, the Art Director ensures that the artwork produced meets the required standards and adheres to the creative vision set out at the beginning of the project. This involves reviewing work, providing feedback, and making sure that the final output is of high quality.', 'situation_json': '{\"art_director_role\": \"expert\", \"creative_process\": \"producing_artwork\", \"directing_others\": \"true\", \"quality_control_process\": \"ensuring_standards\", \"adheres_to_vision\": \"true\", \"reviewing_work\": \"true\", \"providing_feedback\": \"true\", \"final_output_quality\": \"high\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132141.61 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136759.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92442.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dentist', 'process': 'Equipment Sterilization', 'situation': 'In the heart of a bustling dental clinic, the hum of the autoclave machine serves as a constant reminder of the crucial process of Equipment Sterilization. The sterilization room, a pristine sanctuary of cleanliness, houses a myriad of equipment, including an autoclave machine and a chemical vapor sterilizer, each awaiting their turn to ensure the sterility of the instruments. Adjacent to this room, the treatment room stands as a testament to the professionalism of the clinic, with its immaculate dental chairs and sparkling dental mirrors, a total of six, neatly arranged on a stainless steel tray. The room, although buzzing with activity, maintains an air of tranquility, as the dentist and the dental assistants meticulously go about their tasks, ensuring that each dental mirror and explorer is cleaned and disinfected before being sterilized. The high-frequency sound waves of the ultrasonic cleaner echo in the room, as the disinfectant solutions, a total of five bottles, work tirelessly to kill any bacteria and viruses. Meanwhile, in the waiting room, a total of eight patients, each with their unique stories, await their turn, their gazes occasionally drifting towards the imaging room, where the dental lab supports the process by providing the necessary equipment and materials. The process, although time-consuming, lasting approximately 1-2 hours daily, is of utmost importance, ensuring the safety and health of each patient.', 'situation_json': '{\"location\": \"dental clinic\", \"rooms\": {\"sterilization room\": {\"equipment\": [\"autoclave machine\", \"chemical vapor sterilizer\"], \"state\": \"pristine\", \"purpose\": \"sterilization\"}, \"treatment room\": {\"equipment\": [\"dental chairs\", \"dental mirrors\"], \"quantity\": 6, \"arrangement\": \"neatly arranged on a stainless steel tray\", \"atmosphere\": \"tranquil\", \"activity\": \"buzzing\"}, \"waiting room\": {\"occupancy\": 8}, \"imaging room\": {\"support\": \"dental lab\"}}, \"equipment states\": {\"autoclave machine\": \"humming\", \"chemical vapor sterilizer\": \"idle\", \"dental chairs\": \"immaculate\", \"dental mirrors\": \"sparkling\", \"ultrasonic cleaner\": \"emitting high-frequency sound waves\", \"disinfectant solutions\": \"working to kill bacteria and viruses\"}, \"timing\": {\"duration\": \"1-2 hours daily\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129739.41 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 132635.42 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79316.47 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Veterinary Technologist & Technician', 'process': 'Radiography', 'situation': 'In a bustling veterinary clinic, the air hums with the rhythm of daily routines and the occasional symphony of a distressed pet from the waiting room. The Radiology Room stands as the heart of diagnosis, a sanctuary bathed in the sterile glow of fluorescent lights, where the state-of-the-art X-ray machine hums softly, ready for the next round of critical imaging. On a sleek stainless steel tray, meticulously organized, lie the positioning aids—five cushioned supports of various sizes, all neatly arranged. Adjacent to them, six freshly sanitized lead aprons hang on sturdy hooks, awaiting their wearers. Three protective lead gloves rest on the counter, each pair carefully checked for any signs of wear. On a small, organized shelf, three thyroid shields are aligned, their polished surfaces reflecting the overhead lights. In the corner, a compact but robust monitoring system displays real-time data, its screen flickering with readouts. Beyond the confines of this room, the clinic buzzes with activity. The waiting area, teeming with anxious pet owners, is a sea of eighteen faces, each twice as worried. In the adjacent examination rooms, ten veterinary technologists and technicians, dressed in crisp navy-blue scrubs, perform their duties with practiced efficiency. Across the hall, in the consultation room, five veterinarians, clad in immaculate white coats, discuss findings with concerned owners in hushed, reassuring tones. Meanwhile, in the treatment areas, eight technicians tend to patients with constant, caring hands, ensuring every need is met. The quieter spaces—the lab and the pharmacy—hum with the diligent work of technicians analyzing samples and preparing medications, respectively. The atmosphere is a blend of concern, care, and clinical precision, all merged seamlessly to ensure the best possible outcomes for the beloved pets who walk through the doors.', 'situation_json': '{\"electrical_equipment_states\": {\"x_ray_machine\": {\"on\": true}, \"monitoring_system\": {\"on\": true, \"display_live_data\": true}}, \"measurable_observable_data\": {\"number_of_positioning_aids\": {\"on_tray\": 5}, \"number_of_aprons\": {\"hanging_on_hooks\": 6}, \"number_of_gloves\": {\"on_counter\": 3}, \"number_of_shields\": {\"on_shelf\": 3}, \"number_of_patients\": {\"in_waiting_area\": 18}, \"number_of_technologists_technicians\": {\"in_exam_room\": 10}, \"number_of_veterinarians\": {\"in_consultation_room\": 5}, \"number_of_technicians\": {\"in_treatment_areas\": 8}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 126259.67 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130909.17 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94727.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paralegal', 'process': 'Document Preparation', 'situation': \"Inside the quiet, organized confines of the law firm, a paralegal begins their daily Document Preparation process. Their pristine, spacious office is adorned with a sturdy oak desk, upon which sits a state-of-the-art computer - essential for drafting and editing legal documents. Nearby, a laserjet printer hums softly, ready to bring those documents to life. The paralegal's fingers dance skillfully across the keyboard, navigating through legal research software and document management systems, their eyes scanning multiple screens filled with a myriad of legal texts and databases. Surrounded by the soft humming of office equipment and the occasional rustling of papers, the paralegal is deeply engrossed in their task. Their work requires meticulous attention to detail and a thorough understanding of legal jargon, as they prepare and organize legal documents for lawyers and maintain open lines of communication with clients and other relevant parties.\", 'situation_json': '{\"office_environment\": \"quiet and organized\", \"office_space\": \"spacious\", \"desk_material\": \"oak\", \"computer_state\": \"state-of-the-art and functioning\", \"printer_state\": \"laserjet, humming softly and ready to print\", \"keyboard_state\": \"being used\", \"screens_state\": \"multiple, filled with legal texts and databases\", \"office_noise_level\": \"soft humming of office equipment and occasional rustling of papers\", \"paralegal_task\": \"deeply engrossed in their task, preparing and organizing legal documents\", \"paralegal_responsibilities\": \"meticulous attention to detail, legal jargon understanding, maintaining communication with clients and relevant parties\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 94746.21 examples/s]s/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 107479.79 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92972.92 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Recreation & Fitness Worker', 'process': 'Planning Fitness Programs', 'situation': \"In the bustling gym/fitness center, a dedicated Recreation & Fitness Worker is huddled over a clipboard, pen in hand, meticulously planning a fitness program. The air is filled with the hum of treadmills, the rhythmic whirring of stationary bikes, and the clanging of weights being lifted to build strength and muscle mass. The worker looks over at the array of equipment at their disposal - the gleaming treadmills, the sturdy stationary bikes, the colorful resistance bands, and the neatly stacked weights - each piece waiting to be incorporated into the program. They are joined by fellow fitness staff, ready to provide guidance and support. The room is a sea of activity, with clients of all ages and fitness levels participating in the fitness programs, their faces a mix of determination and satisfaction. The worker makes a note of the heart rate monitor and stopwatch, essential for measuring the clients' progress and ensuring they are pushing their limits safely. The body composition analyzer is not far off, ready to provide detailed insights into the clients' body fat percentage, muscle mass, and bone density. The worker glances around the gym, ensuring the screwdrivers and wrenches are in their toolbox for immediate equipment maintenance, and the cleaning supplies and lubricant are ready to keep the equipment in pristine condition. The room is a symphony of fitness, each element working together to support the clients in their journey towards improved health and well-being.\", 'situation_json': '{\"treadmills_status\": \"humming\", \"stationary_bikes_status\": \"whirring rhythmically\", \"weights_usage\": \"being lifted\", \"equipment_condition\": \"gleaming\", \"staff_availability\": true, \"heart_rate_monitors_presence\": true, \"stopwatch_presence\": true, \"body_composition_analyzer_presence\": true, \"tools_availability\": true, \"cleaning_supplies_availability\": true, \"lubricant_availability\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 123489.30 examples/s] examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 149441.67 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92530.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Pharmacy Technician', 'process': 'Regulatory Compliance', 'situation': 'In a bustling pharmacy, the Pharmacy Technician is stationed at the prescription counter, surrounded by an array of equipment. The counter is cluttered yet organized, with a computer system taking center stage, its screen glowing with the familiar prescription software interface. To the left, a medication dispensing system stands ready, its automated count-and-package mechanism gleaming under the fluorescent lights. Nearby, a scanner awaits its turn for hard-copy prescriptions. The room hums with activity as customers wait patiently in the designated waiting area, their eyes occasionally darting towards the counseling room, where a private session is underway. The insurance office, a separate yet integral part of the pharmacy, is busy with its own operations. In the background, a group of co-workers are engaged in a hushed discussion, their faces marked with the intensity of the task at hand - regulatory compliance.', 'situation_json': '{\"Pharmacy Technician\": null, \"profession\": \"Pharmacy Technician\", \"process\": \"Regulatory Compliance\", \"equipment\": [{\"type\": \"computer system\", \"status\": \"powered on\", \"interface\": \"prescription software\", \"location\": \"center stage\"}, {\"type\": \"medication dispensing system\", \"status\": \"ready\", \"mechanism\": \"automated count-and-package\", \"location\": \"left\"}, {\"type\": \"scanner\", \"status\": \"awaiting\", \"purpose\": \"hard-copy prescriptions\", \"location\": \"nearby\"}, {\"type\": \"fluorescent lights\", \"status\": \"on\"}, {\"type\": \"waiting area\", \"status\": \"occupied\", \"customers\": \"patiently waiting\"}, {\"type\": \"counseling room\", \"status\": \"in use\", \"activity\": \"private session\"}, {\"type\": \"insurance office\", \"status\": \"busy\", \"operations\": \"own\"}], \"co-workers\": {\"status\": \"engaged\", \"topic\": \"regulatory compliance\", \"intensity\": \"high\"}, \"noise level\": \"humming\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125109.42 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139474.86 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93593.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Massage Therapist', 'process': 'Sanitizing Equipment', 'situation': 'In a bustling, albeit calming, massage clinic, the professional massage therapists meticulously carry out the task of sanitizing their equipment after each session. The clinic, imbued with a comforting sense of tranquility, has multiple treatment rooms, each carefully designed to ensure the utmost relaxation. Each room houses a singular massage table, its padding pristine and accommodating to different body types and heights, and nearby stands a cabinet stocked with massage lotions, creams, and oils to ease the therapeutic process. Towels of varying sizes are a common sight, used to cover clients and maintain their dignity and warmth. Within the clinic, a hushed quiet pervades, broken only by the occasional murmur of soft conversations and the distant hum of a computer system running specialized booking software. The waiting room adjacent to the reception area is elegant, decorated with vibrant yet soothing artwork, comfortable chairs, and tasteful lighting. Visible to the massage therapists, it is a space designed to welcome and calm clients before their appointments. Meanwhile, the staff are active in various tasks, with the therapists sanitizing their equipment diligently. A distinct scent of antiseptic wafts through the air as they ensure every tool is clean and ready for the next session. Clients sitting in the waiting room watch the staff with a sense of reassurance knowing that their needs are being attended to with the utmost care.', 'situation_json': '{\"equipment\": {\"type\": \"Massage Equipment\", \"treatment room\": {\"massage table\": {\"padding\": \"pristine\", \"accommodating\": \"different body types and heights\"}, \"cabinet\": {\"stock\": [\"massage lotions\", \"creams\", \"oils\"]}}, \"sanitization status\": {\"tables\": \"clean\", \"tools\": \"clean\"}, \"status\": \"sanitized\"}, \"environment\": {\"tranquility\": \"comforting\", \"waiting room\": {\"decor\": {\"artwork\": {\"type\": \"vibrant\", \"aesthetic\": \"soothing\"}, \"chairs\": \"comfortable\", \"lighting\": \"tasteful\"}, \"visibility\": \"visible to massage therapists\", \"status\": \"active with clients\"}, \"sound\": {\"hushed quiet\": {\"interrupted by\": [\"occasional murmurs of soft conversations\", \"distant hum of computer system\"]}}, \"scent\": {\"smell\": \"distinct antiseptic\"}}, \"clients\": {\"status\": \"reassured\"}, \"time\": {\"process\": \"after each session\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124020.51 examples/s]examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 125714.03 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 98393.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Database Administrator', 'process': 'Data Security', 'situation': \"In the midst of the bustling IT department, a Database Administrator is fiercely dedicated to their daily routine of safeguarding the organization's data. Surrounded by the hum of a powerful network infrastructure and a plethora of monitors displaying various system diagnostics, the DBA can be found in a meticulously organized office space. Among the numerous equipment, a top-tier computer with an impressive array of 8GB RAM and a quad-core processor stands out as the centerpiece. This machine, adorned with a sleek 27-inch monitor, serves as the primary tool for managing the intricate database management system (DBMS). The DBA meticulously deploys MySQL, Oracle, and Microsoft SQL Server software to ensure seamless data flow and accessibility. Nearby, a server room houses the physical servers that host the databases. In order for the DBA to maintain the servers' smooth operation, the server room is equipped with advanced cooling and power systems to protect against environmental hazards and unauthorized access. However, this daily challenge is not without interaction as the DBA actively collaborates with the broader IT team and end-users to meet the specific needs of the organization. This includes supporting software developers in creating applications that utilize the database, as well as network administrators in ensuring secure data transfer between systems and users. With an unwavering focus on performance, integrity and security, the DBA works tirelessly for 8 hours each day to ensure the database, and all its potential, is fully realized.\", 'situation_json': '{\"profession\": \"Database Administrator\", \"process\": \"Data Security\", \"equipment\": {\"computer\": {\"ram\": \"8GB\", \"processor\": \"quad-core\", \"monitor\": \"27-inch\", \"software\": [\"MySQL\", \"Oracle\", \"Microsoft SQL Server\"]}, \"server_room\": {\"features\": [\"advanced cooling\", \"power systems\"], \"security\": \"protection against unauthorized access\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131355.88 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137612.71 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85260.83 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Performance Evaluation', 'situation': \"In the heart of a bustling corporate office, a Management Analyst is engrossed in the intricate process of Performance Evaluation. The analyst is nestled in the quiet confines of an office room, illuminated by the soft glow of the desk lamp. The room is adorned with a modest laptop, its screen filled with performance evaluation forms and employee data. Nearby, a printer hums softly, ready to bring these digital forms into physical reality. A slightly more imposing computer sits in the corner, its screen displaying complex project management software, a testament to the analysts' dedication to strategy and efficiency. The room is a sanctuary of productivity, a stark contrast to the bustling waiting room just outside, where employees, their faces a blend of anticipation and nervousness, await their turn for evaluation.\", 'situation_json': '{\"location\": \"corporate office\", \"room_description\": \"quiet confines of an office room\", \"lighting\": \"soft glow of the desk lamp\", \"equipment\": [\"modest laptop\", \"printer\", \"imposing computer\"], \"laptop_details\": {\"screen_content\": \"performance evaluation forms and employee data\", \"location\": \"desk\"}, \"printer_details\": {\"status\": \"humming softly\", \"location\": \"nearby\"}, \"computer_details\": {\"screen_content\": \"complex project management software\", \"location\": \"corner\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137428.36 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150745.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93116.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Epidemiologist', 'process': 'Report Writing', 'situation': 'An epidemiologist, tucked away in their cluttered office within a bustling public health department, is deeply engrossed in the task of report writing for several hours. Their desk, a testament to their dedication, is adorned with a myriad of equipment - a robust computer, a sophisticated statistical software, and an assortment of data collection tools. The computer, with its high-performance processor and large screen, is heavily utilized for meticulous data analysis, while the statistical software is indispensable for the intricate statistical analysis of data. Nearby, public health facilities, teeming with information, are accessible resources for the epidemiologist to study. Within the department, the epidemiologist interacts with a host of professionals - from other epidemiologists, providing valuable feedback, to public health professionals, collaborating on various projects. Their day-to-day tasks are mentally challenging, as they strive to reduce the risk and occurrence of health outcomes. The epidemiologist often works alongside healthcare professionals, gathering data, and community members, sourcing information on health trends and risk factors. This daily routine unfolds against a backdrop of constant collaboration and data analysis.', 'situation_json': '{\"location\": \"public health department\", \"equipment\": {\"computer\": {\"specs\": \"high-performance processor and large screen\", \"usage\": \"meticulous data analysis\"}, \"statistical software\": {\"usage\": \"intricate statistical analysis of data\"}, \"data collection tools\": {\"usage\": \"gathering data\"}}, \"resources\": {\"public health facilities\": {\"usage\": \"study\", \"status\": \"accessible\"}}, \"interactions\": {\"professionals\": {\"epidemiologists\": {\"nature\": \"feedback\"}, \"public health professionals\": {\"nature\": \"collaboration\"}}, \"community members\": {\"nature\": \"information sourcing\"}}, \"tasks\": {\"report writing\": {\"duration\": \"several hours\", \"challenge level\": \"mentally challenging\"}, \"risk reduction\": {\"target\": \"health outcomes\"}}, \"work environment\": {\"background\": \"constant collaboration and data analysis\"}, \"workspace\": {\"description\": \"cluttered office\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125729.52 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136349.52 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90904.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Court Appearances', 'situation': \"A lawyer meticulously prepares for their court appearance in a bustling courtroom. Their polished mahogany desk is adorned with a neat stack of legal documents, each neatly organized and highlighted with bright fluorescent tabs. A state-of-the-art laptop sits atop the desk, its screen illuminated with various legal databases and open case files. The room is filled with a hushed murmur of hushed conversations, punctuated by the occasional rustle of papers or the soft click of heels against the tiled floor. The lawyer's colleagues are scattered about the room, their faces etched with a mixture of concern and determination. The air is thick with anticipation as the lawyer takes a deep breath, ready to present their case before the esteemed judge and attentive jury.\", 'situation_json': '{\"description\": \"A lawyer meticulously prepares for their court appearance in a bustling courtroom. Their polished mahogany desk is adorned with a neat stack of legal documents, each neatly organized and highlighted with bright fluorescent tabs. A state-of-the-art laptop sits atop the desk, its screen illuminated with various legal databases and open case files. The room is filled with a hushed murmur of hushed conversations, punctuated by the occasional rustle of papers or the soft click of heels against the tiled floor. The lawyer\\'s colleagues are scattered about the room, their faces etched with a mixture of concern and determination. The air is thick with anticipation as the lawyer takes a deep breath, ready to present their case before the esteemed judge and attentive jury.\", \"room_occupancy\": \"filled\", \"room_acoustics\": \"hushed murmur with occasional rustling of papers and soft clicks of heels\", \"room_ambience\": \"anticipation\", \"desk_material\": \"mahogany\", \"desk_state\": \"polished\", \"desk_content\": [\"stack of legal documents\", \"laptop\"], \"desk_content_details\": {\"legal documents\": {\"quantity\": \"neat stack\", \"organization\": \"neatly organized\", \"highlighted\": \"bright fluorescent tabs\"}, \"laptop\": {\"state\": \"state-of-the-art\", \"screen_illumination\": \"legal databases and open case files\"}}, \"colleagues_presence\": \"scattered\", \"colleagues_mood\": \"concerned and determined\", \"hearing_status\": \"ready to present case\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121769.52 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131151.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92253.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Market Research', 'situation': 'In the bustling market research department of a corporate office, the Public Relations Specialist is engulfed in a world of dynamic energy and rapid-fire information exchange. The sprawling department is a maze of modern conveniences, housing 20 pristine computers, each humming with life as they process reams of data and churn out insightful analyses. The specialists are immersed in their work, surrounded by stacks of survey reports and graphs that line their desks. The air is filled with the soft tapping of keyboards and the gentle hum of conversation among the market researchers. In a corner, a sleek coffee machine provides a welcome break, its warm aroma mingling with the scent of freshly printed reports. The room is bathed in the gentle glow of overhead lights, casting a soft, inviting light that belies the serious business at hand. The office buzzes with the energy of a dozen market researchers, each deeply focused on their tasks. The walls are adorned with whiteboards covered in colorful charts and notes, reflecting the constant brainstorming and strategizing that goes on. The room is punctuated by the occasional ring of a phone, answered swiftly and professionally. The atmosphere is one of intense focus and collaborative effort, as the specialists work together to shape the public image of their clients and steer them through the ever-shifting landscape of market trends and public opinion.', 'situation_json': '{\"document\": {\"roomType\": \"corporate office\", \"department\": \"market research\", \"energyLevel\": \"dynamic\", \"informationExchangeRate\": \"rapid-fire\", \"layout\": \"maze\", \"conveniences\": \"modern\", \"computerCount\": 20, \"computerState\": \"pristine\", \"surveyReports\": \"stacks\", \"graphs\": \"spread\", \"deskState\": \"lined\", \"keyboardSound\": \"soft tapping\", \"conversationVolume\": \"gentle hum\", \"coffeeMachineState\": \"sleek\", \"reportScent\": \"freshly printed\", \"airScent\": \"warm aroma\", \"lighting\": \"gentle glow\", \"lightSource\": \"overhead lights\", \"researcherCount\": 12, \"researcherFocus\": \"deep\", \"whiteboardState\": \"covered\", \"whiteboardContent\": \"colorful charts and notes\", \"brainstormingFrequency\": \"constant\", \"strategizingFrequency\": \"constant\", \"phoneRingFrequency\": \"occasional\", \"phoneAnswerSpeed\": \"swift\", \"phoneAnswerManner\": \"professional\", \"atmosphere\": \"intense focus and collaborative effort\", \"specialistTask\": \"shaping public image and steering through market trends and public opinion\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122440.42 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 111736.83 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 80221.99 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Counselor', 'process': 'Parent Consultation', 'situation': \"The parent enters the counselor's office, a small, cozy space adorned with warm, soothing colors and soft lighting to create a comforting atmosphere. The counselor, seated behind a neatly organized desk with a laptop opened to student records, greets the parent with a reassuring smile. A box of tissues sits gently placed on the corner of the desk, a subtle reminder of the emotional support available. The notebook, filled with detailed notes and action plans, lies open next to the laptop, ready for new entries. The parent takes a seat on the plush chair facing the desk, feeling a sense of relief as they settle into the peaceful surroundings of the counselor's office. The waiting room outside is quiet, with only a few parents sitting patiently, engrossed in magazines or checking their phones. The school counselor begins the consultation, attentively listening to the parent's concerns and offering expert guidance, ensuring the parent feels heard and supported throughout the process.\", 'situation_json': '{\"additionalProperties\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 83405.76 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 110373.02 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77114.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sports Coach', 'process': 'Player Performance Evaluation', 'situation': 'Player performance evaluation is a critical process in sports coaching that involves assessing and analyzing the skills, abilities, and overall performance of athletes to identify areas for improvement and optimize their potential. This process is typically done regularly, such as after each game or training session, to provide continuous feedback and track progress. The outcome of player performance evaluation is a comprehensive understanding of each player’s strengths and weaknesses, which informs training programs and strategies for improving performance.', 'situation_json': '{\"role\": \"sports_coach\", \"process_name\": \"Player Performance Evaluation\", \"description\": \"Player performance evaluation is a critical process in sports coaching that involves assessing and analyzing the skills, abilities, and overall performance of athletes to identify areas for improvement and optimize their potential. This process is typically done regularly, such as after each game or training session, to provide continuous feedback and track progress. The outcome of player performance evaluation is a comprehensive understanding of each player\\\\u2019s strengths and weaknesses, which informs training programs and strategies for improving performance.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 81233.06 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 106543.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 65773.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Carpenter', 'process': 'Finishing', 'situation': \"Imagine a bustling woodworking shop, filled with the warm, earthy scent of freshly cut timber and the hum of saws and sanders. The shop is well-lit, with bright overhead lights casting clear, shadowless illumination over the workspace. The Carpenter stands at a sturdy, well-worn workbench, surrounded by an array of tools and materials. On the bench, a beautiful, handcrafted wooden table awaits the final touches. The Carpenter meticulously sands the surface with a fine-grit sandpaper, creating a silky-smooth texture. A variety of sanding tools, from small handheld models to large belt sanders, are neatly arranged on nearby shelves. Safety equipment, including dust masks and ear protection, hangs from hooks within easy reach. In the background, an apprentice diligently sweeps sawdust into a pile, while a few feet away, another Carpenter discusses a project with a client, their voices mingling with the steady rhythm of the work. The shop's well-ventilated design ensures that dust and fumes are quickly dispersed, maintaining a healthy and comfortable working environment. In one corner, a circular saw sits ready for the next task, its blade gleaming under the lights. The Carpenter's movements are precise and deliberate, guided by years of experience and a deep understanding of the craft. The atmosphere is one of focused productivity, with each person absorbed in their tasks, contributing to the transformation of raw materials into functional and beautiful pieces.\", 'situation_json': '{\"situation\": \"Imagine a bustling woodworking shop, filled with the warm, earthy scent of freshly cut timber and the hum of saws and sanders. The shop is well-lit, with bright overhead lights casting clear, shadowless illumination over the workspace. The Carpenter stands at a sturdy, well-worn workbench, surrounded by an array of tools and materials. On the bench, a beautiful, handcrafted wooden table awaits the final touches. The Carpenter meticulously sands the surface with a fine-grit sandpaper, creating a silky-smooth texture. A variety of sanding tools, from small handheld models to large belt sanders, are neatly arranged on nearby shelves. Safety equipment, including dust masks and ear protection, hangs from hooks within easy reach. In the background, an apprentice diligently sweeps sawdust into a pile, while a few feet away, another Carpenter discusses a project with a client, their voices mingling with the steady rhythm of the work. The shop\\'s well-ventilated design ensures that dust and fumes are quickly dispersed, maintaining a healthy and comfortable working environment. In one corner, a circular saw sits ready for the next task, its blade gleaming under the lights. The Carpenter\\'s movements are precise and deliberate, guided by years of experience and a deep understanding of the craft. The atmosphere is one of focused productivity, with each person absorbed in their tasks, contributing to the transformation of raw materials into functional and beautiful pieces.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 126015.93 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147350.75 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 76026.47 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'IT Manager', 'process': 'IT Strategy Planning', 'situation': 'The IT Manager, nestled in their office space within the bustling company headquarters, diligently works on the IT Strategy Planning. The room is filled with the soft hum of a nearby server room, housing the main computer systems and servers. Their laptop, adorned with a colorful sticker of a circuit board, sits on their clutter-free desk, surrounded by notepads filled with scribbles of possible IT solutions and roadmaps. The IT Manager uses project management software to plan and track the progress of IT projects, ensuring that every aspect of the strategy is accounted for. They work closely with the IT department, a team of dedicated professionals, each engrossed in maintaining and updating various equipment. The IT Manager frequently communicates with other departments, understanding their needs and ensuring that the IT strategy supports their goals and objectives. The executive boardroom, just a few steps away, is where the IT Manager presents the strategy to the executive team, ensuring that their feedback is incorporated into the plan. The pantry, with its comforting aroma of fresh coffee, supports breaks and relaxation, contributing to a positive work environment. The lounge area, filled with comfortable chairs and colorful pillows, encourages informal discussions and fosters a collaborative atmosphere.', 'situation_json': '{\"room_description\": \"bustling company headquarters\", \"equipment\": {\"laptop\": {\"description\": \"adorned with a colorful sticker of a circuit board\", \"state\": \"on\", \"location\": \"desk\"}, \"server_room\": {\"description\": \"houses the main computer systems and servers\", \"state\": \"running\", \"location\": \"nearby\"}, \"project_management_software\": {\"description\": \"used for planning and tracking the progress of IT projects\", \"state\": \"operational\", \"location\": \"laptop\"}, \"equipment_maintained_by_it_department\": {\"description\": \"various equipment maintained and updated\", \"state\": \"varies\", \"location\": \"varies\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120911.91 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 112746.70 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92357.17 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mental Health Counselor', 'process': 'Referrals', 'situation': 'In the cozy, professional waiting room of a mental health clinic, a Mental Health Counselor prepares for their daily referral process. With a laptop and a stack of psychological tests at their desk, they are ready to assess clients mental health and monitor progress. The counselor, known for their compassion and empathy, works diligently to provide quality care. Nearby, in the private therapy room, a comfortable space is arranged with two chairs, a small table, and therapeutic aids. The room is decorated with soft lighting, calming colors, and plants, creating a serene and welcoming atmosphere. The counselor looks up from their notes as a client enters, signaling the start of another day of helping individuals improve their overall well-being.', 'situation_json': '{\"waiting_room\": {\"description\": \"cozy, professional\", \"equipment\": {\"laptop\": true, \"psychological_tests\": true}}, \"therapy_room\": {\"description\": \"private, comfortable, arranged with two chairs, a small table, and therapeutic aids\", \"decor\": {\"lighting\": \"soft\", \"colors\": \"calming\", \"plants\": true}}, \"counselor\": {\"traits\": [\"compassionate\", \"empathetic\"], \"equipment\": {\"laptop\": true, \"psychological_tests\": true}, \"status\": \"ready for referral process\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 104985.32 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 106854.08 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 59019.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Computer Systems Analyst', 'process': 'Troubleshooting', 'situation': 'In the heart of the bustling IT department, a Computer Systems Analyst is ensconced in a cubicle, the silvery glow from his computer screen casting long, dancing shadows across the whiteboard filled with sketches and diagrams. A nearby printer hums contentedly, as if in anticipation of the project proposals and reports it will soon churn out. The air is filled with the scent of freshly brewed coffee and a faint hint of plastic from the array of equipment littering the desk - a laptop nestled amidst a swarm of power cords, a testing software CD, and a diagnostic tool. A few feet away, a door leads to a server room, its constant hum a comforting reminder of the pulsating technology that drives the entire operation. Amidst the controlled chaos, the analyst pores over lines of code, his eyes scanning for any anomaly that might disrupt the delicate balance of the system. Elsewhere in the department, other analysts huddle in meeting rooms, discussing complex system designs and brainstorming potential solutions. Their whiteboards are a plethora of multi-colored diagrams and arrows pointing in every direction, a visual representation of the intricate web of technology they strive to maintain. The testing environment nearby stands ready, a controlled space where new systems are put through their paces to ensure they will function flawlessly once deployed. The process of troubleshooting is a mental challenge that can last anywhere from a few minutes to several days. Dealing with complex and often non-reproducible issues is no small feat, but the analyst is undeterred. Despite the risk of misdiagnosing an issue or losing crucial data, they remain focused, their fingers flying across the keyboard in a flurry of activity. From the hum of the server room to the rhythmic tapping of keyboards, the symphony of the IT department plays on, a testament to the intricate dance of technology and human ingenuity.', 'situation_json': '{\"ambient_noises\": [\"hum of the server room\", \"rhythmic tapping of keyboards\"], \"equipment_states\": {\"laptop\": \"powered on\", \"power_cords\": \"plentiful\", \"testing_software_cd\": \"present\", \"diagnostic_tool\": \"present\", \"printer\": \"standby\"}, \"measurable_observations\": {\"air_quality\": \"fresh\", \"coffee_scent\": \"strong\", \"plastic_scent\": \"faint\"}, \"process_duration\": \"variable (a few minutes to several days)\", \"risks\": [\"misdiagnosing an issue\", \"losing crucial data\"], \"location\": \"IT department cubicle\", \"nearby_locations\": [\"server room\", \"meeting rooms\", \"testing environment\"], \"environment_impressions\": [\"controlled chaos\", \"symphony of the IT department\"], \"equipment_types\": [\"laptop\", \"power cords\", \"testing software CD\", \"diagnostic tool\", \"printer\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119032.46 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 103891.30 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 69529.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Clinical Laboratory Technician', 'process': 'Test Result Interpretation', 'situation': 'In the heart of the bustling clinic laboratories, the Clinical Laboratory Technician diligently conducts Test Result Interpretation, a process repeated every hour. The technician is nestled in the main laboratory area, surrounded by numerous pieces of equipment, each serving a unique purpose. A gleaming microscope, recently cleaned and calibrated, rests on the sturdy workbench, its lens reflecting the sterile white lights overhead. Nearby, a meticulously maintained centrifuge stands ready for use, its rotor poised for a high-speed spin. In the sterile area, a biosafety cabinet sits quietly, its filtered air ensuring a hazard-free environment. Within the examination room, a doctor and nurse attend to a patient, their forms a quiet contrast against the hum of machines.', 'situation_json': '{\"location\": \"bustling clinic laboratories\", \"equipment\": {\"microscope\": {\"state\": \"gleaming\", \"cleaned_and_calibrated\": true, \"location\": \"main laboratory area\", \"resting_on\": \"sturdy workbench\", \"reflection\": \"sterile white lights overhead\"}, \"centrifuge\": {\"state\": \"meticulously maintained\", \"location\": \"main laboratory area\", \"ready_for_use\": true, \"rotor\": \"poised for high-speed spin\"}, \"biosafety_cabinet\": {\"state\": \"quiet\", \"location\": \"sterile area\", \"filtered_air\": true, \"purpose\": \"hazard-free environment\"}, \"medical_equipment_in_examination_room\": {\"location\": \"examination room\", \"state\": \"quiet\", \"occupants\": [\"doctor\", \"nurse\"]}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  77%|███████▋  | 556/723 [1:34:29<34:43, 12.48s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Glazier', 'process': 'Glass Finishing', 'situation': \"As the sun beats down mercilessly on the expansive construction site, casting a dazzling glint off the temporary scaffolding structures, the seasoned glazier, clad in a sturdy harness and sporting a pair of reflective safety glasses, takes his position on the rooftop. The hustle and bustle of the construction crew below is a familiar symphony, with the rhythmic pounding of hammers and the intermittent buzz of power tools creating an orchestra of progress. The glazier's eyes, shaded beneath the peaked cap, scan the geometric patterns etched into the architect's blueprints, his fingers tracing over the delicate dimensions as if to commit them to muscle memory. A deck of nearly a dozen glass samples, each revealing a unique interplay of light and color, is neatly aligned on his foldable tray, awaiting the client's discerning eye. The client, dressed in a crisp suit, stands alongside the architect, both peers scrutinizing the projections and calculations, their heads nodding in synchronized approval. Behind them, a group of four construction workers, hands tucked into tool belts adorned with an array of screwdrivers, wrenches, and pliers, engage in animated conversation. A stack of clear glass panels, their edges barely catching the sunlight, rests securely against the scaffolding, ready for the glazier's expert touch. The whirring sound of the crane, positioned strategically nearby, hints at the heavy lifting to come, as it prepares to hoist the massive glass sheets to the designated areas.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 79508.28 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 107974.74 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 72165.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Art Director', 'process': 'Staff Training', 'situation': \"In a lively art studio buzzing with creative energy, an Art Director conducts a daily staff training session that lasts 8 hours. The studio is filled with the hum of activity, a symphony of clicking keyboards and the soft scratching of pencils on paper. The Art Director, standing at the center of the room, is surrounded by a group of 15 eager designers, each seated at a sleek, modern workstation equipped with a high-speed computer and a large, high-definition monitor. The walls are adorned with colorful mood boards, storyboards, and a myriad of vibrant posters, all testaments to the creative genius that flourishes here.\\n\\nThe Art Director's workstation is a command center, featuring a top-of-the-line laptop and a dual-monitor setup displaying an array of design software, including Adobe Creative Suite, Sketch, and Figma. A large, ergonomic drawing tablet is placed near the keyboard, ready for any spontaneous creative sparks. The desk is neatly organized, with pens, pencils, and a stack of fresh sketchbooks within easy reach.\\n\\nIn the background, a spacious meeting room is visible, equipped with a large-screen television for presentations and comfortable seating for up to 20 people. Next to it, a cozy coffee area offers a respite, with the aroma of freshly brewed coffee wafting through the air. A handful of team members are gathered around the coffee maker, taking a brief break from their intensive design projects.\\n\\nNear the entrance, a reception area welcomes visitors with a sleek, modern design. A receptionist sits behind a gleaming desk, occasionally glancing up to greet new arrivals with a friendly smile. The reception area leads to a quiet office environment, where the Art Director often retreats for focused work, away from the studio's perpetual buzz.\\n\\nThroughout the space, the mood is industrious yet relaxed, a perfect blend of creativity and professionalism. The Art Director's staff training session is in full swing, with the Art Director sharing insights, providing feedback, and guiding the team on the latest design trends and techniques. The energy in the room is palpable, a testament to the collective drive and passion for art and design that unites the team.\", 'situation_json': '{\"duration_hours\": 8, \"designers_present\": 15, \"electric_equipment_present\": {\"computers\": {\"count\": 16, \"state\": \"active\"}, \"monitors\": {\"count\": 18, \"state\": \"active\"}, \"tv\": {\"count\": 1, \"state\": \"inactive\"}, \"drawing_tablet\": {\"count\": 1, \"state\": \"active\"}, \"coffee_maker\": {\"count\": 1, \"state\": \"active\"}}, \"room_contents\": {\"workstations\": {\"count\": 15, \"state\": \"in-use\"}, \"mood_boards\": {\"count\": \"multiple\"}, \"storyboards\": {\"count\": \"multiple\"}, \"posters\": {\"count\": \"multiple\"}, \"meeting_room_seats\": {\"count\": 20, \"state\": \"available\"}, \"coffee_area_seats\": {\"count\": \"multiple\", \"state\": \"partially-in-use\"}, \"reception_desk\": {\"count\": 1, \"state\": \"in-use\"}}, \"activity_level\": \"high\", \"mood\": \"industrious yet relaxed\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 111508.43 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124592.24 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91208.19 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dentist', 'process': 'Patient Consultation', 'situation': \"In the heart of the bustling dental clinic, the dentist prepares for the weekly Patient Consultation. The sterilized consultation room, filled with the soft hum of the dental chair, mirrors, lights, drills, scalers, suction devices, and X-ray machines, stands ready. The dentist's tools, a small army of dental mirrors and explorers, lay gleaming on the tray, their status impeccable after a thorough sterilization process that involved an autoclave machine and chemical vapor sterilizers. Meanwhile, in the nearby waiting room, a handful of people - a nurse on her day off, a student with a toothache, and a businessman with a chipped tooth - sit nervously, their eyes flickering between the educational posters on the walls and the ticking clock. The dentist, armed with years of experience and a calm demeanor, steps into the room, ready to embark on a mental challenge that is as much about understanding human nature as it is about dental health.\", 'situation_json': '{\"room_state\": \"prepared\", \"electrical_equipment_state\": {\"dental_chair\": \"on\", \"mirrors\": \"on\", \"lights\": \"on\", \"drills\": \"off\", \"scalers\": \"off\", \"suction_devices\": \"off\", \"x_ray_machines\": \"off\"}, \"tools_state\": {\"dental_mirrors\": \"sterilized\", \"explorers\": \"sterilized\"}, \"waiting_room_state\": {\"number_of_people\": 3, \"people_description\": [\"nurse\", \"student\", \"businessman\"], \"people_status\": [\"nervous\", \"nervous\", \"nervous\"]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120093.53 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141353.52 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 97739.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Veterinary Technologist & Technician', 'process': 'Record Keeping', 'situation': 'In the bustling clinic, the Veterinary Technologist & Technician is situated in their quiet office space, an oasis of calm amidst the activity. The room is bathed in the soft glow of the overhead lights, casting a warm illumination on the organized filing system that takes up a significant portion of one wall. Nearby, the reception area hums with the comings and goings of pet owners, their furry companions patiently waiting in the designated waiting room, while other animals are housed in the kennel. The treatment areas are a flurry of activity, as veterinarians and technicians alike tend to the medical needs of the animal patients.\\nIn the midst of this, the Veterinary Technologist & Technician focuses on the task at hand - Record Keeping. Their desk is adorned with a variety of equipment, including a computer and paper charts, necessary for their daily record keeping tasks. The computer screen flickers with life, displaying a digital patient chart, while a stack of paper charts rests neatly beside it. The dental mirror tray sits close by, its array of five dental mirrors gleaming under the light, each meticulously cleaned and ready for use.\\nAs the day progresses, the technician updates patient charts, maintaining medical records with precision. They collaborate with the veterinarians to ensure records are complete and up-to-date, and communicate with clients, ensuring they provide essential patient history and contact information. The primary challenges of this process are not lost on the technician; maintaining accuracy and confidentiality of records, ensuring all relevant information is captured, and complying with legal and regulatory requirements.\\nThe number of patients and the complexity of their cases dictate the duration and frequency of this task, but the Veterinary Technologist & Technician remains steadfast in their commitment to providing high-quality patient care and supporting the work of veterinarians.', 'situation_json': '{\"lighting\": \"soft glow of overhead lights\", \"room_organization\": \"organized filing system\", \"number_of_dental_mirrors\": 5, \"state_of_dental_mirrors\": \"meticulously cleaned\", \"equipment\": [\"computer\", \"paper charts\", \"dental mirror tray\"], \"state_of_computer\": \"operational\", \"state_of_paper_charts\": \"resting neatly\", \"state_of_dental_mirror_tray\": \"gleaming under the light\", \"challenges\": [\"maintaining accuracy and confidentiality of records\", \"ensuring all relevant information is captured\", \"complying with legal and regulatory requirements\"], \"duration_frequency_of_task\": \"dictated by the number of patients and the complexity of their cases\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128676.41 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 111898.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73160.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Recreation & Fitness Worker', 'process': 'Record Keeping', 'situation': 'The Recreation & Fitness Worker, immersed in the serene tranquility of their indoor office, sits pensively at their desk, surrounded by towering stacks of folders and papers. Amidst the bustling gym and office, they are shielded by the office walls, creating a sanctuary from the echoing clamor of the treadmills and straining grunts of the weightlifting area. In their hands, a worn clipboard filled with intricate notes on the clients progress, meticulously updated daily. The fitness assessment area looms with a vast array of menacing weights, heart rate monitors, and stopwatches, all essential tools used in determining a >clients fitness levels, and in need of regular maintenance. In the corner, a lone computer hums, the recreation and wellness service schedules and clients records illuminated on its screen. The nearby waiting room bustles with a constant stream of anxious clients, their eyes darting nervously from the glistening exercise equipment to the colorful posters that line the wall. The locker room emits a faint scent of sweat and disinfectant, a testament to its daily usage by clients changing and storing their belongings. In the distance, a fellow fitness staff is seen diligently cleaning an array of exercise equipment, meticulously oiling each machine, and ensuring the clients future safety and satisfaction.', 'situation_json': '{\"location\": \"indoor office\", \"surroundings\": \"towering stacks of folders and papers\", \"equipment_states\": {\"clipboard\": \"worn\", \"weights\": \"present and numerous\", \"heart rate monitors\": \"present\", \"stopwatches\": \"present\", \"computer\": \"present and humming\", \"exercise equipment\": \"present and being cleaned\", \"locker room\": \"present and smells of sweat and disinfectant\"}, \"observable_environments\": {\"waiting room\": \"bustling with clients\", \"weightlifting area\": \"echoing with grunts\", \"fitness assessment area\": \"looming with equipment\", \"exercise area\": \"visible with numerous equipment\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112965.31 examples/s] examples]\n",
      "Filter:   0%|          | 0/4271 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paralegal', 'process': 'Legal Compliance', 'situation': \"In the bustling heart of a Law Firm, a paralegal is hard at work in their office, a space bursting with activity and organization. The room is filled with the soft hum of a computer, used for drafting legal documents, conducting research, and communication. A printer, essential for producing hard copies of these documents, stands ready beside it. The paralegal is surrounded by legal databases, statutes, and regulations, all easily accessible on their computer. Their desk is a testament to their diligence, with case law books and documents neatly stacked and labeled. Two monitors display a myriad of windows, each open to a different legal research database or document management software. The room, though busy, is a sanctuary of focus, a quiet workspace necessary for the intricate work of a paralegal. Outside the office, the waiting area buzzes with clients and attorneys, their voices a low murmur. The atmosphere is professional yet empathetic, as clients seek legal assistance and attorneys provide guidance on legal matters. The location, a law library, is just a few steps away, a resource area filled with legal texts and databases, ready to be used for legal research. A law library, accessible at a moment's notice, is crucial for the paralegal, providing them with access to legal resources. In this setting, the paralegal is responsible for assisting the attorney in ensuring that every task follows local, state, and federal laws, and industry regulations - a process known as legal compliance. They conduct small legal research, communicate with clients, and interact with other legal professionals. They are also responsible for drafting legal documents, filing them with local courts and government agencies, arranging hearings and trials, and more.\", 'situation_json': '{\"location\": \"Law Firm\", \"room\": \"office\", \"room_state\": \"busy\", \"equipment\": {\"computer\": {\"state\": \"on\", \"purpose\": \"drafting legal documents, conducting research, communication\"}, \"printer\": {\"state\": \"ready\", \"purpose\": \"producing hard copies of documents\"}, \"legal_databases\": {\"access\": \"computer\", \"state\": \"accessible\"}, \"statutes\": {\"access\": \"computer\", \"state\": \"accessible\"}, \"regulations\": {\"access\": \"computer\", \"state\": \"accessible\"}, \"case_law_books\": {\"state\": \"neatly stacked and labeled\", \"location\": \"desk\"}, \"documents\": {\"state\": \"neatly stacked and labeled\", \"location\": \"desk\"}, \"monitors\": {\"state\": \"on\", \"display\": \"legal research database or document management software\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128227.34 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 68202.64 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 108452.57 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140313.87 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88418.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist', 'process': 'Billing and Coding', 'situation': \"In the heart of the Physical Therapy Clinic, a Physical Therapist is nestled in the cozy confines of the Billing Office, a separate area from the treatment rooms. The room, painted in calming shades of blue, is small yet functional. A sturdy, wooden desk sits against the far wall, its surface cluttered with various tools of the trade. There are piles of Patient Records, each detailing diagnoses, procedures, and insurance information, meticulously kept and updated. A sleek, advanced Coding Software adorns the computer screen, its interface a complex web of codes and numbers. The therapist, dressed in their professional attire, expertly navigates this maze of information, their fingers dancing across the keyboard as they input codes for diagnoses and procedures with precision and accuracy. The waiting room, visible through a glass partition, buzzes with a handful of patients, a testament to the therapist's busy schedule. The therapist, however, remains focused, their mind a kaleidoscope of coding systems, insurance policies, and financial stability considerations. This is the daily routine of the Physical Therapist, a balancing act of treating patients and ensuring accurate billing and coding, a task as complex as it is crucial.\", 'situation_json': '{\"room_description\": {\"color\": \"blue\", \"size\": \"small\", \"functionality\": \"functional\", \"desk\": {\"material\": \"wooden\", \"surface\": \"cluttered\", \"tools\": [\"Patient Records\", \"Coding Software\"], \"patient_records\": {\"details\": [\"diagnoses\", \"procedures\", \"insurance information\"], \"status\": \"updated and meticulously kept\"}, \"coding_software\": {\"description\": \"sleek, advanced\", \"interface\": \"complex web of codes and numbers\"}}, \"waiting_room\": {\"visibility\": \"visible through a glass partition\", \"patients\": \"a handful\", \"atmosphere\": \"buzzing\"}, \"physical_therapist\": {\"state_of_mind\": \"focused\", \"thoughts\": [\"coding systems\", \"insurance policies\", \"financial stability considerations\"], \"schedule\": \"busy\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 80026.15 examples/s] examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 93193.66 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73670.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Database Administrator', 'process': 'Database Design', 'situation': \"In the hushed, cool atmosphere of the server room, a Database Administrator stood surrounded by the steady hum of servers and the gentle whir of cooling fans. The room, meticulously maintained, was adorned with rows of sleek, black servers, each meticulously labeled and interconnected with a labyrinth of colorful cables. A soft, blue glow emanating from the servers' LED lights cast an ethereal light, reflecting off the polished tiles of the raised floor. Just beyond the transparent, security-filtered windows, the bustling world of the IT department could be seen, with colleagues intently focused on their tasks, their fingers dancing over keyboards and mice. Nearby, the office space hummed with quiet efficiency, where developers collaborated with stakeholders, their eyes locked on the luminous screens of their laptops, discussing the parameters of the new database design. Amidst this landscape of technology and concentration, the Database Administrator orchestrated the intricate dance of data flow and storage, ensuring that every piece of information had its place, ready to serve the needs of the organization seamlessly and reliably. The scent of ozone and the faint smell of electronics filled the air, a testament to the vital role technology played in this digital age. As the Database Administrator meticulously worked on the database design, the occasional click of keys and the intermittent beep of notifications from the adjacent control room resonated, signaling the constant vigilance required to maintain the digital heartbeat of the organization. This interplay of technology, expertise, and collaboration underscored the critical importance of the Database Administrator's role in the modern workplace.\", 'situation_json': '{\"description\": \"A Database Administrator stood surrounded by the steady hum of servers and the gentle whir of cooling fans in the hushed, cool atmosphere of the server room. The room, meticulously maintained, was adorned with rows of sleek, black servers, each meticulously labeled and interconnected with a labyrinth of colorful cables. A soft, blue glow emanating from the servers\\' LED lights cast an ethereal light, reflecting off the polished tiles of the raised floor. Just beyond the transparent, security-filtered windows, the bustling world of the IT department could be seen, with colleagues intently focused on their tasks, their fingers dancing over keyboards and mice. Nearby, the office space hummed with quiet efficiency, where developers collaborated with stakeholders, their eyes locked on the luminous screens of their laptops, discussing the parameters of the new database design. Amidst this landscape of technology and concentration, the Database Administrator orchestrated the intricate dance of data flow and storage, ensuring that every piece of information had its place, ready to serve the needs of the organization seamlessly and reliably. The scent of ozone and the faint smell of electronics filled the air, a testament to the vital role technology played in this digital age. As the Database Administrator meticulously worked on the database design, the occasional click of keys and the intermittent beep of notifications from the adjacent control room resonated, signaling the constant vigilance required to maintain the digital heartbeat of the organization. This interplay of technology, expertise, and collaboration underscored the critical importance of the Database Administrator\\'s role in the modern workplace.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 105190.91 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142036.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 98196.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mechanical Engineer', 'process': 'Continuous Improvement', 'situation': \"A bustling company office is filled with an air of strategic planning and creative thought as the Mechanical Engineer commences their daily tasks in Continuous Improvement. In the engineering lab, one can find a multitude of CAD software, testing equipment, and calculators meticulously arranged on the table, each with a distinct purpose in the design and development process. The nearby office room is buzzing with the hum of blueprints being approved, fostering an atmosphere of collaboration between design engineers, project managers, and technicians. Adjacent to these areas, a dedicated meeting room stands ready for the day's brainstorming sessions, complete with markers, a projector, and a whiteboard. Simultaneously, the Quality Control Inspector and Quality Assurance Manager are meticulously checking each component for any defects using advanced measurement tools and machinery. Meanwhile, a group of trainees and trainers engage in a practical training session in the workshop, their voices intermingling with the whirring sounds of projectors and flipcharts. The mechanical engineer, clad in safety glasses and with a sturdy hard hat nearby, works closely with a maintenance technician, skillfully using calipers to measure the dimensions of various components. The engineer's laptop, equipped with CAD software, is filled with 3D models, while their calculator lies nearby, tackling complex calculations with precision. The continuous process of designing, analyzing, testing, and improving progresses under the watchful eyes of the project manager and the engineering team. The duration of these daily tasks is continuous, and the challenge is both mental and physical. The location of these activities is primarily indoors, in the company office, where every day is a testament to the relentless pursuit of mechanical excellence.\", 'situation_json': '{\"location\": \"indoor (company office)\", \"primary_task\": \"continuous improvement\", \"tools_and_equipment\": {\"CAD_software\": true, \"testing_equipment\": true, \"calculators\": true, \"blueprints\": true, \"approval_process\": true, \"markers\": true, \"projector\": true, \"whiteboard\": true, \"measuring_tools\": true, \"calipers\": true, \"safety_glasses\": true, \"hard_hat\": true, \"laptop_with_CAD_software\": true}, \"objects_in_surroundings\": {\"engineering_lab\": true, \"office_room\": true, \"meeting_room\": true, \"laptop\": true, \"calculator\": true, \"3D_models\": true, \"projector\": true, \"flipcharts\": true}, \"people_and_job_roles\": {\"mechanical_engineer\": true, \"maintenance_technician\": true, \"design_engineers\": true, \"project_managers\": true, \"technicians\": true, \"quality_control_inspectors\": true, \"quality_assurance_managers\": true, \"trainees\": true, \"trainers\": true, \"engineering_team\": true}, \"processes_and_actions\": {\"drawing\": true, \"measuring\": true, \"brainstorming\": true, \"tackling_complex_calculations\": true, \"designing_analyzing_testing_and_improving\": true, \"checking_components_for_defects\": true, \"practical_training_session\": true}, \"challenge_level\": \"both mental and physical\", \"duration\": \"continuous\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128517.27 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141333.44 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88481.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Executive Assistant', 'process': 'Calendar Management', 'situation': '{', 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 84370.26 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 156794.01 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84060.72 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Project Management', 'situation': \"The Management Analyst meticulously examines and studies the organization's structure, efficiency, processes, and operations to make data-driven recommendations. The analyst is situated in a bustling corporate office, surrounded by the hum of activity and the steady rhythm of keyboard clicks. The analyst's cubicle is neatly organized, with a powerful computer equipped with advanced software for data analysis such as Excel, SPSS, and other analytical tools. The cubicle walls are adorned with charts and graphs, showcasing key insights and trends. The analyst skillfully navigates through complex data sets, turning raw information into actionable insights. The office environment is dynamic, with colleagues diligently working on their tasks, occasionally stopping by to discuss findings or seek advice. The air is filled with a blend of focused concentration and collaborative energy. Nearby, there are meeting rooms where the analyst conducts interviews with employees and presents findings to clients. The rooms are equipped with modern presentation tools, including high-definition projectors and interactive whiteboards, allowing for clear and engaging presentations. The analyst seamlessly transitions between these spaces, ensuring that all stakeholders are aligned and informed. The corporate office is the heart of the operation, where financial and operational data is accessed and analyzed. The analyst's work extends to the headquarters, where they interact with specific departments to gather additional insights and support. The frequency of these interactions is dictated by the organization's needs and priorities, ensuring that the analysis is comprehensive and tailored to the business's unique challenges. The entire process is supported by a wealth of talented and dedicated staff, from administrative assistants to fellow analysts, each contributing their expertise to the collective goal of driving organizational efficiency and success.\", 'situation_json': '{\"details\": {\"properties\": [{\"name\": \"office\", \"value\": \"corporate\"}, {\"name\": \"three_wall_enclosure\", \"value\": {\"properties\": [{\"name\": \"name\", \"value\": \"cubicle\"}, {\"name\": \"hum\", \"value\": true}, {\"name\": \"keyboard_click_rhythm\", \"value\": \"steady\"}, {\"name\": \"organization_state\", \"value\": \"neat\"}, {\"name\": \"power_supply_state\", \"value\": \"power_on\"}, {\"name\": \"equipment_contains\", \"value\": [\"computer\", \"software for data analysis\"]}]}}, {\"name\": \"office_environment\", \"value\": \"dynamic\"}, {\"name\": \"colleagues_state\", \"value\": \"working\"}, {\"name\": \"three_wall_enclosure_properties_wall_adornment\", \"value\": {\"properties\": [{\"name\": \"name\", \"value\": \"graphs\"}, {\"name\": \"visual_information_type\", \"value\": \"key insights and trends\"}]}}]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138229.64 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145726.54 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95794.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Drafting Legal Documents', 'situation': \"In the heart of the bustling law firm, nestled in a private office adorned with sleek, modern furniture and walls lined with an impressive array of legal reference books, a lawyer sits poised at a state-of-the-art laptop. The room is bathed in the soft glow of a desk lamp, casting long shadows that dance gracefully across the partially open blinds that filter the mid-afternoon sunlight. To the lawyer's left, a high-end printer hums gently, ready to churn out drafts of intricately crafted legal documents with crisp, precise lines of text. Behind the laptop, a tower of legal reference books stands guard, each volume marked withderned bookmarks and highlighted passages, a testament to countless hours spent poring over legal precedents and principles. On the edge of the desk, a glossy, stainless-steel mug steams gently, bearing the imprint of a prestigious law school crest, a silent reminder of the rigorous academic journey that led the lawyer to this point. In the next room, the muffled sounds of a collegial conversation float through the slightly ajar door, as a group of lawyers enthusiastically discuss a recent case, their voices interspersed with occasional bursts of laughter. Across the hall, in the law library, the reverential silence is punctuated only by the soft rustling of pages as a legal assistant diligently research legal precedents, the scent of aged paper wafting subtly through the air. Down the hall, the waiting room hums with a palpable sense of anticipation, as a handful of clients sit patiently, their eyes scanning the latest issues of legal journals and industry publications that line the shelves. The lawyer's current task is to draft a complex legal document, a process that demands unwavering focus and meticulous attention to detail. Every keystroke is deliberate, as sentences are carefully crafted to convey precise legal nuances. The document will be scrutinized under a microscope, ensuring it is not only legally sound but also persuasively articulates the client's position. The weight of responsibility is palpable, but the lawyer's dedication and years of experience instill a quiet confidence. As the laptop's screen flickers with words that will shape the legal landscape for their client, the lawyer leans back slightly, takes a sip of the steaming coffee, and prepares to weave another chapter in the rich tapestry of the law.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 94650.24 examples/s]xamples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133271.88 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92033.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Counselor', 'process': 'Professional Development', 'situation': \"In the heart of the bustling school, the school counselor prepares for their daily professional development in their office, a sanctuary designed for confidential conversations. The office, bathed in the soft glow of the overhead fluorescent lights, is filled with a variety of equipment. There are two laptops, one for managing student records and the other for communication purposes, their screens displaying an array of colorful graphs and charts. Nestled in the corner, a neat stack of office supplies, teeming with forms, papers, and pens, is an essential tool for record-keeping and planning. In the center, a large desk supports a splayed-out notebook, its pages filled with meticulous notes from previous sessions. The room is also equipped with educational materials, including an assortment of worksheets, handouts, and books, for group activities. The room is a testament to the counselor's dedication to providing comprehensive support to students. Around the counselor, the school hums with life as students and teachers move through the hallways and classrooms. The counselor's day is a blend of meetings, counseling sessions, and collaboration with teachers and parents. The process, professional development, is a challenging endeavor, often taxing the counselor's mental faculties. But, the counselor is undeterred, for they understand the importance of their role in guiding students through their academic, career, and personal growth.\", 'situation_json': '{\"office_lighting\": \"overhead fluorescent lights\", \"number_of_laptops\": 2, \"laptop_purposes\": [\"managing student records\", \"communication\"], \"screens_display\": \"array of colorful graphs and charts\", \"office_supplies\": \"stack of forms, papers, and pens\", \"office_supplies_location\": \"neat stack in the corner\", \"essential_tool_for\": \"record-keeping and planning\", \"desk_item\": \"large desk supporting a notebook\", \"notebook_content\": \"meticulous notes from previous sessions\", \"educational_materials\": [\"assortment of worksheets\", \"handouts\", \"books\"], \"educational_materials_purpose\": \"group activities\", \"office_testament\": \"counselor\\'s dedication to providing comprehensive support to students\", \"school_activity\": \"humming with life as students and teachers move through the hallways and classrooms\", \"daily_endeavor\": \"blend of meetings, counseling sessions, and collaboration with teachers and parents\", \"endeavor_effect\": \"challenging, often taxing the counselor\\'s mental faculties\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 115771.70 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 77922.99 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 56709.49 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Sports Coach', 'process': 'Team Strategy Development', 'situation': 'In the heart of the bustling coaching office, a vast space pulsating with the energy of ambition and determination, the sports coach and his assistant are engrossed in the process of developing team strategies. The frequency of this mentally demanding process is weekly, each session lasting for an hour. The room, a symphony of scribbled notes and coffee stains, is filled with the constant hum of the assistant coach’s laptop, tirelessly churning out statistics and game plans. The whiteboard, a vibrant tapestry of strategies past and present, stands as a silent sentinel in the corner, eagerly awaiting its next colorful illustration. The surrounding atmosphere is a potent blend of focus and camaraderie, as the duo brainstorms, debates, and ultimately crafts the most advantageous strategies for the team.', 'situation_json': '{\"room_description\": \"The coaching office is vast, pulsating with ambition and determination. The room is filled with scribbled notes and coffee stains, and the constant hum of a laptop. A whiteboard stands in the corner.\", \"frequency\": \"weekly\", \"duration\": \"1 hour\", \"equipment\": {\"laptop\": {\"state\": \"on\", \"sound\": \"humming\", \"usage\": \"generating statistics and game plans\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130426.26 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150242.57 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93319.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Media Monitoring', 'situation': 'In the bustling indoor office of a PR agency, our Public Relations Specialist is deeply immersed in the daily task of Media Monitoring, a crucial aspect of their role. Surrounded by the soft hum of computers and the intermittent ringing of phones, they meticulously track media coverage across various sources - from the quick-fire world of social media platforms to the more traditional, yet still potent, newsrooms. A high-powered computer and an array of specialized media monitoring tools are their trusted companions in this process, enabling them to analyze trends and frame reports with pinpoint precision. The atmosphere is a blend of tranquility and urgency, as the specialist strives to keep abreast of all news relevant to their organization and the wider industry, striving to maintain a positive public image amidst the shifting currents of public sentiment.', 'situation_json': '{\"location\": \"indoor office of a PR agency\", \"environment_sound\": \"soft hum of computers and intermittent ringing of phones\", \"equipment_used\": \"high-powered computer, specialized media monitoring tools\", \"activities\": \"tracking media coverage across various sources from the quick-fire world of social media platforms to the more traditional, yet still potent, newsrooms\", \"purpose\": \"analyzing trends and framing reports with pinpoint precision\", \"atmosphere\": \"blend of tranquility and urgency\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 95950.81 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145137.39 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93967.56 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Carpenter', 'process': 'Installation', 'situation': 'Surrounded by the familiar hum of the jobsite, the carpenter, clad in his well-worn denim overalls and dusty work boots, meticulously examines the blueprints of the upcoming installation project. Across the large workshop, the apprentice and contractor huddle together, discussing the complexities of the project with the architect who periodically points to various sections of the plans. To their left, three sturdy wooden workbenches are arranged side by side, holding an array of tools such as hammers, saws, and measuring tapes, their surfaces covered in a layer of sawdust.\\n\\nIn the nearby warehouse, rows upon rows of wooden planks, doors, and windows sit patiently awaiting their turn in the installation process. Above them, fluorescent lights bathe the vast space with a somber glow, casting elongated shadows on the floor. The distinct smell of freshly cut timber fills the air, hinting at the imminent transformation of the raw materials into beautiful, functional features of the building.\\n\\nThe project manager and client, satisfied with the progress of the consultation, both nod in silent agreement as they exit the consultation room, a tranquil sanctuary in the midst of the bustling jobsite. The client pauses briefly to examine a tiny model of the building, its intricate details painstakingly replicated by the skilled hands of the carpenter. The client, confident in the abilities of their hired expert, looks forward to witnessing the final results of the carpenter’s magic.', 'situation_json': '{\"carpenter\": \"true\", \"overalls\": \"denim\", \"boots\": \"dusty work boots\", \"blueprints\": \"examining\", \"apprentice\": \"true\", \"contractor\": \"true\", \"architect\": \"true\", \"discussion\": \"complexities of the project\", \"plans\": \"true\", \"workbenches\": 3, \"tools\": [\"hammers\", \"saws\", \"measuring tapes\"], \"sawdust\": \"true\", \"warehouse\": \"true\", \"wooden planks\": \"row upon rows\", \"doors\": \"true\", \"windows\": \"true\", \"awaiting\": \"installation process\", \"fluorescent lights\": \"true\", \"bathe\": \"somber glow\", \"casting shadows\": \"true\", \"smell of timber\": \"true\", \"transformation\": \"true\", \"functional features\": \"building\", \"project manager\": \"true\", \"client\": \"true\", \"progress\": \"satisfied\", \"consultation room\": \"true\", \"model of the building\": \"tiny\", \"details\": \"replicated\", \"confidence\": \"true\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112407.25 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 113557.18 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89871.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'IT Manager', 'process': 'IT Support', 'situation': \"In the heart of the IT Department, nestled in the bustling office adorned with state-of-the-art technology, the IT Manager takes a moment to survey their domain. The room is a whirlwind of activity, with IT Staff diligently tending to their computers, the hum of servers filling the air. The server room, a sanctum of cool, sterile air, houses 25 gleaming servers, each blinking with a rhythmic pulse, their status lights glowing a comforting green. The office walls are lined with an array of monitors, displaying a symphony of graphs and data streams, a testament to the constant monitoring and upkeep of the IT infrastructure. The IT Manager's desk is a fortress of organization, with a laptop open to a complex network diagram, a steaming coffee from the nearby Coffee Machine perched precariously on the edge. In the nearby Lounge Area, IT team members take a brief respite, laughter echoing as they strategize and collaborate. The air is thick with the scent of freshly brewed coffee and the faint scent of ozone from the servers. The IT Manager's phone buzzes with an incoming message, their team awaiting their next instruction as they navigate the ever-evolving landscape of IT Support.\", 'situation_json': '{\"situation\": \"In the heart of the IT Department, nestled in the bustling office adorned with state-of-the-art technology, the IT Manager takes a moment to survey their domain. The room is a whirlwind of activity, with IT Staff diligently tending to their computers, the hum of servers filling the air. The server room, a sanctum of cool, sterile air, houses 25 gleaming servers, each blinking with a rhythmic pulse, their status lights glowing a comforting green. The office walls are lined with an array of monitors, displaying a symphony of graphs and data streams, a testament to the constant monitoring and upkeep of the IT infrastructure. The IT Manager\\'s desk is a fortress of organization, with a laptop open to a complex network diagram, a steaming coffee from the nearby Coffee Machine perched precariously on the edge. In the nearby Lounge Area, IT team members take a brief respite, laughter echoing as they strategize and collaborate. The air is thick with the scent of freshly brewed coffee and the faint scent of ozone from the servers. The IT Manager\\'s phone buzzes with an incoming message, their team awaiting their next instruction as they navigate the ever-evolving landscape of IT Support.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 138674.42 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 149970.89 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82356.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mental Health Counselor', 'process': 'Treatment Planning', 'situation': \"In the heart of a bustling clinic, a Mental Health Counselor, adorned in a calming, pastel blue shirt, diligently prepares for their weekly treatment planning session. As they enter their personal office, the soft hum of the air conditioner provides a soothing backdrop. The room, bathed in warm, natural light filtering through the large window, is a sanctuary of tranquility. A plush, grey armchair, its texture inviting and comforting, sits opposite a sleek wooden desk that holds a neatly organized array of tools: a fresh notebook with a sturdy, mahogany-toned cover, a pen with a smooth, gliding ink, and a well-thumbed copy of the Diagnostic and Statistical Manual of Mental Disorders. The Counselor's laptop, a portal to patient records and research resources, rests atop a polished, mahogany desk, a testament to their dedication to continued learning. In the waiting room, three individuals from diverse backgrounds, occupations, and ages sit, each lost in their thoughts, awaiting their turn to seek solace and guidance. The Counselor's colleagues, also Mental Health Counselors, breeze in and out of the staff lounge, engaged in discussions about their own cases, exchanging insights, and offering support.\", 'situation_json': '{\"clinic_state\": \"bustling\", \"counselor_shirt_color\": \"pastel blue\", \"air_conditioner_state\": \"humming\", \"room_lighting\": \"natural\", \"window_size\": \"large\", \"armchair_texture\": \"plush\", \"armchair_color\": \"grey\", \"desk_material\": \"wooden\", \"notebook_state\": \"new\", \"pen_state\": \"smooth\", \"laptop_state\": \"on\", \"laptop_purpose\": \"patient records and research resources\", \"waiting_room_occupancy\": 3, \"waiting_room_diversity\": \"diverse backgrounds, occupations, and ages\", \"colleagues_state\": \"breezing in and out of the staff lounge\", \"colleagues_discussion\": \"own cases, insights, and support\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 100118.25 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 120521.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82552.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Construction Manager', 'process': 'Communication', 'situation': \"The Construction Manager stands in the bustling heart of the construction site, a vast expanse of concrete and steel gleaming under the sun. Surrounding the manager are towering cranes, their long arms gracefully maneuvering heavy machinery with precision. Scattered across the site are numerous workers, each dressed in high-visibility vests and hard hats, their movements synchronized like a well-oiled machine. The air is filled with the symphony of drills, hammers, and the distant hum of power tools. Nearby, a group of architects and engineers huddle together, poring over blueprints and whispering about the intricate details of the project. Contractors, with tape measures draped around their necks, bark orders to their crews, ensuring every bolt is tightened and every tile is perfectly laid. In the nearby site office, the Construction Manager's laptop sits open, displaying a myriad of complex project management software. A mobile phone lies beside it, buzzing intermittently with incoming calls and messages. The manager's hard hat rests on the desk, a symbol of their constant necessity for safety and vigilance. Behind them, the chatter of a heated team meeting can be heard through an open window, as various stakeholders discuss progress, deadlines, and potential hurdles. The site office, though functional, is adorned with a whiteboard filled with schedules, milestones, and safety protocols. The Construction Manager's role is the linchpin, binding together this intricate web of communication and coordination, ensuring that every aspect of the project moves seamlessly forward.\", 'situation_json': '{\"*args\": \"The Construction Manager stands in the bustling heart of the construction site, a vast expanse of concrete and steel gleaming under the sun. Surrounding the manager are towering cranes, their long arms gracefully maneuvering heavy machinery with precision. Scattered across the site are numerous workers, each dressed in high-visibility vests and hard hats, their movements synchronized like a well-oiled machine. The air is filled with the symphony of drills, hammers, and the distant hum of power tools. Nearby, a group of architects and engineers huddle together, poring over blueprints and whispering about the intricate details of the project. Contractors, with tape measures draped around their necks, bark orders to their crews, ensuring every bolt is tightened and every tile is perfectly laid. In the nearby site office, the Construction Manager\\'s laptop sits open, displaying a myriad of complex project management software. A mobile phone lies beside it, buzzing intermittently with incoming calls and messages. The manager\\'s hard hat rests on the desk, a symbol of their constant necessity for safety and vigilance. Behind them, the chatter of a heated team meeting can be heard through an open window, as various stakeholders discuss progress, deadlines, and potential hurdles. The site office, though functional, is adorned with a whiteboard filled with schedules, milestones, and safety protocols. The Construction Manager\\'s role is the linchpin, binding together this intricate web of communication and coordination, ensuring that every aspect of the project moves seamlessly forward.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  80%|███████▉  | 575/723 [1:52:29<23:31,  9.54s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Glazier', 'process': 'Glass Repair', 'situation': 'A Glazier is meticulously working on repairing a broken window on a residential building. The rooftop, where the action takes place, is bathed in the warm afternoon sunlight. A pair of scaffolding stands erect next to the broken window, providing the Glazier a stable and secure platform to work from. The Glazier, dressed in protective clothing - a hard hat, safety glasses, and gloves - is holding a glass cutter in his right hand, its sharp blade gleaming in the sunlight. He has already measured the window with a tape measure, its silver body lying to his left. On his right, a set of glass samples rest, each piece offering a unique texture and tint of glass. A small pot of sealant stands nearby, ready to secure and seal the edges of the new glass pane. The Glazier is surrounded by the sounds of the city - distant car horns, children playing, and the hum of a nearby construction site. Inside the building, a customer watches from the window, eager to see the finished product. The Glazier, with a steady hand and a keen eye, is about to make the first cut.', 'situation_json': '{\"description\": \"A Glazier is meticulously working on repairing a broken window on a residential building. The rooftop, where the action takes place, is bathed in the warm afternoon sunlight. A pair of scaffolding stands erect next to the broken window, providing the Glazier a stable and secure platform to work from. The Glazier, dressed in protective clothing - a hard hat, safety glasses, and gloves - is holding a glass cutter in his right hand, its sharp blade gleaming in the sunlight. He has already measured the window with a tape measure, its silver body lying to his left. On his right, a set of glass samples rest, each piece offering a unique texture and tint of glass. A small pot of sealant stands nearby, ready to secure and seal the edges of the new glass pane. The Glazier is surrounded by the sounds of the city - distant car horns, children playing, and the hum of a nearby construction site. Inside the building, a customer watches from the window, eager to see the finished product. The Glazier, with a steady hand and a keen eye, is about to make the first cut.\", \"equipment_states\": {\"glass_cutter\": {\"state\": \"being_used\", \"held_by\": \"right_hand\"}, \"tape_measure\": {\"state\": \"unused\", \"location\": \"left\"}, \"glass_samples\": {\"state\": \"unused\", \"location\": \"right\"}, \"sealant_pot\": {\"state\": \"ready\", \"location\": \"nearby\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 91153.61 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143125.49 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89851.08 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Art Director', 'process': 'Team Coordination', 'situation': 'In the hushed corridors of the bustling agency, the Art Director embarks on another day of team coordination. They navigate between the collaborative confines of the meeting room, where ideas are pitched and client concepts deliberated, and the vibrant design studio, filled with the hum of computers and the scent of fresh coffee. Their well-worn sketchbook, a testament to countless creative sessions, sits atop a sleek laptop, a tool that connects them to the world of design software and remote working options. A budget meeting room stands ready for financial discussions, while the pristine conference room is primed for professional client interactions. The Art Director, with a keen eye for detail and a passion for creativity, orchestrates the symphony of team members, clients, and stakeholders, ensuring all notes are in tune and the project crescendos to a harmonious finish.', 'situation_json': '{\"description\": \"In the hushed corridors of the bustling agency, the Art Director embarks on another day of team coordination. They navigate between the collaborative confines of the meeting room, where ideas are pitched and client concepts deliberated, and the vibrant design studio, filled with the hum of computers and the scent of fresh coffee. Their well-worn sketchbook, a testament to countless creative sessions, sits atop a sleek laptop, a tool that connects them to the world of design software and remote working options. A budget meeting room stands ready for financial discussions, while the pristine conference room is primed for professional client interactions. The Art Director, with a keen eye for detail and a passion for creativity, orchestrates the symphony of team members, clients, and stakeholders, ensuring all notes are in tune and the project crescendos to a harmonious finish.\", \"electrical_equipment_states\": {\"laptop\": \"on\", \"computers\": \"on\", \"lighting\": \"on\"}, \"observable_details\": {\"sketchbook\": \"well-worn\", \"meeting_room\": \"collaborative\", \"design_studio\": \"vibrant\", \"budget_meeting_room\": \"ready for financial discussions\", \"conference_room\": \"primed for professional client interactions\", \"coffee\": \"fresh\"}, \"measurable_details\": {\"sound_level\": \"hushed in corridors, hum of computers in design studio\", \"scent\": \"fresh coffee in design studio\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131135.89 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 152887.88 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95970.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dentist', 'process': 'Patient Education', 'situation': 'In the spacious and well-lit indoor office of a dental clinic, a seasoned dentist is poised for his Patient Education session with a new patient. The treatment room is meticulously organized, with a comfortable dental chair nestled in the middle and a sterile tray of dental instruments nearby. At least four gleaming dental mirrors of varying sizes rest on the tray, each possessing a gleaming and perfectly polished surface, reflecting the diligent care the clinic takes in maintaining its equipment. A nearby light source emits a soft yet intense glow, primed to illuminate the patient’s mouth for better visibility. Across the room, the patient sits in subdued anticipation, clutching a brochure on oral health that the dentist had handed him earlier. The dental assistant, donning a pristine white coat, stands by, eager to provide support and assistance during the session. Meanwhile, the waiting room just beyond the office houses a handful of people, their faces etched with a mix of nervousness and impatience. The walls are decorated with educational posters, serving as reminders for patients to maintain good oral hygiene. Despite the slight buzz of activity, the environment remains hushed, providing an ideal space for the dentist to tackle the verbal challenge ahead.', 'situation_json': '{\"location\": \"indoor office of a dental clinic\", \"room_size\": \"spacious\", \"lighting\": \"well-lit\", \"room_organization\": \"meticulously organized\", \"dental_chair_presence\": true, \"dental_chair_comfort\": \"comfortable\", \"dental_instruments_tray_presence\": true, \"sterile_tray\": true, \"dental_mirrors_count\": 4, \"dental_mirrors_condition\": \"gleaming and perfectly polished\", \"light_source\": true, \"light_intensity\": \"soft yet intense glow\", \"light_purpose\": \"to illuminate the patient\\'s mouth\", \"patient_location\": \"in the room\", \"patient_anticipation\": \"subdued anticipation\", \"patient_brochure_about\": \"oral health\", \"dental_assistant_presence\": true, \"dental_assistant_appearance\": \"pristine white coat\", \"dental_assistant_role\": \"to provide support and assistance\", \"waiting_room_presence\": true, \"waiting_room_occupancy\": \"handful of people\", \"waiting_room_mood\": \"nervousness and impatience\", \"wall_decorations\": \"educational posters\", \"decorations_purpose\": \"to remind patients about oral hygiene\", \"environment_buzz_level\": \"slight buzz\", \"environment_noise\": \"hushed\", \"environment_purpose\": \"ideal space for the dentist to teach\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128267.71 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 127147.93 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 57932.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Veterinary Technologist & Technician', 'process': 'Surgical Assistance', 'situation': 'In the brightly-lit, indoor operating room of the clinic, the veterinary technologist or technician meticulously arranges the surgical instruments on a sterile tray. Four gleaming, stainless-steel surgical instruments of various sizes lay neatly in a row, including two scalpels, a pair of forceps, and a set of sutures. The anesthesia machine, a vital piece of equipment in this process, hums softly in the background, its green light indicating that it is primed and ready for use. Nearby, the monitoring equipment, a compact display with multiple wires and sensors, stands at the ready to provide continuous updates on the animal’s vital signs throughout the procedure. The quiet of the operating room is occasionally broken by the distant chatter from the pet owners in the waiting room. In the consultation room, the pet owner waits nervously for the appointment, while the veterinarian prepares to provide the medical advice. The veterinary technician, dressed in scrubs and a surgical mask, is ready to assist the veterinarian during the surgery, monitoring the animal’s vital signs with a keen eye. This emotional process, requiring focus, teamwork, and compassion, is a daily occurrence in the life of a veterinary technologist or technician. Their role is crucial in ensuring the safety and well-being of the animal during surgery, with the outcome being a successful and safe surgical procedure for the animal.', 'situation_json': '{\"location\": \"brightly-lit, indoor operating room of the clinic\", \"instruments\": [\"scalpel\", \"scalpel\", \"pair of forceps\", \"set of sutures\"], \"instrument_count\": 4, \"instrument_material\": \"stainless-steel\", \"instrument_state\": \"meticulously arranged on a sterile tray\", \"anesthesia_machine_state\": \"humming softly\", \"anesthesia_machine_light\": \"green\", \"anesthesia_machine_readiness\": \"primed and ready for use\", \"monitoring_equipment_state\": \"ready to provide continuous updates\", \"background_noise\": \"occasional distant chatter from the pet owners\", \"waiting_room_status\": \"pet owner waiting nervously\", \"patient_status\": \"vital signs being monitored\", \"assistant_status\": \"ready to assist\", \"veterinarian_status\": \"preparing to provide medical advice\", \"emotional_atmosphere\": \"requiring focus, teamwork, and compassion\", \"outcome\": \"successful and safe surgical procedure for the animal\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 84247.73 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 123559.29 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88926.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Recreation & Fitness Worker', 'process': 'Staff Training', 'situation': 'The bustling gym, brightly illuminated with the hum of activity, hosts the critical process of staff training. The Recreation & Fitness Worker, a beacon of energy and expertise, stands at the center of a plush, deep blue exercise mat, surrounded by a semicircle of ten eager new staff members, each clad in color-coordinated fitness attire. The mat is strategically placed near the gleaming row of 15 different exercise machines, each one polished and perfectly maintained, their digital displays flickering with standby lights. The weights station holds racks filled with an array of 30 dumbbells and barbells, ranging from 5 to 50 pounds, each weight neatly nestled in its designated slot. Resistance bands of various colors and tensions are draped over a sturdy, metal stand beside the weights, offering 20 distinct levels of resistance. The new staff members, a mix of nervous anticipation and eager determination, stand alert with clipboards and pens at the ready, as the Recreation & Fitness Worker begins to demonstrate the first set of exercises. Their focused attention is occasionally interrupted by the clank of weights or the whir of treadmills from the busy gym floor just 20 feet away. The surrounding air is filled with the energetic buzz of 50 fitness enthusiasts engaged in their workouts, creating an atmosphere of collective determination. Nearby, three other trainers and gym management staff observe from a short distance, their gazes intent on the training session, ready to offer support yet discreetly positioned to avoid distracting the trainees. This dynamic yet controlled environment is perfectly orchestrated to ensure that the new staff members are equipped with the skills and knowledge necessary for their new roles, all under the watchful and expert guidance of the Recreation & Fitness Worker.', 'situation_json': '{\"document\": {\"exersise_mats\": [{\"color\": \"deep blue\", \"texture\": \"plush\", \"quantity\": 1, \"status\": \"in use\"}], \"exersise_machines\": [{\"phisical_condition\": \"polished and perfectly maintained\", \"power_condition\": \"flickering with strandby lights\", \"quantity\": 15}], \"staff_members\": [{\"equipment\": \"clipboards\", \"clothing\": \"color-coordinated fitness attire\", \"learning_level\": \"new\", \"emotions\": [\"nervous anticipation\", \"eager determination\"], \"quantity\": 10, \"status\": \"alert\"}], \"weights_station\": [{\"weights\": [{\"type\": \"barbells\", \"total_quantity\": 30, \"weightInPounds\": [5, 50]}], \"weights_condition\": \"neatly nestled in its designeted slot\"}], \"resistance_bends\": [{\"colors\": \"various\", \"tensions\": \"various\", \"total_quantity\": 1, \"levles_of_resistance\": 20}], \"gym_activity\": [{\"typeOfActivity\": \"clank of weights or whirr of treadmills\", \"status\": \"ongoing\", \"radius\": {\"measurement_value\": 20, \"measurement_unit\": \"feet\"}}], \"gym_enviroment\": [{\"type\": \"energetic buzz of fitness enthusiasts engaged in their workouts\", \"atmosphere\": \"collective determination\", \"total_quantity\": 50}], \"observers\": [{\"professions\": [\"trainers\", \"gym management staff\"], \"quantity\": 3, \"forcefulness_of_gaze\": {\"measurement_value\": 100, \"measurement_unit\": \"\"}, \"position\": \"discrete distance to avoid distraction of trainees\"}]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142590.95 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 156068.66 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95537.17 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paralegal', 'process': 'Trial Preparation', 'situation': \"In the hushed, dimly-lit law library of the bustling law firm, the air is thick with the scent of aged parchment and the faint hum of the ancient HVAC system. The room, a labyrinth of towering bookshelves, is bathed in the soft, yellow glow of vintage brass desk lamps, casting long, dancing shadows as the paralegal's fingers dance across the keyboard of their sleek, modern laptop. The clatter of their fingers is the only sound breaking the silence, save for the occasional muffled footfall in the hallway outside. The library, a sanctuary of legal knowledge, is home to countless leather-bound tomes, their spines adorned with gold lettering that glints in the lamplight. The paralegal's desk, a sprawling mahogany beast of a thing, is strewn with open books, legal pads scrawled with notes, and a forest of Post-it notes in every shade of the rainbow. The desk lamp casts a warm glow on the paralegal's face, highlighting the furrow of concentration on their brow as they pore over a dense legal text, their eyes scanning the fine print with the familiarity of a seasoned professional. The clock on the wall ticks away the seconds, each one bringing the paralegal one step closer to the deadline that looms like a specter in the back of their mind. Yet, amidst the chaos of paperwork and the weight of responsibility, there's a sense of order, a rhythm to the paralegal's work that's almost soothing. They're the unsung hero of the legal world, the oil that keeps the cogs of justice turning, and this is their domain, their battleground, where they wage war on legal jargon and red tape, one painstakingly drafted document at a time.\", 'situation_json': '{\"type\": \"object\", \"additionalProperties\": {\"type\": \"object\", \"properties\": {\"room_description\": {\"type\": \"string\"}, \"lighting\": {\"type\": \"string\"}, \"atmosphere\": {\"type\": \"string\"}, \"furniture\": {\"type\": \"string\"}, \"electronics\": {\"type\": \"string\"}, \"paraphernalia\": {\"type\": \"string\"}, \"paralegal_activity\": {\"type\": \"string\"}, \"decor\": {\"type\": \"string\"}, \"time_measurement\": {\"type\": \"string\"}, \"deadline_pressure\": {\"type\": \"string\"}, \"order_in_chaos\": {\"type\": \"string\"}, \"role_of_paralegal\": {\"type\": \"string\"}, \"mood\": {\"type\": \"string\"}, \"clock_time\": {\"type\": \"string\"}, \"clock_type\": {\"type\": \"string\"}, \"clock_location\": {\"type\": \"string\"}}}, \"required\": [\"room_description\", \"lighting\", \"atmosphere\", \"furniture\", \"electronics\", \"paraphernalia\", \"paralegal_activity\", \"decor\", \"time_measurement\", \"deadline_pressure\", \"order_in_chaos\", \"role_of_paralegal\", \"mood\", \"clock_time\", \"clock_type\", \"clock_location\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 106878.45 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 153042.00 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95083.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist', 'process': 'Continuing Education', 'situation': \"In the heart of the clinic, a Physical Therapist embarks on a three-day Continuing Education journey. The spacious treatment room, with its soft ivory walls, serves as the epicenter of this process. A gleaming silver laptop, accompanied by two stethoscopes, lies on the large wooden desk, ready for use. The laptop hums softly, as it is opened to reveal a plethora of patient records, each neatly categorized in the coding software. Nearby, a pair of sturdy hands, the therapist's most valuable tools, await the manual therapy session, supported by a bottle of soothing massage lotion. The nearby waiting room, with a few patients nestled in comfortable chairs, emits a calm and collected atmosphere. The therapist's colleagues, each engrossed in their respective roles, contribute to the hum of activity in the clinic. The balance beam, resistance bands, and exercise equipment stand ready, their gleaming surfaces reflecting the soft lighting of the room.\", 'situation_json': '{\"room_description\": {\"color\": \"ivory\", \"spaciousness\": true, \"treatment_room\": true}, \"laptop_description\": {\"quantity\": 1, \"color\": \"silver\", \"open\": true, \"software\": [\"coding software\", \"patient records\"], \"state\": \"humming\"}, \"stethoscopes_description\": {\"quantity\": 2, \"near_laptop\": true}, \"hands_description\": {\"condition\": \"sturdy\", \"usage\": \"manual therapy\", \"supported_by\": [\"massage lotion\"]}, \"waiting_room_description\": {\"occupancy\": true, \"mood\": \"calm\", \"colleague_activity\": true}, \"equipment_description\": {\"balance_beam\": {\"state\": \"ready\"}, \"resistance_bands\": {\"state\": \"ready\"}, \"exercise_equipment\": {\"state\": \"ready\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112206.09 examples/s]examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 68449.32 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91615.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Database Administrator', 'process': 'Database Maintenance', 'situation': \"In the heart of the IT department, a dedicated Database Administrator meticulously tends to the daily Database Maintenance process, a task that commands utmost attention and precision. The process takes place in the secure confines of the server room, an area strictly controlled for temperature and humidity, housing the physical servers that host the databases. The Database Administrator, skilled in using a Database Management System, such as Oracle, MySQL, or SQL Server, employs various tools to execute the process. Around the main table are an assortment of computers, network infrastructure equipment, and servers, all humming quietly, their steady, rhythmic activity a testament to the Database Administrator's diligence. The Database Administrator checks on the status of the servers, ensuring they are running optimally and that software updates are installed. Meanwhile, the office environment buzzes with activity, with Database Developers, Data Analysts, and Network Administrators working collaboratively. The Database Administrator periodically checks in with them, ensuring the organization's technology needs are met. The Database Administrator also takes care of the backup and recovery process, ensuring that the process is done correctly and that the backup files are stored securely in Data Storage. Remote monitoring is made possible by a fast and reliable network, ensuring the availability and reliability of databases. The entire process is a display of technical proficiency and dedication, a testament to the Database Administrator's role as the key person involved in maintaining the database system.\", 'situation_json': '{\"location\": \"server room\", \"temperature_controlled\": true, \"humidity_controlled\": true, \"equipment\": {\"servers\": {\"status\": \"running\", \"software_updates\": \"installed\"}, \"computers\": \"active\", \"network_infrastructure_equipment\": \"active\", \"backup_and_recovery_process\": \"enabled\", \"data_storage\": \"secure\", \"remote_monitoring\": \"enabled\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 87157.81 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150193.44 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96138.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mechanical Engineer', 'process': 'Designing Mechanical Systems', 'situation': \"As a Mechanical Engineer, I'm primarily responsible for the design and development of mechanical systems and equipment. This process involves conducting research and analyses to determine the requirements and specifications for new or modified systems. It also involves the use of computer-aided design (CAD) software to create detailed drawings and models of the systems. Additionally, I collaborate with other team members, including engineers from different disciplines, to ensure that the systems are designed to function safely and efficiently. The outcome of this process is the creation of mechanical systems that meet the client's needs and industry standards. I'm currently seated at my clutter-free, L-shaped, steel-gray desk, the surface adorned with precise, neatly arranged blueprints held down by a vintage, brass desk lamp and a sleek, black laptop humming softly, its screen displaying intricate CAD designs in a mesmerizing kaleidoscope of blues and greens. To my left, a towering bookshelf, its shelves groaning under the weight of countless technical manuals and reference books, each spine meticulously labeled in a uniform, sans-serif font. The air is filled with the faint scent of toner ink and the quiet whir of the laptop's cooling fan. My colleagues, a team of five, are scattered around the open-plan office, each engrossed in their own tasks, the room filled with the occasional murmur of conversation and the distant ringing of a telephone. The office, bathed in the harsh glow of fluorescent lighting, is a symphony of order and chaos, with desks arranged in neat rows, yet cluttered with stacks of papers, empty coffee cups, and assorted office supplies. The far wall is dominated by a sprawling whiteboard, scrawled with complex equations, schematics, and brainstorming notes, a testament to our collective genius and madness. The room is filled with the low hum of activity, the occasional clatter of a keyboard, the rustle of paper, and the faint buzz of conversation. The atmosphere is charged with a sense of purpose, a collective drive to push the boundaries of what's possible, to create something new, something better. I'm currently in the midst of designing a complex mechanical system, the details of which are still taking shape in my mind. I'm surrounded by the tools of my trade - a precision screwdriver, its tip gleaming in the harsh office lighting, lies discarded on the desk, a testament to a recent foray into the world of prototyping. My laptop, its screen a riot of colors and shapes, is my primary tool, the CAD software within its digital confines my paint and brush. Yet, it's not just about the tools, it's about the people. My team, my colleagues, my mentors - we're all in this together, each of us bringing our unique perspective, our individual expertise to the table. We're not just designing mechanical systems, we're building something greater than the sum of its parts. We're building a future.\", 'situation_json': '{\"desk\": {\"material\": \"steel-gray\", \"shape\": \"L-shaped\", \"clutter\": \"clutter-free\"}, \"desk_contents\": {\"blueprints\": {\"quantity\": 1, \"arrangement\": \"neatly\", \"color\": \"blue\"}, \"laptop\": {\"status\": \"humming softly\", \"screen_display\": \"intricate CAD designs\", \"colors\": [\"blues\", \"greens\"]}, \"desk_lamp\": {\"material\": \"brass\", \"age\": \"vintage\"}}, \"bookshelf\": {\"material\": \"wood\", \"shelf_weight\": \"groaning\", \"books\": {\"quantity\": \"countless\", \"label_font\": \"uniform, sans-serif\"}}, \"office\": {\"layout\": \"open-plan\", \"desks\": {\"quantity\": 5, \"arrangement\": \"neat rows\", \"clutter\": \"cluttered with stacks of papers, empty coffee cups, assorted office supplies\"}, \"whiteboard\": {\"contents\": \"complex equations, schematics, brainstorming notes\", \"dimensions\": \"sprawling\"}, \"lighting\": \"fluorescent\", \"sounds\": [\"occasional murmur of conversation\", \"distance ringing of a telephone\", \"low hum of activity\", \"clatter of a keyboard\", \"rustle of paper\", \"faint buzz of conversation\"], \"atmosphere\": \"charged with a sense of purpose\", \"collective_drive\": \"to push the boundaries of what\\'s possible, to create something new, something better\"}, \"mechanical_system\": {\"design_status\": \"in progress\", \"details\": \"still taking shape in my mind\"}, \"tools\": {\"precision_screwdriver\": {\"status\": \"discarded\", \"location\": \"on the desk\"}}, \"laptop_tool\": {\"software\": \"CAD\", \"function\": \"primary tool\"}, \"design_philosophy\": \"not just about the tools, it\\'s about the people. My team, my colleagues, my mentors - we\\'re all in this together, each of us bringing our unique perspective, our individual expertise to the table. We\\'re not just designing mechanical systems, we\\'re building something greater than the sum of its parts. We\\'re building a future.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142302.62 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139033.21 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90264.79 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Executive Assistant', 'process': 'Confidential Information Handling', 'situation': \"In a luxurious tan painted Executive Office, exceptionally lightened by a large east-facing window, an Executive Assistant sits at a modern glass desk with a smooth finish. The room is filled with the hum of a sleek, high-performance laptop running email management software and calendar tools. On the polished mahogany shelves behind the desk are neatly organized files and a few potted plants that add a touch of nature. The room boasts pristine white walls adorned with inspiring artwork that complements the modern office aesthetic. In the corner sits a locked, fireproof file cabinet containing sensitive documents, ensuring confidentiality. The room is equipped with a state-of-the-art multi-line telephone for efficient communication. Across the room, a large whiteboard displays ongoing projects and deadlines. The Executive Assistant is dressed professionally, adding to the aura of competence and efficiency. In the adjacent office down the hall, the Executive is working diligently at their desk, occasionally requesting the Assistant's support for administrative tasks. Nearby, other staff members are busily engaged in their respective duties, their voices creating a soft background murmur. Periodically, the Executive Assistant interacts with other colleagues and external clients both in person and via teleconference, maintaining a calm and professional demeanor throughout. The environment is both productive and serene, reflecting the precision and dedication required for managing confidential information.\", 'situation_json': '{\"situation\": \"In a luxurious tan painted Executive Office, exceptionally lightened by a large east-facing window, an Executive Assistant sits at a modern glass desk with a smooth finish. The room is filled with the hum of a sleek, high-performance laptop running email management software and calendar tools. On the polished mahogany shelves behind the desk are neatly organized files and a few potted plants that add a touch of nature. The room boasts pristine white walls adorned with inspiring artwork that complements the modern office aesthetic. In the corner sits a locked, fireproof file cabinet containing sensitive documents, ensuring confidentiality. The room is equipped with a state-of-the-art multi-line telephone for efficient communication. Across the room, a large whiteboard displays ongoing projects and deadlines. The Executive Assistant is dressed professionally, adding to the aura of competence and efficiency. In the adjacent office down the hall, the Executive is working diligently at their desk, occasionally requesting the Assistant\\'s support for administrative tasks. Nearby, other staff members are busily engaged in their respective duties, their voices creating a soft background murmur. Periodically, the Executive Assistant interacts with other colleagues and external clients both in person and via teleconference, maintaining a calm and professional demeanor throughout. The environment is both productive and serene, reflecting the precision and dedication required for managing confidential information.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136627.37 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 110660.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96114.19 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Risk Management', 'situation': 'In the heart of a bustling corporate office, a Management Analyst, engrossed in the task of risk management, is sitting at a well-organized desk. The desk is adorned with not one, not two, but four high-tech computers, each serving a distinct purpose. A primary computer is used for running specialized risk management software, while another is dedicated to project management and tracking. A third, portable laptop is used for conducting research and creating reports, while the fourth computer is solely dedicated to financial modeling and budgeting. Surrounding each computer is a myriad of additional tools - presentation software for crafting compelling arguments, documentation tools for maintaining a thorough record, and a plethora of communication tools for seamless collaboration with stakeholders, management, and employees alike. A handful of employees are seated nearby, engrossed in their own tasks, while a meeting room, filled with a multitude of stakeholders, lies just around the corner.', 'situation_json': '{\"location\": \"corporate office\", \"equipment\": {\"computers\": 4, \"computers_purpose\": {\"primary\": \"risk management software\", \"secondary\": \"project management and tracking\", \"portable\": \"research and report creation\", \"dedicated\": \"financial modeling and budgeting\"}, \"additional_tools\": {\"presentation_software\": true, \"documentation_tools\": true, \"communication_tools\": true}}, \"employees_present\": true, \"meeting_room_status\": \"occupied\", \"stakeholders_present\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139206.84 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 149047.52 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96563.61 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Counselor', 'process': 'Referral Coordination', 'situation': 'In the heart of a bustling school, nestled within the labyrinthine corridors, lies the school counseling office. This sanctuary of calm, painted in soothing shades of pale blue and soft grey, is where most counseling sessions take place. The room is adorned with two comfortable chairs, their fabric a deep blue that contrasts with the lighter hues of the walls. A small table, its surface uncluttered but for a neat stack of notebooks and a solitary pen, sits between the chairs. A laptop, humming gently, rests on a larger desk nearby, its screen illuminated with student records and communication tools. A phone, sleek and black, waits silently for its next call. In one corner, a modest bookshelf leans against the wall, filled with educational materials and books on social-emotional learning, their spines neatly aligned. The room is a beacon of peace amidst the hive of activity that is the school, a place where students can feel at ease to share their concerns and seek guidance. Every week, without fail, the school counselor, a beacon of empathy and wisdom, coordinates referrals and develops plans to address students needs. This may involve providing counseling services directly to the student, or it may involve coordinating with other professionals such as teachers or psychologists to provide those services. The ultimate goal is to help the student succeed academically and socially. A nearby waiting room, comfortable and welcoming, is available for students and parents to wait before their session. The process of referral coordination is emotional, challenging yet rewarding. It is a balancing act that requires patience, understanding, and a whole lot of heart.', 'situation_json': '{\"description\": \"The room is adorned with two comfortable chairs, their fabric a deep blue that contrasts with the lighter hues of the walls. A small table, its surface uncluttered but for a neat stack of notebooks and a solitary pen, sits between the chairs. A laptop, humming gently, rests on a larger desk nearby, its screen illuminated with student records and communication tools. A phone, sleek and black, waits silently for its next call. In one corner, a modest bookshelf leans against the wall, filled with educational materials and books on social-emotional learning, their spines neatly aligned. The room is a beacon of peace amidst the hive of activity that is the school, a place where students can feel at ease to share their concerns and seek guidance.\", \"equipment_states\": {\"chairs\": {\"color\": \"deep blue\", \"count\": 2, \"comfortability\": \"comfortable\"}, \"table\": {\"objects_on_surface\": [\"neat stack of notebooks\", \"solitary pen\"], \"surface_state\": \"uncluttered\"}, \"laptop\": {\"location\": \"larger desk nearby\", \"screen_state\": \"illuminated with student records and communication tools\", \"noise_state\": \"humming gently\"}, \"phone\": {\"color\": \"sleek and black\", \"wait_state\": \"silently for its next call\"}, \"bookshelf\": {\"books\": [\"educational materials\", \"books on social-emotional learning\"], \"alignment\": \"neatly aligned\", \"location\": \"in one corner of the room\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 143566.73 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150645.61 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95047.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Legal Research', 'situation': \"Inside the bustling law firm, the lawyer sits at their desk in a secluded corner, surrounded by an air of focus and determination. The room is filled with the hum of soft chatter from the nearby staff room, where colleagues and support staff are engrossed in their own legal research. On the desk sits a powerful computer, its screen illuminated with various legal research databases. The lawyer's fingers dance across the keyboard, navigating through Westlaw and LexisNexis with ease, the ticking of the clock the only soundtrack to their diligent work. A legal pad filled with notes and scribbles sits off to the side, a testament to the countless hours spent on this particular case. In the office, there are several other lawyers engaged in similar tasks, each of them immersed in their own legal research. Across the room, a group of paralegals and law clerks huddles together, collaborating on a complex legal document. The law library, a haven for legal research, lies just beyond the bustling office, filled with countless legal texts and resources. In the break room, a few lawyers can be seen taking a brief respite from their lengthy negotiations, their faces filled with fatigue but determined to continue their work.\", 'situation_json': '{\"location\": \"law firm\", \"work_environment\": \"secluded corner, surrounded by an air of focus and determination\", \"background_noise\": \"hum of soft chatter from nearby staff room\", \"equipment\": {\"computer\": {\"state\": \"powerful, screen illuminated with various legal research databases\"}}, \"legal_research_data\": {\"Westlaw\": \"navigating with ease\", \"LexisNexis\": \"navigating with ease\"}, \"legal_pad\": \"filled with notes and scribbles\", \"professional_environments\": {\"office\": {\"number_of_lawyers\": \"several\", \"work_status\": \"engaged in similar tasks, each immersed in their own legal research\"}, \"law_library\": {\"state\": \"filled with countless legal texts and resources\"}, \"break_room\": {\"number_of_lawyers\": \"a few\", \"activity\": \"taking a brief respite from their lengthy negotiations\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 87894.32 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 157755.03 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89161.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Classroom Management', 'situation': 'In the bustling indoor space of the middle school classroom, the Middle School Teacher diligently manages a conducive learning environment. The room is filled with an array of equipment, most notably the crisp whiteboard and the sleek laptop on the teacher’s desk, both of which are instrumental in presenting and sharing information. Nearby, the students are engaged in their work at their desks, their focus unwavering. Occasionally, the teacher gives guidance using the red pen to grade assignments with the help of a detailed rubric. In the proximity, the staff room and the library serve as additional spaces for collaborative activities and research. The teacher also frequents the office space for planning and administrative tasks. Throughout the day, students and teachers alike actively participate in Parent Communication in a quiet office space, and assessments are frequently conducted to ensure comprehensive understanding of the curriculum.', 'situation_json': '{\"classroom_space\": \"indoor\", \"equipment\": {\"whiteboard\": \"crisp\", \"laptop\": \"sleek\"}, \"students_focus\": \"unwavering\", \"teacher_guidance_tool\": \"red pen\", \"teacher_grading_tool\": \"detailed rubric\", \"additional_spaces\": {\"staff_room\": \"collaborative activities\", \"library\": \"research\"}, \"teacher_planning_space\": \"office space\", \"parent_communication_space\": \"quiet office space\", \"assessment_frequency\": \"frequent\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 97791.02 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147866.45 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92331.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Substance Abuse Counselor', 'process': 'Community Outreach', 'situation': \"In the heart of the bustling community, nestled within the vibrant, multi-hued community center, the substance abuse counselor is deeply engaged in their pivotal role of community outreach. The spacious community center, adorned with colorful murals and hand-crafted posters, hums with life and activity. The counselor, dressed in a crisp, professional suit, sits at a table laden with an array of resources. Among these are three laptops, their glossy screens reflecting the soft warm lights above; two sleek smartphones, neatly placed beside sleeves of pamphlets and brochures featuring diverse hues. Beside the counselor, a stack of notebooks waits patiently, their crisp, blank pages promising to absorb the day's insights and plans. The waiting room, just a few paces away, is filled with a constellation of chairs, twenty in total, occupied by a mix of clients, support staff, and community members, each engrossed in reading materials tailored to substance abuse and recovery. Across the hall, in a room bathed in natural light filtering through large windows, a group therapy session is underway. Ten clients, supported by five family members, are actively participating, their heads bowed in intense discussion. Meanwhile, in the office adjacent, the counselor's colleague is diligently documenting progress notes on a computer, while eight other colleagues are immersed in workshops at various localities, including schools and faith-based organizations. The air is filled with a potent blend of determination, empathy, and the shared vision of healing and support that defines the community outreach initiative of substance abuse counselors.\", 'situation_json': '{\"situation\": \"In the heart of the bustling community, nestled within the vibrant, multi-hued community center, the substance abuse counselor is deeply engaged in their pivotal role of community outreach. The spacious community center, adorned with colorful murals and hand-crafted posters, hums with life and activity. The counselor, dressed in a crisp, professional suit, sits at a table laden with an array of resources. Among these are three laptops, their glossy screens reflecting the soft warm lights above; two sleek smartphones, neatly placed beside sleeves of pamphlets and brochures featuring diverse hues. Beside the counselor, a stack of notebooks waits patiently, their crisp, blank pages promising to absorb the day\\'s insights and plans. The waiting room, just a few paces away, is filled with a constellation of chairs, twenty in total, occupied by a mix of clients, support staff, and community members, each engrossed in reading materials tailored to substance abuse and recovery. Across the hall, in a room bathed in natural light filtering through large windows, a group therapy session is underway. Ten clients, supported by five family members, are actively participating, their heads bowed in intense discussion. Meanwhile, in the office adjacent, the counselor\\'s colleague is diligently documenting progress notes on a computer, while eight other colleagues are immersed in workshops at various localities, including schools and faith-based organizations. The air is filled with a potent blend of determination, empathy, and the shared vision of healing and support that defines the community outreach initiative of substance abuse counselors.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 118728.69 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140993.05 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 66112.56 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'IT Manager', 'process': 'Project Management', 'situation': \"The IT Manager, a diligent professional with a remarkable understanding of technology and business processes, is nestled in their office within the bustling Company Headquarters. Equipped with a high-performance laptop, they skillfully navigate through a multitude of tasks. Their desk, a testament to their role, is adorned with an array of equipment: a gleaming desktop computer, a powerful server, and a myriad of networking equipment. The server, humming quietly in the corner, hosts a variety of applications and securely stores an extensive amount of data. The networking equipment ensures a seamless flow of communication and information across the organization. The office is a hive of activity, with IT staff members busily managing various IT functions under the manager's strategic guidance. Meeting rooms, pantries, and lounges are interspersed throughout the office space, contributing to a positive, collaborative work environment. The server room, a vital nerve center of the organization, is just a few steps away, requiring regular maintenance and monitoring. The IT Manager also spends considerable time visiting client sites, understanding their IT needs, and providing solutions. They engage in rigorous project management, ensuring alignment of technology with business strategy, a task that requires strong leadership, communication, and strategic decision-making skills.\", 'situation_json': '{\"location\": \"Company Headquarters\", \"equipment\": {\"laptop\": {\"performance\": \"high-performance\"}, \"desktop_computer\": {\"condition\": \"gleaming\"}, \"server\": {\"state\": \"powered\", \"noise_level\": \"quiet\", \"hosted_applications\": \"variety\", \"data_storage_capacity\": \"extensive\"}, \"networking_equipment\": {\"state\": \"powered\", \"function\": \"seamless_communication_and_information_flow\"}}, \"office_space\": {\"activity_level\": \"high\", \"layout\": {\"feature\": [\"meeting_rooms\", \"pantries\", \"lounges\"]}, \"environment\": \"positive_and_collaborative\"}, \"additional_facility\": {\"server_room\": {\"location\": \"nearby\", \"maintenance_needed\": true, \"monitoring_needed\": true}}, \"manager_activity\": {\"onsite_management\": {\"frequency\": \"regular\"}, \"onsite_client_visits\": {\"frequency\": \"considerable\"}, \"project_management_activities\": {\"leadership\": \"strong\", \"communication\": \"effective\", \"decision_making\": \"strategic\", \"alignment\": \"technology_and_business_strategy\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134267.57 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 158205.03 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 70771.89 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Carpenter', 'process': 'Maintenance', 'situation': \"In the heart of the Maintenance Workshop, a bustling carpenter diligently tends to the upkeep and repair of wooden structures and objects. The workshop is a symphony of purposeful activity, filled with the rhythmic sounds of tools against wood. The carpenter, clad in worn jeans and a shirt dotted with paint splatters, skillfully wields a hammer, driving nails into a sturdy oak plank laid out on the Workshop Bench. The bench, a stalwart of the workshop, is littered with various tools - a measuring tape coiled4 beside a sketchpad, a sander humming softly as it smoothes out a rough edge, and a collection of sandpapers of different grits, their edges softened by use. Nearby, a circular saw sits idle, its blade glinting menacingly under the bright fluorescent lights. The air is filled with a fine dust, a testament to the ongoing work, and the scent of freshly sawed wood mingles with the fainter odor of stain and varnish. In the background, an assistant stands by, ready to fetch tools or provide assistance as needed. The workshop is a well-ventilated area, necessary to prevent the buildup of harmful fumes, and the air is fresh and cool, a stark contrast to the warmth of the workbench light above. Behind them, the storage area is a organized chaos of shelves lined with tools, materials, and partial projects waiting for their turn at attention. The carpenter's hands, calloused from years of work, move with an expertise born of experience, each tap of the hammer echoing through the space with a sense of accomplishment. The maintenance tasks are a daily routine, the carpenter and assistant moving synchronously, a dance of efficiency and skill honed over time. The process, a delicate balance of craftsmanship and practicality, is a tribute to the dedication and hard work that goes into maintaining the structural integrity and aesthetic quality of wooden elements. The goal is crystal clear - to ensure the functionality and extended lifespan of wooden structures while keeping them aesthetically pleasing, a timeless testament to the carpenter's art and skill.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  82%|████████▏ | 592/723 [2:10:30<12:57,  5.94s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Media Relations', 'situation': \"In the communication office, a Public Relations Specialist is seated at their desk, surrounded by the buzz of their colleagues at work. The room is vibrant and filled with activity, with a bright, open-concept design that encourages collaboration and creativity. The specialist's desk is orderly yet busy, with a high-performance laptop, a state-of-the-art phone, and a collection of media kits neatly stacked to one side. The office building is nestled in the heart of the city, flanked by bustling media offices and news agencies that are a crucial point of contact for the specialist. The specialist is currently in the midst of creating a press release for an upcoming event, carefully crafting each sentence to ensure the right message is conveyed to their target audience. Their challenge lies in ensuring that the message is not only understood, but also resonates with the target audience. The specialist works continuously, constantly managing and responding to various ongoing communications tasks while also monitoring the situation for any potential crisis that may arise. This work involves a high degree of mental strain, as the specialist must maintain a positive image for their clients or employer while also mitigating any negative publicity.\", 'situation_json': '{\"office_ambience\": \"vibrant\", \"office_design\": \"open-concept\", \"desk_state\": \"orderly yet busy\", \"laptop_performance\": \"high-performance\", \"phone_model\": \"state-of-the-art\", \"media_kits_state\": \"neatly stacked\", \"office_location\": \"heart of the city\", \"surrounding_offices\": \"media offices and news agencies\", \"current_task\": \"creating a press release\", \"mental_strain\": true, \"crisis_management\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114812.97 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 135455.64 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95794.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Glazier', 'process': 'Glass Selection', 'situation': \"In the bustling shop, a glazier is busy with the meticulous process of glass selection. The shop, filled with the scent of freshly cut glass and the hum of quiet efficiency, is a testament to the glazier's craft. The glazier is surrounded by an array of equipment essential to their task: a worn but faithful tape measure, a collection of vibrant glass samples showcasing different types and colors, a sleek laptop open to customer records and glazing options, and a trusty measuring tape draped over the workbench.\\n\\nNext to the workbench, a glass cutter with a sharp, gleaming blade rests alongside a pair of safety glasses, ready to be donned at a moment's notice. Nearby, a putty knife and sealant sit organized, their handles slightly worn from frequent use. Additional essentials include another tape measure, more glass samples, a second glass cutter, a suction cup for handling larger glass panels, and a reliable ladder for reaching those hard-to-access areas. Power tools, such as diamond saws and drills, stand ready, while safety gear like harnesses, roof anchors, guardrails, suction cups, and protective clothing are neatly arranged, reflecting the glazier's commitment to safety.\\n\\nThe shop is adjacent to the warehouse, where large sheets of glass are stored and cut to size. The customer's office is nearby, and a window in the corner of the shop hints at the glazier's work—repairing the frame and preparing new glass for installation. Across the way, the glass shop hums with activity, as glass is cut and shaped for various projects. Outside, the construction site buzzes with energy, where the final stage of installation will take place.\\n\\nIn the midst of this organized chaos, the glazier works diligently, consulting with a client who sips coffee from a nearby mug, discussing the specific needs and preferences for their new glass installation. The client's requirements involve energy efficiency, security, and aesthetic considerations, guiding the glazier's selection of the perfect glass. The glazier's movements are precise, their eyes keen as they take measurements and showcase different glass options, ensuring the selected glass meets all safety standards and regulations. The outcome is a glass that not only fits the window perfectly but also enhances the overall look and functionality of the client's space.\", 'situation_json': '{\"Scene\": {\"Shop\": {\"Scent\": \"freshly cut glass\", \"Hum\": \"quiet efficiency\", \"Adjacent\": [\"warehouse (stores and cuts large sheets of glass)\", \"customer\\'s office\", \"window\"], \"AmbientSound\": {\"shop\": \"hum with activity, constant cutting and shaping of glass for various projects\", \"construction site\": \"buzz with energy, final stage of installation\"}, \"Client\": {\"Activity\": \"sips coffee from a nearby mug\", \"Discussions\": \"specific needs and preferences for new glass installation\", \"Requirements\": [\"energy efficiency\", \"security\", \"aesthetic considerations\"]}}, \"Equipment\": {\"tape measure\": {\"state\": \"worn but faithful\", \"location\": \"surrounded by glazier\"}, \"glass samples\": {\"state\": [\"vibrant\", \"various types and colors\"], \"location\": \"surrounded by glazier\"}, \"laptop\": {\"state\": \"sleek\", \"openTo\": [\"customer records\", \"glazing options\"], \"location\": \"surrounded by glazier\"}, \"measuring tape\": {\"state\": \"trusty\", \"location\": \"draped over the workbench\"}, \"glass cutter\": {\"state\": [\"sharp, gleaming blade\", \"trusty\"], \"location\": [\"next to workbench\", \"additional essentials\"], \"associatedTools\": [\"pair of safety glasses\", \"diamond saws\", \"drills\"]}, \"putty knife\": {\"state\": [\"worn handles\", \"organized\"], \"location\": \"nearby\"}, \"sealant\": {\"location\": \"nearby\"}, \"suction cup\": {\"state\": \"large\", \"location\": \"additional essentials\"}, \"ladder\": {\"state\": \"reliable\", \"location\": \"additional essentials\"}, \"safety gear\": {\"state\": \"neatly arranged\", \"types\": [\"harnesses\", \"roof anchors\", \"guardrails\", \"suction cups\", \"protective clothing\"], \"location\": \"additional essentials\"}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 141693.32 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 154251.75 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95943.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Art Director', 'process': 'Trend Analysis', 'situation': \"The Art Director, clad in a sharp, tailored suit, steps into the bustling creative agency, the scent of fresh coffee wafting through the air. The office, a symphony of open-plan workspaces and private meeting rooms, is abuzz with the hum of creative energy. The Art Director's desk, a sprawling, immaculate expanse of polished wood, is adorned with not one, not two, but three state-of-the-art monitors, each displaying a different design software interface, their vibrant colors a testament to the director's commitment to staying current with the latest design trends. The director's chair, a sleek, ergonomic masterpiece, is positioned perfectly to offer a panoramic view of the design studio, where a team of designers, armed with Wacom tablets and high-end computers, are hunched over their desks, lost in the world of digital creation. The studio is a riot of color, with mood boards and inspirational prints plastered on every wall, each one a visual representation of the director's keen eye for detail and aesthetic sensibilities. The Art Director's day begins with a meeting in the conference room, a space filled with the quiet hum of anticipation. The room, bathed in the soft glow of a chandelier crafted from repurposed light bulbs, is dominated by a sleek, oval table, its surface a mirror-like reflection of the director's steely resolve. Around the table sit the design team, their eyes flicking between the director and the array of laptops and tablets scattered across the table. The air is thick with the scent of freshly brewed coffee, the lifeblood of the creative agency, poured from a gleaming, industrial-style coffee maker that sits pride of place in the corner of the room. The meeting begins, the director's voice cutting through the chatter like a laser, their words painting a vivid picture of the project's vision. The team listens, rapt, their fingers itching to bring the director's words to life. After the meeting, the Art Director retreats to their office, a sanctuary of calm amidst the creative chaos. The room, bathed in the soft glow of a vintage table lamp, is a study in minimalism, with a single, striking artwork adorning the wall behind the director's desk. The director's laptop, a sleek, silver beast, sits open on the desk, its screen displaying the project's budget, a labyrinth of numbers that the director navigates with the ease of a seasoned sailor. The Art Director's day is a dance, a delicate balancing act of creativity and commerce, of inspiration and logistics. It is a testament to the director's skill, their ability to straddle the line between art and business, between vision and reality. It is, in a word, art direction.\", 'situation_json': '{\"situation\": \"The Art Director, clad in a sharp, tailored suit, steps into the bustling creative agency, the scent of fresh coffee wafting through the air. The office, a symphony of open-plan workspaces and private meeting rooms, is abuzz with the hum of creative energy. The Art Director\\'s desk, a sprawling, immaculate expanse of polished wood, is adorned with not one, not two, but three state-of-the-art monitors, each displaying a different design software interface, their vibrant colors a testament to the director\\'s commitment to staying current with the latest design trends. The director\\'s chair, a sleek, ergonomic masterpiece, is positioned perfectly to offer a panoramic view of the design studio, where a team of designers, armed with Wacom tablets and high-end computers, are hunched over their desks, lost in the world of digital creation. The studio is a riot of color, with mood boards and inspirational prints plastered on every wall, each one a visual representation of the director\\'s keen eye for detail and aesthetic sensibilities. The Art Director\\'s day begins with a meeting in the conference room, a space filled with the quiet hum of anticipation. The room, bathed in the soft glow of a chandelier crafted from repurposed light bulbs, is dominated by a sleek, oval table, its surface a mirror-like reflection of the director\\'s steely resolve. Around the table sit the design team, their eyes flicking between the director and the array of laptops and tablets scattered across the table. The air is thick with the scent of freshly brewed coffee, the lifeblood of the creative agency, poured from a gleaming, industrial-style coffee maker that sits pride of place in the corner of the room. The meeting begins, the director\\'s voice cutting through the chatter like a laser, their words painting a vivid picture of the project\\'s vision. The team listens, rapt, their fingers itching to bring the director\\'s words to life. After the meeting, the Art Director retreats to their office, a sanctuary of calm amidst the creative chaos. The room, bathed in the soft glow of a vintage table lamp, is a study in minimalism, with a single, striking artwork adorning the wall behind the director\\'s desk. The director\\'s laptop, a sleek, silver beast, sits open on the desk, its screen displaying the project\\'s budget, a labyrinth of numbers that the director navigates with the ease of a seasoned sailor. The Art Director\\'s day is a dance, a delicate balancing act of creativity and commerce, of inspiration and logistics. It is a testament to the director\\'s skill, their ability to straddle the line between art and business, between vision and reality. It is, in a word, art direction.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 101244.41 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130978.08 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88322.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dentist', 'process': 'Performing Dental Procedures', 'situation': \"In the heart of the bustling dental clinic, the treatment room, a sanctuary of gleaming steel and pristine white, is where Dr. Amelia, a dentist with a decade of experience, begins her day. The room, bathed in the cool glow of fluorescent lights, is a symphony of equipment, each piece meticulously placed and humming with potential. The dental chair, a throne of comfort and technology, stands sentinel in the center, its upholstery a plush, inviting navy blue, ready to cradle the day's first patient. To its side, a tray groans under the weight of an array of dental mirrors, their silver surfaces winking like tiny, perfect moons, each one polished to a mirror sheen and ready for action. The dental drill, a sleek, black beast of burden, lies in wait, its high-speed whine a distant threat, while the suction device, a quiet, unassuming hero, nestles nearby, ready to save the day with a simple slurp. The room is a hive of activity, with dental assistants buzzing to and fro, their scrubs a riot of color against the sterile backdrop. In the waiting room, a menagerie of patients await their turn, a dozen or so strong, each lost in their own world of magazines and headphones, the air thick with the scent of coffee and antiseptic. The clinic, a labyrinth of corridors and rooms, echoes with the distant hum of activity, a symphony of health and healing that is music to Dr. Amelia's ears. Today, like every day, is a dance with teeth and gums, a ballet of drill and mirror, and she, the maestro, takes her place at the helm, ready to guide her patients through the mysterious, wonderful world of dentistry.\", 'situation_json': '{\"treatment_room\": {\"florentine_lights\": {\"state\": \"on\"}, \"dental_chair\": {\"color\": \"navy_blue\", \"state\": \"ready\"}, \"dental_instruments\": {\"dental_mirror\": {\"quantity\": 6, \"state\": \"polished\"}, \"dental_drill\": {\"state\": \"idle\"}, \"suction_device\": {\"state\": \"ready\"}}, \"assistants\": {\"quantity\": 2, \"uniform\": \"scrubs\", \"color\": \"various\"}, \"waiting_room\": {\"patients\": {\"quantity\": 12, \"activities\": [\"reading_magazines\", \"listening_to_headphones\"]}, \"scent\": [\"coffee\", \"antiseptic\"]}, \"clinic\": {\"activity_level\": \"high\", \"sound\": \"hum_of_activity\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129996.26 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 96516.11 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96642.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Client Communication', 'situation': \"In the heart of the bustling Web Development Company, a dedicated Web Developer is deeply immersed in the Client Communication process. The office, bathed in the warm glow of the overhead lights, is a hub of creativity and innovation. The developer is seated at a spacious desk, flanked by a sophisticated computer with a sleek, ergonomic keyboard and a responsive mouse. The developer's computer screen is a vivid display of project management tools, with detailed timelines, color-coded tasks, and ongoing communication threads with the client. In the same room, the Project Manager is engrossed in reviewing project specifications, while the designer is meticulously crafting the visual aspects of the website. The client, located in a different city, is connected through a video conference call, the screen flickering with their image. The atmosphere in the office is calm, yet filled with a sense of urgency as the team strives to understand the client's requirements and provide timely updates.\", 'situation_json': '{\"office_lighting\": \"overhead lights\", \"office_vibe\": \"hub of creativity and innovation\", \"developer_desk\": \"spacious\", \"developer_computer\": \"sophisticated\", \"developer_keyboard\": \"ergonomic\", \"developer_mouse\": \"responsive\", \"developer_screen_status\": \"vivid display of project management tools\", \"developer_screen_content\": \"detailed timelines, color-coded tasks, ongoing communication threads with client\", \"project_manager_activity\": \"reviewing project specifications\", \"designer_activity\": \"crafting visual aspects of website\", \"client_connection\": \"video conference call\", \"client_location\": \"different city\", \"office_atmosphere\": \"calm, sense of urgency\", \"team_goal\": \"understand client requirements, provide timely updates\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122842.62 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134236.59 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84165.33 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Registered Nurse', 'process': 'Care Coordination', 'situation': \"In the treatment room, the air is sterile and crisp, the walls painted a soothing pastel blue. The sunlight streams in through the large windows, casting a warm glow on the polished surfaces. On the counter, a neatly arranged tray holds a stethoscope, its gleaming silver tubing coiled like a serpent, and a blood pressure monitor, its screen displaying a standby mode with a faint green backlight. Next to it, a pulse oximeter sits ready, its sensor clip open and awaiting a patient's finger. In the center of the room stands a meticulously made hospital bed, its white sheets and blankets folded with precision, a pillow plumped invitingly. A wheelchair is tucked into the corner, its chrome frame shining, ready to transport patients with ease.\\n\\nThe adjacent waiting room is a picture of contrasting calm and anticipation. Six people sit in the blue upholstered chairs, their faces a mix of patience and anxiety. A stack of well-thumbed magazines lies on the side table, and a flat-screen TV murmurs softly in the background, displaying a nature documentary. The air is filled with the faint scent of disinfectant, a reminder of the rigorous cleaning procedures in place.\\n\\nJust down the hallway, the nursing station is a hub of activity. Two nurses are engaged in a hushed conversation, one consulting a medication chart, the other jotting notes on a documentation form. A medication cabinet, secured with a heavy lock, stands against the wall, housing an array of pharmaceuticals. A nearby supply room is stocked with boxes of gloves, gowns, and other personal protective equipment, ready for the next shift.\\n\\nIn the quiet of the treatment room, a sense of readiness permeates the air. The equipment stands at attention, the nurses are poised and professional, and the patients wait with a mix of hope and trepidation. The scene is set for the continuous, meticulous work of care coordination, where every detail counts and every moment matters.\", 'situation_json': '{\"treatment_room\": {\"air_quality\": \"sterile\", \"air_temperature\": \"crisp\", \"wall_color\": \"pastel blue\", \"sunlight\": \"streaming\", \"counter\": {\"tray\": {\"position\": \"neatly arranged\", \"objects\": {\"stethoscope\": {\"tubing_color\": \"silver\", \"tubing_state\": \"coiled\"}, \"blood_pressure_monitor\": {\"screen_display\": \"standby\", \"backlight_color\": \"faint green\"}}, \"pulse_oximeter\": {\"sensor_clip_state\": \"open\"}}, \"hospital_bed\": {\"sheets_color\": \"white\", \"sheets_state\": \"folded with precision\", \"pillow_state\": \"plumped\"}, \"wheelchair\": {\"frame_material\": \"chrome\", \"frame_state\": \"shining\", \"position\": \"tucked into the corner\"}}, \"adjacent_waiting_room\": {\"people_count\": 6, \"chairs_color\": \"blue\", \"people_state\": {\"faces\": \"mix of patience and anxiety\"}, \"magazines_state\": \"well-thumbed\", \"tv_state\": {\"volume\": \"soft\", \"display\": \"nature documentary\"}}, \"hallway\": {\"nursing_station\": {\"nurses_count\": 2, \"nurses_activity\": {\"conversation_state\": \"hushed\", \"objects\": {\"medication_chart\": {}, \"documentation_form\": {\"nurse_action\": \"jotting notes\"}}}, \"medication_cabinet\": {\"lock_state\": \"secured\", \"contents\": \"pharmaceuticals\"}}, \"supply_room\": {\"contents\": {\"gloves\": true, \"gowns\": true, \"personal_protective_equipment\": true}}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 116637.59 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142653.63 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93918.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist', 'process': 'Manual Therapy', 'situation': 'Inside a clean and quiet treatment room, a physical therapist is seen performing manual therapy on a patient. The therapist is using their hands to manipulate joints, massage soft tissues, and stretch muscles while applying gentle massage lotion to reduce friction and improve comfort. The patient is comfortably lying on a therapy table and is communicating any discomfort or pain they feel. In the waiting room, six patients are seated, waiting for their appointments, while two receptionists are greeting them, scheduling appointments, and handling paperwork. The nearby gym and hydrotherapy pool are equipped with various exercise equipment and are ready for strengthening and conditioning exercises and aquatic therapy sessions.', 'situation_json': '{\"room_type\": \"treatment\", \"room_cleanliness\": \"clean\", \"room_noise_level\": \"quiet\", \"treatment_performed\": \"manual therapy\", \"therapist_included\": false, \"therapy_table_presence\": true, \"patient_comfort\": true, \"patient_communication\": true, \"waiting_room_patients\": 6, \"receptionists_present\": 2, \"receptionist_duties\": [\"greeting\", \"appointment scheduling\", \"paperwork handling\"], \"gym_equipment\": true, \"hydrotherapy_pool_presence\": true, \"exercise_equipment_presence\": true, \"strengthening_exercises_equipment\": true, \"conditioning_exercises_equipment\": true, \"aquatic_therapy_sessions_equipment\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125859.50 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 149731.46 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 62137.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Database Administrator', 'process': 'Performance Monitoring', 'situation': 'Inside the bustling data center, the seasoned Database Administrator begins his daily Performance Monitoring process. The center is filled with an array of sleek servers, storage devices, and networking equipment, all carefully organized and humming with activity. The Database Administrator sits at his desk, a myriad of tools at his disposal. He has a high-performance computer running database management software, its screen illuminated with various SQL scripts and database monitoring tools. His eyes dart between multiple screens, each displaying critical data about the database performance. The Database Administrator is the linchpin of this environment, working closely with the System Administrator and Network Administrator to ensure the databases remain optimized, available, and secure.', 'situation_json': '{\"Environment\": \"Data center\", \"EquipmentPresent\": [\"Servers\", \"Storage devices\", \"Networking equipment\"], \"EquipmentOrganization\": \"Carefully organized\", \"EquipmentActivity\": \"Humming with activity\", \"EmployeeJobRole\": \"Database Administrator\", \"EmployeeTools\": [\"High-performance computer\", \"Database management software\", \"Database monitoring tools\", \"Multiple screens\"], \"EmployeeAssistants\": [\"System Administrator\", \"Network Administrator\"], \"DatabasePerformance\": \"Optimized, available, and secure\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  83%|████████▎ | 600/723 [2:28:11<3:08:42, 92.06s/ examples] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Stakeholder Communication', 'situation': \"In the heart of the sprawling, sunlit corporate office, the Management Analyst finds themselves ensconced in an expansive, sleekly modern meeting room, a sanctuary of polished mahogany and plush leather, designed with the precision of a Swiss watch. The air is filled with the faint hum of a high-end, state-of-the-art projector, casting a crisp, vivid presentation onto a wall-sized screen, a digital tapestry of intricate graphs and charts, each one a testament to the analyst's meticulous data analysis. The analyst, a picture of professionalism in their tailored, navy blue suit, is engaged in a fluid, dynamic dialogue with a diverse array of stakeholders, their voices a symphony of perspectives echoing through the room. The stakeholders, a mix of seasoned executives and enthusiastic project team members, are seated around a massive, gleaming conference table, their faces a mosaic of concentration and curiosity, reflecting in the polished surface. The analyst's laptop, a sleek, silver marvel of modern engineering, lies open before them, a portal to the vast, complex data sets they've been navigating with the finesse of a seasoned explorer. The room, a testament to the analyst's ability to command a space, is filled with an aura of anticipation, the air practically crackling with the potential of the insights about to be shared.\", 'situation_json': '{\"type\": \"object\", \"additionalProperties\": {\"type\": \"string\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120036.49 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 145321.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92521.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paramedic', 'process': 'Communication with Medical Staff', 'situation': \"In the heart of the bustling emergency services sector, the scene unfolds within the narrow yet finely equipped confines of an ambulance. The walls, painted a sterile and yet somehow calming shade of blue, are adorned with an array of medical instruments and supplies, all meticulously arranged and ready for immediate use. The paramedic, clad in a pristine, navy-blue uniform, his name tag gleaming with the reflection of the faint emergency lights, is the epitome of focused efficiency. He sits at the driver’s seat, his hands steady on the steering wheel, eyes scanning the road ahead with a practiced intensity. Beside him, on the passenger seat, lies a state-of-the-art radio, its antenna whirring with intermittent static as it maintains a constant line of communication with the medical staff at the nearby hospital. The radio’s display flickers with updates—real-time vital information that could mean the difference between life and death. Behind him, in the treatment room, a space no larger than a cramped cabin, a crisis is unfolding. A patient, their face pale and sweat-glistened, is strapped to a gurney, their chest rising and falling in shallow breaths. The paramedic’s partner, an equally competent figure in the same uniform, leans over the patient, a stethoscope pressed to their chest, listening intently to the irregular rhythm of their heart. On the tray beside them, an array of eight dental mirrors gleam under the harsh fluorescent lights, each one polished to a mirror-like finish. Beside the tray, a defibrillator hums ominously, its electronic display blinking in succession, ready for deployment at a moment’s notice. Awaiting instructions, a team of four hospital staff gathers at the emergency room entrance, their faces a mix of grave concern and focused anticipation, waiting for the inevitable transfer of their new patient. The ambulance's sirens wail incessantly, their high-pitched howls cutting through the cacophony of city traffic as the vehicle weaves through gridlocked streets, each movement a calculated maneuver towards the waiting hospital staff. The urgency is palpable, the environment tense, yet there’s a calm, professional unity that binds the team together, each member playing their part in this intricate ballet of emergency care.\", 'situation_json': '{\"text\": \"In the heart of the bustling emergency services sector, the scene unfolds within the narrow yet finely equipped confines of an ambulance. The walls, painted a sterile and yet somehow calming shade of blue, are adorned with an array of medical instruments and supplies, all meticulously arranged and ready for immediate use. The paramedic, clad in a pristine, navy-blue uniform, his name tag gleaming with the reflection of the faint emergency lights, is the epitome of focused efficiency. He sits at the driver\\\\u2019s seat, his hands steady on the steering wheel, eyes scanning the road ahead with a practiced intensity. Beside him, on the passenger seat, lies a state-of-the-art radio, its antenna whirring with intermittent static as it maintains a constant line of communication with the medical staff at the nearby hospital. The radio\\\\u2019s display flickers with updates\\\\u2014real-time vital information that could mean the difference between life and death. Behind him, in the treatment room, a space no larger than a cramped cabin, a crisis is unfolding. A patient, their face pale and sweat-glistened, is strapped to a gurney, their chest rising and falling in shallow breaths. The paramedic\\\\u2019s partner, an equally competent figure in the same uniform, leans over the patient, a stethoscope pressed to their chest, listening intently to the irregular rhythm of their heart. On the tray beside them, an array of eight dental mirrors gleam under the harsh fluorescent lights, each one polished to a mirror-like finish. Beside the tray, a defibrillator hums ominously, its electronic display blinking in succession, ready for deployment at a moment\\\\u2019s notice. Awaiting instructions, a team of four hospital staff gathers at the emergency room entrance, their faces a mix of grave concern and focused anticipation, waiting for the inevitable transfer of their new patient. The ambulance\\'s sirens wail incessantly, their high-pitched howls cutting through the cacophony of city traffic as the vehicle weaves through gridlocked streets, each movement a calculated maneuver towards the waiting hospital staff. The urgency is palpable, the environment tense, yet there\\\\u2019s a calm, professional unity that binds the team together, each member playing their part in this intricate ballet of emergency care.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 104977.72 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133553.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96405.32 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mechanical Engineer', 'process': 'Project Management', 'situation': \"A Mechanical Engineer is meticulously reviewing blueprints and computer-aided designs on their computer in their cluttered, yet organized office. The room is filled with an array of testing equipment, including calipers and micrometers, along with analytical and testing equipment used for measuring, analyzing, testing, and validating the performance of mechanical designs. The engineer is also surrounded by measuring tools, such as calipers, micrometers, and measuring tapes, which are used for taking precise measurements of components and systems. In one corner of the office, there is a laptop used for designing, analyzing, and documenting mechanical systems using CAD software, simulation tools, and other engineering tools. A whiteboard on the wall is covered in scribbles and diagrams, documenting the engineer's latest designs and ideas. Nearby, a flipchart stands ready for the engineer's next presentation or brainstorming session.\", 'situation_json': '{\"items\": [{\"name\": \"blueprints_and_CAD_designs\", \"value\": \"being reviewed\"}, {\"name\": \"office\", \"value\": \"cluttered, yet organized\"}, {\"name\": \"testing_equipment\", \"value\": \"calipers, micrometers, analytical and testing equipment\"}, {\"name\": \"measuring_tools\", \"value\": \"calipers, micrometers, measuring tapes\"}, {\"name\": \"laptop_for_design\", \"value\": \"present\"}, {\"name\": \"whiteboard\", \"value\": \"covered in scribbles and diagrams\"}, {\"name\": \"flipchart\", \"value\": \"ready for presentation or brainstorming\"}], \"in_office\": true, \"has_laptop\": true, \"has_testing_equipment\": true, \"has_measuring_tools\": true, \"whiteboard_used\": true, \"flipchart_ready\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134738.86 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 129422.40 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73188.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Counselor', 'process': 'Staff Collaboration', 'situation': \"Imagine a sunlit, minimally adorned school counseling office, bathed in the soft glow of natural light streaming through the large windows, offering a peaceful sanctuary amidst the bustling school campus. The room is filled with an inviting atmosphere, featuring comfortable furnishings designed to put even the most anxious of visitors at ease. A plush, navy blue couch is positioned across from the counselor's ergonomic desk, adorned with a sleek, modern desktop computer and a telephone. The walls are adorned with vibrant, inspirational posters and motivational quotes, interspersed with framed certificates and educational awards, each gleaming under the subtle overhead lighting. To one side, a well-stocked bookshelf displaying an array of self-help books, workbooks, and educational materials adds to the room's scholarly ambiance. Nearby, the waiting room is a serene space, equipped with several beige leather chairs, a circular coffee table piled high with magazines, and a reassuring Miniature Zen garden. The aroma of freshly brewed coffee wafts through the air, adding a comforting touch to the environment. Currently, three teachers are seated in the counseling office, their postures engaged as they actively participate in a staff collaboration meeting. They are discussing the progress and needs of a diverse group of students, their voices animated yet respectful. The counselor, a proficient note-taker, jots down insights and action plans on a crisp, cream-colored legal pad. Beside her, a high-end laptop displaying analytics and student data hums quietly. A transparent glass board, mounted on the wall, is filled with color-coded sticky notes outlining various student issues and collaborative strategies. Amidst this productive meeting, the counselor's phone gently vibrates, signaling an incoming call that requires her immediate attention.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119877.31 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136075.05 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94367.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Executive Assistant', 'process': 'Email Management', 'situation': \"In the quiet, expansive executive office, the air is filled with the faint hum of the laptop's fan, a steady rhythm against the otherwise silent room. The laptop, a sleek, silver, high-end model, sits on the polished, mahogany desk, its screen a beacon of productivity in the otherwise dimly lit room. The desk, a grand piece of furniture, is neatly organized, with the laptop at its center, flanked by a meticulously arranged tray of pens, a sleek, black landline phone, and a pile of neatly sorted documents, tied together with a red ribbon. The wall behind the desk is adorned with a large, abstract painting, its vibrant colors a stark contrast to the otherwise neutral tones of the room. The executive, a woman in her late forties, is seated in her ergonomic, leather chair, her eyes scanning the laptop screen, her fingers dancing on the keyboard as she types out a response to an email. Her expression is one of concentration, her brows furrowed slightly as she considers her words carefully. The room is filled with the soft ticking of a wall clock, the only other sound the occasional rustle of the executive's clothing as she shifts in her chair. The office, located on the top floor of the building, offers a panoramic view of the city skyline, the sun casting a warm, golden glow over the buildings, a stark contrast to the cool, blue light of the laptop screen. The executive's assistant, a man in his early thirties, is seated at his desk in the reception area, his eyes scanning the computer screen, his fingers clicking the mouse as he sorts through the executive's inbox. The reception area is a stark contrast to the executive's office, filled with the low hum of conversation and the occasional ring of the phone. The assistant's desk is a clutter of papers, pens, and a large, black coffee mug, a testament to the busy nature of his work. The waiting room, a small, comfortable space, is filled with the low murmur of conversation, a few clients or visitors seated on the plush, leather sofas, flipping through magazines as they wait for their appointment. The office, a bustling hub of activity, is a stark contrast to the quiet, serene executive office, a testament to the busy nature of the executive's work. The executive, her eyes still scanning the laptop screen, hits send, a small smile playing on her lips as she leans back in her chair, satisfied with her response. The assistant, his task complete, stands up, grabbing his coffee mug as he heads towards the break room, ready to start the next task on his list.\", 'situation_json': '{\"situation\": \"In the quiet, expansive executive office, the air is filled with the faint hum of the laptop\\'s fan, a steady rhythm against the otherwise silent room. The laptop, a sleek, silver, high-end model, sits on the polished, mahogany desk, its screen a beacon of productivity in the otherwise dimly lit room. The desk, a grand piece of furniture, is neatly organized, with the laptop at its center, flanked by a meticulously arranged tray of pens, a sleek, black landline phone, and a pile of neatly sorted documents, tied together with a red ribbon. The wall behind the desk is adorned with a large, abstract painting, its vibrant colors a stark contrast to the otherwise neutral tones of the room. The executive, a woman in her late forties, is seated in her ergonomic, leather chair, her eyes scanning the laptop screen, her fingers dancing on the keyboard as she types out a response to an email. Her expression is one of concentration, her brows furrowed slightly as she considers her words carefully. The room is filled with the soft ticking of a wall clock, the only other sound the occasional rustle of the executive\\'s clothing as she shifts in her chair. The office, located on the top floor of the building, offers a panoramic view of the city skyline, the sun casting a warm, golden glow over the buildings, a stark contrast to the cool, blue light of the laptop screen. The executive\\'s assistant, a man in his early thirties, is seated at his desk in the reception area, his eyes scanning the computer screen, his fingers clicking the mouse as he sorts through the executive\\'s inbox. The reception area is a stark contrast to the executive\\'s office, filled with the low hum of conversation and the occasional ring of the phone. The assistant\\'s desk is a clutter of papers, pens, and a large, black coffee mug, a testament to the busy nature of his work. The waiting room, a small, comfortable space, is filled with the low murmur of conversation, a few clients or visitors seated on the plush, leather sofas, flipping through magazines as they wait for their appointment. The office, a bustling hub of activity, is a stark contrast to the quiet, serene executive office, a testament to the busy nature of the executive\\'s work. The executive, her eyes still scanning the laptop screen, hits send, a small smile playing on her lips as she leans back in her chair, satisfied with her response. The assistant, his task complete, stands up, grabbing his coffee mug as he heads towards the break room, ready to start the next task on his list.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 96237.32 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131212.17 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84992.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Negotiations', 'situation': \"In the heart of the bustling law firm, the negotiation room, a sanctuary of polished mahogany and crisp legalese, hums with an electric tension. The air is thick with the scent of polished leather and the faintest hint of aged parchment from the nearby law library, a silent sentinel of legal precedent. The room, bathed in the soft glow of a brass chandelier, is a symphony of power and intellect, with plush, high-backed leather chairs encircling a table that's seen more deals than a Las Vegas casino. The lawyer, a silver-tongued orator, commands the head of the table, their eyes reflecting the sheen of the polished surface as they engage in a dance of words with the opposing counsel. The client, a nervous yet determined figure, sits to their left, clutching a manila folder like a lifeline. A mediator, the embodiment of calm in a crisp suit, observes the proceedings from a position of quiet authority. The room is a stark contrast to the hum of activity outside, where paralegals dart like thoroughbreds, and law clerks pore over tomes in the library, their world a silent counterpoint to the negotiation's symphony. The lawyer's phone, a sleek black slab, lies silent for now, but it's a silent companion, ready to buzz with the next challenge. The lawyer's laptop, a portal to legal research and drafting, is open, its screen casting a soft glow on the lawyer's focused face. The clock on the wall ticks down the seconds, each one a potential breakthrough or a step further from resolution. The negotiation is a chess game, each move calculated, each word a pawn with the potential to shift the board's dynamic. The lawyer's legal pad, filled with neat, slanted handwriting, is a testament to their strategic thinking, a battle plan in the war of words. The room is a stage, and the players are locked in a performance that will determine the fate of more than just the case at hand. The air is thick with the weight of expectation, the thrill of the chase, and the promise of a deal well done.\", 'situation_json': '{\"room_details\": {\"furniture\": {\"table\": {\"material\": \"polished_mahogany\", \"shape\": \"rectangular\", \"dimensions\": {\"length\": 200, \"width\": 100, \"height\": 75}}, \"chairs\": 8, \"material\": \"leather\"}, \"decor\": {\"chandelier\": {\"material\": \"brass\", \"light_source\": \"electric\"}}, \"scent\": \"aged_parchment, polished_leather\"}, \"atmosphere\": {\"tension\": \"high\", \"mood\": \"focused, intense\"}, \"lighting\": \"soft_glow\", \"sounds\": [\"ticking_clock\", \"muffled_activity_outside\"], \"people\": {\"lawyer\": {\"position\": \"head_of_table\", \"expression\": \"focused\", \"tools\": {\"phone\": {\"brand\": \"unknown\", \"status\": \"silent\"}, \"laptop\": {\"brand\": \"unknown\", \"status\": \"open, active\"}, \"notepad\": {\"material\": \"paper\", \"writing_instrument\": \"pen\", \"contents\": \"neat, slanted handwriting\"}}, \"client\": {\"emotion\": \"nervous, determined\", \"possession\": \"manila_folder\"}, \"mediator\": {\"demeanor\": \"calm\", \"position\": \"observant\"}}, \"time_details\": {\"current_time\": \"afternoon\", \"timer\": {\"type\": \"clock\", \"status\": \"ticking\"}}, \"outside_details\": {\"activity\": \"high\", \"sounds\": \"muffled\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110991.58 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138144.38 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77576.52 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'IT Manager', 'process': 'System Updates', 'situation': \"In the heart of the IT department lies the office space, its glass walls providing a clear view of the buzzing activity of the numerous IT staff working tirelessly on various tasks. The IT Manager, with their trusty laptop at hand, and a plethora of screens, each displaying a different set of data, is ensconced in their ergonomic chair, their fingers dancing across the keyboard as they coordinate the next system update. A neat stack of five servers, all humming softly, stand at a corner, their status lights indicating they are in the process of an update. In the nearby server room, a cacophony of sounds resonates as various equipment, including numerous computers, servers, and networking devices, are subject to maintenance and updates. The IT team, fifteen in total, are scattered across the room, each engrossed in their respective tasks - configuring, testing, and implementing updates. The air is filled with a sense of urgency, yet everyone seems to be in their element. Across the hall, through a large glass window, the calm demeanor of the CIO can be seen, their eyes occasionally flicking towards the IT department, ensuring everything is running smoothly. The frequency of these updates varies, but they are undertaken as needed, each one ensuring the reliability and up-to-date nature of the organization's IT infrastructure.\", 'situation_json': '{\"department\": \"IT\", \"office_space\": {\"walls\": \"glass\", \"activity\": \"buzzing\", \"staff_count\": 15, \"equipment_in_sight\": [\"laptop\", \"screens\", \"servers\", \"computers\", \"networking devices\"], \"servers_status\": [\"updating\"], \"server_count\": 5, \"server_activity\": [\"humming\", \"updating\"], \"team_activity\": [\"configuring\", \"testing\", \"implementing\"], \"team_count\": 15, \"team_engagement\": \"engrossed\", \"team_location\": \"scattered\", \"attitude\": \"sense of urgency\", \"element\": \"in their element\", \"work_pace\": \"urgent\", \"CIO_visibility\": true, \"CIO_attitude\": \"calm\", \"CIO_monitoring_frequency\": \"occasional\", \"update_frequency\": \"varies\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110553.11 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141089.66 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93850.21 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Substance Abuse Counselor', 'process': 'Continuing Education', 'situation': 'In a spacious indoor training center, a dedicated substance abuse counselor engages in a rigorous three-hour continuing education process. The counselor, armed with a well-used black notebook and a sleek silver laptop, is accompanied by a diverse group of fellow counselors and professional trainers, all eager to hone their skills and expand their knowledge. The buzz of excited conversation fills the air as they all gather in a vibrant and well-lit workshop room. Here, they delve into the latest research and trends in their field, utilizing online platforms and professional literature from the library to ensure they are well-informed and ready to tackle the challenges ahead. Also present in the workshop room are clients, waiting patiently and participating actively. They represent a diverse mix of individuals, each struggling with their own unique substance abuse issues. Interspersed among them are community members and support staff, all playing a vital role in the prevention, treatment, and recovery process. The clients, their family members, and the counselors then move to private counseling rooms, where progress monitoring can take place in a confidential, comfortable environment. Here, the counselor, equipped with a set of specialized assessment tools and a neat file of confidential information, undertakes the mental task of evaluating the clients progress and making necessary adjustments to the treatment plans.', 'situation_json': '{\"location\": \"indoor training center\", \"location_description\": \"spacious\", \"duration\": 180, \"device_used\": [\"black notebook\", \"silver laptop\"], \"staff_present\": [\"substance abuse counselors\", \"professional trainers\"], \"staff_description\": \"diverse group\", \"mood\": \"eager to hone skills\", \"conversation_level\": \"buzz\", \"lighting\": \"well-lit\", \"room\": \"workshop room\", \"materials_used\": [\"online platforms\", \"professional literature\"], \"source\": \"library\", \"attendees\": [\"clients\", \"community members\", \"support staff\"], \"clients_description\": \"diverse mix\", \"clients_issues\": \"substance abuse issues\", \"meeting_locations\": [\"workshop room\", \"private counseling rooms\"], \"meeting_location_description\": [\"vibrant\", \"comfortable and confidential\"], \"activity\": \"progress monitoring\", \"tools_used\": \"specialized assessment tools\", \"clients_privacy\": \"confidential information\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110030.54 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141282.17 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77145.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Collaboration with Colleagues', 'situation': 'As the middle school teacher gathers with her colleagues in the staff room for their weekly collaboration meeting, the sound of shuffling papers and clicking laptop keys fills the air. On the large oak table sits a variety of equipment, including three laptops, two notepads, and a whiteboard. The whiteboard is filled with colorful markers, while the laptops have sticky notes with reminders attached to their sleek screens. Her colleagues sit around the table, each wearing a blend of casual and professional attire, glasses perched on their noses, and pens poised to take notes. One colleague, clad in a navy blue blazer, checks his rubric sheets while another, in a bright red cardigan, skims through a stack of handouts. The staff room, filled with the aroma of freshly brewed coffee and old books, serves as the hub for collaboration and planning. It is adorned with posters of educational quotes, a bulletin board with event announcements, and a shelf with educational resources and workbooks.', 'situation_json': '{\"situation\": \"The sound of shuffling papers and clicking laptop keys fills the air in the staff room. On the large oak table, there are three laptops, two notepads, and a whiteboard. The whiteboard is filled with colorful markers. The laptops have sticky notes with reminders attached to their screens. Her colleagues are dressed in a blend of casual and professional attire, and they have glasses, pens, and rubric sheets. One colleague is wearing a navy blue blazer and another is wearing a bright red cardigan. The staff room is filled with the aroma of freshly brewed coffee and old books, and it has educational quotes on the walls, a bulletin board, and a shelf with resources.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114502.02 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 119237.42 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90177.54 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Reporting and Analysis', 'situation': 'In the heart of the bustling communications department, a Public Relations Specialist is engaged in their weekly routine of Reporting and Analysis. The room is filled with the subtle hum of computers and muted chatter, a testament to the team of PR professionals working diligently. The Specialist’s desk is a collage of papers, reports, and a sleek laptop, the screen reflecting a myriad of charts and tables from Google Analytics, Hootsuite, and Brandwatch. The phone sits silently, ready to connect with media outlets and stakeholders alike. Nearby, the senior management team’s meeting rooms await the presentation of the Specialist’s findings, their decisions crucial to the company’s future. The office environment, with its indoor settings, provides the perfect backdrop for this mentally challenging task, a role that requires not just analytical skills, but also creativity and strategic thinking.', 'situation_json': '{\"description\": \"The heart of the bustling communications department, filled with the subtle hum of computers and muted chatter, a collage of papers, reports, and a sleek laptop, the screen reflecting a myriad of charts and tables from Google Analytics, Hootsuite, and Brandwatch, a silent phone, nearby senior management team\\\\u2019s meeting rooms, indoor office environment.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110855.11 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 143162.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85489.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Glazier', 'process': 'Project Management', 'situation': \"The glazier stands on the scaffolding, the early morning sun casting a golden hue over the construction site. The construction site is a symphony of activity, with workers in hard hats and high-visibility vests scurrying about, their boots echoing against the temporary platforms. To his left, a crane gracefully lifts a massive bundle of glass panels, destined for the future façade of the high-rise building looming ahead. Directly beneath him, a makeshift table is cluttered with tools of the trade - a battery-powered glass cutter, its hum echoing softly, a ladder leaning against the scaffolding, its rungs stark against the blue-gray backdrop, and a putty knife resting quietly beside a tube of sealant. The site is filled with the rhythmic beeping of reversing vehicles and the distant chatter of workers. Behind him, a row of suction cups glint in the sunlight, their powerful grip holding a neatly labeled stack of glass panels, each awaiting its turn to transform the skeletal structure into a gleaming masterpiece. A project manager in a reflective vest walks by, clipboard in hand, barking orders into a walkie-talkie, the static crackling in the morning air. In the distance, the cityscape begins to awaken, lights flickering on in nearby offices, Sarah, the glazier's apprentice, is nearby, meticulously measuring a window frame with her tape measure, her eyes scanning the dimensions with focused scrutiny. The scent of fresh coffee wafts through the air from a nearby food truck, a small oasis of warmth amidst the cool morning. The glazier takes a deep breath, the crisp air filling his lungs as he prepares for another day of transforming raw materials into architectural beauty.\", 'situation_json': '{\"type\": \"object\", \"additionalProperties\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 89060.15 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139225.54 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96305.79 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Art Director', 'process': 'Vendor Negotiation', 'situation': \"In the heart of a bustling Design Agency, the Art Director steers the process of Vendor Negotiation, a weekly task that unfolds in the quiet confines of their office. Armed with a sleek computer and a smartphone, they navigate the mental challenges that come with discussing contracts, terms, and conditions. The computer serves as their main tool, used for researching vendors, reviewing portfolios, and preparing negotiation strategies. Surrounded by a research library, a valuable resource for understanding vendor capabilities, the Art Director dives deep into the process. They often switch between their office and the boardroom, where negotiations with vendors take place. Here, they present proposals, discuss terms, and aim to reach mutually beneficial agreements. In the adjacent meeting room, the Art Director interacts with the creative team, understanding their requirements and relaying them to vendors during negotiations. The creative team, consisting of graphic designers, photographers, and other artists, is the lifeblood of the agency, working collaboratively on creative projects under the Art Director's guidance. A vendor, an external party providing resources and services essential for the projects, plays a crucial role in the process. The Art Director ensures that the relationships with vendors are beneficial and the outcomes are of high quality.\", 'situation_json': '{\"location\": \"Design Agency\", \"equipment\": {\"computer\": \"sleek\", \"phone\": \"smartphone\"}, \"settings\": {\"office\": \"quiet\", \"boardroom\": \"for negotiations\", \"meeting room\": \"for team interactions\"}, \"tasks\": {\"vendor negotiations\": \"weekly\", \"researching vendors\": \"via computer\", \"reviewing portfolios\": \"via computer\", \"preparing negotiation strategies\": \"via computer\", \"presenting proposals\": \"in boardroom\", \"discussing terms\": \"in boardroom\", \"ensuring mutually beneficial agreements\": \"in boardroom\", \"understanding team requirements\": \"in meeting room\", \"relaying requirements to vendors\": \"in boardroom\"}, \"resources\": {\"research library\": \"for vendor understanding\"}, \"team\": {\"creative team\": {\"graphic designers\": true, \"photographers\": true, \"other artists\": true}}, \"vendor\": {\"role\": \"providing essential resources and services\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135260.08 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 156843.43 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91974.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dentist', 'process': 'Record Keeping', 'situation': \"The dental office, a sanctuary of hygiene and precision, is bustling with quiet efficiency. The dentist, clad in a pristine white coat, sits in the ergonomically designed dental chair, the hum of the air conditioning a subtle accompaniment to the soft hum of the nearby autoclave sterilizing last night's instruments. The dental assistant, always prepared, stands nearby, a tray laden with five gleaming dental mirrors of various sizes and a set of sophisticated diagnostic tools at hand. Behind him, a state-of-the-art computer hums quietly, patient data displayed on the screen, waiting for updates. The waiting room beyond the semi-transparent glass door is a plush haven, filled with eight comfortable chairs, each occupied by a patient or their companions, their eyes flicking between the informative posters adorning the walls and the glossy magazines fanned out on the round table. The reception area is alive with the soft chatter of the receptionist, her fingers dancing over the keyboard, scheduling the next appointment, while the patients file in and out with pleasant smiles. The dental office supports this process with its organized layout, from the well-stocked cabinet of sterilized equipment to the comfortable dental chair where the patient reclines, trusting in the expert care of the dentist and his assistant. The atmosphere is one of calm professionalism, each tool and procedure designed to ensure the highest standard of oral healthcare.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120490.89 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137472.26 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96546.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Coding', 'situation': \"Web Developers are responsible for designing, coding, and debugging websites and applications that meet the client's specifications. They use various programming languages and technologies to create visually appealing and user-friendly interfaces. They ensure that websites are functional and optimized for performance, accessibility, and security. Web Developers collaborate with designers, project managers, and other stakeholders to develop innovative solutions that meet the client's needs.\", 'situation_json': '{\"event\": \"Designing and Coding\", \"equipment_state\": \"In Use\", \"language\": \"Programming Languages\", \"technologies\": \"web technologies\", \"client_specifications\": \"met\", \"interfaces\": \"User Friendly and Visually Appealing\", \"website_state\": \"Functional\", \"performance\": \"Optimized\", \"accessibility\": \"Optimized\", \"security\": \"Optimized\", \"collaboration\": \"Designers and Project Managers\", \"solutions\": \"Innovative\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 105713.29 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 127749.10 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84351.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Registered Nurse', 'process': 'Discharge Planning', 'situation': \"In the bustling corridors of a sprawling hospital, a Registered Nurse moves with purposeful strides towards the nursing station. The station is a hub of activity, with six nurses diligently documenting patient care and coordinating with other healthcare professionals. The walls are adorned with colorful charts detailing medication schedules and care plans. The smell of antiseptic wafts through the air, a testament to the meticulous cleaning that occurs regularly.\\n\\nThe nurse picks up a clipboard, reviewing the discharge plan for a patient in room 305. The patient room is a sanctuary of sorts, with soft lighting and pastel-colored walls. Medical equipment, including a stethoscope and a blood pressure monitor, is neatly arranged on a tray by the bedside. The patient, an elderly woman with a warm smile, sits comfortably on the bed, eager to go home.\\n\\nThe nurse begins by assessing the patient's condition, using the stethoscope to listen to her heart and lungs. The sounds are clear and strong, a reassuring sign. Next, she checks the patient's vital signs using a blood pressure monitor and pulse oximeter. The room is filled with the quiet hum of the machines and the occasional click of the nurse's pen as she documents the readings.\\n\\nIn the adjacent treatment room, three doctors huddle over a computer, discussing the patient's lab results. The room is filled with medical paraphernalia, from oxygen tanks to IV drips. The nurse steps in briefly to confer with the doctors, ensuring that the discharge plan aligns with the patient's medical needs.\\n\\nBack in the patient's room, the nurse pulls up a chair and begins to explain the post-discharge care plan. She uses brochures and diagrams to illustrate the details, ensuring the patient and her family understand the importance of follow-up appointments and medication schedules. The room is filled with a sense of calm and understanding, as the nurse's soothing voice reassures the patient and her family.\\n\\nIn the waiting room down the hall, four people sit patiently, some engrossed in magazines, others checking their phones. The nurse makes a mental note to check on them once the discharge process is complete. The pharmacy, located near the waiting room, is a flurry of activity as medications are prepared for discharge.\\n\\nAs the nurse finalizes the discharge paperwork, she feels a sense of accomplishment. The patient is ready to go home, armed with the knowledge and support needed for a smooth transition. The nurse walks the patient and her family to the exit, offering final words of encouragement before turning back to her busy day, ready to assist the next patient in need.\", 'situation_json': '{\"description\": \"In the bustling corridors of a sprawling hospital, a Registered Nurse moves with purposeful strides towards the nursing station. The station is a hub of activity, with six nurses diligently documenting patient care and coordinating with other healthcare professionals. The walls are adorned with colorful charts detailing medication schedules and care plans. The smell of antiseptic wafts through the air, a testament to the meticulous cleaning that occurs regularly.\\\\n\\\\nThe nurse picks up a clipboard, reviewing the discharge plan for a patient in room 305. The patient room is a sanctuary of sorts, with soft lighting and pastel-colored walls. Medical equipment, including a stethoscope and a blood pressure monitor, is neatly arranged on a tray by the bedside. The patient, an elderly woman with a warm smile, sits comfortably on the bed, eager to go home.\\\\n\\\\nThe nurse begins by assessing the patient\\'s condition, using the stethoscope to listen to her heart and lungs. The sounds are clear and strong, a reassuring sign. Next, she checks the patient\\'s vital signs using a blood pressure monitor and pulse oximeter. The room is filled with the quiet hum of the machines and the occasional click of the nurse\\'s pen as she documents the readings.\\\\n\\\\nIn the adjacent treatment room, three doctors huddle over a computer, discussing the patient\\'s lab results. The room is filled with medical paraphernalia, from oxygen tanks to IV drips. The nurse steps in briefly to confer with the doctors, ensuring that the discharge plan aligns with the patient\\'s medical needs.\\\\n\\\\nBack in the patient\\'s room, the nurse pulls up a chair and begins to explain the post-discharge care plan. She uses brochures and diagrams to illustrate the details, ensuring the patient and her family understand the importance of follow-up appointments and medication schedules. The room is filled with a sense of calm and understanding, as the nurse\\'s soothing voice reassures the patient and her family.\\\\n\\\\nIn the waiting room down the hall, four people sit patiently, some engrossed in magazines, others checking their phones. The nurse makes a mental note to check on them once the discharge process is complete. The pharmacy, located near the waiting room, is a flurry of activity as medications are prepared for discharge.\\\\n\\\\nAs the nurse finalizes the discharge paperwork, she feels a sense of accomplishment. The patient is ready to go home, armed with the knowledge and support needed for a smooth transition. The nurse walks the patient and her family to the exit, offering final words of encouragement before turning back to her busy day, ready to assist the next patient in need.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114823.24 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 74879.19 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 48003.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist', 'process': 'Patient Education', 'situation': \"In the quietly bustling clinic, the physical therapist carefully prepares the treatment room for the patient education session. The room is clean and well-lit, with white walls adorned with anatomical posters and motivational quotes, providing a calm yet focused atmosphere. The therapist's professional attire, a crisp white coat and a stethoscope hanging around their neck, signifies their expertise and readiness.\\n\\nThe treatment room is equipped with a variety of exercise equipment, such as resistance bands, weights, and balance beams, all neatly arranged and ready for use. A sturdy therapy table stands in the center, covered with a fresh, soft cloth, inviting the patient to comfortably lie down. Nearby, an exercise mat is rolled out, providing a stable and comfortable surface for floor exercises.\\n\\nOn the sleek, organized desk, a laptop is open, displaying the patient's electronic records. The coding software is ready, with coding systems and billing processes at the therapist's fingertips. Beside the laptop, patient records are meticulously stacked, detailing diagnoses, procedures, and insurance information, ensuring accurate and efficient documentation.\\n\\nThe room is filled with the soft, soothing hum of the air conditioning, maintaining a comfortable temperature. The therapist's hands are clean, and a bottle of massage lotion stands ready, ensuring minimal friction and maximum comfort during treatment. A goniometer is placed on the table, ready to measure the patient's joint range of motion.\\n\\nIn the adjacent waiting room, patients sit comfortably, awaiting their appointments. The space is designed to be welcoming, with plush chairs and an assortment of magazines to keep patients occupied. The reception area is staffed by friendly receptionists who greet patients, schedule appointments, and handle administrative tasks with efficiency and warmth.\\n\\nThe physical therapist, with a reassuring smile, is ready to educate the patient, guiding them through exercises and explaining the therapeutic process with patience and expertise. The hour-long session promises to be informative and empowering, as the therapist works to improve the patient's mobility and overall well-being.\", 'situation_json': '{\"situation_json\": {\"treatment_room\": {\"atmosphere\": \"calm yet focused\", \"walls\": {\"colour\": \"white\", \"decorations\": [\"anatomical posters\", \"motivational quotes\"]}, \"equipment\": {\"exercise\": {\"resistance_bands\": {\"state\": \"neatly arranged\"}, \"weights\": {\"state\": \"neatly arranged\"}, \"balance_beams\": {\"state\": \"ready for use\"}}, \"therapy_table\": {\"state\": \"sturdy\", \"cover\": {\"fresh\": true, \"soft\": true}}, \"exercise_mat\": {\"state\": \"rolled out\"}, \"desk\": {\"laptop\": {\"state\": \"open\", \"display\": \"patient\\'s electronic records\", \"software\": {\"coding_ready\": true, \"systems\": [\"coding\", \"billing\"]}}, \"patient_records\": {\"state\": \"meticulously stacked\", \"details\": [\"diagnoses\", \"procedures\", \"insurance information\"]}}, \"air_conditioning\": {\"state\": \"soft soothing hum\", \"temperature\": \"comfortable\"}, \"therapist\": {\"hands\": {\"state\": \"clean\"}, \"massage_lotion\": {\"state\": \"ready\"}, \"goniometer\": {\"state\": \"ready to measure\"}}}, \"waiting_room\": {\"patients\": {\"sitting_comfortably\": true, \"awaiting_appointments\": true}, \"space\": {\"design\": \"welcoming\", \"chairs\": {\"plush\": true}, \"magazines\": {\"available\": true}}, \"reception_area\": {\"receptionists\": {\"state\": \"friendly\", \"tasks\": [\"greet patients\", \"schedule appointments\", \"handle administrative tasks\"]}}}, \"education_session\": {\"duration\": \"hour-long\", \"processes\": [\"informative\", \"empowering\"], \"goals\": [\"improve mobility\", \"overall well-being\"]}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 122562.78 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 102052.99 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86667.50 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Management Analyst', 'process': 'Strategic Planning', 'situation': 'In the heart of a bustling corporation, the Management Analyst immerses themselves in the daily process of Strategic Planning. The faint hum of chatter and muffled footsteps echo through the open office spaces, designed to promote collaboration and interaction with various stakeholders. The familiar scent of fresh coffee wafts from the nearby break room, a source of comfort in the midst of countless data sheets and analytics reports. The analyst sits in their cubical, surrounded by towering bookshelves filled with financial literature and binders of past research, all within arm’s reach of a sleek, minimalist computer housing an extensive assortment of data analysis software. A laptop, projector, and other specialized equipment sit beside them, awaiting the presentations that will liven up the dull, grey conference room with color-coded graphs and pie charts. Meetings are scheduled daily, taking place in the nearby meeting room, adorned with a table large enough to house piles of documents and a projector for the synthetic overhead lighting to bring life to spreadsheets and reports. The analyst works closely with the management team to understand their goals and develop strategies for the company, while also interacting with the hardworking employees who make the company function. Their search for efficiency may lead them to conduct interviews, surveys, or questionnaires, to obtain the necessary insights to enhance business operations. Sometimes, a focus group discussion with clients may take place in focus group facilities, answering questions and gathering perceptions to shape the analyst’s data. After an hour has passed, the analyst begins to let out a sigh of relief, taking a moment to gaze at the busy reception area where clients, management, and employees await each other for scheduled appointments. With the planning process done for the day, the Management Analyst retreats to their office to gather their thoughts and review data before returning to their cubical to ready themselves for another session of Strategic Planning, eager and determined to unlock the corporation’s true potential.', 'situation_json': '{\"profession\": \"Management Analyst\", \"process\": \"Strategic Planning\", \"description\": \"In the heart of a bustling corporation, the Management Analyst immerses themselves in the daily process of Strategic Planning. The faint hum of chatter and muffled footsteps echo through the open office spaces, designed to promote collaboration and interaction with various stakeholders. The familiar scent of fresh coffee wafts from the nearby break room, a source of comfort in the midst of countless data sheets and analytics reports. The analyst sits in their cubical, surrounded by towering bookshelves filled with financial literature and binders of past research, all within arm\\\\u2019s reach of a sleek, minimalist computer housing an extensive assortment of data analysis software. A laptop, projector, and other specialized equipment sit beside them, awaiting the presentations that will liven up the dull, grey conference room with color-coded graphs and pie charts. Meetings are scheduled daily, taking place in the nearby meeting room, adorned with a table large enough to house piles of documents and a projector for the synthetic overhead lighting to bring life to spreadsheets and reports. The analyst works closely with the management team to understand their goals and develop strategies for the company, while also interacting with the hardworking employees who make the company function. Their search for efficiency may lead them to conduct interviews, surveys, or questionnaires, to obtain the necessary insights to enhance business operations. Sometimes, a focus group discussion with clients may take place in focus group facilities, answering questions and gathering perceptions to shape the analyst\\\\u2019s data. After an hour has passed, the analyst begins to let out a sigh of relief, taking a moment to gaze at the busy reception area where clients, management, and employees await each other for scheduled appointments. With the planning process done for the day, the Management Analyst retreats to their office to gather their thoughts and review data before returning to their cubical to ready themselves for another session of Strategic Planning, eager and determined to unlock the corporation\\\\u2019s true potential.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 90314.75 examples/s] examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 108546.56 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 72244.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paramedic', 'process': 'Inventory Management', 'situation': 'In the cool and organized ambience of a state-of-the-art ambulance, a paramedic meticulously performs the task of inventory management. The paramedic counts and checks the status of 4 pristine-white dental mirrors carefully placed on a sterile tray. Their gloved hands move swiftly yet precisely, ensuring that no mirror is overlooked. The paramedic simultaneously notes the presence of 3 newly-stocked, unused defibrillators and the sufficient supply of 5 oxygen tanks. Through the thin walls of the ambulance, the commotion of the nearby bustling hospital emergency room can be heard, a constant reminder of the urgent nature of their job. A dedicated team of medical staff awaits the arrival of the ambulance with the patient, ready to offer further evaluation and treatment. The paramedic, deeply immersed in the task, is acutely aware of the importance of their role in saving lives.', 'situation_json': '{\"location\": \"ambulance\", \"equipment\": {\"dental_mirrors\": {\"count\": 4, \"state\": \"pristine-white\", \"placement\": \"sterile tray\"}, \"defibrillators\": {\"count\": 3, \"state\": \"unused\", \"stock_status\": \"newly-stocked\"}, \"oxygen_tanks\": {\"count\": 5, \"supply_status\": \"sufficient\"}}, \"external_noises\": \"commotion from nearby hospital emergency room\", \"medical_staff_presence\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 50193.88 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 74148.97 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 45965.17 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Executive Assistant', 'process': 'Expense Reporting', 'situation': 'Completing the expense reporting within a bustling office environment requires meticulous attention to detail. The Executive Assistant is seated at an expansive, wood-paneled desk, adorned with a sleek laptop and a high-performance printer. As the shimmering sun reflects off the walls, the office buzzes with a steady hum of activity. The manager’s office is adjacent, with its door slightly ajar, allowing occasional glimpses of paperwork and dialogues about strategic decisions. The accounting department, a hub of financial information, is situated just down the hall, with accountants shuffling through thick binders and focusing intently on their computer screens.\\n\\nIn the nearby waiting room, five clients are seated, their eyes fixed on magazines or their smartphones, awaiting their turns. The reception area, adorned with polished marble floors and modern artwork, serves as the initial point of contact, where visitors are greeted warmly and directed accordingly. Soft, classical music wafts through the air, offering a calming backdrop to the professional atmosphere.\\n\\nThe Executive Assistant is deeply engrossed in the monthly expense reporting task, meticulously entering each expense into the system, printing out detailed reports, and organizing them neatly in a secure file cabinet. The office is a harmonious blend of technology and paperwork, with the Executive Assistant adeptly managing both. Her computer is equipped with the latest calendar and email software, enabling efficient communication with the executive and other stakeholders. The nearby training room is currently set up for a session on information security, highlighting the company’s commitment to staying current on best practices.\\n\\nAs they work diligently, the Executive Assistant interacts occasionally with support staff, coordinating to ensure that all travel-related expenses are accurately documented. The executive’s office, just a few steps away, is a bustling nexus of activity, where important decisions are made and crucial meetings are held. The office floors are dotted with meeting rooms, buzzing with discussions and negotiations. \\n\\nFrom the conference rooms to the executive office, the environment is one of both collaboration and efficiency. The Executive Assistant’s desk is a testament to their organizational skills—not a single item out of place, ensuring that the complex process of expense reporting runs smoothly and efficiently. As the task wraps up, a sense of satisfaction fills the air, knowing that every expense has been accounted for and managed meticulously.', 'situation_json': '{\"environment\": {\"description\": \"bustling office environment\", \"room_types\": [\"office\", \"waiting_room\", \"reception_area\"]}, \"electrical_equipment\": {\"laptop\": {\"state\": \"on\", \"performance_level\": \"sleek\"}, \"printer\": {\"state\": \"on\", \"performance_level\": \"high_performance\"}}, \"measurable_observables\": {\"clients_waiting\": 5, \"room_type_count\": 3}, \"additional_details\": {\"activity_level\": \"steady\", \"sun_reflection\": \"shimmering\", \"music_type\": \"classical\", \"music_volume\": \"soft\", \"manager_office_door_state\": \"slightly_ajar\", \"task_focus\": \"monthly_expense_reporting\", \"executive_office_activity_level\": \"bustling\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 89723.95 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 65049.10 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 74559.75 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mechanical Engineer', 'process': 'Research and Development', 'situation': 'Imagine stepping into the bustling Mechanical Engineering R&D Lab, a sprawling indoor workspace bathed in the cool glow of fluorescent lights. The lab is a symphony of precision and innovation, filled with the hum of laptops and the whirr of specialized testing machines. At the heart of this high-tech environment, you find the mechanical engineer, adeptly navigating the intricate dance of research and development. A high-end computer-aided design (CAD) software hums to life on their laptop, as they meticulously craft and refine 3D models of mechanical components with mere clicks and keystrokes. Nearby, a meticulously organized array of analytical and testing equipment stands ready, their chrome surfaces gleaming under the artificial light. Among them are three sophisticated testing machines, their gauges and dials waiting patiently for the next batch of components. Scattered across the vast workspace are assorted measuring tools—calipers, micrometers, and gauges—each lying neatly on padded trays.\\n\\nClose by, a team of fellow engineers huddles in a meeting room, their heads bent over blueprints and notebooks, deep in conversation. The palpable energy of collaboration fills the air as ideas are shared and problems are solved. Occasionally, a pop of color catches your eye—a technician’s safety glasses, a hard hat hanging on a hook, or a blueprint marked with vivid annotations. To one side, a large whiteboard displays a complex diagram, lines and arrows intersecting in a dynamic chaos that only makes sense to those in the know. The engineer, however, seems undistracted, their focus split between the laptop screen and the half-assembled prototype sprawled across the workbench. A screwdriver dangles from their fingertips, ready to be wielded with practiced ease.\\n\\nIn the periphery, the clink of keys and the rustle of papers hint at the presence of other colleagues, their proximity signaling a shared dedication to the task at hand. The nearby control room pulses with life, its monitors flickering with real-time data, and the steady stream of administrative tasks that keep the machine of progress well-oiled. The roar of machinery from the manufacturing floor occasionally penetrates the walls, a reminder of the tangible effects of their intangible work. The Mechanical Engineering R&D Lab is not just a workspace; it’s a theater of innovation, where the subtle dance of science, creativity, and collaboration plays out in real time.', 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112089.96 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 130727.66 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 82835.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Psychologist', 'process': 'Collaboration with Other Professionals', 'situation': 'In the cozy confines of a warmly lit, inviting office adorned with motivational posters and colorful bulletin boards, a dedicated School Psychologist diligently prepares for her weekly collaboration meeting. This room, located amidst the bustling halls of a vibrant school, is her sanctuary and a place where she works tirelessy to support students in need. The psychologist gently picks up a well-worn, blue notebook, its pages filled with insights and observations from past consultations, ready to jot down new notes and ideas.', 'situation_json': '{\"room_ambience\": \"cozy\", \"room_lighting\": \"warm\", \"office_decor\": \"inviting\", \"office_motifs\": [\"motivational posters\", \"colorful bulletin boards\"], \"location\": \"amidst the bustling halls of a vibrant school\", \"psychologist_state\": \"diligently preparing\", \"chronological_event\": \"pre-meeting\", \"consultation_notes\": \"well-worn\", \"notebook_color\": \"blue\", \"note_purpose\": \"jot down new notes and ideas\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 75054.51 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 127371.23 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81199.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Insurance Agent', 'process': 'Claims Processing', 'situation': \"The Insurance Agent, clad in a crisp blue suit with a meticulously organized desk, sits in the heart of the vibrant office—a vast expanse of gray and white cubicles buzzing with quiet activity. Surrounded by four well-worn computers, each humming softly as they process a myriad of claims, and a top-of-the-line phone system, the agent skillfully navigates the intricate web of insurance claims.\\n\\nThe claims department, a hive of activity, is tucked away in a corner of the office, its walls adorned with motivational posters and the dull glow of fluorescent lights. The claims adjuster, a seasoned professional with a stack of files piled high on their desk, consults with the agent, poring over the details of a particularly complex claim.\\n\\nIn the private meeting room, the policyholder, a middle-aged individual with worry lines etched on their face, waits anxiously. The room is a stark contrast to the bustling office—quiet, painted in soothing pastel colors, with comfortable chairs and a small table where documents are spread out. The agent and the adjuster carefully explain the claims process, reassuring the policyholder with their calm demeanor and professional expertise.\\n\\nAcross the hall, the customer service area is a flurry of activity. Phones ring incessantly, and agents efficiently handle each call, their voices a blend of sympathetic understanding and practical advice. The reception area, just beyond, is filled with clients waiting their turn, flipping through magazines or checking their phones, the murmur of their conversations adding a low hum to the office atmosphere.\\n\\nBack at the agent's desk, the computer screens flicker with spreadsheets, emails, and policy documents. The agent expertly toggles between windows, updating records, sending correspondence, and ensuring every detail of the claims process is meticulously documented. The printer whirs to life, spitting out reams of paper, each sheet a testament to the agent's thoroughness and dedication.\", 'situation_json': '{\"entities\": [{\"type\": \"area\", \"attributes\": {\"volume\": null, \"size\": \"vast expanse\", \"buzzingWithQuietActivity\": true, \"description\": \"heart of the vibrant office\", \"furniture\": [{\"type\": \"office cubicle\", \"attributes\": {\"colorScheme\": [\"grey\", \"white\"], \"arrangement\": \"vast expanse\", \"numOffices\": null}}, {\"type\": \"desk\", \"attributes\": {\"cleanliness\": \"meticulously organized\", \"items\": [{\"type\": \"computer\", \"attributes\": {\"state\": \"well-worn\", \"quantity\": 4, \"operatingCondition\": \"humming softly\", \"dataBeingProcessed\": \"myriad of claims\"}}, {\"type\": \"phone system\", \"attributes\": {\"state\": \"top-of-the-line\"}}]}}]}}, {\"type\": \"area\", \"attributes\": {\"location\": \"corner of the office\", \"description\": \"claims department\", \"state\": \"a hive of activity\", \"wallDecor\": [\"motivational posters\"], \"lighting\": \"fluorescent\"}}, {\"type\": \"entities\", \"attributes\": {\"type\": \"claims adjuster\", \"experience\": \"seasoned professional\", \"posture\": \"consulting with the agent\", \"items\": [{\"type\": \"filing\", \"attributes\": {\"quantity\": \"stack\", \"height\": \"highly stacked\", \"position\": \"piled high\"}}]}}], \"userInfo\": {\"json_output_destination\": \"database indexing\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 93881.19 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133365.14 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92740.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Curriculum Development', 'situation': \"In the heart of the bustling school, the Middle School Teacher engages in the continuous process of Curriculum Development. The challenge is mentally taxing, with the process spanning several months. The teacher is surrounded by a myriad of locations, including classrooms, libraries, and offices. Within these spaces, the teacher's desk is a hub of personal belongings and teaching resources. Meanwhile, the student desks are abuzz with the hum of young minds at work. The teacher's tools for this process are diverse, including computers, software, and professional development resources, all aimed at aligning the learning content with the latest educational standards and trends. The teacher is not alone in this endeavor, joined by colleagues such as instructional coaches, administrators, and educational consultants. In the classroom, the most common location for curriculum implementation, the air is filled with the scent of pencils and the sound of pages turning. Here, whiteboards serve as a canvas for presenting lessons and sharing notes, while laptops display digital presentations and exciting learning opportunities. The process is continuous, with constant revisions and updates occurring throughout the school year. Risks include outdated or inaccurate information, but the teacher mitigates this by regularly reviewing and updating materials. The teacher's red pen is always at the ready, a familiar sight on assignments awaiting assessment. Rubrics, another staple of grading, ensure consistency and clear expectations for students. In the teacher's office, communication with parents often takes place, the teacher providing guidance on academic progress and behavior. The teacher's notepad is always close at hand, used to document meetings and take notes on areas of improvement. Meanwhile, grading records provide concrete evidence of student performance, contextualizing the teacher's observations. The technology lab, an integrated part of the curriculum development process, is a hive of activity. Here, the teacher is always looking for new ways to incorporate technology into lessons. The teacher lounge, a space for collaboration and support, is often filled with animated discussions about the latest educational research and trends and ideas for improving the curriculum. Professional development workshops are another valuable resource, helping the teacher stay abreast of the latest trends and advancements.\", 'situation_json': '{\"locations\": [\"classroom\", \"library\", \"office\", \"technology lab\", \"teacher lounge\"], \"equipment\": [{\"name\": \"teacher\\'s desk\", \"descriptions\": [\"hub of personal belongings and teaching resources\"]}, {\"name\": \"student desks\", \"descriptions\": [\"young minds at work\"]}, {\"name\": \"computers\", \"descriptions\": [\"aligning learning content with standards and trends\"]}, {\"name\": \"software\", \"descriptions\": [\"aligning learning content with standards and trends\"]}, {\"name\": \"professional development resources\", \"descriptions\": [\"aligning learning content with standards and trends\"]}, {\"name\": \"whiteboards\", \"descriptions\": [\"presenting lessons and sharing notes\"]}, {\"name\": \"laptops\", \"descriptions\": [\"displaying digital presentations and learning opportunities\"]}, {\"name\": \"rubrics\", \"descriptions\": [\"consistent grading and expectations\"]}, {\"name\": \"grading records\", \"descriptions\": [\"concrete evidence of student performance\"]}, {\"name\": \"notepad\", \"descriptions\": [\"documenting meetings and taking notes\"]}, {\"name\": \"red pen\", \"descriptions\": [\"assessment and feedback\"]}]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 113372.67 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 133610.83 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88196.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Substance Abuse Counselor', 'process': 'Counseling Sessions', 'situation': 'In the heart of a bustling clinical setting, a compassionate Substance Abuse Counselor readies for a weekly counseling session. With 50 minutes on the clock, the counselor settles into their private, indoor counseling room. The room, a serene oasis in contrast to the office buzz, is furnished with a plush, navy blue couch and matching armchair, serving as a comforting perch for the client. The off-white walls are adorned with motivational artwork and informative posters about substance abuse. To the counselor’s left sits a polished wooden desk, topped with a pristine, white laptop and a neat stack of 3 color-coded notebooks. Each notebook has a different purpose: one for recording client progress, one for crafting treatment plans, and one for personal reflection. A drawer discreetly holds a collection of specialized assessment tools, questionnaires, and interview guides used to evaluate and track client progress. Nearby, in the waiting room, family members of the next client, two adults, wait patiently for their turn, flipping through well-thumbed brochures on substance abuse and recovery.', 'situation_json': '{\"setting\": \"clinical\", \"room_description\": \"private, indoor counseling room\", \"room_furniture\": [\"plush navy blue couch\", \"matching armchair\", \"polished wooden desk\"], \"room_decor\": [\"motivational artwork\", \"informative posters about substance abuse\"], \"equipment_description\": [\"white laptop\", \"3 color-coded notebooks\"], \"equipment_purpose\": [\"recording client progress\", \"crafting treatment plans\", \"personal reflection\"], \"storage\": [\"discrete desk drawer\"], \"storage_content\": [\"specialized assessment tools\", \"questionnaires\", \"interview guides\"], \"waiting_room_description\": \"nearby waiting room\", \"waiting_room_occupants\": [\"two adults\"], \"waiting_room_items\": [\"well-thumbed brochures on substance abuse and recovery\"], \"session_duration\": 50}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 108085.70 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 118703.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92893.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Lawyer', 'process': 'Professional Development', 'situation': 'In the heart of the bustling city, the grand law firm stands tall and imposing, a testament to the centuries-old legal profession. Inside, a lawyer, amidst the professional hustle, commits to daily professional development - a key aspect of their career trajectory. The lawyer sits inside their private office, a sanctum of quiet concentration, the scent of old leather-bound books and the gentle hum of the cooling system providing a soothing backdrop to the intellectual challenge at hand. The room is filled with an extensive collection of legal books stacked neatly on dark wooden shelves, a symbol of the knowledge and wisdom accumulated over years in the field. The lawyer sits in front of a large oak desk, a gleaming Apple MacBook Pro and a stack of crisp A4 legal paper the only signs of modernity in the otherwise timeless space. As the lawyer delves deep into the legal research required for the day, they are acutely aware of the responsibility they hold in shaping the legal landscape of the cases they handle. The room, while seemingly secluded, is a hub of activity, with paralegals popping in and out, bringing documents, updating schedules, and providing support. The lawyer knows that each case is a complex puzzle, and the goal is to provide the most effective legal solution, with integrity and professionalism at the core. This daily routine, while ordinary to the casual observer, is a testament to the intricacies and dedication of the legal profession.', 'situation_json': '{\"building_type\": \"grand law firm\", \"building_location\": \"heart of the bustling city\", \"equipment\": {\"computer\": \"Apple MacBook Pro\", \"cooling_system\": \"active\", \"books\": \"extensive collection of legal books\", \"desk\": \"large oak desk\", \"paper\": \"stack of crisp A4 legal paper\"}, \"environment\": {\"scent\": \"old leather-bound books\", \"hum\": \"gentle hum\", \"atmosphere\": \"sanctum of quiet concentration\", \"activity\": \"hub of activity\"}, \"professional_support\": \"paralegals\", \"work_description\": \"legal research\", \"case_complexity\": \"complex puzzle\", \"core_values\": \"integrity and professionalism\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 91067.01 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 119418.65 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90603.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Social Media Management', 'situation': \"In the heart of the bustling office, nestled in the corner of the spacious, modern communication office, the Public Relations Specialist sits, ensconced in their ergonomic chair. The room hums with a gentle, energetic vibrancy, the low hum of multiple conversations blending seamlessly with the soft clicking of keyboards and the occasional ping of incoming messages. The specialist's workplace is meticulously arranged, with a sleek laptop positioned in the center of the expansive, spotless desk, its screen illuminated with vivid, dynamic graphics that depict various social media platforms. To the left, a sophisticated smartphone, its casing a stylish blend of silver and shiny black, rests securely in a uniquely designed stand. This is the specialist’s command center, where they masterfully navigate the digital landscape, crafting compelling narratives that amplify the organization's voice and resonate with its growing online community.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121818.88 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 126884.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89002.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Glazier', 'process': 'Quotation Preparation', 'situation': 'A glazier is standing on a bustling construction site, surrounded by high-rise buildings and other glaziers working on various tasks. The sound of construction equipment fills the air, with cranes and scaffoldings visible in the distance. He is preparing a quotation for a large window installation on the building in front of him, measuring the dimensions with a tape measure, while carrying a ladder for accessibility. He holds a laptop, where he will input the measurements and details of the job for later analysis. He is wearing safety glasses and protective clothing, as he carefully maneuvers around the site, taking note of every detail that will impact the final quote. He glances at the nearby glass shop, where large panes of glass await to be cut and shaped for the job, and the warehouse where smaller panes are stored. He occasionally interacts with clients and workers, offering friendly greetings and engaging in brief discussions about the project. His focus, however, remains on the task at hand, as he works diligently to provide an accurate and competitive quote for the client.', 'situation_json': '{\"location\": \"construction site\", \"surroundings\": \"high-rise buildings\", \"co-workers\": \"glaziers\", \"task\": \"window installation\", \"method\": \"tape measure\", \"equipment\": [\"ladder\", \"laptop\", \"safety glasses\", \"protective clothing\"], \"environment\": \"construction equipment sounds\", \"visible equipment\": [\"cranes\", \"scaffoldings\"], \"additional equipment\": [\"glass shop\", \"warehouse\"], \"interactions\": [\"clients\", \"workers\"], \"focus\": \"accurate and competitive quote\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 112492.54 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 136159.86 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 75323.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Auto Mechanic', 'process': 'Air Conditioning Service', 'situation': \"In the heart of a busy garage, an Auto Mechanic is diligently working to service the Air Conditioning system of a vehicle. The vehicle, a 2018 Honda Civic, is hoisted atop a robust car lift, its engine compartment and undercarriage fully exposed. The Mechanic, armed with his trusted toolbox containing a variety of tools such as a screwdriver, refractormeter, and a set of wrenches, is positioned in the service bay, a designated area for vehicle maintenance and repair services. Nearby, the diagnostic bay is subtly lit, its computer screen displaying a detailed analysis of the vehicle's A/C system. The Mechanic's eyes are fixed on the vehicle's interior, the cabin where the Air Conditioning system is primarily located and accessed. He begins by inspecting every corner of the system, cleaning out any dirt or debris that might have accumulated over time. In the waiting room, four customers, with varying levels of patience, await their vehicle's turn for service.\", 'situation_json': '{\"vehicle_make\": \"Honda\", \"vehicle_model\": \"Civic\", \"vehicle_year\": 2018, \"lift_state\": \"hoisted\", \"toolbox_contents\": [\"screwdriver\", \"refrigerant_meter\", \"wrenches\"], \"mechanic_position\": \"service_bay\", \"diagnostic_display\": \"on\", \"diagnostic_results\": \"A/C system analysis\", \"mechanic_focus\": \"vehicle_interior\", \"interior_inspection\": \"cleaning\", \"waiting_customers\": 4}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114289.78 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139024.57 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 63159.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Dentist', 'process': 'Scheduling Appointments', 'situation': \"In the heart of a bustling dental clinic, the rhythm of scheduling appointments begins to unfold. A polished wooden desk, adorned with a gleaming computer screen and a sleek black phone, takes center stage in the cozy reception area. The receptionist, a beacon of efficiency, navigates the digital calendar with ease and precision. The day's schedule flickers to life, a colorful tapestry of appointments, each one representing a patient in need of dental care.With the turn of the hour, the waiting room begins to populate. The gentle hum of conversation punctuated by the occasional clink of a tray, as the dental assistant prepares for the day's procedures. The aroma of disinfectant and sterile equipment lingers in the air, serving as a constant reminder of the clinic's commitment to cleanliness and patient safety. The sense of anticipation for the upcoming procedures is palpable, as patients wait for their turn to sit in the cushioned dental chair.Meanwhile, the dentist is in the consultation room, engaging in a lively discussion with a patient. Visual aids, such as models, diagrams, or videos, are used to explain procedures and conditions. The atmosphere is one of shared understanding and mutual respect, as the dentist takes the time to address any concerns or questions the patient may have.Back in the reception area, the phone continues its incessant ringing, as the receptionist juggles the flurry of appointment requests. The rhythm intensifies as the first patient of the hour is called in, marking the start of another productive day in the dental clinic.\", 'situation_json': '{\"location\": \"dental clinic\", \"area\": \"reception area\", \"desk\": \"polished wooden desk\", \"desk_objects\": [\"gleaming computer screen\", \"sleek black phone\"], \"receptionist\": {\"action\": \"navigating digital calendar\", \"efficiency\": \"beacon of efficiency\"}, \"waiting_room\": {\"action\": \"populating\", \"hour_turn\": true, \"conversation\": \"hum of conversation\", \"clink_tray\": true, \"dental_assistant_preparation\": true, \"aroma\": \"aroma of disinfectant and sterile equipment\", \"patient_anticipation\": true}, \"consultation_room\": {\"discussion\": \"lively discussion\", \"visual_aids\": [\"models\", \"diagrams\", \"videos\"], \"explanation\": \"procedures and conditions\", \"atmosphere\": \"shared understanding and mutual respect\", \"concern_address\": true}, \"phone\": {\"action\": \"incessant ringing\", \"appointment_requests\": true}, \"first_patient\": {\"hour\": true, \"appointment_start\": true}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110834.85 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 126947.00 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91325.19 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Content Management', 'situation': \"In the heart of a bustling web development company, a web developer meticulously crafts the backbone of a client's website. Perched on their ergonomic chair, the developer's fingers dance across the keyboard of their high-performance laptop, the screen illuminated with lines of code. The laptop, equipped with a crisp, high-resolution screen, is flanked by a sleek, wireless mouse and a comfortable, ergonomic keyboard, both of which aid in the navigation and input of the complex code. A second, larger monitor sits to the developer's left, displaying the website's design plans in intricate detail. Nearby, a designer pours over the visual elements of the site, their eyes keenly focused on ensuring the design's feasibility and alignment with the client's requirements. The developer's desk, cluttered yet organized, is a testament to the hours of work and dedication invested in this project. On the desk, a steaming cup of coffee sits precariously close to the edge, its aroma wafting through the air, adding a sense of comfort to the otherwise tense atmosphere. The office, filled with the soft hum of productivity, is a hub of creativity and innovation, where challenges are met head-on and solutions are crafted with precision. The goal: to create a fully-functional, aesthetically pleasing website that not only meets the client's requirements but exceeds their expectations.\", 'situation_json': '{\"equipment\": {\"laptop\": {\"state\": \"high-performance\", \"screen\": {\"resolution\": \"high\"}, \"accessories\": {\"mouse\": \"wireless, sleek\", \"keyboard\": \"ergonomic\"}}, \"monitor\": {\"size\": \"large\", \"position\": \"left\", \"display\": \"design plans in intricate detail\"}}, \"office_atmosphere\": {\"productivity\": \"soft hum\", \"creativity\": true, \"innovation\": true, \"challenges\": \"met head-on\", \"solutions\": \"crafted with precision\"}, \"beverage\": {\"type\": \"coffee\", \"state\": \"steaming\", \"location\": \"desk, near edge\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 59361.49 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 113698.45 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85204.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Registered Nurse', 'process': 'Documentation', 'situation': \"In the bustling indoor patient care unit, the Registered Nurse is in the midst of her daily 8-hour shift, meticulously documenting patient data. She is surrounded by equipment essential to her role, including a gleaming Stethoscope, a Blood Pressure Cuff, and a Pulse Oximeter. The stethoscope, with its polished brass body and soft ear tips, is used to listen to the patient's heart, lungs, and other body sounds. The Blood Pressure Cuff, neatly coiled on the desk, is used to measure the patient's blood pressure. The Pulse Oximeter, a small device with a glowing LED screen, is used to monitor the patient's oxygen saturation levels and pulse rate. In the nearby Supply Room, she frequently accesses an array of medical supplies, including bandages, gowns, and gloves, to ensure her work is conducted in a sterile and safe manner. In the waiting room, patients and their families anxiously await their appointments, while the Emergency Department hums with activity as RNs provide urgent care to patients with life-threatening conditions. In the Patient Rooms, she administers daily care, such as administering medications, checking vital signs, and performing assessments. At the Nurses' Station, she collaborates with her colleagues, including Physicians and Physical Therapists, to coordinate patient care. The Registered Nurse plays a vital role as a patient advocate, providing emotional support and education to patients and their families, and participating in research and quality improvement initiatives to improve patient outcomes. The Registered Nurse's role is a physically and emotionally challenging one, but she remains dedicated to ensuring optimal patient outcomes and providing compassionate care.\", 'situation_json': '{\"equipment_state\": {\"Stethoscope\": {\"condition\": \"gleaming\"}, \"Blood Pressure Cuff\": {\"condition\": \"neatly coiled\"}, \"Pulse Oximeter\": {\"condition\": \"small device\", \"state\": \"glowing LED screen\"}}, \"supplies\": {\"bandages\": \"available\", \"gowns\": \"available\", \"gloves\": \"available\"}, \"environment\": {\"Indoor Patient Care Unit\": {\"description\": [\"busy\", \"8-hour shift\"]}, \"Supply Room\": {\"accessibility\": \"frequently accessed\"}, \"Waiting Room\": {\"description\": [\"anxious patients and families waiting\"]}, \"Emergency Department\": {\"description\": \"hum with activity\"}, \"Patient Rooms\": {\"description\": [\"daily care\", \"medications administered\", \"vital signs checked\", \"assessments performed\"]}, \"Nurses\\' Station\": {\"description\": \"collaboration with colleagues\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 75614.59 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 93795.31 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 56857.28 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist', 'process': 'Progress Tracking', 'situation': \"In the bustling physical therapy clinic, a seasoned Physical Therapist is meticulously tracking the progress of a patient, whose warm smile and eagerness to improve fill the room. The treatment room, a spacious sanctuary for healing, is equipped with a plethora of equipment—a sturdy balance beam, four color-coded resistance bands lined up neatly along the wall, a state-of-the-art therapy table, and an inviting exercise mat. The tools of the trade are well-maintained and ready for another day of assisting patients in their journey towards better health and mobility. The Physical Therapist, with a determined gaze, is reviewing the patient's records on a nearby laptop, while a crisp white stethoscope dangles from their neck. The clinic is abuzz with activity, as another group of patients await their turn in the waiting room just outside, the sound of chatter forming a comforting background noise to the day's work. The Physical Therapist occasionally glances up from the records, offering an encouraging nod to their patient while making mental notes of the day's progress. In this scene, Physical Therapy becomes a symphony of care, compassion, and hard work, elevating the mundane to the extraordinary.\", 'situation_json': '{\"room_description\": \"spacious sanctuary for healing\", \"equipment\": [\"sturdy balance beam\", \"four color-coded resistance bands\", \"state-of-the-art therapy table\", \"inviting exercise mat\"], \"equipment_condition\": \"well-maintained\", \"laptop_present\": true, \"laptop_state\": \"open\", \"stethoscope_present\": true, \"stethoscope_state\": \"dangling from neck\", \"waiting_room_status\": \"filled with patients\", \"waiting_room_noise_level\": \"comforting background noise\", \"therapist_actions\": [\"reviewing records\", \"glancing up from records\", \"offering nod of encouragement\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 95254.59 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 89806.45 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 56477.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Market Research Analyst', 'process': 'Competitor Analysis', 'situation': 'In the heart of a bustling office, a dedicated Market Research Analyst is meticulously conducting a monthly Competitor Analysis. Their desk, illuminated by the soft glow of a computer screen, is adorned with neatly arranged stacks of industry reports and competitor financials, creating a landscape of intricate information. Surrounded by the subtle hum of data being processed, they dive into this strategic task with absolute focus, their fingers expertly navigating the keys of their state-of-the-art analytical software. In the adjacent meeting room, a blank whiteboard awaits the presentation of their findings to a room filled with expectant colleagues and team managers, who eagerly await the analysts insights into the competitive landscape.', 'situation_json': '{\"location\": \"office\", \"task\": \"competitor analysis\", \"furniture\": [\"desk\", \"meeting room\", \"whiteboard\"], \"lighting\": \"soft glow of a computer screen\", \"equipment\": [\"computer\", \"state-of-the-art analytical software\"], \"documents\": [\"industry reports\", \"competitor financials\"], \"task_frequency\": \"monthly\", \"task_status\": \"in progress\", \"analyst_focus\": \"absolute\", \"colleagues_status\": \"expectant\", \"colleagues_count\": \"filled room\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 94149.61 examples/s] examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141542.27 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 75555.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paramedic', 'process': 'Medical Equipment Operation', 'situation': \"The ambulance, a sleek, gleaming vehicle, is a beacon of hope on the bustling streets. Its siren, a shrill, piercing wail, parts the sea of traffic as it speeds towards its destination. Inside, the treatment room is a symphony of organized chaos. The stretcher, a steel-framed bed with crisp, white sheets, lies at the center, surrounded by a myriad of medical equipment. The defibrillator, a robust, silver machine, stands at the ready, its paddles resting in a cradle, charged and eager. The oxygen tank, a bulky, green cylinder, hums softly, its gauge needle steady at full. The paramedic, dressed in a sharp, navy uniform, moves with practiced efficiency, checking tubes, adjusting flow rates, all while the patient, pale and wan, lies motionless on the stretcher. The paramedic's stethoscope, a classic, dual-tubed instrument, hangs around their neck, ready for use. The radio crackles to life, the dispatcher's voice calm yet urgent, relaying updates on the patient's condition and the ambulance's ETA. The driver, focused and alert, navigates the streets, sirens blaring, lights flashing, a guardian angel in a race against time.\", 'situation_json': '{\"situation\": \"An ambulance, a sleek, gleaming vehicle, is a beacon of hope on the bustling streets. Its siren, a shrill, piercing wail, parts the sea of traffic as it speeds towards its destination. Inside, the treatment room is a symphony of organized chaos. The stretcher, a steel-framed bed with crisp, white sheets, lies at the center, surrounded by a myriad of medical equipment. The defibrillator, a robust, silver machine, stands at the ready, its paddles resting in a cradle, charged and eager. The oxygen tank, a bulky, green cylinder, hums softly, its gauge needle steady at full. The paramedic, dressed in a sharp, navy uniform, moves with practiced efficiency, checking tubes, adjusting flow rates, all while the patient, pale and wan, lies motionless on the stretcher. The paramedic\\'s stethoscope, a classic, dual-tubed instrument, hangs around their neck, ready for use. The radio crackles to life, the dispatcher\\'s voice calm yet urgent, relaying updates on the patient\\'s condition and the ambulance\\'s ETA. The driver, focused and alert, navigates the streets, sirens blaring, lights flashing, a guardian angel in a race against time.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 84838.04 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 122208.92 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 77900.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Executive Assistant', 'process': 'Meeting Coordination', 'situation': 'A professional Executive Assistant is highly organized and efficient. They schedule and organize various meetings and events for executives. Ensuring all meeting details are accurate, and all preparations are in place are crucial. They communicate continuously with the executives and attendees to set meeting agendas, delegate tasks, and ensure everyone is well-prepared. Executive Assistants also manage calendars, arrange travel plans, and oversee the entire coordination process. The success of the meeting or event is their priority, requiring excellent communication skills, time management, and attention to detail.', 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 105309.47 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 122098.14 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86979.59 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mechanical Engineer', 'process': 'Technical Documentation', 'situation': 'In the heart of the engineering office, a mechanical engineer meticulously engages in Technical Documentation, their computer humming softly as they meticulously input intricate equations into CAD software with their nimble fingers. The scent of fresh coffee lingers in the air, mingling with the faint whir of the cooling fan from their laptop. The engineer is surrounded by a symphony of machinery - a calculator resting nearby, its gleaming buttons untouched for now; measuring tools meticulously arranged on a sturdy tray, the brand new calipers reflecting the fluorescent office lights. The office walls are adorned with blueprints, the rigorous detail in each line a testament to countless hours of dedicated labor. In the distance, a faint murmur of low voices from the engineering lab hint at other projects in various stages of development. A few feet away, a team of engineers collaborate in a meeting room, their voices a harmonious orchestra of innovation.', 'situation_json': '{\"office_scent\": \"fresh coffee\", \"computer_state\": \"humming softly\", \"engineer_activity\": \"meticulously inputting intricate equations into CAD software\", \"engineer_speed\": \"nimble\", \"laptop_fan_state\": \"on\", \"laptop_fan_intensity\": \"faint whir\", \"calculator_state\": \"resting nearby\", \"calculator_buttons_state\": \"gleaming\", \"measuring_tools_state\": \"meticulously arranged on a sturdy tray\", \"caliper_condition\": \"brand new\", \"caliper_reflection\": \"fluorescent office lights\", \"blueprint_condition\": \"adorned on the walls\", \"blueprint_detailed_level\": \"rigorous\", \"lab_voices_state\": \"faint murmur\", \"lab_voices_location\": \"distance\", \"team_activity\": \"collaborating in a meeting room\", \"team_voices_state\": \"harmonious orchestra of innovation\", \"office_lights_source\": \"fluorescent\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 123603.69 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 122746.52 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85522.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Insurance Agent', 'process': 'Customer Service', 'situation': \"In the heart of a bustling insurance company, an agent is hard at work in their private, yet cozy office. The room, bathed in a soft, warm glow from the overhead lights, is adorned with framed certifications hanging proudly on the walls, a testament to the agent's expertise and dedication. A sleek computer, humming quietly, sits on a modern glass desk, flanked by a neatly stacked pile of brochures and forms, and a sophisticated digital scanner. A crisp white phone, slightly worn from frequent use, rests within easy reach. The agent's cubicle, sharing a communal space with a handful of other agents, buzzes with hushed conversations and the steady rhythm of fingers dancing on keyboards. A large, vibrant green plant in the corner adds a touch of life and freshness to the otherwise serious environment. In the reception area, a few people wait patiently, their eyes occasionally flicking towards the digital signage displaying the day's appointments. The customer service area, characterized by its soothing tones and plush chairs, awaits the next client with a welcoming atmosphere. The agent, skilled in the art of customer service, is ready to advise and assist, ensuring that each policy is tailored to the individual's unique needs and circumstances.\", 'situation_json': '{\"room_description\": {\"lighting\": \"soft, warm glow\", \"decor\": [\"framed certifications\"], \"size\": \"private, yet cozy\", \"color\": [\"white\", \"green\"]}, \"equipment\": {\"computer\": {\"status\": \"on\", \"noise\": \"humming quietly\"}, \"brochures_and_forms\": {\"status\": \"neatly stacked\"}, \"digital_scanner\": {\"status\": \"present\"}, \"phone\": {\"status\": \"slightly worn\"}, \"digital_signage\": {\"status\": \"displaying appointments\"}}, \"surroundings\": {\"agents\": {\"noise_level\": \"hushed conversations\", \"rhythm\": \"steady rhythm of fingers dancing on keyboards\"}, \"reception_area_status\": \"people waiting\", \"customer_service_area\": {\"atmosphere\": \"welcoming\", \"color_scheme\": \"soothing tones\", \"chair_type\": \"plush\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 124955.70 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144556.48 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78636.34 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Psychologist', 'process': 'Counseling Sessions', 'situation': \"In the heart of a bustling school, nestled amidst numerous classrooms and offices, lies the school psychologist's counseling office - a tranquil haven designed to provide comfort and confidentiality for students. The office is adorned with warm, earthy hues, fostering a sense of calm and serenity. A sturdy, wooden desk, littered with a laptop, a notebook, and an assortment of psychological assessment tools, sits in the corner, basking in the soft glow of the table lamp. Nearby, a filing cabinet, full of meticulously maintained records, stands tall. A comfortable seating arrangement, consisting of a cozy sofa and a few cushioned chairs, occupies the center of the room, inviting students to engage in open and honest conversations. Occasionally, the muffled sounds of students and teachers in the adjoining staff room can be heard, serving as a gentle reminder of the world outside.\", 'situation_json': '{\"location\": \"school psychologist\\'s counseling office\", \"color_scheme\": \"warm, earthy hues\", \"desk\": \"sturdy, wooden\", \"desk_state\": \"littered with a laptop, a notebook, and an assortment of psychological assessment tools\", \"table_lamp\": \"on\", \"filing_cabinet\": \"tall\", \"filing_cabinet_state\": \"full of meticulously maintained records\", \"seating_arrangement\": \"comfortable\", \"seating_arrangement_items\": \"cozy sofa and a few cushioned chairs\", \"seating_arrangement_location\": \"center of the room\", \"adjoining_room\": \"staff room\", \"adjoining_room_noise\": \"muffled sounds of students and teachers\", \"adjoining_room_noise_frequency\": \"occasionally\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 113963.35 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 108028.13 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90334.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Lesson Planning', 'situation': \"In the heart of a bustling middle school, a dedicated teacher retreats to their office, an oasis of organized chaos, for their daily lesson planning ritual. The office, bathed in the soft glow of a vintage desk lamp, is a sanctuary of knowledge, adorned with motivational posters in hues of teal and beige that whisper encouragement to the teacher and students alike. The teacher's desk, a fortress of functionality, is a symphony of neatly stacked papers, each one a testament to the day's lessons, and a menagerie of colorful pens, each one a silent partner in the dance of instruction. A sleek laptop, a portal to infinite educational resources, rests on the desk, its screen reflecting the teacher's determined gaze. Beside it, a printer, a loyal steed, stands ready to materialize the teacher's plans into tangible reality. The walls, lined with bookshelves groaning under the weight of educational tomes and teaching aids, are a testament to the teacher's commitment to their craft. The air is filled with the faint scent of freshly printed paper and the quiet hum of the printer, a lullaby that sings of progress and planning. The teacher, surrounded by this tapestry of teaching tools and resources, begins their dance, their fingers tapping out a rhythm on the keyboard, each keystroke a step closer to the day's lessons. The office, a microcosm of the teacher's mind, is a living, breathing entity, pulsing with the heartbeat of education.\", 'situation_json': '{\"situation\": \"A middle school teacher is in their office, planning lessons for the day. The office is filled with educational resources and teaching tools. The teacher is using a laptop to create and print out lesson plans.\", \"details\": {\"Room Lighting\": \"Soft glow from a vintage desk lamp\", \"Wall Decor\": \"Motivational posters in teal and beige\", \"Desk Organization\": \"Neatly stacked papers, colorful pens\", \"Electronic Devices\": {\"Laptop\": \"Sleek, used for lesson planning\", \"Printer\": \"Sleek, functional, humming softly\"}, \"Bookshelves\": \"Groaning under weight of educational tomes and teaching aids\", \"Scents\": \"Freshly printed paper\", \"Teacher Activity\": \"Typing on laptop, planning lessons\", \"Office Atmosphere\": \"Organized chaos, pulsing with heartbeat of education\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129272.82 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 153437.88 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83187.05 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Substance Abuse Counselor', 'process': 'Documentation', 'situation': 'In a quiet, private counseling room, a substance abuse counselor is engrossed in documentation, their attention focused on the blue glowing screen of their laptop. Lined paper and a black ballpoint pen lie nearby, ready to be used for note-taking during the upcoming session or for creating treatment plans. The room is well-lit, with soft yellow lighting illuminating the white walls and the single potted plant in the corner, a touch of green in the otherwise muted color scheme. Across the hall, the waiting room is occupied by a small group of people, their faces reflecting a mix of nervousness and hope as they wait for their turn. The counselor takes a moment to look up from their work, their thoughts drifting to the upcoming session, ready to provide the much-needed guidance and support to help individuals struggling with substance use disorders.', 'situation_json': '{\"room\": \"counseling room\", \"room_attributes\": {\"size\": \"quiet\", \"privacy\": \"private\", \"color\": \"white\", \"lighting\": \"soft yellow\", \"additional_items\": [\"laptop\", \"lined paper\", \"black ballpoint pen\", \"single potted plant\"]}, \"laptop_attributes\": {\"screen\": \"blue glowing\"}, \"pen_attributes\": {\"color\": \"black\", \"type\": \"ballpoint\"}, \"plant_attributes\": {\"type\": \"potted plant\", \"color\": \"green\"}, \"waiting_room_attributes\": {\"occupancy\": \"small group of people\", \"emotions\": [\"nervousness\", \"hope\"]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129039.78 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131883.53 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86479.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Loan Officer', 'process': 'Customer Service', 'situation': 'A Loan Officer, immersed in their daily tasks, is seated at their spacious, well-organized office desk, with two computer monitors displaying the Loan Application Portal and various financial databases. The desk is neatly arranged with a sleek black computer, a nearly empty mug of coffee, and a neat stack of loan applications. On the left, a silver-colored calculator sits at the ready for quick financial calculations. The office walls are adorned with certificates of achievement and a few framed photographs. The Loan Officer is intently reviewing and verifying the employment and income details of a loan applicant. Nearby, the office is abuzz with activity, as bank staff and clients move to and fro, the soft hum of their conversations punctuating the otherwise quiet atmosphere. Across the room, a door leads to a meeting room where clients are discussing their loan applications with other Loan Officers. The occasional chime of a ringing phone adds to the daily rhythm of the office, as the Loan Officer receives communication from their clients.', 'situation_json': '{\"description\": \"A Loan Officer, immersed in their daily tasks, is seated at their spacious, well-organized office desk, with two computer monitors displaying the Loan Application Portal and various financial databases. The desk is neatly arranged with a sleek black computer, a nearly empty mug of coffee, and a neat stack of loan applications. On the left, a silver-colored calculator sits at the ready for quick financial calculations. The office walls are adorned with certificates of achievement and a few framed photographs. The Loan Officer is intently reviewing and verifying the employment and income details of a loan applicant. Nearby, the office is abuzz with activity, as bank staff and clients move to and fro, the soft hum of their conversations punctuating the otherwise quiet atmosphere. Across the room, a door leads to a meeting room where clients are discussing their loan applications with other Loan Officers. The occasional chime of a ringing phone adds to the daily rhythm of the office, as the Loan Officer receives communication from their clients.\", \"office_state\": {\"monitors\": 2, \"computer\": \"black and sleek\", \"mug_of_coffee\": \"nearly empty\", \"loan_applications\": \"neat stack\", \"calculator\": \"silver-colored\", \"certificates\": \"on the walls\", \"photographs\": \"few framed\", \"office_desk\": \"spacious and well-organized\", \"office_activity\": \"busy\", \"conversation_level\": \"soft hum\", \"office_atmosphere\": \"quiet\", \"meeting_room_door\": \"across the room\", \"ringing_phone\": \"occasional chime\"}, \"background_noise\": \"soft hum of conversations\", \"meeting_room_activity\": \"clients discussing loan applications with other Loan Officers\", \"communication_received\": {\"client_communication\": \"ringing phone\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 118033.81 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140969.75 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91933.47 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Public Relations Specialist', 'process': 'Stakeholder Communication', 'situation': \"In the heart of a bustling Corporate Office, the dynamic atmosphere is enhanced by the constant buzz of activity. The expansive office space is divided into various zones, each with its unique purpose and layout. The main hub is the Presentation Room, where the Public Relations Specialist is diligently preparing for an upcoming meeting with key stakeholders. The room is filled with rows of neatly arranged chairs, each equipped with a small table for note-taking, and a large projection screen dominates the front wall, ready to display vibrant slides and visuals.\\n\\nAdjacent to the Presentation Room are several Meeting Rooms, each designed with modern aesthetics and functional comfort in mind. These rooms are equipped with large conference tables, comfortable chairs, and state-of-the-art communication equipment, including high-definition screens and advanced audio systems. The walls are adorned with motivational quotes and corporate slogans, adding a touch of inspiration to the professional atmosphere.\\n\\nIn one of the Meeting Rooms, the PR team is huddled around a large table, their laptops open and phones at the ready. The senior management is present, discussing crisis management strategies, their faces a mix of concentration and concern. The meeting is intense, with everyone deeply engaged in the discussion, their minds racing with ideas and solutions.\\n\\nThe Coffee Break Area is a welcoming oasis amidst the bustling office. Here, employees take short breaks to refresh and refocus. The aroma of freshly brewed coffee fills the air, and the sound of laughter and light conversation provides a momentary respite from the high-energy environment of the meeting rooms. The area is equipped with comfortable seating, a coffee machine, and a selection of snacks, fostering a sense of camaraderie and creativity.\\n\\nThe PR team works seamlessly together, with each member understanding their role and responsibilities. The atmosphere is electric, with the buzz of strategic planning and the anticipation of successful outcomes palpable in the air. The office is a hive of activity, with everyone focused on the task at hand, all working towards the common goal of maintaining and enhancing the company's public image and reputation.\", 'situation_json': '{\"main_area\": \"Presentation Room\", \"main_area_electrical_equiment\": {\"notes_tables\": \"small table\", \"projection_screen\": \"large wall\", \"projector\": true}, \"adjacent_area\": \"Meeting Rooms\", \"adjacent_area_states\": {\"communication_equiment\": \"high-definition screens\"}, \"senior_management_state\": \"Present\", \"breaking_area\": \"Coffee Break Area\", \"breaking_area_states\": {\"coffe_machine\": true, \"snacks\": true}, \"PR_team_state\": \"Working\", \"work_atmosphere\": \"Electric\", \"working_towards\": \"Maintaining and enhancing company reputation\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 110397.24 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 131795.24 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 73855.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Glazier', 'process': 'Safety Measures', 'situation': 'On a bustling construction site, amidst the clamor of power tools and the constant movement of cranes, a glazier prepares for the daily task of installing glass windows in a high-rise building. The site is surrounded by various tools and equipment, such as roof anchors, harnesses, and suction cups, neatly arranged and ready for use. The glazier dons a protective uniform, complete with gloves, safety glasses, and sturdy boots. Nearby, a group of construction workers are busy erecting scaffolding, while an architect and a project manager discuss plans in the distance. The glazier surveys the situation, mentally mapping out the safety measures needed to ensure a smooth and secure installation process.', 'situation_json': '{\"location\": \"construction site\", \"surroundings\": [\"power tools\", \"cranes\", \"roof anchors\", \"harnesses\", \"suction cups\"], \"equipment_state\": {\"arrangement\": \"neatly arranged\", \"readiness\": \"ready for use\"}, \"glazier_uniform\": {\"protective_clothing\": \"protective uniform\", \"gloves\": true, \"safety_glasses\": true, \"boots\": \"sturdy boots\"}, \"workers_activity\": \"erecting scaffolding\", \"professionals_present\": [\"architect\", \"project manager\"], \"professionals_activity\": \"discussing plans\", \"glazier_action\": \"surveying the situation\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114862.78 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 127513.58 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94472.90 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Auto Mechanic', 'process': 'Battery Replacement', 'situation': \"In the heart of the bustling auto repair shop, the Auto Mechanic prepares for a daily routine: Battery Replacement. The shop is filled with the hum of various tools and machinery. A car lift, a staple in the shop, stands tall and strong, ready to hoist vehicles off the ground, its hydraulic system gleaming under the industrial lights. Nearby, a toolbox holds a myriad of tools, their metallic bodies reflecting the shop lights, each one waiting to be used in the symphony of repair. The workbench, the Auto Mechanic's sanctuary, stands sturdy, its surface worn from years of use, yet it holds a certain charm. In the waiting room, a handful of people sit, their eyes glued to their phones or magazines, a stark contrast to the busy scene in the workshop. As the Auto Mechanic dons their gloves, they approach the vehicle, their mind already running through the steps of the process: disconnect the battery cables, remove the old battery, clean the battery tray and cable ends, place the new battery, connect the cables, and finally, test the battery. Each step is executed with precision and care, a testament to the Auto Mechanic's years of experience and dedication to their profession.\", 'situation_json': '{\"environment\": {\"type\": \"shop\", \"name\": \"auto repair shop\", \"size\": \"bustling\", \"lighting\": \"industrial\", \"noise_level\": \"hum of various tools and machinery\"}, \"equipment\": {\"car_lift\": {\"status\": \"ready\", \"appearance\": \"tall and strong\", \"hydraulic_system\": \"gleaming\", \"purpose\": \"hoist vehicles off the ground\"}, \"toolbox\": {\"location\": \"nearby\", \"contents\": {\"tools\": {\"metallic_bodies\": \"reflecting shop lights\", \"status\": \"waiting to be used\", \"purpose\": \"repair\"}}}, \"workbench\": {\"status\": \"sturdy\", \"surface\": \"worn from years of use\", \"purpose\": \"work space\", \"charm\": \"certain\"}, \"waiting_room\": {\"occupants\": \"handful of people\", \"activity\": \"waiting\", \"distraction\": \"phones or magazines\"}}, \"process\": {\"name\": \"Battery Replacement\", \"steps\": {\"disconnect_battery_cables\": {\"status\": \"executed with precision and care\", \"purpose\": \"disconnect the battery cables\"}, \"remove_old_battery\": {\"status\": \"executed with precision and care\", \"purpose\": \"remove the old battery\"}, \"clean_battery_tray_and_cable_ends\": {\"status\": \"executed with precision and care\", \"purpose\": \"clean the battery tray and cable ends\"}, \"place_new_battery\": {\"status\": \"executed with precision and care\", \"purpose\": \"place the new battery\"}, \"connect_cables\": {\"status\": \"executed with precision and care\", \"purpose\": \"connect the cables\"}, \"test_battery\": {\"status\": \"executed with precision and care\", \"purpose\": \"test the battery\"}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 123413.00 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 144519.16 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 79388.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Diagnostic Medical Sonographer', 'process': 'Collaboration with Medical Team', 'situation': 'In the heart of a bustling medical clinic, a Diagnostic Medical Sonographer readies for another day of collaboration with the medical team. The sonographer moves swiftly through the controlled medical environment, ensuring the temperature and humidity levels are held at an optimal level for the sensitive imaging equipment. The ultrasound machine and transducer probe, cleaned and calibrated to perfection, sit patiently in the treatment room. In the waiting room, a handful of patients, each with their own unique needs, sit quietly absorbed in magazines or gazing at the muted television screen. The sonographer, with a practiced smile, greets each patient in turn, explaining the ultrasound procedure with clarity and reassurance. In the radiology department, the physician, a seasoned radiologist, waits to interpret the results of today’s scans, his office a testament to his years of experience with walls adorned with medical literature and certificates. As the sonographer begins the first ultrasound, the controlled hum of the clinic continues around them, a symphony of caring and collaboration perfectly orchestrated to benefit its patients.', 'situation_json': '{\"clinic_atmosphere\": \"busy\", \"equipment_condition\": \"ready\", \"equipment_cleanliness\": \"clean\", \"equipment_calibration\": \"perfect\", \"equipment_location\": \"treatment room\", \"temperature_level\": \"optimal\", \"humidity_level\": \"optimal\", \"waiting_room_activity\": \"quiet\", \"number_of_patients\": \"a handful\", \"patient_mood\": \"absorbed\", \"sonographer_greeting\": \"practiced smile\", \"sonographer_explanation_clarity\": \"clear and reassuring\", \"radiologist_presence\": \"waiting\", \"radiologist_experience\": \"seasoned\", \"radiologist_office_decor\": \"personal medical literature and certificates\", \"scan_interpreters\": \"radiologist\", \"background_activity\": \"controlled hum\", \"clinic_caring_and_collaboration\": \"symphony of caring and collaboration\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129076.73 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128966.78 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93319.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Designing', 'situation': \"Imagine a bustling modern office, the hum of soft voices and the occasional clatter of keyboards filling the air. The web developer's desk is a haven of organized chaos, strewn with sticky notes and coffee cups. At the center sits a state-of-the-art laptop, its screen glowing with lines of code. Beside it, an ergonomic mouse and keyboard ensure comfort during hours of focused work.\\n\\nThe development environment is alive with activity. A large, sleek monitor displays the website in progress, its vibrant colors and dynamic layout a testament to the developer's skill. The development tools are meticulously arranged on the screen, ready to be utilized at a moment's notice. The text editor is open, cursor blinking patiently, awaiting the next line of code.\\n\\nIn the office, the coffee maker is a lifeline, constantly brewing fresh cups to keep the team alert. The quiet environment is occasionally interrupted by the soft murmurs of colleagues discussing projects or sharing ideas in the collaboration area. The testing environment, a separate and secure section, is busy with simulations and quality checks, ensuring that every aspect of the website functions flawlessly.\\n\\nThe web developer is engrossed in their work, fingers dancing across the keyboard as they translate client requirements into functional code. Nearby, the project manager is in a meeting with the client, discussing progress and next steps. The designer is deeply focused on creating visually stunning mockups, while the content developer is diligently crafting engaging copy.\\n\\nThe office is a hive of productivity, each team member contributing to the success of the project. The developer's dedication and the collaboration among the team ensure that the website will not only meet but exceed client expectations.\", 'situation_json': '{\"office\": {\"type\": \"modern\", \"ambient_sound\": \"hum of soft voices and occasional clatter of keyboards\"}, \"desk\": {\"organisation_level\": \"organized chaos\", \"contents\": [\"sticky notes\", \"coffee cups\"]}, \"laptop\": {\"condition\": \"state-of-the-art\", \"display\": \"lines of code\"}, \"peripherals\": {\"mouse\": \"ergonomic\", \"keyboard\": \"ergonomic\"}, \"development_environment\": {\"activity_level\": \"alive\", \"monitor\": {\"type\": \"large\", \"condition\": \"sleek\", \"display\": \"website in progress\"}, \"development_tools\": \"meticulously arranged\", \"text_editor\": {\"state\": \"open\", \"cursor\": \"blinking\"}}, \"coffee_maker\": {\"state\": \"constantly brewing\"}, \"collaboration_area\": {\"ambient_sound\": \"soft murmurs of colleagues discussing projects or sharing ideas\"}, \"testing_environment\": {\"activity_level\": \"busy\", \"tasks\": [\"simulations\", \"quality checks\"], \"quality\": \"ensuring flawless functionality\"}, \"nearby_roles\": {\"project_manager\": {\"activity\": \"in a meeting with the client\", \"discussion_topics\": [\"progress\", \"next steps\"]}, \"designer\": {\"activity\": \"creating visually stunning mockups\"}, \"content_developer\": {\"activity\": \"crafting engaging copy\"}}, \"office_ambiance\": {\"type\": \"hive of productivity\", \"teamwork\": {\"contribution\": \"success of the project\", \"team_dedication\": \"developer\\'s dedication\", \"collaboration\": \"collaboration among the team\"}}, \"client_expectations\": {\"outcome\": \"exceed expectations\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 89091.31 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 74988.27 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91737.07 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Registered Nurse', 'process': 'Infection Control', 'situation': \"In the bustling, fluorescent-lit corridors of the healthcare facility, the Registered Nurse, clad in a crisp, hospital-issued scrub top,uations In a patient room revealed the sterile environment, with three dental mirrors gleaming with pristine cleanliness on a tray placed meticulously on the counter. The room hummed with the quiet rhythm of medical equipment, a stethoscope coiled neatly beside a blood pressure monitor, and a pulse oximeter displaying the reassuring stats of a recovering patient. The nurse, with latex-gloved hands, meticulously documented the latest findings on a clipboard, periodically pausing to consult the notes on a nearby handheld device. Nearby, in the common areas, the sound of disinfectant spray echoed as a fellow healthcare staff diligently wiped down surfaces, ensuring the waiting room remained a sanitary space for the eleven patients seated, a sea of pastel gowns and worried expressions, who looked up briefly as the nurse passed by, the comforting smile she offered them reflecting her dedication to their well-being. In the nursing station, the nurse coordinated with a team: a Physician hunching over a computer screen, a Physical Therapist jotting down notes, and a Patient/Family group huddled together, deep in conversation. ThePM room, with its negative pressure ensuring the containment of airborne pathogens, stood as a testament to the critical work of infection control, the nurse ensuring every protocol was rigorously followed. Behind her, the supply room brimmed with bandages, gowns, and gloves, each item meticulously inventoried for quick access. Through the day, the nurse's mental and physical fatigue was evident, but her commitment to safeguarding her patients' health never wavered, her every action a testament to the vital role nurses play in infection control.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133520.53 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137729.09 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 83966.79 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist', 'process': 'Therapeutic Exercise', 'situation': 'In the heart of a bustling clinic, a Physical Therapist is diligently working on a Therapeutic Exercise process. The therapy room, their primary location for such an exercise, is brimming with various equipment. The room is filled with the soft hum of exercise machines interspersed with the gentle rustling of resistance bands. A sturdy therapy table, clad in a pristine white linen cloth, occupies the center stage, surrounded by a plethora of exercise mats and balance equipment. The Physical Therapist is meticulously supervising a patient, who is engaged in a series of controlled movements on one of the exercise mats, their focus intense, perspiration glistening on their forehead. The Physical Therapist, meanwhile, is observing the patient with a keen eye, occasionally taking notes in a worn-out notepad. A laptop, open and displaying patient records, sits on a nearby desk, providing ready access to the treatment plan. In the waiting room, just outside the therapy room, the soft noises of a television are interspersed with the quiet chatter of patients. The chairs, though comfortable, are mostly unoccupied, a testament to the efficient scheduling of the clinic. The Physical Therapist, unfazed by the surrounding activity, continues their work with an air of determination.', 'situation_json': '{\"location\": \"therapy room\", \"equipment\": [\"exercise machines\", \"resistance bands\", \"therapy table\", \"exercise mats\", \"balance equipment\", \"laptop\"], \"equipment_states\": {\"exercise machines\": \"on\", \"resistance bands\": \"in use\", \"therapy table\": \"set up\", \"exercise mats\": \"in use\", \"balance equipment\": \"ready\", \"laptop\": \"open\"}, \"observations\": {\"patient_activity\": \"engaged in controlled movements\", \"patient_focus\": \"intense\", \"patient_sweat\": \"present\", \"physical_therapist_activity\": \"supervising and taking notes\", \"waiting_room_activity\": \"quiet chatter and television noise\", \"waiting_room_occupancy\": \"mostly unoccupied\"}, \"time\": \"daytime\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 80489.00 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 106138.67 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85487.14 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Market Research Analyst', 'process': 'Data Analysis', 'situation': 'In the heart of the bustling office, a Market Research Analyst meticulously pores over a wealth of data on their trusty dual-screen computer setup, bathed in the soft luminescence of the monitors. The room, painted in a soothing beige hue, houses a total of six analysts, each engrossed in their own data-driven explorations. The collective hum of keyboards and mouse clicks forms a symphonic rhythm, punctuated only by the occasional murmurs of focused conversations. The air is filled with a palpable sense of purpose, as the team delves into the intricate task of analyzing consumer behavior, competitor strategies, and market dynamics. The far-right corner is home to a well-used whiteboard, adorned with color-coded scribbles, arrows, and diagrams, a testament to the collaborative efforts undertaken within the space. On the left, a compact coffee station offers a much-needed caffeine fix to fuel the analytical rigor. Equipped with their statistical software, survey tools, and reporting tools, the Market Research Analyst navigates through a world of numbers, patterns, and trends, piecing together insights that will steer marketing strategy and influence business decisions.', 'situation_json': '{\"room_color\": \"beige\", \"number_of_analysts\": 6, \"electronic_equipment_states\": {\"dual_screen_computer_setups\": 6, \"keyboard_states\": [\"humming\"], \"mouse_click_states\": [\"clicking\"], \"monitors\": {\"luminescence\": \"soft\", \"number\": 12}, \"whiteboard_usage\": \"well-used\", \"whiteboard_content\": \"color-coded scribbles, arrows, and diagrams\", \"data_analysis_software\": [\"statistical\", \"survey tools\", \"reporting tools\"], \"coffee_station\": \"present\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119121.30 examples/s]examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 120208.78 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 81579.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paramedic', 'process': 'Patient Assessment', 'situation': \"In the bustling chaos of an outdoor accident scene, a paramedic moves swiftly towards the patient, a detailed depiction of urgency and precision. The paramedic carries several pieces of crucial medical equipment on their person. A stethoscope hangs around their neck, its metallic body glinting beneath the harsh sunlight. The blood pressure monitor, nestled in the paramedic's bag, looms large with its promise of vital cardiovascular assessment. The pulse oximeter, a beacon of modern medical technology, is clipped securely on the paramedic's finger, ready to provide insight into the patient's respiratory status. The glucometer, a compact device with life-saving capabilities, is kept close for quick access in case of metabolic emergencies. Lastly, a suction device, small yet vital, is within reach should the patient's airway require clearing. The paramedic moves with purpose, aware of time's urgency, as they prepare to commence the Patient Assessment.\", 'situation_json': '{\"location\": \"outdoor accident scene\", \"equipment\": {\"stethoscope\": {\"status\": \"carried\", \"location\": \"around neck\"}, \"blood pressure monitor\": {\"status\": \"packed\", \"location\": \"in paramedic\\'s bag\"}, \"pulse oximeter\": {\"status\": \"worn\", \"location\": \"on paramedic\\'s finger\"}, \"glucometer\": {\"status\": \"carried\", \"location\": \"close for quick access\"}, \"suction device\": {\"status\": \"within reach\", \"location\": \"close\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 108905.44 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141798.84 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91780.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Executive Assistant', 'process': 'Office Management', 'situation': \"In the heart of the company, the indoor office sprawls, a bustling hub of productivity where every detail counts. The Executive Assistant's domain, the executive office, is an oasis of order amidst the hum. It's a sprawling space, filled with the quiet hum of high-end, top-of-the-line equipment. The desk, a massive, polished slab of mahogany, is immaculate, save for the sleek, latest-model laptop and the desktop computer, their screens glowing softly, reflecting the relentless pace of progress. The executive's high-back leather chair, plush and imposing, sits vacant, a silent sentinel awaiting its commander's return. The walls are adorned with a gallery of framed achievements, each one a testament to the executive's relentless drive. The air is cool, crisp, a testament to the efficient air conditioning system, a silent guardian against the urban heat. The windows, floor-to-ceiling, offer a panoramic view of the cityscape, a constant reminder of the executive's domain. The office is a sanctuary of solitude, a place where decisions are made, strategies are born, and empires are shaped. Yet, it's not isolated. The door, always slightly ajar, allows glimpses into the office floor, a sea of cubicles and workstations, a hive of activity. The faint aroma of freshly brewed coffee wafts in from the nearby break room, a constant source of sustenance for the office's denizens. The Executive Assistant's office, a smaller, no less important counterpart, is just a few steps away. It's a hub of communication, where the phone, a sleek, modern device, is never silent, and the printer, a workhorse, is always ready to serve. The calendar software, a complex web of schedules and appointments, is the Assistant's Bible, a constant source of guidance and direction. The email client, a digital sieve, filters through the deluge of messages, separating the important from the trivial. The file cabinet, a steel sentinel, stands guard over the office's secrets, its drawers filled with the detritus of progress. The meeting rooms, just a short walk away, are sanctuaries of collaboration, their tables strewn with the remnants of strategy sessions and brainstorming marathons. The boardroom, the office's grand arena, is where the big decisions are made, its expansive table a stage for power plays and compromises. The accounting department, a labyrinth of desks and calculators, is where the numbers are crunched, the expenses tallied, and the budgets balanced. The manager's office, a smaller version of the executive's sanctum, is where the rubber meets the road, where decisions are implemented, and progress is tracked. The airport, the office's portal to the world, is where the Assistant's work often begins and ends, a crucible of coordination and communication. The Assistant, the office's unseen hero, is the lubricant that keeps this complex machine running smoothly. They are the glue that binds the office together, the oil that keeps the cogs turning, the air traffic controller that guides the office's denizens through the complex, ever-changing landscape of the corporate world. Their work is unseen, unheralded, but it is indispensable. They are the Executive Assistant, and this is their domain.\", 'situation_json': '{\"office_details\": {\"desk\": {\"material\": \"mahogany\", \"state\": \"immaculate\"}, \"equipment\": [{\"type\": \"laptop\", \"brand\": \"latest-model\", \"state\": \"glowing softly\"}, {\"type\": \"desktop computer\", \"state\": \"glowing softly\"}], \"chair\": {\"type\": \"high-back leather\", \"state\": \"vacant\"}, \"walls\": {\"decoration\": \"gallery of framed achievements\"}, \"windows\": {\"type\": \"floor-to-ceiling\", \"view\": \"panoramic cityscape\"}, \"air_conditioning\": {\"state\": \"efficient\"}, \"door\": {\"state\": \"slightly ajar\"}, \"aroma\": {\"type\": \"coffee\", \"origin\": \"break room\"}, \"assistant_office\": {\"communication_tools\": {\"phone\": \"sleek, modern device\", \"printer\": \"always ready\"}, \"organization_tools\": {\"calendar_software\": \"complex web of schedules\", \"email_client\": \"digital sieve\"}, \"file_cabinet\": {\"state\": \"steel sentinel\"}}, \"meeting_rooms\": {\"state\": \"sanctuaries of collaboration\"}, \"boardroom\": {\"state\": \"grand arena\"}, \"accounting_department\": {\"tools\": \"desks and calculators\"}, \"manager_office\": {\"state\": \"smaller version of executive\\'s sanctum\"}, \"airport\": {\"role\": \"portal to the world\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 120181.37 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 151601.78 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 87852.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mechanical Engineer', 'process': 'Training and Mentoring', 'situation': 'In the heart of a bustling office, the monthly training and mentoring session for Mechanical Engineers commences. The meeting room, a spacious chamber with a large wooden table, is adorned with the tranquil hues of cream and beige, exuding a sense of professionalism and focus. Ten trainees, a mix of eager newcomers and seasoned engineers, sit around the table, their eyes fixed on the projector screen at the front of the room. On the table rest ten laptops, each open to display the same slideshow filled with mechanical diagrams and analytical data. Nearby, a flipchart stands ready, its blank pages waiting to be filled with knowledge. The whiteboard, a testament to previous sessions, displays scribbles of formulas and mechanics, still fresh from the last discussion held there. In the corner, a small table holds a neat stack of pen drives, each containing the same essential training materials. The trainers, two seasoned Mechanical Engineers, stand near the projector, ready to begin the six-hour long session.', 'situation_json': '{\"location\": \"office\", \"room_description\": \"spacious chamber with a large wooden table, adorned with the tranquil hues of cream and beige\", \"number_of_participants\": 10, \"participant_types\": [\"newcomers\", \"seasoned engineers\"], \"room_equipments\": [\"projector screen\", \"laptops\", \"flipchart\", \"whiteboard\", \"pen drives\"], \"activity_duration\": 6}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 116262.36 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 128859.17 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91476.50 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Insurance Agent', 'process': 'Policy Issuance', 'situation': 'In the heart of a bustling insurance company, the Insurance Agent is poised to commence their daily task of Policy Issuance. As they step into their office, the comforting hum of the indoor environment envelops them, the air conditioning subtly taming the midday heat. The office is a picturesque scene of efficiency, a desk neatly arranged with a meticulously cleaned computer and a phone, both crucial tools for the Agent to access policy forms and communicate with clients and underwriters. On the wall, a vibrant whiteboard displays the day’s schedule, with client meetings and policy presentations penciled in meeting rooms, and regular training and updates on policy changes and industry trends noted for the training rooms. The Agent is aware that the nearby reception area, currently housing a modest queue of five clients, can greatly influence the clients’ first impression of the company. As they settle into their desk chair, the Agent prepares to navigate the mental challenges of the day ahead, ensuring that every policy issued is accurate, complete, and fully understood by the client. The ultimate goal is clear: to safeguard the clients’ assets and provide them with the much-needed financial security.', 'situation_json': '{\"location\": \"insurance company\", \"equipment\": {\"air conditioning\": \"on\", \"computer\": \"clean\", \"phone\": \"ready\", \"whiteboard\": {\"schedule\": {\"meetings\": [{\"location\": \"meeting room\", \"type\": \"client meetings, policy presentations\"}, {\"location\": \"training room\", \"type\": \"training and updates on policy changes and industry trends\"}], \"clients_in_queue\": 5}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 117616.80 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 139219.05 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 71207.78 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Psychologist', 'process': 'Crisis Intervention', 'situation': \"In a bustling school during a busy day, Dr. Smith, a seasoned School Psychologist, is urgently called to the counseling office, a cozy, private space filled with comfortable chairs and neutral-toned walls adorned with motivational posters. Her laptop, a crucial tool for documentation and research, rests on a clutter-free desk beside her notebook, used for jotting down notes and thoughts. The atmosphere is tense as she prepares to engage in crisis intervention with a distressed student who is experiencing a severe emotional crisis. The student, hands trembling, is seated with Ms. Johnson, the compassionate school counselor, who has managed to guide the student to the office. Three other teachers, well-versed in crisis management, are present, each with their own set of concerns and observations about the student. The student's parents are also due to arrive shortly. In this high-stakes situation, Dr. Smith, with her calming demeanor and excellent communication skills, is ready to evaluate the situation, create a plan, and provide immediate support, utilizing her psychological assessment tools. The goal is to prevent further escalation, alleviate the student's distress, and help reinstate the student to a functional state.\", 'situation_json': '{\"location\": \"school\", \"atmosphere\": \"tense\", \"area_description\": \"counseling office\", \"area_size\": \"cozy\", \"area_privacy\": \"private\", \"area_decor\": \"motivational posters, neutral-toned walls\", \"furniture\": \"comfortable chairs\", \"desk_state\": \"clutter-free\", \"electrical_equipment\": \"laptop\", \"equipment_state\": \"fully functional\", \"other_equipment\": \"notebook\", \"other_equipment_state\": \"usable\", \"person_count\": 6, \"other_persons\": [\"student\", \"school counselor\", \"three teachers\", \"student\\'s parents\"], \"student_state\": \"distressed\", \"student_symptoms\": \"severe emotional crisis, trembling hands\", \"other_person_states\": [\"compassionate\", \"concerned\", \"guide\", \"experienced in crisis management\"], \"intervention_type\": \"crisis intervention\", \"goal\": \"prevent further escalation, alleviate distress, reinstate student to functional state\", \"tools_used\": \"psychological assessment tools\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 104836.18 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 82174.86 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 51008.28 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Substance Abuse Counselor', 'process': 'Progress Monitoring', 'situation': \"In the heart of a bustling clinic, the treatment room is a sanctum of quiet solace, bathed in the soft glow of warm, inviting light. The walls, painted a soothing pastel blue, are adorned with calming artwork, creating an atmosphere of peace and trust. A comfortable, plush armchair sits across from a simple wooden desk, where the substance abuse counselor meticulously reviews the assessment tools spread out before them. The room exudes a sense of orderly calm, with a neatly arranged bookshelf lined with resources and a small potted plant adding a touch of life to the corner.\\n\\nIn this serene setting, the counselor is deeply engrossed in their work, their laptop open and ready for documentation. They carefully flip through the pages of their notebook, meticulously recording the progress of their clients. The laptop's screen displays a detailed schedule of appointments, each entry carefully planned and color-coded for clarity.\\n\\nJust outside, the waiting room is a picture of quiet anticipation. Comfortable chairs, upholstered in soothing neutral tones, are arranged in a welcoming semicircle. A small coffee table in the center holds a selection of educational materials, including brochures and pamphlets on substance abuse prevention and available treatment resources. The room is filled with the soft hum of a few clients quietly engaging in hushed conversations, their eyes occasionally glancing at the clock, eagerly awaiting their turn.\\n\\nBack in the treatment room, the counselor prepares for the upcoming session, their mind focused on the emotional, mental, and verbal challenges ahead. They take a moment to review the confidentiality agreement, ensuring it is properly documented and filed, ready to provide a safe and secure space for their clients to open up and share their journey towards recovery.\\n\\nThe clinic itself is a hub of activity, with various localities and surroundings adding to its dynamic atmosphere. Beyond the treatment room, there are community centers used for workshops and resource dissemination, and schools where the counselor engages with students to raise awareness. The workshop and conference rooms are buzzing with professionals eager to learn and collaborate, with a variety of collaborating organizations working together to improve treatment access and resources.\\n\\nIn this intricate web of support and care, the substance abuse counselor stands as a pillar of strength, dedicated to guiding their clients through the intricate process of progress monitoring, enhancing their well-being, and fostering a path to recovery.\", 'situation_json': '{\"situation\": \"{\\\\n    \\\\\"situation\\\\\": {\\\\n        \\\\\"room1\\\\\": {\\\\n            \\\\\"name\\\\\": \\\\\"Treatment Room\\\\\",\\\\n            \\\\\"ambience\\\\\": {\\\\n                \\\\\"light\\\\\": \\\\\"Warm, soft\\\\\",\\\\n                \\\\\"atmosphere\\\\\": \\\\\"Calm, soothing\\\\\",\\\\n                \\\\\"wallColor\\\\\": \\\\\"Pastel blue\\\\\",\\\\n                \\\\\"artwork\\\\\": \\\\\"Calming\\\\\"\\\\n            },\\\\n            \\\\\"furniture\\\\\": {\\\\n                \\\\\"armchair\\\\\": {\\\\n                    \\\\\"type\\\\\": \\\\\"Plush\\\\\",\\\\n                    \\\\\"position\\\\\": \\\\\"Across from desk\\\\\"\\\\n                },\\\\n                \\\\\"desk\\\\\": {\\\\n                    \\\\\"type\\\\\": \\\\\"Wooden\\\\\",\\\\n                    \\\\\"position\\\\\": \\\\\"Center\\\\\"\\\\n                },\\\\n                \\\\\"bookshelf\\\\\": {\\\\n                    \\\\\"arrangement\\\\\": \\\\\"Neat\\\\\"\\\\n                },\\\\n                \\\\\"plant\\\\\": {\\\\n                    \\\\\"type\\\\\": \\\\\"Potted\\\\\",\\\\n                    \\\\\"position\\\\\": \\\\\"Corner\\\\\"\\\\n                }\\\\n            },\\\\n            \\\\\"tools\\\\\": {\\\\n                \\\\\"laptop\\\\\": {\\\\n                    \\\\\"status\\\\\": \\\\\"Open\\\\\",\\\\n                    \\\\\"display\\\\\": \\\\\"Appointment schedule, color-coded\\\\\"\\\\n                },\\\\n                \\\\\"notebook\\\\\": {\\\\n                    \\\\\"status\\\\\": \\\\\"Open\\\\\",\\\\n                    \\\\\"content\\\\\": \\\\\"Client progress notes\\\\\"\\\\n                }\\\\n            },\\\\n            \\\\\"confidentialityAgreement\\\\\": {\\\\n                \\\\\"status\\\\\": \\\\\"Reviewed, documented, filed\\\\\"\\\\n            }\\\\n        },\\\\n        \\\\\"room2\\\\\": {\\\\n            \\\\\"name\\\\\": \\\\\"Waiting Room\\\\\",\\\\n            \\\\\"ambience\\\\\": {\\\\n                \\\\\"atmosphere\\\\\": \\\\\"Calm, anticipatory\\\\\",\\\\n                \\\\\"conversations\\\\\": \\\\\"Quiet, hushed\\\\\"\\\\n            },\\\\n            \\\\\"furniture\\\\\": {\\\\n                \\\\\"chairs\\\\\": {\\\\n                    \\\\\"type\\\\\": \\\\\"Comfortable, upholstered in neutral tones\\\\\",\\\\n                    \\\\\"arrangement\\\\\": \\\\\"Semicircle\\\\\"\\\\n                },\\\\n                \\\\\"coffeeTable\\\\\": {\\\\n                    \\\\\"position\\\\\": \\\\\"Center\\\\\",\\\\n                    \\\\\"items\\\\\": {\\\\n                        \\\\\"educationalMaterials\\\\\": {\\\\n                            \\\\\"type\\\\\": \\\\\"Brochures, pamphlets\\\\\",\\\\n                            \\\\\"topic\\\\\": \\\\\"Substance abuse prevention, treatment resources\\\\\"\\\\n                        }\\\\n                    }\\\\n                }\\\\n            }\\\\n        },\\\\n        \\\\\"clinic\\\\\": {\\\\n            \\\\\"type\\\\\": \\\\\"Hub of activity\\\\\",\\\\n            \\\\\"facilities\\\\\": {\\\\n                \\\\\"communityCenters\\\\\": {\\\\n                    \\\\\"use\\\\\": \\\\\"Workshops, resource dissemination\\\\\"\\\\n                },\\\\n                \\\\\"schools\\\\\": {\\\\n                    \\\\\"engagement\\\\\": \\\\\"Student awareness\\\\\"\\\\n                }\\\\n            },\\\\n            \\\\\"professionals\\\\\": {\\\\n                \\\\\"engagement\\\\\": \\\\\"Learning, collaboration\\\\\",\\\\n                \\\\\"organizations\\\\\": {\\\\n                    \\\\\"type\\\\\": \\\\\"Various collaborating organizations\\\\\",\\\\n                    \\\\\"goal\\\\\": \\\\\"Improve treatment access, resources\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n}\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121188.66 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 125594.16 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91272.81 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Parent Communication', 'situation': 'In the heart of the bustling school, the Middle School Teacher prepares for Parent Communication, a crucial aspect of their role that fosters collaboration and a comprehensive understanding of students progress. The teachers office, a sanctuary of tranquility and privacy, is adorned with a neatly organized oak desk and a comfortable swivel chair. A waiting area nearby, furnished with three navy blue upholstered chairs, accommodates parents waiting their turn. Facing the desk, a whiteboard spans the wall, displaying the days schedule, and a notebook lies open, ready to document the conversation.\\n\\nThe teacher, perched on the chair, poises a red pen over grading records from the pile on the right corner of the desk. The records, carefully organized in color-coded folders, reveal a cohesive narrative of each students performance. The laptop on the left, emanating a soft hum, functions as a digital repository of resources and digital presentations. The teacher takes a deep breath, mentally preparing for the imminent dialogue, as the first parent arrives, signaling the beginning of a 30-minute to an hour-long session of insightful exchange.', 'situation_json': '{\"office_description\": {\"description\": \"The teacher\\'s office, a sanctuary of tranquility and privacy\", \"desk\": {\"description\": \"neatly organized oak desk\", \"chair\": {\"description\": \"comfortable swivel chair\"}}, \"waiting_area\": {\"description\": \"three navy blue upholstered chairs\", \"distance\": \"nearby\"}, \"whiteboard\": {\"description\": \"spans the wall\", \"schedule\": {\"description\": \"the days schedule\", \"status\": \"displayed\"}}, \"notebook\": {\"description\": \"open\", \"purpose\": \"document the conversation\"}}, \"equipment_states\": {\"teacher_position\": \"perched on the chair\", \"red_pen\": \"poised over grading records\", \"grading_records\": {\"description\": \"pile on the right corner of the desk\", \"organization\": \"color-coded folders\", \"purpose\": \"reveal a cohesive narrative of each student\\'s performance\"}, \"laptop\": {\"description\": \"on the left\", \"status\": \"humming softly\", \"function\": \"digital repository of resources and digital presentations\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 84682.97 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 124545.46 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91992.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Loan Officer', 'process': 'Documentation', 'situation': \"In the heart of a bustling urban bank, a Loan Officer meticulously begins their daily process of reviewing loan applications on their computer. The black, high-resolution screen displays the Loan Application Portal, where a queue of virtual applications awaits assessment. At the comfortably cluttered oak desk, the Loan Officer is surrounded by the rhythmic hum of a quietly efficient office - the steady ticking of the grey calculator, the soft whir of the laser printer, and the occasional ring of the black telephone. The Loan Officer skillfully analyzes the financial information of each applicant, their eyes flickering between the computer screen and the neatly stacked papers. In the nearby meeting room, a Borrower anxiously waits for their turn, while an Underwriter scrutinizes risk assessments. The office environment, with its soft lighting and neutral colors, is a supportive backdrop to the Loan Officer's analytical work. This mundane but vital task goes on for an hour each day, the Loan Officer's unwavering focus ensuring that each application is thoroughly evaluated before reaching a final decision.\", 'situation_json': '{\"location\": \"urban bank\", \"equipment\": {\"computer\": {\"state\": \"on\", \"screen_resolution\": \"high\", \"display\": \"loan application portal\"}, \"desk\": {\"material\": \"oak\", \"state\": \"cluttered\"}, \"calculator\": {\"color\": \"grey\", \"state\": \"ticking\"}, \"printer\": {\"type\": \"laser\", \"state\": \"whirring\"}, \"telephone\": {\"color\": \"black\", \"state\": \"ringing occasionally\"}}, \"process\": {\"name\": \"reviewing loan applications\", \"duration\": \"1 hour\", \"frequency\": \"daily\"}, \"work_environment\": {\"lighting\": \"soft\", \"colors\": \"neutral\", \"meeting_room\": \"nearby\", \"atmosphere\": \"supportive\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119707.38 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 142032.68 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88147.21 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Radiologic Technologist', 'process': 'Image Acquisition', 'situation': 'In the heart of a bustling clinic, a radiology room serves as the epicenter of the Image Acquisition process. The room is adorned with crisp white walls, gleaming with cleanliness, and a faint scent of disinfectant lingers in the air. At the center of this pristine environment, the x-ray machine stands tall and imposing, its metallic surface reflecting the sterile glow of the overhead lights. The machine is expertly adjusted and maintained by the Radiologic Technologist, who operates it with dexterity and precision, following the physicians precise orders to capture high-quality images. The machine is surrounded by a myriad of additional equipment; lead aprons hang neatly on a rack, ready to shield against scattered radiation, while a variety of positioning devices are carefully arranged on a nearby tray, each one meticulously selected to accurately position the patient. In the adjacent control room, the technologist monitors the imaging process, ensuring the safety and well-being of the patient. Meanwhile, in the waiting room just outside, a handful of patients sit patiently, their expressions a mix of anxiety and anticipation, as they wait their turn to be examined.', 'situation_json': '{\"location\": \"clinic\", \"room_description\": \"crisp white walls, sterile glow of overhead lights\", \"scent\": \"disinfectant\", \"equipment\": {\"name\": \"x-ray machine\", \"status\": \"on\", \"adjustment\": \"expertly\", \"maintenance\": \"maintained\", \"reflection\": \"sterile glow\", \"operator\": \"Radiologic Technologist\", \"operation\": \"dexterity and precision\", \"purpose\": \"capture high-quality images\", \"order_compliance\": \"physicians precise orders\", \"environment\": \"pristine\", \"additional_equipment\": {\"lead_aprons\": {\"status\": \"available\", \"location\": \"rack\"}, \"positioning_devices\": {\"status\": \"available\", \"location\": \"tray\", \"selection\": \"meticulous\"}}, \"control_room\": {\"monitoring\": \"technologist\", \"purpose\": \"imaging process\", \"goal\": \"safety and well-being of patient\"}, \"waiting_room\": {\"occupancy\": \"handful\", \"patient_expressions\": [\"anxiety\", \"anticipation\"], \"purpose\": \"examination\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 94392.85 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 110732.57 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91600.40 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'HR Specialist', 'process': 'Compensation and Benefits', 'situation': \"The HR Specialist in Compensation and Benefits is responsible for designing, implementing, and administering employee compensation and benefits programs that are competitive, cost-effective, and aligned with the organization's strategic objectives. This involves conducting salary surveys, analyzing market trends, developing pay structures, and creating incentive and bonus plans that are attractive to employees and contribute to the organization's ability to attract and retain talent. The HR Specialist also manages the day-to-day administration of the compensation and benefits programs, including interpreting and applying policies and procedures, processing payroll, managing benefits enrollment and administration, and answering employee questions and concerns.\\n\\nIn the bustling HR office, the specialist diligently maneuvers through the intricacies of the job. A sleek, modern computer hums beside them, its dual monitors displaying a myriad of complex spreadsheets and databases filled with neatly arranged compensation data. The HRIS (Human Resource Information System) is their central hub, managing employee information with meticulous precision. A compact but efficient phone sits within arm's reach, ready for instant communication with employees, managers, and vendors.\\n\\nNearby, in the open workspace of the HR department, colleagues hunch over their desks, engrossed in their respective tasks. Occasionally, the hum of conversation rises as they consult on complex cases or share insights. The break room, a haven of relaxation, sees a steady stream of employees seeking respite from their desks. Some engage in casual chatter over steaming mugs of coffee, while others contentedly munch on sandwiches.\\n\\nThe HR office is a beehive of activity, with employees frequently stopping by to seek clarification on their benefits or to discuss potential adjustments to their compensation packages. Managers, carrying notebooks filled with strategic plans, breeze in and out, ensuring their teams are well-supported and their benefits are properly administered. Vendor representatives occasionally visit, armed with bundles of documents and proposals, eager to discuss the latest trends in retirement plans or health insurance coverage.\\n\\nSurrounding the office are various localities that enhance the work environment. The conference room stands ready for meetings, its polished table reflecting the seriousness of strategic discussions. The kitchen, filled with the aroma of freshly brewed coffee and the clink of mugs, offers a welcoming space for informal gatherings. The break room, adorned with cozy sofas and vibrant wall art, serves as a beautiful oasis for mental breaks throughout the day.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133677.30 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 134992.22 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93386.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Auto Mechanic', 'process': 'Brake Check', 'situation': 'In the heart of the bustling car workshop, an Auto Mechanic meticulously prepares for a daily routine – a Brake Check. The client, a loyal patron, is waiting in the customer waiting area, a space thoughtfully designed with comfortable seating and a selection of refreshments. Meanwhile, the mechanic, a seasoned professional, is in the garage surrounded by the reassuring clutter of tools and equipment. A sturdy tool bench stands to his right, adorned with an array of wrenches of various sizes and a trusty old laptop, its screen flickering with diagnostic data, while a robust jack, used to lift vehicles for easy access to the brakes, leans against the bench. A car lift, large and imposing, dominates the central space, its hydraulic system ready to hoist the client’s vehicle off the ground. In the parts room, just a few steps away, brake components for replacement are neatly arranged on shelves. As the mechanic approaches the vehicle, he mentally rehearses the process, his experienced hands already visualizing the steps – checking brake fluid levels, inspecting brake lines, pads, and rotors or drums for wear and tear. He is aware of the challenge ahead – a physical one that demands focus, precision, and the right tools. With a final glance at the wait room, he begins his task, driven by the singular goal of restoring the client’s vehicle to proper working condition, ensuring the braking system operates safely and smoothly.', 'situation_json': '{\"car_lift_status\": \"ready\", \"brake_components_status\": \"neatly arranged\", \"jack_status\": \"available\", \"client_status\": \"waiting\", \"tool_bench_status\": \"cluttered\", \"laptop_status\": \"functioning\", \"wrenches_status\": \"available\", \"mechanic_mindset\": \"prepared\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 109506.43 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 140500.96 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 78792.08 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Diagnostic Medical Sonographer', 'process': 'Equipment Maintenance', 'situation': 'In the heart of a bustling clinic, a Diagnostic Medical Sonographer toils away diligently in the controlled environment of the indoor imaging room. The soft hum of machines fills the air as they prepare to undertake the daily task of equipment maintenance. The focus of their attention is the gleaming ultrasound machine, its pristine white surface contrasting with the darker hues of the nearby computer system. The sonographer carefully cleans the machine, the metallic clinking of their tools breaking the silence. They then move on to calibrating the computer system, ensuring its reliability and data accuracy for future patient scans. Meanwhile, patients in the waiting room chat quietly, their eyes occasionally flicking towards the closed door behind which the sonographer works tirelessly to ensure the safety and wellbeing of every individual that passes through the clinic.', 'situation_json': '{\"Location\": \"indoor imaging room\", \"Equipment\": {\"Ultrasound machine\": {\"State\": \"gleaming\", \"Color\": \"white\"}, \"Computer system\": {\"State\": \"darker hues\", \"Action\": \"calibrating\"}}, \"Sounds\": \"soft hum of machines\", \"Tools\": \"metallic clinking of tools\", \"Patient activity\": \"chatting quietly\", \"Patient state\": \"waiting\", \"Professional activity\": \"cleaning machine and calibrating computer system\", \"Time\": \"daily\", \"Environment\": \"controlled\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 103243.33 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 152379.38 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93486.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Maintenance', 'situation': \"In the quiet and comfortable indoor cubical, a web developer is diligently working on their laptop. The silver laptop, resting on a dark wooden desk, is surrounded by a slew of equipment essential for web development. A sleek, black mouse and a compact, ergonomic keyboard lie on either side of the laptop, while a high-definition screen displays multiple lines of meticulously written code. The room is dimly lit to prevent glare from the screen. The wall behind the developer is adorned with a large whiteboard filled with colorful diagrams and patterns, used for the planning and designing of websites and web applications. The developer has a pair of headphones on, blocking out the low hum of the air conditioning and the occasional ring of the nearby coffee maker. A steaming cup of freshly brewed coffee sits on the corner of the desk. The developer works tirelessly, updating content and fixing bugs to ensure the website is functioning at its best. This process is an integral part of the developer's daily routine, ensuring websites remain current, operational, and user-friendly.\", 'situation_json': '{\"location\": \"indoor cubical\", \"lighting\": \"dim\", \"laptop_color\": \"silver\", \"laptop_position\": \"on a dark wooden desk\", \"peripherals\": [\"sleek black mouse\", \"compact ergonomic keyboard\"], \"screen_display_status\": \"multiple lines of meticulously written code\", \"wall_whiteboard_status\": \"filled with colorful diagrams and patterns\", \"headphones\": \"on\", \"headphones_purpose\": \"blocking out the low hum of the air conditioning and the occasional ring of the nearby coffee maker\", \"coffee_status\": \"freshly brewed\", \"coffee_position\": \"corner of the desk\", \"coffee_temperature\": \"steaming\", \"work_status\": \"updating content and fixing bugs\", \"maintenance_importance\": \"integral part of the developer\\'s daily routine\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119563.64 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 159249.99 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96367.54 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist Assistant', 'process': 'Communication with Therapist', 'situation': 'In a bustling clinic filled with the sound of soft chatter from the waiting room, the Physical Therapist Assistant (PTA), a dedicated professional with a compassionate demeanor, prepares to communicate with their supervising Physical Therapist (PT). The PTA is nestled in their workspace, a clean and organized area adorned with a sleek, silver computer for documenting patient progress and a sleek, black phone for instant communication. The workspace also houses a carefully arranged tray with six crisp, white resistance bands for patient exercises. Nearby, in the therapy room, a lone patient diligently performs their prescribed exercises under the watchful eye of the PTA. The room is a sanctuary of healing, filled with a variety of equipment such as a pristine, blue stability ball and a well-maintained, adjustable therapy table. Outside, the clinical environment with its muted colors and calm atmosphere supports the communication between the PT and PTA. The importance of this process is paramount, as it ensures the delivery of accurate and detailed information for the best possible care for the patient.', 'situation_json': '{\"clinic_atmosphere\": \"bustling\", \"waiting_room_noise\": \"soft chatter\", \"pta_workspace_cleanliness\": \"clean and organized\", \"pta_workspace_computer\": \"sleek, silver\", \"pta_workspace_phone\": \"sleek, black\", \"pta_workspace_resistance_bands\": 6, \"therapy_room_patient_count\": 1, \"therapy_room_equipment_stability_ball\": \"pristine, blue\", \"therapy_room_equipment_therapy_table\": \"well-maintained, adjustable\", \"communication_importance\": \"paramount\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 135776.50 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 89737.62 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 50556.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Registered Nurse', 'process': 'Medication Administration', 'situation': 'In the heart of a bustling hospital, a Registered Nurse meticulously prepares for the hourly medication administration process within the indoor confines of a medical ward. The medication room, a sanctum of order and precision, is illuminated by the soft hum of fluorescent lights, casting a sterile glow on the plethora of equipment. On the spotless counter, a single medication chart lies unfurled, its edges crisp and straight. Surrounding it are neatly arranged medications, each labeled meticulously, awaiting their turn to be administered. Nearby, a solitary stethoscope gleams in the sterile light, its silver body a stark contrast against the white surroundings. In the adjacent patient room, a patient lies comfortably, their identity confirmed through a digital patient ID band. The nurse, clad in a pristine uniform, approaches with a calm and confident demeanor, the documentation form for the medication tucked securely under one arm. Meanwhile, in the waiting room, a handful of people sit, quietly observing as the nurse goes about her duties with professional diligence. The nursing station, a hub of activity, hums with the low murmur of other healthcare professionals conferring over patient care, adding to the symphony of the hospital.', 'situation_json': '{\"location\": \"hospital\", \"room\": \"medical ward\", \"lighting\": \"fluorescent lights\", \"lighting_condition\": \"soft hum\", \"lighting_effect\": \"sterile glow\", \"equipment_presence\": \"plethora\", \"counter_condition\": \"spotless\", \"chart_presence\": \"single\", \"chart_condition\": \"edges crisp and straight\", \"medication_arrangement\": \"neatly arranged\", \"labeling_condition\": \"meticulously\", \"stethoscope_condition\": \"solitary, gleaming\", \"stethoscope_color\": \"silver\", \"patient_room_condition\": \"adjacent\", \"patient_comfort\": \"comfortably\", \"id_verification\": \"digital patient ID band\", \"nurse_approach\": \"calm and confident\", \"document_presence\": \"tucked securely under one arm\", \"waiting_room_condition\": \"quietly observing\", \"nursing_station_presence\": \"hub of activity\", \"nursing_station_sound\": \"low murmur\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 116102.52 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 156807.73 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 98029.72 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Market Research Analyst', 'process': 'Focus Group Moderation', 'situation': \"In the heart of the bustling research facility, the Market Research Analyst, a maestro of insights, orchestrates a weekly ritual: the Focus Group Moderation. The scene unfolds in the sprawling, sunlit conference room, where 15 participants, a microcosm of the target demographic, are nestled in ergonomic chairs, their eyes gleaming with curiosity. The analyst, dressed in a crisp, navy blue suit, stands at the helm, a sleek laptop resting on a polished mahogany table, brimming with advanced data analysis software and survey tools, ready to be deployed. Adjacent, the observation room hums with stakeholders - clients in tailored attire and colleagues in casual chic - their eyes glued to the one-way mirror, absorbing every nuance of the impending discussion. The room is a symphony of technology: state-of-the-art audio-visual recording equipment captures every word, every gesture, while a smartboard, its surface as smooth as a freshly poured espresso, awaits the analyst's touch to ignite into a canvas of insights. The air is thick with anticipation, the scent of freshly brewed coffee from the cafe wafting in, as the analyst takes a deep breath, ready to guide the group through the next hour to three hours of exploration, their voice steady, their mind a whirlwind of data, trends, and human psychology.\", 'situation_json': '{\"room_size\": \"sprawling\", \"room_light\": \"sunlit\", \"participant_count\": 15, \"participant_mood\": \"curious\", \"analyst_attire\": \"crisp, navy blue suit\", \"laptop_status\": \"sleek, ready\", \"software_type\": \"advanced data analysis, survey tools\", \"table_material\": \"polished mahogany\", \"observation_room_occupancy\": \"humming with stakeholders\", \"stakeholder_attire\": \"clients in tailored attire, colleagues in casual chic\", \"recording_equipment_type\": \"state-of-the-art audio-visual\", \"smartboard_status\": \"awaits the analyst\\'s touch\", \"air_quality\": \"thick with anticipation\", \"coffee_aroma\": \"freshly brewed coffee\", \"analyst_mindset\": \"a whirlwind of data, trends, human psychology\", \"session_duration\": \"hour to three hours\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 142637.29 examples/s]examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 154853.11 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95879.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Paramedic', 'process': 'Patient Transport', 'situation': 'In the heart of the bustling city, a paramedic prepares for their on-call shift, their ambulance gleaming under the morning sun. The ambulance, a mobile treatment room, is equipped with a stretcher, three oxygen tanks, one defibrillator, and a myriad of medical supplies, all meticulously arranged for quick access. The paramedic, adorned in their crisp uniform, checks and double-checks each piece of equipment, ensuring everything is in pristine condition. Their radio, a lifeline to the hospital staff, crackles softly in the silence, a reminder of the vital role they play in the healthcare chain. Meanwhile, the driver, a key member of the team, waits patiently in the front seat, ready to navigate the busy streets with finesse. Their mission: save lives, one call at a time.', 'situation_json': '{\"ambulance\": {\"state\": \"on-call\", \"location\": \"bustling city\", \"equipment_states\": {\"stretcher\": \"ready\", \"oxygen_tanks\": 3, \"defibrillator\": \"ready\", \"medical_supplies\": \"arranged\", \"radio\": \"functioning\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 84355.54 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 79446.67 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 50184.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Mechanical Engineer', 'process': 'Troubleshooting and Problem Solving', 'situation': \"In the expansive control room, bathed in the cool glow of fluorescent lights, the mechanical engineer stands before a bank of humming computers, each screen displaying complex simulations and real-time data feeds. The room is alive with the quiet hum of machinery and the occasional beep of monitoring equipment. The engineer, clad in a crisp white lab coat, is surrounded by an array of high-tech testing equipment, including pressure gauges and flow meters meticulously arranged on a stainless-steel workbench. \\n\\nTo the engineer's left, a nearby workshop is abuzz with activity, where a team of maintenance technicians in blue overalls meticulously assemble components, the clanking of tools punctuating the air. The workshop is well-lit, with bright overhead lamps illuminating every corner, and rows of tall shelves neatly organized with tools and spare parts. \\n\\nAcross the hall, a meeting room is set up with a large projection screen and a whiteboard covered in complex diagrams and equations. A group of design engineers, clustered around a central table, engage in lively discussions, their laptops open and calculators at hand. The room exudes an air of intense concentration and collaboration, with the occasional sound of pages turning in technical manuals. \\n\\nFurther down the corridor, the engineering library is a haven of quiet efficiency. Tall bookshelves line the walls, filled with technical manuals, industry standards, and research papers. The librarian, seated at a wooden desk, assists a few technicians in locating specific resources, while several engineers sit at desks, deeply absorbed in their reading or working on their laptops. \\n\\nBack in the control room, the mechanical engineer, deep in thought, scrutinizes the data on the screens. A nearby laptop displays intricate CAD models, while a set of measuring tools lies neatly arranged on a side table. The atmosphere is charged with anticipation as the engineer methodically troubleshoots a complex mechanical issue, determined to find the root cause and devise an effective solution.\", 'situation_json': '{\"lighting\": {\"ambient\": \"fluorescent\", \"workshop\": \"overhead lamps\"}, \"equipment\": {\"computers\": {\"type\": \"bank\", \"state\": \"humming\", \"display\": [\"simulations\", \"real-time data feeds\"]}, \"experimentation equipment\": {\"pressure gauges\": \"active\", \"flow meters\": \"active\"}, \"meeting room\": {\"screen\": \"large projection\", \"whiteboard\": \"covered in complex diagrams and equations\"}, \"library\": {\"bookshelves\": \"tall\", \"resources\": [\"technical manuals\", \"industry standards\", \"research papers\"]}}, \"sounds\": [\"hum of machinery\", \"beep of monitoring equipment\", \"clanking of tools\", \"occasional sound of pages turning\"], \"teams\": {\"maintenance\": {\"uniforms\": \"blue overalls\", \"activity\": \"assembling components\"}, \"design\": {\"activity\": \"lively discussions\", \"tools\": [\"laptops\", \"calculators\", \"technical manuals\"]}}, \"atmosphere\": {\"control room\": \"charged with anticipation\", \"meeting room\": \"intense concentration and collaboration\", \"library\": \"quiet efficiency\"}, \"miscellaneous\": {\"control room\": {\"engineer workspace\": {\"equipment\": {\"CAD models\": \"intricate\", \"measuring tools\": \"neatly arranged\"}}}, \"librarian assistance\": \"active\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137433.46 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 154744.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91967.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Insurance Agent', 'process': 'Policy Review', 'situation': \"In the heart of a bustling insurance company, an Insurance Agent meticulously embarks on a mental challenge that is the Policy Review. Ensconced in their private cubicle, surrounded by the gentle hum of computer screens and the muted sounds of a lively office, they are shielded from distractions. Their trusted computer, a sleek black device, sits before them, its screen illuminated with client data, insurance policies, and company databases. A calculator, small yet powerful, lies to one side, ready to perform calculations related to insurance premiums, coverage, and limits. Meeting rooms, nearby, are actively used for client meetings and policy presentations. For the next few hours, the agent will methodically review their client's current insurance policies, assessing adequacy, relevance, and potential gaps. They will strive to ensure their client is not overpaying or underinsured, and has the right coverage in place to protect their assets. Underwriters, their supportive colleagues, may be consulted during this process. The agent is acutely aware of the weight of this task, as the outcome of this review will directly impact their client's financial security. A detailed documentation highlighting any gaps or areas of improvement in the client's current policies will provide the blueprint for addressing these needs. Inside the agent's mind, a symphony of critical thinking, analysis, and strategic planning plays, preparing to orchestrate the best possible policy review outcome.\", 'situation_json': '{\"location\": \"insurance company\", \"agent_description\": \"meticulous, private cubicle, surrounded by computer screens, muted office sounds, trusted computer, small calculator, nearby meeting rooms, supportive colleagues\", \"computer_description\": \"sleek black device, displays client data, insurance policies, company databases\", \"calculator_description\": \"small, powerful\", \"task_description\": \"review client\\'s current insurance policies, assess adequacy, relevance, potential gaps, ensure client not overpaying or underinsured, right coverage, financial security, detailed documentation, areas of improvement\", \"time_frame\": \"few hours\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 140726.72 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 149791.56 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 88470.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Executive Assistant', 'process': 'Travel Arrangements', 'situation': \"Nestled in the heart of a bustling business district, the business office hums with a constant undercurrent of activity.  \\nAs an Executive Assistant, you find yourself seated at your meticulously organized desk in a small but comfortably appointed cubicle. Your desk, adorned with a sleek, state-of-the-art computer, a high-speed printer, and a modern phone, serves as the command center for your logistical operations. \\nThe glow from your computer screen reveals intricate travel itineraries, carefully curated on software that seamlessly integrates with your calendar and email client. Your phone, positioned at arm's length, buzzes intermittently with updates from travel providers and confirmation messages. \\nYour cubicle walls are adorned with colorful Post-it notes, each bearing important reminders and deadlines, peppered with motivational quotes that keep you focused and driven. \\nNearby, the bustling reception area is filled with clients and visitors, their chatter creating a low hum that occasionally filters into your workspace. Just outside your cubicle, the open office space is a beehive of activity, with colleagues energetically typing on their keyboards, engaged in phone conversations, or huddled in impromptu meetings at their desks. \\nDown the hall, the spacious conference room is set up for an upcoming meeting, with laptops open and projectors displaying the latest reports. \\nThe break room offers a brief respite from the whirlwind of activity, with the aroma of freshly brewed coffee and the occasional burst of laughter providing a momentary distraction. \\nAt the same time, your focus remains unwaveringly on the task at hand—ensuring that every detail of the executive's travel arrangements is meticulously planned and executed. Your reliability and efficiency are the bedrock of the office's smooth functioning, as you navigate the labyrinthine world of travel logistics with ease and precision.\", 'situation_json': '{\"location\": \"Business office\", \"furniture_status\": {\"desk\": \"meticulously organized\", \"cubicle\": \"comfortably appointed\", \"walls\": {\"adorned with\": \"colorful Post-it notes\", \"additional_info\": \"important reminders and deadlines, motivational quotes\"}}, \"equipment_state\": {\"computer\": \"state-of-the-art\", \"printer\": \"high-speed\", \"phone\": \"modern\"}, \"ongoing_activities\": {\"travel itineraries\": \"revealed on computer screen\", \"calendar and email client\": \"integrates seamlessly\", \"phone updates\": \"intermittent\", \"other departments\": \"bustling reception area, visitor chatter, open office space, conference room setup, break room aroma, occasional laughter\"}, \"task_status\": {\"executive\\'s travel arrangements\": \"meticulously planned and executed\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 127681.98 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 161648.37 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84126.07 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Psychologist', 'process': 'IEP Development', 'situation': \"In the heart of a bustling school, our School Psychologist finds themselves in a designated meeting room, comfortably seating the educational team of teachers, administrators, and parents. The room, akin to a calming haven in the midst of chaos, is painted in soothing shades of blue and white, with natural light pouring in from the large windows. The walls are adorned with inspirational quotes and pictures of students, a constant reminder of the purpose of the gathering. On the large oval table, a myriad of diagnostic tools, documents, and notebooks are neatly arranged, awaiting the commencement of the IEP Development process. Just outside, a small waiting area, thoughtfully fitted with comfortable seating and a selection of magazines, serves as a haven for parents awaiting their turn. The School Psychologist, a beacon of guidance and support, is about to embark on a yearly task that is as challenging as it is crucial - to develop an Individualized Education Program (IEP) for a student with special needs. Armed with a laptop and notes from the student's files, they prepare to navigate the complex landscape of the student's needs, strengths, and goals, to ultimately create a tailored plan that promises success and growth.\", 'situation_json': '{\"location\": \"designated meeting room in a school\", \"room_color\": \"blue and white\", \"lighting\": \"natural light from large windows\", \"wall_decoration\": \"inspirational quotes and pictures of students\", \"table\": \"oval table with a myriad of diagnostic tools, documents, and notebooks\", \"waiting_area\": \"small waiting area with comfortable seating and magazines\", \"primary_equipment\": \"laptop\", \"secondary_equipment\": \"notes from student\\'s files\", \"process\": \"develop Individualized Education Program (IEP)\", \"task_frequency\": \"yearly\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129254.29 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 138144.38 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 97052.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Loan Officer', 'process': 'Loan Application Review', 'situation': \"Every week, a meticulous Loan Officer settles into their office in the bank, surrounded by the soft hum of nearby financial departments. For the next three hours, they will delve into the in-depth task of reviewing and evaluating loan applications. The process is mentally challenging, but the Loan Officer finds a sense of order in their surroundings. The office is bathed in gentle, warm lighting, casting a comfortable ambiance over the area. The computer, equipped with powerful financial software, remains the focal point of their workstation. It is pristine and well-maintained, as the Loan Officer takes pride in their work. The black leather chair, worn around the edges, has seen countless hours of contemplation. Next to it, a small table cradles a neatly arranged collection of sleek calculators, secure file cabinets standing tall against the wall, and an unassuming-looking phone. The Loan Officer is also equipped with a well-organized calendar, displaying appointments with potential clients. The office, a testament to the Loan Officer's dedication, welcomes customers and colleagues alike in a peaceful, yet professional setting.\", 'situation_json': '{\"office_lighting\": \"gentle, warm\", \"computer_state\": \"pristine and well-maintained\", \"chair_state\": \"worn around the edges\", \"table_contents\": [\"sleek calculators\", \"secure file cabinets\", \"unassuming-looking phone\"], \"calendar_state\": \"well-organized\", \"office_ambiance\": \"peaceful, yet professional\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 101923.13 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 154287.62 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96425.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Professional Development', 'situation': 'A Middle School Teacher is responsible for educating students in the middle school level, typically ranging from 6th to 8th grade. This includes planning and preparing lessons, as well as delivering instruction in a way that is engaging and understandable for students. They are also responsible for assessing students progress and providing feedback and support to help them improve. Additionally, Middle School Teachers may collaborate with other educators, parents, and administrators to create a positive learning environment and support students academic and social development. The teacher is currently participating in a 6-hour professional development workshop to stay up-to-date with educational research and trends. The workshop is taking place in a small, windowless conference room at the middle school. The room is equipped with 10 desks with 10 whiteboards and 10 laptops. The desks and chairs are arranged in a semi-circle facing the front of the room where a projector screen is set up. There are 9 other teachers in attendance, dressed in casual clothing. The atmosphere is focused but relaxed. The teacher is currently sitting at her desk, typing notes on her laptop as the presenter talks about the latest research on teaching strategies for middle school students.', 'situation_json': '{\"equipment\": {\"desks\": 10, \"whiteboards\": 10, \"laptops\": 10, \"projector_screen\": 1}, \"room_description\": {\"size\": \"small\", \"window\": false, \"layout\": \"semi-circle\", \"atmosphere\": \"focused but relaxed\"}, \"attendees\": {\"number_of_teachers\": 9, \"clothing\": \"casual\"}, \"activity\": {\"duration\": 6, \"type\": \"professional development workshop\", \"topic\": \"teaching strategies for middle school students\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 121839.35 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141774.15 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 85330.75 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Substance Abuse Counselor', 'process': 'Supervision', 'situation': \"Each week, a substance abuse counselor spends an hour supervising their clients to ensure they are adhering to their treatment plans. This process takes place in the counselor's private office within the clinic. The office is painted a calming shade of pale blue, with a large window overlooking the lush greenery outside. A sleek, black computer rests on the counselor's mahogany desk, with various pamphlets and brochures detailing resources and preventative measures for substance abuse strewn across its surface. A plush couch in a beige shade sits against one wall, with a leather chair positioned opposite it. A single, white notebook rests on a small table between the seating arrangements, ready to receive any notes or insights the counselor might have during their sessions. The waiting room, just outside the counselor's office, contains several individuals, each with their own reasons for being there. Some appear anxious, others stoic, their various expressions reflecting the different stages of the recovery process. The counselor's fellow colleagues, other substance abuse counselors, can be seen busying themselves, conducting their own sessions in the various private rooms scattered throughout the clinic. This task, while emotionally challenging, is rewarding as it allows the counselor to contribute to a caring and supportive environment for individuals struggling with substance abuse.\", 'situation_json': '{\"location\": \"private office within a clinic\", \"color_scheme\": \"pale blue, black, mahogany, beige, white, leather\", \"furniture\": \"desk, couch, chair, table, waiting room\", \"equipment\": \"computer, pamphlets, brochures, notebook\", \"environment_details\": \"large window overlooking lush greenery, various private rooms scattered throughout the clinic\", \"activity\": \"weekly supervision\", \"duration\": \"1 hour\", \"clients_present\": true, \"emotions_present\": \"anxious, stoic\", \"treatment_resources_present\": true, \"supportive_environment\": true, \"challenging_nature\": \"emotionally challenging\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139163.86 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 87411.18 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 48611.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Radiologic Technologist', 'process': 'Image Analysis', 'situation': \"In the bustling radiology department of a modern hospital, a **Radiologic Technologist**, clad in a pristine white coat, approaches the gleaming **X-ray machine**, the room's crown jewel. The machine, enshrouded in a labyrinth of cables and blinking lights, hums with anticipation. Beside it, an array of **positioning devices**—lithe and orchestrated in their setup—awaits the next patient. The technologist's room is a whirlwind of tactile precision, where the practiced twist of a dial or the swift press of a button can spell the difference between a clear image and a retake. The technologist, with an unyielding dedication to accuracy, glances at the **imaging schedule**, their brow furrowing over a pair of protective **lead-framed glasses**. The **waiting room** just outside—a mecca of quiet anticipation—stirs with a sea of faces, eyes flicking past the clock with growing curiosity. Ten patients, a symphony of restless shifting, await their turn. In the adjacent **CT scan room**, the **CT scanner**—a colossal, whirling monolith—thrums with industry, echoing the chatter of its patients and the distant call of the technologist over the intercom. Meanwhile, in the neighboring **MRI room**, the **Magnetic Resonance Imaging machine** stands sentinel, its powerful magnetic field thrumming an ethereal lullaby that fills the otherwise sterile air. The technologist, with deft fingers, skims over the **lead apron** draped over a nearby stool, ensuring its fastenings are secure before donning the garment like a second skin. The **XRay rooms**, clad in their lead-lined sanctuaries, muffle the rest of the hospital's clamor. As the technologist assembles the necessary **tools**—pliers, wrenches, all glinting under the harsh fluorescent lights—they take a moment to ground themselves, preparing to navigate the intricate dance of assisting patients, operating machines, and maintaining safety protocols.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 134386.57 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 158536.86 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95486.59 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'HR Specialist', 'process': 'Compliance', 'situation': \"In the company headquarters, the HR Specialist in Compliance is busy conducting a compliance audit in their indoor office. The compliance office is neatly organized, with a computer and various audit tools spread out on the desk. In the corner of the office, a stack of compliance policies and regulations sits on a shelf, their pages yellowing with age. Next door, the legal department is bustling with activity, as they work to interpret and apply laws and regulations to the company's operations. Meanwhile, the HR specialist's colleagues in the HR office are processing paperwork and handling administrative tasks. The compliance office is a compact, windowless room, but the HR Specialist is focused on their task, carefully reviewing each document and checking for compliance violations. The compliance officer takes a break, standing up and stretching, before returning to their work, committed to ensuring that the company adheres to all relevant laws and regulations.\", 'situation_json': '{\"office_location\": \"company headquarters\", \"office_layout\": \"indoor\", \"office_cleanliness\": \"neatly organized\", \"desk_items\": [\"computer\", \"various audit tools\"], \"compliance_documents\": {\"location\": \"shelf in the corner\", \"quantity\": \"stack\", \"condition\": \"yellowing with age\"}, \"adjacent_departments\": [\"legal\", \"HR office\"], \"legal_department_activity\": \"bustling with activity, interpreting and applying laws and regulations\", \"HR_office_activity\": \"processing paperwork and handling administrative tasks\", \"office_size\": \"compact\", \"window\": \"none\", \"compliance_officer_activity\": \"conducting an audit, reviewing documents and checking for compliance violations\", \"break_frequency\": \"once\", \"break_activity\": \"stand up and stretch\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133799.56 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 159832.55 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 63089.16 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Auto Mechanic', 'process': 'Coolant System Check', 'situation': \"In the heart of the bustling garage, bathed in the harsh glow of the overhead fluorescent lights, the Auto Mechanic stands, his overalls streaked with the badges of honor that only years of dedicated service can bestow. The air is thick with the scent of oil and the faint, sweet aroma of coolant, a testament to the day's labor. The service bay, a sprawling expanse of concrete, is a symphony of organized chaos, each tool meticulously placed on the magnetic strip of the toolbox, its red exterior a stark contrast against the steel grey of the bench. The coolant tester, a sleek, black device with a digital display, lies pristine, untouched, awaiting its moment of truth. Beside it, the radiator stop-leak, a bottle of mysterious, murky blue liquid, promises an end to minor leaks, a silent guardian of the cooling system. The screwdriver, a trusted companion, lies ready, its shaft worn smooth by years of use, its tip poised to pry open the secrets of the Air Conditioning system. The refractometer, a sleek, black device with a single, unblinking eye, waits patiently, ready to scrutinize the very essence of the coolant, its concentration of freeze protection, inhibitors for pH level and corrosion. The car lift, a towering, hydraulic behemoth, stands ready, its arm outstretched, eager to hoist the vehicle into the mechanicl's realm. The laptop, a sleek, silver slate, lies closed, its surface unmarred by the grime of the garage, a portal to the vehicle's inner workings, ready to diagnose the braking system with a mere click. The jack, a humble tool of immense power, lies ready, its shaft polished by the touch of countless hands, ready to lift the vehicle, to grant access to the brakes, the very lifeline of the vehicle. The wrenches, an arsenal of tools, lie ready, their teeth sharp, their grips worn smooth, ready to remove and replace brake components with ease. The scan tool, a device that bridges the gap between the mechanic and the vehicle's brain, the on-board diagnostics system, lies dormant, ready to awaken and decipher the vehicle's secrets. The timing light, a tool that dances with the ignition system, its beam of light a silent communicator, ready to check the timing and identify any issues. The compression tester, a device that delves into the heart of the engine, its gauge a silent witness to the pressure in the cylinders, ready to diagnose any issues with the pistons, rings, or valves. The transmission jack, a specialized tool, lies ready, its arm outstretched, eager to lift and support the transmission during service. The transmission filter, a humble guardian of the transmission fluid, lies ready, its mesh a barrier against impurities. The transmission fluid, a vital lifeblood, lies ready, its red hue a promise of smooth operation. The garage is a hive of activity, the hum of distant drills and the clank of tools echoing through the vast space. The waiting room, a sanctuary of comfort amidst the symphony of repair, is filled with the low murmur of patients, their numbers swelling with the day's workload. The mechanic's colleagues, a team of skilled professionals, are scattered across the garage, each engrossed in their own tasks, their overalls a sea of blue amidst the steel and concrete. The challenge of the day is not just the physical labor, but the mental puzzle, the constant battle against the unknown, the quest to diagnose and repair the vehicle's ailments. The Auto Mechanic stands at the epicenter of this storm, his eyes scanning the tools, his mind racing, ready to unravel the day's mystery.\", 'situation_json': '{\"air_conditioning_system\": {\"state\": \"closed\"}, \"ambient_temperature\": {\"unit\": \"celsius\", \"value\": 25}, \"atmospheric_pressure\": {\"unit\": \"pascal\", \"value\": 101325}, \"brake_components\": {\"state\": \"intact\"}, \"brake_system\": {\"diagnostic_state\": \"functional\"}, \"coolant_concentration\": {\"freeze_protection\": {\"state\": \"unknown\"}, \"inhibitors\": {\"corrosion\": \"unknown\", \"ph_level\": \"unknown\"}}, \"coolant_tester\": {\"state\": \"pristine\"}, \"garage_ambiance\": {\"sound_level\": {\"unit\": \"decibel\", \"value\": 80}, \"smell\": {\"coolant\": \"faint\", \"oil\": \"thick\"}}, \"garage_equipment\": {\"car_lift\": {\"state\": \"ready\"}, \"jack\": {\"state\": \"ready\"}}, \"garage_layout\": {\"concrete_floor\": {\"state\": \"clean\"}}, \"garage_lighting\": {\"fluorescent_lights\": {\"state\": \"on\"}}, \"garage_staff\": {\"colleagues\": {\"number\": 5, \"state\": \"engaged\"}}, \"garage_tools\": {\"radiator_stop_leak\": {\"state\": \"ready\"}, \"screwdriver\": {\"state\": \"ready\"}}, \"garage_vehicles\": {\"vehicle_lifted\": false}, \"humidity\": {\"unit\": \"percentage\", \"value\": 50}, \"on_board_diagnostics\": {\"scan_tool\": {\"state\": \"dormant\"}}, \"oil_state\": {\"level\": \"adequate\"}, \"overalls\": {\"color\": \"blue\", \"state\": \"worn\"}, \"radiator\": {\"leak\": {\"state\": \"minor\"}}, \"transmission_fluid\": {\"level\": \"adequate\", \"state\": \"ready\"}, \"transmission_filter\": {\"state\": \"ready\"}, \"transmission_jack\": {\"state\": \"ready\"}, \"vehicle_ignition\": {\"timing_light\": {\"state\": \"ready\"}}, \"vehicle_state\": {\"compression\": {\"state\": \"unknown\"}}, \"waiting_room\": {\"patrons\": {\"number\": 10, \"state\": \"waiting\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  93%|█████████▎| 676/723 [3:44:06<25:02, 31.98s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Diagnostic Medical Sonographer', 'process': 'Equipment Preparation', 'situation': \"In a bustling hospital, the Diagnostic Medical Sonographer prepares for an ultrasound examination in the dedicated ultrasound room. The room is illuminated by soft, ambient lighting, creating a calming environment for both the sonographer and the patient. The sonographer meticulously checks over the equipment, including the ultrasound machine with its sleek black exterior, the handheld transducer probe, and the clear, water-based gel. Each piece of equipment is in pristine condition, recently sterilized and meticulously cleaned. In the waiting room nearby, a diverse group of patients sit anxiously, waiting to be called upon. Some are routine check-ups, while others are here for more serious reasons. The sonographer, with a strong sense of responsibility and a warm demeanor, ensures that every piece of equipment is functioning optimally before the patient is called in. The entire process, from preparing the equipment to the patient's arrival in the room, takes about 10 minutes.\", 'situation_json': '{\"location\": \"hospital\", \"room\": \"ultrasound room\", \"lighting\": \"soft, ambient\", \"equipment\": {\"ultrasound_machine\": {\"condition\": \"pristine\", \"recently_sterilized\": true, \"color\": \"black\", \"exterior\": \"sleek\"}, \"transducer_probe\": {\"condition\": \"pristine\", \"recently_sterilized\": true, \"handheld\": true}, \"gel\": {\"use\": \"water-based\", \"condition\": \"clear\"}}, \"waiting_room_patients\": {\"presence\": true, \"number\": \"diverse\", \"anxiety\": \"high\", \"reasons\": [\"routine\", \"serious\"]}, \"sonographer_responsibility\": \"high\", \"sonographer_demeanor\": \"warm\", \"time_to_prepare\": \"10 minutes\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 141819.22 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 153987.88 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95770.54 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Optimization', 'situation': 'A web developer is diligently working on process optimization in the comfort of their office. The room is dimly lit, with the soft glow of multiple laptop screens providing most of the light. In total, there are six laptops sprawled out on the spacious wooden desk, each one adorned with the latest web development tools. A sleek, ergonomic mouse and keyboard sit at the ready for precise navigation and input. Nearby, a high-performance computer is humming softly, its numerous tabs and windows filled with project management tools and communication software, allowing seamless coordination with clients and teammates. The room is relatively quiet, save for the soft tapping of keys and the occasional whir of a cooling fan. The only other person present is a web designer, who works in a separate corner of the office, engrossed in creating the visual aspects of a website or application. The testing area is located just a few steps away from the coding area, where the developer will meticulously ensure that their optimized code works as expected.', 'situation_json': '{\"lighting\": \"dimly lit\", \"number_of_laptops\": 6, \"laptop_state\": \"active\", \"desk_material\": \"wooden\", \"desk_size\": \"spacious\", \"screen_states\": \"active\", \"developer_tools\": \"present\", \"mouse_state\": \"ready\", \"keyboard_state\": \"ready\", \"mouse_type\": \"ergonomic\", \"keyboard_type\": \"ergonomic\", \"computer_sound\": \"humming\", \"computer_performance\": \"high\", \"tabs_and_windows_states\": \"active\", \"project_management_tools\": \"present\", \"communication_software\": \"present\", \"communication_software_states\": \"active\", \"noise_level\": \"quiet\", \"collaborators\": \"web designer\", \"collaborators_count\": 1, \"collaborators_states\": \"active\", \"separate_work_spaces\": \"true\", \"testing_area\": \"present\", \"testing_area_proximity\": \"nearby\", \"testing_area_state\": \"ready\", \"coding_area_state\": \"active\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 149026.96 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 89539.37 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 50734.69 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist Assistant', 'process': 'Equipment Preparation', 'situation': \"In the bustling setting of a physical therapy clinic, the Physical Therapist Assistant embarks on the daily task of Equipment Preparation. The clinic is filled with the hum of activity, as patients gather in the waiting area, a spacious and inviting environment where soft chairs and carefully placed magazines provide a comfortable refuge. The waiting area hosts eight patients, each engrossed in various forms of distraction to ease their anticipation—some lost in conversation, others absorbed in their phones. The therapy room is a hive of activity, with equipment meticulously arranged for the upcoming therapy sessions. Three therapy tables, draped in crisp white linens, are ready for use, their adjustable heights fine-tuned for patient comfort. Various exercise equipment—from colorful resistance bands to sturdy stability balls—are neatly organized on racks, awaiting their turn to aid in patient recovery. The gym area is equally prepared, with treadmills and stationary bikes lined up, each machine glistening with recent maintenance. Assistive devices such as crutches, canes, and walkers are strategically placed near the entrance, ready to assist patients with mobility challenges. The nearby equipment storage room houses an array of therapeutic modalities, including Thermotherapy Units ready to provide soothing heat and Cryotherapy Units poised to offer relieving cold. The air is filled with a sense of purpose and readiness, as the Physical Therapist Assistant ensures every piece of equipment is perfectly prepared to support the patients' road to recovery.\", 'situation_json': '{\"situation\": \"{\\\\n  \\\\\"location\\\\\": \\\\\"Physical Therapy Clinic\\\\\",\\\\n  \\\\\"area\\\\\": [\\\\n    {\\\\n      \\\\\"name\\\\\": \\\\\"Waiting Area\\\\\",\\\\n      \\\\\"description\\\\\": \\\\\"Spacious and inviting\\\\\",\\\\n      \\\\\"seating\\\\\": {\\\\n        \\\\\"type\\\\\": \\\\\"Soft Chairs\\\\\",\\\\n        \\\\\"count\\\\\": 8\\\\n      },\\\\n      \\\\\"entertainment\\\\\": [\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Magazines\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\"\\\\n        },\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Conversation\\\\\",\\\\n          \\\\\"count\\\\\": 4\\\\n        },\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Phones\\\\\",\\\\n          \\\\\"count\\\\\": 4\\\\n        }\\\\n      ]\\\\n    },\\\\n    {\\\\n      \\\\\"name\\\\\": \\\\\"Therapy Room\\\\\",\\\\n      \\\\\"equipment\\\\\": [\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Therapy Tables\\\\\",\\\\n          \\\\\"count\\\\\": 3,\\\\n          \\\\\"linens\\\\\": \\\\\"Crisp White\\\\\",\\\\n          \\\\\"height\\\\\": \\\\\"Adjustable\\\\\"\\\\n        },\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Resistance Bands\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\",\\\\n          \\\\\"color\\\\\": \\\\\"Colorful\\\\\"\\\\n        },\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Stability Balls\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\",\\\\n          \\\\\"condition\\\\\": \\\\\"Sturdy\\\\\"\\\\n        }\\\\n      ]\\\\n    },\\\\n    {\\\\n      \\\\\"name\\\\\": \\\\\"Gym Area\\\\\",\\\\n      \\\\\"equipment\\\\\": [\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Treadmills\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\",\\\\n          \\\\\"maintenance\\\\\": \\\\\"Recent\\\\\"\\\\n        },\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Stationary Bikes\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\",\\\\n          \\\\\"maintenance\\\\\": \\\\\"Recent\\\\\"\\\\n        }\\\\n      ]\\\\n    },\\\\n    {\\\\n      \\\\\"name\\\\\": \\\\\"Entryway\\\\\",\\\\n      \\\\\"assistive_devices\\\\\": [\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Crutches\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\"\\\\n        },\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Canes\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\"\\\\n        },\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Walkers\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\"\\\\n        }\\\\n      ]\\\\n    },\\\\n    {\\\\n      \\\\\"name\\\\\": \\\\\"Equipment Storage Room\\\\\",\\\\n      \\\\\"therapeutic_modalities\\\\\": [\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Thermotherapy Units\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\",\\\\n          \\\\\"state\\\\\": \\\\\"Ready\\\\\"\\\\n        },\\\\n        {\\\\n          \\\\\"type\\\\\": \\\\\"Cryotherapy Units\\\\\",\\\\n          \\\\\"count\\\\\": \\\\\"Multiple\\\\\",\\\\n          \\\\\"state\\\\\": \\\\\"Ready\\\\\"\\\\n        }\\\\n      ]\\\\n    }\\\\n  ],\\\\n  \\\\\"atmosphere\\\\\": \\\\\"Purposeful and ready\\\\\"\\\\n}\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 136338.67 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 157953.94 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 84202.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Market Research Analyst', 'process': 'Market Segmentation', 'situation': 'Inside the bustling corporate office, the Market Research Analyst begins their daily task of Market Segmentation. The analyst is perched at their spacious oak desk, surrounded by a sea of numerical data printed on crisp white sheets. Their trusty laptop, an ultrabook with a sleek silver finish, sits in front of them, its screen illuminated with rows and columns of data waiting to be analyzed. They have multiple software applications open - one for data analysis, another for survey tools, and a third for generating reports. To their right, a stack of industry reports sourced from the nearby library rests as a reference for their analysis. In the background, the hum of discussions from the nearby meeting rooms can be heard, where teams and stakeholders are engaged in brainstorming sessions. Across the hall, the data analysis lab stands ready, a controlled environment where the analyst can safely interpret and analyze the data. Outside the large glass windows, the cityscape moves along, a constant reminder of the diverse market that awaits segmentation and analysis.', 'situation_json': '{\"analyst_desk\": \"spacious oak desk\", \"surroundings\": \"sea of numerical data printed on crisp white sheets\", \"laptop\": \"ultrabook with a sleek silver finish\", \"software_applications\": [\"data analysis\", \"survey tools\", \"report generation\"], \"industry_reports\": \"stack of industry reports sourced from the nearby library\", \"background_noise\": \"hum of discussions from nearby meeting rooms\", \"brainstorming_sessions\": true, \"data_analysis_lab\": \"controlled environment for data interpretation and analysis\", \"cityscape_view\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 139634.56 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 159074.64 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91752.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Registered Nurse', 'process': 'Patient Education', 'situation': 'In the heart of a bustling hospital, a Registered Nurse is in the midst of a Patient Education session. The nurse is armed with a diverse array of educational materials and teaching aids, including vivid diagrams, detailed models, and an array of online resources. The nurse is also equipped with a stethoscope and a blood pressure monitor, both gleaming with a recent polish, and a pulse oximeter that flickers with a constant, reassuring green light. The nurse stands in a patient room, its walls painted a soothing, pastel green, standing opposite a patient, who is engrossed in a pamphlet about managing diabetes. In the nearby waiting room, a dozen more patients await their turn, their faces a blend of curiosity and determination. The nurse is joined by a team of fellow healthcare professionals, each engrossed in their own tasks, from updating electronic health records to consulting with patients.', 'situation_json': '{\"location\": \"hospital\", \"equipment\": {\"diagrams\": true, \"models\": true, \"online_resources\": true, \"stethoscope\": {\"state\": \"polished\"}, \"blood_pressure_monitor\": {\"state\": \"polished\"}, \"pulse_oximeter\": {\"state\": \"on\", \"light_color\": \"green\"}}, \"room_color\": \"pastel green\", \"number_of_patients\": 1, \"additional_patients\": 12, \"expression_of_patients\": \"curiosity and determination\", \"number_of_healthcare_professionals\": \"team\", \"professional_tasks\": [\"updating electronic health records\", \"consulting with patients\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 95887.65 examples/s] examples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 150601.29 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96381.28 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Patrol Officer', 'process': 'Arrest Procedures', 'situation': 'A seasoned patrol officer, donning a crisp, neatly pressed uniform, is positioned in the bustling outdoor environment of a street in a neighborhood, meticulously executing arrest procedures on a suspected perpetrator. Equipped with essential gear such as a pair of sturdy, silver, steel handcuffs to safeguard against potential evasion, a sleek, black police radio to ensure vital communication with backup officers, and a robust, navy blue protective vest for personal safety, the officer maintains control of the dynamic situation. The crime scene is a stark, vivid backdrop to the ordeal, with various witnesses and passersby adding complex layers to the scenario. Potential interference and hostility from onlookers threaten the efficient progression of the arrest. A solitary, reliable squad car, shimmering under the fading sun, stands ready to transport the suspect to the police station. The officer, meticulously following protocols, balances the delicate intricacies of reading the suspect their rights, preserving the crime scene, and skillfully gathering evidence that could ultimately determine the outcome of the arrest.', 'situation_json': '{\"location\": \"outdoor\", \"location_details\": \"street in a neighborhood\", \"officer_uniform\": \"crisp, neatly pressed\", \"officer_equipment\": {\"handcuffs\": \"sturdy, silver, steel\", \"police_radio\": \"sleek, black\", \"protective_vest\": \"robust, navy blue\"}, \"crime_scene_description\": \"stark, vivid\", \"witnesses_present\": true, \"potential_interference\": true, \"squad_car_present\": true, \"squad_car_description\": \"solitary, reliable\", \"suspect_in_custody\": true, \"arrest_protocols_followed\": true, \"evidence_gathering\": true}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 129624.46 examples/s]amples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 154039.52 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 93762.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Psychologist', 'process': 'Professional Development', 'situation': 'In the heart of a bustling school campus, the school psychologist is engrossed in their daily routine of professional development. A myriad of tests and diagnostic tools, both standardized and non-standard, are neatly organized on their well-worn, oak wood desk. Some of these tools include cognitive, academic, and behavioral assessments, each one meticulously selected to evaluate the unique needs of every student. A sleek, silver laptop sits open, its screen glowing with the latest student records, while a leather-bound notebook rests beside it, filled with hand-written notes from countless meetings and consultations. The room is adorned with the vibrant artwork of students, and a calm, peaceful atmosphere is maintained despite the constant flow of students and teachers seeking guidance and support. In this nurturing environment, the school psychologist strives to determine the instructional needs of each student, design effective learning programs, and facilitate the use of various intervention strategies. They assess student needs, define learning outcomes, create individualized education plans, and ensure that adequate resources are provided to meet those needs. All the while, they provide counseling services to students, teachers, and parents, serve on interdisciplinary teams, and conduct research to improve academic outcomes and instructional strategies.', 'situation_json': '{\"equipment\": {\"desk\": \"well-worn, oak wood\", \"tests_and_diagnostic_tools\": [\"cognitive\", \"academic\", \"behavioral\"], \"laptop\": \"sleek, silver\", \"notebook\": \"leather-bound\"}, \"environment\": {\"artwork\": \"vibrant\", \"atmosphere\": \"calm, peaceful\", \"flow_of_visitors\": \"constant\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 132258.45 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 157244.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92413.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Insurance Agent', 'process': 'Reporting', 'situation': \"The description of Insurance Agent entails various aspects of the job including assessing risks, drafting insurance policies, and providing advice to clients. Insurance Agents invariably monitor and document the policies they manage. Reporting constitutes keeping a systematic record of policies and the dynamics of premiums. Conclusively, Reporting for Insurance Agents is integral to ensuring accuracy and compliance. The indoor office room of the agency buzzes with the hum of the computer as the Insurance Agent meticulously processes the data. The computer screen displays a myriad of reports, each meticulously labeled and color-coded for easy reference. The printer hums softly in the corner, ready to spit out crisp paper copies at a moment's notice. The walls are adorned with certificates and awards, testaments to the agent's diligence and success. In the waiting room, a handful of clients, ranging from elderly individuals with furrowed brows to young professionals with eager expressions, await their turn. The window behind them offers a view of the bustling cityscape, a constant reminder of the diverse clientele served. The agent’s colleagues, engaged in deep discussions and the rhythmic tapping of keys, highlight the collaborative nature of the work environment. Moreover, the nearby training room echoes with the muffled laughter and occasional gasps of participants as they absorb the latest industry trends and best practices.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 76787.77 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 79138.16 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 50098.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Fabricator', 'process': 'Assembly', 'situation': \"The factory floor buzzes with activity as Fabricators meticulously operate their designated machinery. The air is filled with the hum of motors and clatter of tools, creating a symphony of productivity. On each workstation, a pristine array of five dental mirrors gleams from their tray, awaiting use. The assembly line stretches out, laden with various stages of construction in a seamless dance of precision and progression.]]   [ Supervisors roam the floor like hawks, ensuring tasks are completed efficiently, their clipboards bristling with checklists and schedules. Nearby, assemblers huddle over in-progress pieces, featuring intricate designs and varied colors. In the inspection area, a Fabricator's keen eyes scrutinize freshly made components, running a fingertip over meticulously crafted edges, verifying quality and tolerance.]]   [ The mood is one of purposeful calm, despite the clamor. Colleagues communicate with terse nods and quiet, determined murmured instructions. Safety is a paramount concern, with personal protective equipment hung neatly in their storage areas, readyfor swift donning. The tool storage area is well-organized, every wrench and screwdriver in its place, waiting for the next task. The material storage is a backdrop of raw potential, bundles of metal and various components stacked in tidy piles.]]\", 'situation_json': '{\"situation\": \"The factory floor buzzes with activity as Fabricators meticulously operate their designated machinery. The air is filled with the hum of motors and clatter of tools, creating a symphony of productivity. On each workstation, a pristine array of five dental mirrors gleams from their tray, awaiting use. The assembly line stretches out, laden with various stages of construction in a seamless dance of precision and progression.\\\\\" Supervisors roam the floor like hawks, ensuring tasks are completed efficiently, their clipboards bristling with checklists and schedules. Nearby, assemblers huddle over in-progress pieces, featuring intricate designs and varied colors. In the inspection area, a Fabricator\\'s keen eyes scrutinize freshly made components, running a fingertip over meticulously crafted edges, verifying quality and tolerance. The mood is one of purposeful calm, despite the clamor. Colleagues communicate with terse nods and quiet, determined murmured instructions. Safety is a paramount concern, with personal protective equipment hung neatly in their storage areas, ready for swift donning. The tool storage area is well-organized, every wrench and screwdriver in its place, waiting for the next task. The material storage is a backdrop of raw potential, bundles of metal and various components stacked in tidy piles. \"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131611.90 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 155309.58 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91662.47 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Medical Assistant', 'process': 'Appointment Scheduling', 'situation': \"Indoors, I, a Medical Assistant, am situated at my desk meticulously handling appointment scheduling. The room is brightly lit, and the air is filled with the hum of quiet conversation and the rhythmic tapping of keyboards. To my left, a sleek computer hums gently, its screen displaying a colorful scheduling software. To my right, a telephone sits, its cord neatly coiled, waiting for my next call. In front of me, a pile of patient records awaits verification, their edges neatly stacked and aligned. Intermittently, I glance up to the nearby doctor's office, coordinating schedules with the physicians. Beyond that, the bustling reception area greets patients, its walls adorned with soothing art, the atmosphere punctuated by the occasional laughter and chatter. The treatment rooms, examination rooms, and administrative office, all indispensable components of the clinic, are filled with purposeful activity. The entire clinic is a symphony of coordinated activity, a testament to the efficiency and dedication of the medical team, and I am proud to be a part of it.\", 'situation_json': '{\"location\": \"indoor clinic\", \"computer_status\": \"on\", \"computer_screen_status\": \"displaying scheduling software\", \"computer_sound\": \"humming gently\", \"telephone_status\": \"idle\", \"telephone_cord_status\": \"neatly coiled\", \"patient_records_status\": \"awaiting verification\", \"patient_records_condition\": \"neatly stacked and well-aligned\", \"doctors_office_status\": \"active\", \"reception_area_status\": \"active and bustling\", \"reception_area_decoration\": \"walls adorned with soothing art\", \"treatment_rooms_status\": \"active\", \"examination_rooms_status\": \"active\", \"administrative_office_status\": \"active\", \"clinic_activity_level\": \"symphony of coordinated activity\", \"clinic_atmosphere\": \"efficient and dedicated\", \"lighting_status\": \"brightly lit\", \"sound_status\": \"filled with quiet conversation and rhythmic tapping of keyboards\", \"clinic_components_status\": \"indispensable\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 119859.65 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 161763.69 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96992.90 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Loan Officer', 'process': 'Loan Approval or Rejection', 'situation': 'In the heart of the bustling bank, the Loan Officer skillfully juggles between the crisp, white pages of loan applications and the glowing screen of their computer. The office, filled with two neatly arranged rows of three desks, is adorned with a plethora of tools essential for the task at hand. Each desk hosts a network cable snaking its way from the computer, leading to a connection point hidden behind a grey, metal cabinet. The room is a testament to order, with manila folders stacked meticulously in an open shelf, contrasting the vibrant red of the day planner. The soft hum of a printer punctuates the silence, echoing the finality of a loan approval or rejection. The clock on the wall ticks away as the Loan Officer prepares to plunge into another day of critical decision-making.', 'situation_json': '{\"location\": \"bustling bank\", \"number_of_desks\": 6, \"desk_arrangement\": \"two neatly arranged rows of three desks\", \"equipment\": [\"computer\", \"manila folders\", \"day planner\", \"printer\", \"grey metal cabinet\", \"network cables\", \"clock\"], \"equipment_states\": {\"computer\": \"glowing screen\", \"day planner\": \"vibrant red\", \"printer\": \"soft hum\", \"grey metal cabinet\": \"hidden connection point\", \"clock\": \"ticking away\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  95%|█████████▌| 687/723 [4:00:21<09:01, 15.05s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Teacher Assistant', 'process': '1. Grading Assignments', 'situation': 'The process of grading assignments involves evaluating the work of students against a set of criteria, determining their level of understanding, and providing feedback to help them improve. This is typically done by Teacher Assistants, who play a crucial role in supporting teachers by handling the administrative tasks associated with grading. Grading assignments also helps teachers identify areas where students may be struggling and adjust their teaching strategies accordingly.', 'situation_json': '{\"role\": \"Teacher Assistant\", \"process\": \"Grading assignments\", \"state\": {\"type\": \"object\", \"properties\": {\"criteria\": {\"type\": \"object\", \"properties\": {\"evaluation_type\": {\"type\": \"string\", \"enum\": [\"metric\", \"subjective\"]}, \"understanding_level\": {\"type\": \"string\", \"enum\": [\"basic\", \"intermediate\", \"advanced\"]}, \"feedback\": {\"type\": \"string\", \"enum\": [\"general\", \"specific\"]}}}, \"teaching_strategies\": {\"type\": \"array\", \"items\": {\"type\": \"string\", \"enum\": [\"lectures\", \"group discussions\", \"individual coaching\"]}}}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 128242.56 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 158608.45 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91433.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Record Keeping', 'situation': \"In the quiet, orderly indoor setting of a bustling middle school, a dedicated middle school teacher embarks on their daily routine of Record Keeping. The classroom, complete with student desks neatly arranged in rows, serves as the central hub for this important task. Adjacent areas, such as the administrative office and the teachers lounge, provide additional support for this process by handling official documentation and assisting with data management. The teacher, a key figure in this operation, uses a variety of tools and equipment, including a computer, printer, and a stack of student files, all neatly organized on their desk. A whiteboard nearby, adorned with scribbled notes from previous lessons, serves as a reminder of the ongoing progress. Surrounded by the buzz of nearby student interactions and the occasional hum of the school's bell, the teacher meticulously inputs, stores, and manages student data. This task, while physically undemanding, presents a constant mental challenge, as it requires a high level of attention to detail and organizational skills.\", 'situation_json': '{\"location\": \"indoor\", \"setting\": \"quiet, orderly\", \"place\": \"middle school\", \"areas\": [\"classroom\", \"administrative office\", \"teachers lounge\"], \"classroom_arrangement\": \"student desks neatly arranged in rows\", \"adjacent_area_support\": \"official documentation and data management\", \"tools\": [\"computer\", \"printer\", \"stack of student files\"], \"tool_organization\": \"neatly organized on desk\", \"whiteboard\": \"scribbled notes from previous lessons\", \"ambient_sounds\": [\"buzz of nearby student interactions\", \"hum of school\\'s bell\"], \"physical_demand\": \"low\", \"mental_demand\": \"high\", \"attention_detail\": \"high\", \"organizational_skills\": \"high\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 114368.93 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141929.16 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90773.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Radiologic Technologist', 'process': 'Patient Positioning', 'situation': 'As a Radiologic Technologist, I am standing in the vividly lit, sterile imaging room within the bustling hospital. The air is cool and slightly humid, filled with the soft hum of the machinery. Directly ahead, the gleaming x-ray machine sits, its smooth surface dotted with a multitude of buttons and dials. Attached to it is the control panel, ablaze with colorful displays and blinking lights, hinting at the complex technology hidden within. Beside the machine, an immaculate lead apron hangs from a hook, waiting to be draped over the next patient to protect them from the subtle radiation. In the corner, a collection of tools — wrenches, screwdrivers, and calibration devices — are neatly arranged on a tray, reflecting the meticulous nature of the maintenance routines. The storage room nearby is filled with maintenance supplies, ranging from lubricants to cleaning agents, all organized on shelves that line the walls.\\n\\nScattered throughout the room are various devices designed to support patient positioning. Some are as simple as cushions, while others are more specialized, such as padded cradles to accommodate different body parts. Next to the x-ray machine, three dental mirrors lie neatly on a tray, their surfaces polished to a high shine. Beyond the imaging room, the control room himself a sanctuary of serenity where the technologist operates the imaging equipment and monitors the patient during the procedure.\\n\\nIn the adjoining waiting room, a calm atmosphere pervades despite the presence of several anxious patients. Ten individuals from various walks of life fill the seats, their faces bearing a mix of anticipation and unease. Among them, a middle-aged woman with a concerned expression reads a magazine, while a young boy engages with a tablet, his focused demeanor a stark contrast to his surroundings. In a corner, an elderly man assisted by his daughter is engrossed in conversation, trying to distract himself from the impending procedure.\\n\\nAcross the hall, my coworkers are engaged in their respective tasks. A technician, dressed in overalls, is meticulously inspecting the CT scanner in the adjacent room, ensuring its operational readiness. In the nearby workshop, the hum of a drill fills the air as another technician repairs a malfunctioning part of the MRI machine. A supervisor, dressed in a lab coat, overlooks their work, her eyes scanning a clipboard to ensure adherence to protocols.\\n\\nIn the midst of this controlled chaos, I turn my attention to the task at hand. Preparing for the arrival of the next patient, I ensure that every button, lever, and switch on the x-ray machine is precisely set. The patient, a middle-aged man with a warm smile, enters the room. greeted by my reassuring smile and gentle words, I explain the procedure, ensuring that he understands each step. With a nod, he takes a seat, and together, we embark on another journey into the intricate world of diagnostic imaging.', 'situation_json': '{\"description\": \"As a Radiologic Technologist, I am standing in the vividly lit, sterile imaging room within the bustling hospital. The air is cool and slightly humid, filled with the soft hum of the machinery. Directly ahead, the gleaming x-ray machine sits, its smooth surface dotted with a multitude of buttons and dials. Attached to it is the control panel, ablaze with colorful displays and blinking lights, hinting at the complex technology hidden within. Beside the machine, an immaculate lead apron hangs from a hook, waiting to be draped over the next patient to protect them from the subtle radiation. In the corner, a collection of tools \\\\u2014 wrenches, screwdrivers, and calibration devices \\\\u2014 are neatly arranged on a tray, reflecting the meticulous nature of the maintenance routines. The storage room nearby is filled with maintenance supplies, ranging from lubricants to cleaning agents, all organized on shelves that line the walls. Scattered throughout the room are various devices designed to support patient positioning. Some are as simple as cushions, while others are more specialized, such as padded cradles to accommodate different body parts. Next to the x-ray machine, three dental mirrors lie neatly on a tray, their surfaces polished to a high shine. Beyond the imaging room, the control room is a sanctuary of serenity where the technologist operates the imaging equipment and monitors the patient during the procedure. In the adjoining waiting room, a calm atmosphere pervades despite the presence of several anxious patients. Ten individuals from various walks of life fill the seats, their faces bearing a mix of anticipation and unease. Among them, a middle-aged woman with a concerned expression reads a magazine, while a young boy engages with a tablet, his focused demeanor a stark contrast to his surroundings. In a corner, an elderly man assisted by his daughter is engrossed in conversation, trying to distract himself from the impending procedure. Across the hall, my coworkers are engaged in their respective tasks. A technician, dressed in overalls, is meticulously inspecting the CT scanner in the adjacent room, ensuring its operational readiness. In the nearby workshop, the hum of a drill fills the air as another technician repairs a malfuntioning part of the MRI machine. A supervisor, dressed in a lab coat, overlooks their work, her eyes scanning a clipboard to ensure adherence to protocols. In the midst of this controlled chaos, I turn my attention to the task at hand. Preparing for the arrival of the next patient, I ensure that every button, lever, and switch on the x-ray machine is precisely set. The patient, a middle-aged man with a warm smile, enters the room. greeted by my reassuring smile and gentle words, I explain the procedure, ensuring that he understands each step. With a nod, he takes a seat, and together, we embark on another journey into the intricate world of diagnostic imaging.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  95%|█████████▌| 690/723 [4:00:45<05:36, 10.20s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'HR Specialist', 'process': 'Diversity and Inclusion', 'situation': 'The HR Specialist for Diversity and Inclusion, situated in the heart of the HR Department, is continually immersed in an ongoing challenge of mental stimulation. Their indoor office, a hub of diverse people and interactions, is filled with a myriad of equipment and resources, all contributing to the process of Diversity and Inclusion. An array of employees and managers, each with their unique roles and responsibilities, frequent this space, either seeking guidance or implementing diversity initiatives.', 'situation_json': '{\"description\": \"The HR Specialist for Diversity and Inclusion, situated in the heart of the HR Department, is continually immersed in an ongoing challenge of mental stimulation. Their indoor office, a hub of diverse people and interactions, is filled with a myriad of equipment and resources, all contributing to the process of Diversity and Inclusion. An array of employees and managers, each with their unique roles and responsibilities, frequent this space, either seeking guidance or implementing diversity initiatives.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 109028.95 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 147077.34 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 92944.17 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Diagnostic Medical Sonographer', 'process': 'Maintaining Patient Records', 'situation': \"In the heart of the bustling clinic, the hum of the radiology department is a soothing symphony to the trained ear of the Diagnostic Medical Sonographer. The air is cool and controlled, a stark contrast to the warmth of the examination room where a patient awaits, nestled comfortably on the padded table, their eyes flickering with a mix of anticipation and apprehension. The sonographer, dressed in crisp scrubs, their stethoscope a familiar weight around their neck, moves with practiced efficiency, their fingers dancing over the keyboard of the ultrasound machine, a state-of-the-art Affiniti 70, its screen a beacon of modern medicine. The machine, a sleek silver beast, purrs to life, its lights casting a soft glow on the sonographer's concentration-creased brow. Beside it, the transducer, a smooth, ergonomic marvel, lies cradled in a sterilization tray, bathed in ultraviolet light, ready for its moment in the spotlight. The ultrasound gel, a clear, viscous substance, waits patiently in its dispenser, a testament to the sonographer's meticulousness, not a drop out of place. The examination room, a sanctuary of healing, is equipped with the latest technology, from the high-definition monitor that will display the ultrasound images to the digital voice recorder that will capture the sonographer's observations. The sonographer's workspace, a sleek desk tucked into a corner, is a model of organization, with patient files neatly stacked, and the sonographer's notes, a testament to their dedication, carefully documented. The sonographer's colleagues, a team of dedicated professionals, work in harmony, their voices a low murmur in the background, a testament to the collaborative nature of their work. The waiting room, a haven of calm amidst the clinic's bustle, is filled with the soft sounds of patient anticipation. Here, patients, a diverse mix of ages and backgrounds, flip through magazines, their eyes occasionally flickering to the door, a silent question in their gaze. The sonographer, attuned to their needs, offers a reassuring smile, a silent promise of efficient, compassionate care. The challenge today is verbal, a complex case that requires the sonographer's full attention, their communication skills, and their medical expertise. The sonographer takes a deep breath, their eyes meeting the patient's, a silent connection made. The process of maintaining patient records begins, a meticulous task that ensures the patient's care is seamless, their information secure, their trust well-placed.\", 'situation_json': '{\"room_temperature\": 20, \"humidity\": 50, \"ultrasound_machine_model\": \"Affiniti 70\", \"ultrasound_machine_state\": \"on\", \"transducer_state\": \"sterilized\", \"ultrasound_gel_state\": \"ready\", \"monitor_definition\": \"high-definition\", \"recording_device_type\": \"digital voice recorder\", \"desk_organization\": \"neat\", \"patient_files_state\": \"neatly stacked\", \"staff_collaboration\": \"harmonious\", \"waiting_room_atmosphere\": \"calm\", \"patient_emotions\": \"anticipation, apprehension\", \"challenge_type\": \"verbal, complex case\", \"sonographer_mood\": \"concentrated\", \"patient_mood\": \"anxious\", \"trust_level\": \"well-placed\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125247.53 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 157813.40 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94784.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Project Planning', 'situation': 'A Web Developer is nestled in their spacious office, its walls adorned with a mix of colorful art prints and coding diagrams. The soft hum of a nearby coffee maker fills the air as the developer puts on their favorite pair of noise-cancelling headphones, ready to focus on the project planning phase. They are surrounded by their indispensable tools - a powerful laptop with high-resolution screen, an ergonomic mouse and keyboard for comfort, and a reliable computer for communication and project management. The desk is cluttered with software tools, development environments, and SEO tools. The developer collaborates closely with designers and clients, communicating via email, chat, or video conference to understand the project requirements. In this calm and well-equipped space, the web developer meticulously plans the project, ensuring every detail is accounted for.', 'situation_json': '{\"room_description\": \"spacious office\", \"room_walls\": [\"colorful art prints\", \"coding diagrams\"], \"noise_level\": \"soft hum of a nearby coffee maker\", \"equipment\": [\"powerful laptop with high-resolution screen\", \"ergonomic mouse\", \"ergonomic keyboard\", \"reliable computer\"], \"desktop_mess\": [\"cluttered with software tools\", \"development environments\", \"SEO tools\"], \"collaboration_tools\": [\"email\", \"chat\", \"video conference\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 89853.97 examples/s]/ examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 152993.64 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89482.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist Assistant', 'process': 'Exercise Demonstration', 'situation': 'In the heart of a busy clinic, a Physical Therapist Assistant (PTA) is seen in a bright, spacious treatment room. The room is well-lit, with five large windows providing ample natural light. The walls are painted in a soothing shade of light blue, creating a calming atmosphere. The room is filled with an array of equipment, including three stability balls of various sizes, a dozen resistance bands neatly stacked in a corner, and two therapy tables positioned in the center. A large exercise mat, which is meticulously placed on the floor, is ready for use. Two patients can be seen waiting in the comfortable waiting area just outside the room, their faces filled with anticipation. The PTA, dressed in a crisp white uniform, is diligently preparing for the exercise demonstration session, a task they undertake daily. In the background, the faint chatter of the receptionist echoes from the lively reception area, while the steady hum of the clinic environment envelops the room, signifying the start of another day.', 'situation_json': '{\"room_description\": {\"color\": \"light blue\", \"size\": \"spacious\", \"lighting\": \"well-lit\", \"windows\": 5, \"natural_light\": true, \"additional_equipment\": {\"stability_balls\": 3, \"resistance_bands\": 12, \"therapy_tables\": 2, \"exercise_mat\": 1}, \"waiting_area\": {\"patients_waiting\": 2, \"comfortable\": true}, \"clinic_environment\": {\"receptionist_chatter\": true, \"hum\": true}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 133237.34 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 156176.15 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96405.32 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Respiratory Therapist', 'process': 'Conducting Diagnostic Tests', 'situation': \"In the pulsating heart of the hospital, the diagnostic lab hums with controlled urgency. Equipment adorns the sterile room like instruments in an orchestra, each tool poised for its role in the symphony of patient care. The spirometer stands tall and ready, its digital display flickering with eager anticipation. Beside it, the pulse oximeter pulses quietly, its small size belying its critical importance. The stethoscope hangs neatly on a hook, its polished metal glinting under the harsh fluorescent lights. Just outside the lab, the patient waiting area is filled with the muted hum of anxious chatter, the soft rustling of magazines, and the occasional impatient sigh. The nursing station nearby buzzes with activity as nurses in crisp uniforms move efficiently, their actions filled with purpose. In the patient room, the patient lies on a neatly made bed, their anxious eyes darting around the room. The physician, dressed in a pristine white coat, stands by the bedside, their brow furrowed in concentration as they discuss the upcoming diagnostic tests. The respiratory therapist, laden with calm professionalism, enters the room. The therapist's hands are steady, their movements precise as they begin the process of conducting diagnostic tests. The air is thick with the weight of the task at hand, each tick of the clock a reminder of the importance of accuracy and swiftness.\", 'situation_json': '{\" environment_detail\": {\"location\": \"hospital\", \"structure\": {\"room_type\": \"diagnostic lab\", \"sub_room_type\": \"sterile room\"}}, \"equipment_states\": {\"spirometer\": {\"state\": \"ready\", \"display\": \"flickering\"}, \"pulse oximeter\": {\"state\": \"quiet\", \"size\": \"small\"}, \"stethoscope\": {\"state\": \"ready\", \"appearence\": \"polished\"}}, \"observations\": {\"audible_characteristics\": {\"general_environment\": {\"ambient_sounds\": \"controlled urgency\", \"sounds_nearby_locations\": {\"patient_waiting_area\": {\"sounds_detected\": [\"anxious chatter\", \"rustling of magazines\", \"impatient sigh\"]}, \"nursing_station\": {\"sounds_detected\": [\"buzzing with activity\"], \"nurses_detected\": {\"appearence\": \"crisp uniforms\", \"movement_pattern\": \"efficient\"}}}, \"patient_room\": {\"sounds_detected\": []}}}, \"ambient_illumination\": {\"ambient_characteristics\": \"harsh fluorescent lights\"}, \"patient_characteristics\": {\"emotional_state\": \"anxious\", \"observable_actions\": \"eyes darting around the room\"}, \"professional_characteristics\": {\"profession\": \"physician\", \"attire\": \"pristine white coat\", \"emotional_state\": \"concentration\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 150308.21 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 156002.06 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94957.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Market Research Analyst', 'process': 'Presentation Preparation', 'situation': 'In the heart of a bustling corporate office, a dedicated Market Research Analyst delves into the intricate art of Presentation Preparation. The process, which usually takes 1-2 weeks, unfolds in the analysts office, a space that hums with the quiet efficiency of a well-oiled machine. The office, bathed in the soft glow of a desk lamp, is strewn with the essentials of the trade a high-performance laptop, humming with activity, and sophisticated presentation software that brings life to raw data. Nearby, a pristine whiteboard or flipchart stands at the ready, waiting for inspiring moments of diagramming and ideation. The analyst, surrounded by the rhythmic click-clack of keyboards and the muted conversations of colleagues, is deeply engrossed in the task at hand. In the adjacent conference room, a projector or screen is being set up, ready to display the culmination of the analysts meticulous efforts. They are not alone in this journey. A supervisor, with an eye for detail and a wealth of experience, guides the analyst through the twists and turns of data analysis, ensuring the final presentation is a powerhouse of insights and strategies. Occasionally, a research team joins in, lending their expertise to the process and infusing different perspectives into the mix. Together, they work tirelessly to create a presentation that captures the essence of market conditions, competitor performance, consumer behavior, and industry trends. This is not just a task. It is a journey filled with mental and emotional challenges, a crusade to transform daunting datasets into powerful narratives that shape strategic decisions.', 'situation_json': '{\"location\": \"corporate office\", \"duration\": \"1-2 weeks\", \"office_space\": \"analysts office\", \"office_space_condition\": \"organized\", \"laptop_state\": \"high-performance\", \"laptop_activity\": \"active\", \"presentation_software_state\": \"sophisticated\", \"presentation_software_activity\": \"active\", \"whiteboard_state\": \"pristine\", \"whiteboard_activity\": \"ready for use\", \"noise_level\": \"moderate\", \"colleagues_presence\": \"present\", \"projector_state\": \"set up\", \"projector_activity\": \"ready for use\", \"supervisor_presence\": \"present\", \"supervisor_activity\": \"guiding the analyst\", \"research_team_presence\": \"sometimes present\", \"research_team_activity\": \"lending expertise\", \"presentation_focus\": \"market conditions, competitor performance, consumer behavior, industry trends\", \"presentation_challenges\": \"mental and emotional challenges\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 89396.92 examples/s]xamples]   \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 111415.07 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94383.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Patrol Officer', 'process': 'Community Interaction', 'situation': 'As the sun begins to set, casting a warm orange glow over the community, Officer Johnson, a seasoned Patrol Officer, steps out of the patrol station. The station, a well-maintained two-story building, is buzzing with activity as the shift change begins. Officer Johnson checks his equipment before heading out on his patrol, ensuring that his patrol car, a sleek, black Chevrolet Tahoe, is in good working order. He holsters his firearm, a sturdy Glock 22, and checks his radio, a Motorola XTS 5000, to make sure it is functioning correctly. He slips on his bulletproof vest, which feels a bit snug but secure, and turns on his body camera, a compact Axon Flex. He also checks his handcuffs, ensuring they are securely attached to his utility belt, ready for use if needed.', 'situation_json': '{\"time_of_day\": \"sunset\", \"light_level\": \"warm orange glow\", \"building_activity\": \"busy\", \"building_type\": \"two-story\", \"building_condition\": \"well-maintained\", \"vehicle_make\": \"Chevrolet\", \"vehicle_model\": \"Tahoe\", \"vehicle_color\": \"black\", \"vehicle_condition\": \"good working order\", \"firearm_make\": \"Glock\", \"firearm_model\": \"22\", \"firearm_state\": \"holstered\", \"radio_make\": \"Motorola\", \"radio_model\": \"XTS 5000\", \"radio_state\": \"functioning correctly\", \"body_armor_type\": \"bulletproof vest\", \"body_armor_fit\": \"snug but secure\", \"camera_make\": \"Axon\", \"camera_model\": \"Flex\", \"camera_state\": \"on\", \"handcuffs_state\": \"securely attached\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 137406.29 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 151353.29 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 96906.05 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Psychologist', 'process': 'Record Keeping', 'situation': \"The school psychologist is responsible for maintaining accurate and confidential records of all interactions with students, staff, and families. This includes documentation of evaluation results, interventions, progress monitoring, consultation, and the record keeping is essential for tracking progress, evaluating effectiveness of interventions, and communicating with parents and staff. The school psychologist ensures that all records are maintained in accordance with state and federal regulations. The ultimate outcome of this process is to have a comprehensive record of the student's psychological profile, which will help their academic and social development. \\n\\nMore to the point, the school psychologist is in their office, surrounded by the hum of the school building. The walls of the office are adorned with diplomas and certificates, testament to their expertise and continual learning; a calming combination of soft green and warm beige. There’s a modest but tidy desk right in the center, flanked by two tall file cabinets brimming with neatly arranged folders. On the desk sits a modern laptop, already open and humming quietly, ready to document today’s consultations and progress notes. Not far from it sits a few well-used notebooks, their spines visibly worn from repeated use. \\n\\nThe school psychologist has a laptop open, delicately typing away on the shiny keyboard. In front of them lies open a notebook dexterously encoding the nuances of the day's session. The room has a scent of coffee and paper bargaining the calmness with the seriousness of the environment, evoking the professional yet approachable atmosphere. The lone window casts a gentle, soothing light across the space, juxtaposing the bustle of the school with the tranquility of the office.\\n\\nRight outside, in the waiting area, parents sit with a mix of anticipation and concern, patiently waiting for their turn to speak about their children. The sound of rustling papers and the click of the keyboard fills the air, a steady rhythm punctuated by the occasional ring of the office phone.\", 'situation_json': '{\"details\": {\"Setting\": {\"building\": \"school\", \"office_area\": \"office\", \"waiting_area\": \"right_outside\"}, \"Personnel\": {\"responsibilities\": [\"maintain accurate records\", \"document evaluations\", \"track progress\", \"communicate with parents/staff\"], \"compliance\": \"state_federal_regulations\"}, \"Office Environment\": {\"wall_color\": \"soft green and warm beige\", \"desk_style\": \"modest\", \"file_cabinets\": {\"number\": 2, \"status\": \"tall and tidy\"}, \"laptop\": {\"condition\": \"modern\", \"state\": \"open\"}, \"notebooks\": {\"condition\": \"well-used\", \"status\": \"open\"}, \"lighting\": \"gentle and soothing\"}, \"Sensory Details\": {\"sounds\": [\"hum of building\", \"rustling papers\", \"keyboard clicks\", \"occasional phone rings\"], \"scents\": \"coffee and paper\"}, \"Occupational Tools\": {\"equipment\": \"laptop\", \"state\": \"open\", \"status\": \"quietly humming\"}, \"Parents\": {\"location\": \"waiting_area\", \"emotions\": [\"anticipation\", \"concern\"]}, \"Outcome\": \"comprehensive record of student\\'s psychological profile\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 91692.32 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 76436.11 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 61789.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Insurance Agent', 'process': 'Risk Assessment', 'situation': \"In the heart of the bustling insurance company, the indoor office is abuzz with the hum of productivity. The Insurance Agent, a seasoned professional with a keen eye for detail, is ensconced in their ergonomic chair, the plush cushioning a testament to the company's commitment to employee comfort. The room is a harmonious blend of modern technology and classic design, with the sleek lines of the laptop and calculator contrasting with the rich, mahogany wood of the desk. The laptop, a cutting-edge model, hums softly, its screen displaying a complex algorithm used for risk calculation. Beside it, a calculator, its keys worn from frequent use, lies ready for manual checks. The desk is a paragon of organization, with neat stacks of paperwork arranged with military precision, each one representing a client's unique risk profile. Behind the desk, a bookshelf towers, its shelves groaning under the weight of insurance law tomes and industry reports, each one a testament to the Agent's commitment to staying informed. The walls are adorned with framed licenses and certifications, a visual chronicle of the Agent's career journey. The room is filled with the soft murmur of the Agent's voice as they explain the intricacies of a policy to a client on the phone, their words measured and reassuring. The client, seated on the other side of the desk, is the picture of attentiveness, their eyes flicking between the Agent and the laptop screen, trying to absorb the complex information being presented. The Agent's colleagues, in their own offices, are a flurry of activity, their voices blending with the Agent's in a symphony of professionalism. The reception area, just outside the office, is a hive of activity, with clients waiting patiently on comfortable sofas, flipping through magazines, their reflections mirrored in the polished surface of a coffee table. The air is filled with the scent of fresh coffee, a testament to the company's commitment to hospitality. The Agent's supervisor, in their own office, is a picture of focus, their eyes scanning a report, a pen tapping thoughtfully against their desk. The training room, down the hall, is a beacon of learning, with trainees huddled around a whiteboard, their faces a mix of concentration and confusion as they grapple with a complex insurance concept. The meeting room, with its expansive table and high-backed chairs, is where the Agent will later meet with the underwriter to discuss a particularly complex risk. The room is filled with a sense of anticipation, a silent promise of the challenges and victories that the day will bring. The Insurance Agent, at the heart of it all, is a beacon of professionalism, their every action a testament to their commitment to their clients and their craft.\", 'situation_json': '{\"desk_organization\": \"Neat\", \"desk_material\": \"Mahogany wood\", \"laptop_model\": \"Cutting-edge\", \"calculator_usage\": \"Frequent\", \"bookshelf_weight\": \"Groaning\", \"certifications_count\": \"Multiple\", \"client_attentiveness\": \"High\", \"colleagues_activity\": \"Flurry\", \"reception_scene\": \"Clients waiting on comfortable sofas\", \"coffee_availability\": \"Fresh\", \"supervisor_focus\": \"High\", \"training_room_scene\": \"Trainees huddled around a whiteboard\", \"meeting_room_preparation\": \"Table set with high-backed chairs\", \"agent_professionalism\": \"High\", \"day_scenario\": \"Challenges and victories\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/7953 [00:00<?, ? examples/s]:07, 35.30s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Fabricator', 'process': 'Blueprint Reading', 'situation': 'As a fabricator, my job involves reading blueprints to understand the design and dimensions of the parts I need to create. This is a crucial step in the fabrication process as it ensures that the final product meets the required specifications. The blueprints provide detailed drawings and measurements of the parts that need to be manufactured. I carefully examine these drawings to ensure that I understand the design and any specific requirements for the part. This may involve using measuring tools to verify dimensions and ensuring that the blueprint is accurate and complete. Once I have a clear understanding of the design, I can begin the process of creating the part using the appropriate materials and machinery.', 'situation_json': '{\"role_requirements\": \"Detailed drawings, measurements\", \"specific_requirements\": \"Design, dimension verification, blueprint accuracy and completeness\", \"tools_used\": \"Measuring tools\", \"required_specifications\": \"Accurate design understanding\", \"materials\": \"Unknown materials\", \"machinery\": \"Unknown machinery\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125292.69 examples/s]\n",
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 79381.13 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 74798.21 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94354.29 examples/s]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 121257.61 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 86656.40 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Medical Assistant', 'process': 'Assisting in Physical Examinations', 'situation': \"As a Medical Assistant at a bustling clinic, you are responsible for assisting in physical examinations, ensuring that patients receive the highest quality of care. Your work environment is dynamic, shifting between the doctor's office, treatment rooms, and administrative areas. Today, you find yourself in the examination room, a space meticulously prepared for the day's consultations. The room is equipped with essential medical tools: a stethoscope, a sleek blood pressure monitor, and a digitial thermometer all neatly arranged on a nearby tray. The vibrant yellow walls create a warm and welcoming atmosphere, a stark contrast to the cold, clinical feel one might expect. The adjacent waiting room bustles with 10 patients, their ages ranging from children to elderly, each looking forward to their turn with the physician. Your colleagues, a team of three skilled Medical Assistants, are diligently preparing other examination rooms, their professional attire adding a layer of formality to the setting. You are equipped with a laptop and a variety of educational materials, ready to assist both the physician and the patient throughout the examination process. The physician, dressed in a pristine white coat, is preparing to enter, while the patient, sitting on the examination table wrapped in a crisp gown, awaits the start of the examination with a mix of anticipation and nervousness. With your expertise and calm demeanor, you ensure that the examination process runs smoothly, providing support and reassurance to both the patient and the physician.\", 'situation_json': '{\"room\": {\"type\": \"examination room\", \"sensor_data\": [{\"humidity\": \"70%\", \"temperature\": \"22\", \"timestamp\": \"noon\"}], \"tools\": [\"blood pressure monitor\", \"thermometer\", \"stethoscope\"]}, \"waiting_room\": {\"patients\": {\"count\": 10, \"ages\": [\"children\", \"elderly\"]}}, \"colleagues\": {\"count\": 3, \"dress_code\": \"professional\", \"priority\": \"preparing rooms\"}, \"special_equipment\": [], \"patient\": {\"position\": \"sitting\", \"dressed\": \"gown\", \"emotions\": [\"anticipation\", \"nervousness\"]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  97%|█████████▋| 701/723 [4:18:26<07:12, 19.65s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Student Assessment', 'situation': \"Every week, for an hour, the Middle School Teacher embarks on the mental challenge of Student Assessment, a task of utmost importance. The process unfolds within the indoor confinements of the classroom, a space filled with student desks where learning and growth transpire. This room, also housing the teacher's desk, serves as a repository for the materials used during assessment - tests, assignments, and graded papers. The silence of the workspace envelops the teacher, providing a distraction-free environment as they delve into evaluating each student's performance. The focus is sharp, honed by the red pen in hand, marking corrections and offering feedback on the papers spread across the desk. Nearby, resides the school library, a haven of resources and reflection. The computer, another essential tool, stands at the ready, its screen illuminated with grades and prepared tests. As the process concludes, the teacher, with a newfound understanding, knows exactly what to share with the students - their progress, their strengths, and their areas for improvement. Their task is demanding, yet their dedication never waivers, driven by the desire to see their students succeed.\", 'situation_json': '{\"location\": \"classroom\", \"frequency\": \"weekly\", \"duration\": \"1 hour\", \"lighting\": \"not specified\", \"noise_level\": \"silent\", \"temperature\": \"not specified\", \"air_flow\": \"not specified\", \"equipment\": {\"teacher_desk\": true, \"student_desks\": {\"state\": \"filled with learning materials\"}, \"materials\": {\"tests\": true, \"assignments\": true, \"graded_papers\": true}, \"resources\": \"nearby school library\", \"computer\": {\"state\": \"ready for use\", \"light\": \"screen illuminated\", \"contents\": \"grades and prepared tests\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 147978.44 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 89709.76 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 55979.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Teacher Assistant', 'process': '10. Participating in Staff Meetings', 'situation': \"Surrounded by the bustling energy of the school, the Teacher Assistant navigates their way to the staff meeting, their laptop bag slung over their shoulder and phone in hand. The meeting room, painted in a calming shade of blue, beckons them with the promise of fruitful discussions and collaborations. Ten neatly spaced out chairs sit around a large oval table, each seat occupied by an attentive teacher or the principal, their laptops open and phones at the ready. The Teacher Assistant takes their seat, their fingers lightly brushing against their red pen and rubric, ready to contribute to the discussions on academic programs and teaching methods. The classroom, with its desks lined in neat rows, beckons them, a reminder of the impact their decisions will have on the students. The library, filled with a myriad of books, offers the promise of additional resources for enhancing teaching methods. The teacher's desk, filled with papers yet to be graded, and the classroom materials storage, filled with textbooks, worksheets, and supplies, remind the Teacher Assistant of the tasks that await them once the meeting concludes.\", 'situation_json': '{\"location\": \"school\", \"room_color\": \"blue\", \"room_energy\": \"bustling\", \"chair_count\": 10, \"table_shape\": \"oval\", \"table_size\": \"large\", \"attendee_status\": \"attentive\", \"teacher_equipment\": [\"laptop\", \"phone\"], \"teacher_assistant_equipment\": [\"laptop bag\", \"phone\", \"red pen\", \"rubric\"], \"classroom_status\": \"desks lined in neat rows\", \"library_status\": \"filled with a myriad of books\", \"teacher_desk_status\": \"filled with papers yet to be graded\", \"classroom_materials_storage_status\": \"filled with textbooks, worksheets, and supplies\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  97%|█████████▋| 703/723 [4:19:01<06:00, 18.01s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'HR Specialist', 'process': 'Onboarding', 'situation': 'In the hushed indoor environment of the HR office, an HR Specialist prepares for an onboarding process. Their desk, the epicenter of this activity, is adorned with a meticulously arranged array of equipment. A high-performance computer, humming softly, stands ready for processing paperwork and setting up accounts, flanked by a stack of document templates waiting to be customized for this particular new hire. A phone, polished to a gleam, sits nearby, poised for communication with other departments and the new hire themselves. In the nearby localities, the HR Manager is overseeing the process, ensuring all necessary steps are completed, while the IT department is ready to assist in setting up the necessary technology and accounts. The new hire, the focal point of this process, is in their workspace, being guided through their new environment. All around, the office is bustling with other HR Specialists, each managing their own set of onboarding processes, creating a symphony of activity.', 'situation_json': '{\"location\": \"indoor\", \"room\": \"HR office\", \"atmosphere\": \"hushed\", \"main_equipment\": {\"computer\": {\"state\": \"on\", \"status\": \"high-performance\", \"appearance\": \"humming softly\", \"function\": \"processing paperwork and setting up accounts\"}, \"document_templates\": {\"state\": \"stacked\", \"status\": \"customizable\", \"function\": \"customizing for new hire\"}, \"phone\": {\"state\": \"off\", \"appearance\": \"polished to a gleam\", \"function\": \"communication with other departments and new hire\"}}, \"localities\": {\"HR_Manager\": {\"state\": \"overseeing\", \"function\": \"ensuring all necessary steps are completed\"}, \"IT_department\": {\"state\": \"ready\", \"function\": \"assisting in setting up technology and accounts\"}, \"new_hire_workspace\": {\"state\": \"guided\", \"function\": \"being guided through new environment\"}, \"other_HR_Specialists\": {\"state\": \"bustling\", \"function\": \"managing onboarding processes\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  97%|█████████▋| 704/723 [4:19:44<07:51, 24.83s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Diagnostic Medical Sonographer', 'process': 'Patient Assessment', 'situation': \"In the pristine, softly lit examination room, the Diagnostic Medical Sonographer, clad in a crisp, sky-blue uniform, diligently prepares for the ultrasound procedure. The ultrasound machine, a state-of-the-art marvel with its sleek black exterior and an array of blinking blue LEDs, hums softly in anticipation. A nearby table holds an assortment of equipment: three transducers of varying sizes, meticulously arranged, and a tube of clear ultrasound gel, ready to be applied. The room is filled with the gentle hum of the machine and the faint scent of medical-grade cleaners, evoking a sense of clinical precision. The patient, a middle-aged individual with a look of mild apprehension, sits on the exam table, covered in a thin, white medical gown. In the waiting room adjacent to the examination room, seven other patients sit, some flipping through well-worn magazines, others staring at the muted television screen. The sonographer's colleagues, a radiologist and an equipment technician, are nearby, the radiologist reviewing patient files in the consultation room, and the technician performing routine checks on another ultrasound machine in the equipment room. The atmosphere is one of quiet efficiency, with each person focused on their respective tasks, ready to provide the best possible care to the patients.\", 'situation_json': '{\"value\": \"{nnotation \\'document prepared based on the description of a situation in the profession Diagnostic Medical Sonographer under the process Patient Assessment\\': [{title: \\\\\"Diagnostic Medical Sonographer\\\\\", process: \\\\\"Patient Assessment\\\\\"}, [{examination_room: {state: \\\\\"pristine\\\\\", features: \\\\\"softly lit\\\\\", details: [{ultrasound_machine: {state: \\\\\"humming softly\\\\\", color: \\\\\"black\\\\\", exterior: \\\\\"sleek\\\\\", LEDs: {number: 3, color: \\\\\"blue\\\\\", state: \\\\\"blinking\\\\\"}}}, {equipment: [{transducers: 3}, {ultrasound_gel: {color: \\\\\"clear\\\\\", application_state: \\\\\"ready\\\\\"}}]}]}}]}\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 86673.63 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 141706.86 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94262.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'SEO Implementation', 'situation': \"In a bustling web design firm, a seasoned Web Developer sits at their polished mahogany desk, surrounded by the ambient hum of office chatter. The desk is adorned with an impressive array of equipment: a high-performance laptop glowing with coding interfaces, a sleek ergonomic mouse that glides smoothly, and aRETRO-OCd ergonomic keyboard that clicks satisfyingly under skilled fingers. A pair of high-quality noise-canceling headphones rests nearby, ready to block out the world and allow deep focus.\\n\\nThe Web Developer is deeply engrossed in the intricate process of SEO (Search Engine Optimization) Implementation. The computer's dual monitors display an array of SEO tools like Google Analytics, Moz, SEMrush, and Ahrefs, each window revealing graphs, charts, and lines of code that outline the strategy to improve the website's visibility on search engines.\\n\\nThe coding area is a hub of intensity, with lines of code meticulously written in Visual Studio Code, the text editor illuminated with color-coded syntax that makes each function, variable, and comment pop out against the dark background. The browser next to it shows the live website, being constantly refreshed to test the effects of the latest SEO tweaks.\\n\\nAround the room, the development environment is alive with activity. Nearby, a Content Developer is crafting SEO-friendly content, typing away on their keyboard with methodical precision. Across the room, a Graphic Designer is manipulating visual elements on their graphic tablet, ensuring each image is not only aesthetically pleasing but also optimized for search engines.\\n\\nIn the collaboration area, the Project Manager is going over the project timeline, ensuring that everything is on track. They occasionally glance at the Web Developer, offering a reassuring nod that signals a job well done. The office buzzes with a quiet energy, a sense of collective focus and determination to bring the website to the top of search engine rankings.\\n\\nThe room is filled with the soft clicks of keyboards, the hum of the coffee maker in the corner keeping everyone alert, and the intermittent murmur of discussions between team members. The Web Developer takes a moment to stretch, the chair creaking slightly under their weight, before diving back into the whirlwind of SEO implementation, driven by the challenge of making the website stand out in the vast digital landscape.\", 'situation_json': '{\"details\": {\"room\": {\"type\": \"web_design_firm\", \"noise\": 3}, \"desk\": {\"material\": \"mahogany\", \"condition\": \"polished\", \"noise\": 2}, \"web_developer_equipment\": {\"laptop\": {\"performance\": \"high\", \"display\": [\"coding_interfaces\", \"SEO_tools\"]}, \"mouse\": {\"type\": \"erogonomic\", \"movement\": \"smooth\"}, \"keyboard\": {\"type\": \"RETRO-OCd\", \"sound\": \"clicking\"}, \"headphones\": {\"quality\": \"high\", \"feature\": \"noise-canceling\"}}, \"SEO_tools\": {\"google_analytics\": {\"type\": \"SEO_tool\", \"display\": [\"graphs\", \"charts\"]}, \"moz\": {\"type\": \"SEO_tool\", \"display\": [\"graphs\", \"charts\"]}, \"semrush\": {\"type\": \"SEO_tool\", \"display\": [\"graphs\", \"charts\"]}, \"ahrefs\": {\"type\": \"SEO_tool\", \"display\": [\"graphs\", \"charts\"]}}, \"coding_area\": {\"intensity\": 4, \"text_editor\": \"Visual Studio Code\", \"syntax_highlighting\": true, \"background\": \"dark\", \"browser\": {\"display\": \"live_website\", \"refresh_rate\": \"constant\"}}, \"nearby\": {\"content_developer\": {\"activity\": \"crafting_SEO_friendly_content\", \"typing\": \"methodical\"}, \"graphic_designer\": {\"activity\": \"manipulating_visual_elements\", \"device\": \"graphic_tablet\"}}, \"collaboration_area\": {\"activity\": \"reviewing_project_timeline\", \"project_manager\": {\"expression\": \"reassuring_nod\", \"signal\": \"job_well_done\"}}, \"office_ambiance\": {\"energy\": 3, \"focus\": 4, \"determination\": 4, \"keyboard_clicks\": \"soft\", \"coffee_maker_noise\": \"hum\", \"discussions\": \"intermittent\"}, \"web_developer_actions\": {\"activity\": \"stretching\", \"chair_sound\": \"creaking\", \"intensity\": 4, \"goal\": \"improving_website_visibility\"}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 144377.64 examples/s] examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 137503.91 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94413.56 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist Assistant', 'process': 'Patient Education', 'situation': 'Inside the serene and spacious treatment room of the physical therapy clinic, a Physical Therapist Assistant (PTA) is at work, surrounded by a variety of equipment. The room is well-lit, with both natural light filtering in through large windows and soft artificial light from overhead fixtures. The walls, painted a calming shade of blue, are adorned with motivational posters and diagrams of the human body. The PTA, a kind-eyed and patient individual, is assisting a patient, guiding them through a series of therapeutic exercises. There are multiple pieces of exercise equipment spread out across the room - two stability balls, a set of resistance bands in various colors and strengths, and a pair of adjustable weights. The patient moves slowly and carefully, following the PTA’s instructions, their face contorted in a mix of determination and mild discomfort. The PTA observes the patient keenly, noting their progress and ensuring they maintain the correct form. In the corner of the room, a table holds a stack of clean towels, a water cooler, and a well-used but well-maintained wheelchair. The sound of soft music filters in from hidden speakers, adding to the serene and supportive atmosphere of the treatment room. Nearby, outside the room, a few people wait in the clean and comfortable waiting room, their expressions eager, hopeful, and a little nervous. The PTA and the other staff members, all dressed in modest, comfortable attire, move through the clinic with a sense of purpose and dedication, their interactions with the patients a careful balance of professionalism and genuine care.', 'situation_json': '{\"room_description\": {\"lighting\": \"well-lit\", \"color\": \"calming blue\", \"decoration\": [\"motivational posters\", \"diagrams of the human body\"], \"number_of_windows\": 1, \"size\": \"spacious\", \"audio\": {\"source\": \"hidden speakers\", \"description\": \"soft music\"}, \"additional_features\": [\"stack of clean towels\", \"water cooler\", \"well-used but well-maintained wheelchair\"]}, \"equipment\": {\"number_of_stability_balls\": 2, \"number_of_resistance_bands\": \"various colors and strengths\", \"number_of_adjustable_weights\": 1}, \"patient_state\": {\"movement\": {\"speed\": \"slow\", \"care\": \"carefully\"}, \"expression\": \"determination\", \"additional_observations\": [\"mild discomfort\"]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 131123.01 examples/s]xamples]  \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 160176.97 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 89143.47 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Market Research Analyst', 'process': 'Report Writing', 'situation': 'In the heart of the bustling Market Research Firm, a seasoned Market Research Analyst is tucked away in their office, a sanctuary cluttered with the paraphernalia of their trade. On their spacious desk, a sleek computer hums to life, housing an arsenal of software tools, from analytical programs to spreadsheet applications and databases. Adjacent to the desk, a neat row of statistical software and survey tools, including Qualtrics and SurveyMonkey, stand ready for deployment. The air in the office is charged with a subdued energy, as the Analyst prepares to delve into the labyrinth of data, armed with a steaming cup of coffee. Around them, the office buzzes with activity, colleagues engrossed in their own analyses, the murmur of team meetings drifting through the air. Further down the hallway, the controlled environment of the data analysis lab awaits, where the Analyst will dissect and interpret the data gathered from various sources. Amidst this focused activity, the Analyst takes a moment to glance at the clock, a silent reminder of the hour-long journey into the realm of market research that lies ahead.', 'situation_json': '{\"office_environment\": \"bustling\", \"analyst_office_state\": \"cluttered with paraphernalia\", \"computer_state\": \"humming, with analytical programs, spreadsheet applications and databases\", \"software_tools\": [\"Qualtrics\", \"SurveyMonkey\"], \"office_energy\": \"subdued\", \"colleagues_activity\": \"engrossed in their own analyses, team meetings\", \"data_analysis_lab_environment\": \"controlled\", \"analyst_task\": \"delve into data analysis\", \"time_reminder\": \"hour-long journey\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  98%|█████████▊| 708/723 [4:36:18<32:08, 128.57s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Respiratory Therapist', 'process': 'Documenting Patient Care', 'situation': \"In the sterile efficiency of a meticulously organized hospital room, the respiratory therapist is engrossed in the critical task of documenting patient care. The room is bathed in the soft, calming glow of muted lighting, designed to soothe the patient while allowing the therapist to accurately perform their task. The air is filled with the gentle hum of medical equipment, a comforting background melody that subtly underscores the importance of the work being done. Adjacent to the therapist, a sleek, modern ventilator stands sentinel, its steady rhythm a testament to the advanced technology keeping pace with the patient's every breath. A nearby table is meticulously arranged with an array of medical instruments: a gleaming stethoscope, ready to be employed at a moment's notice; a compact yet powerful spirometer, poised to measure lung capacity; and a discreet pulse oximeter, quietly assessing oxygen saturation levels. The walls of the room are adorned with essential medical diagrams and charts, a visual reminder of the intricate anatomy and physiology that guide the therapist's every decision. Beyond the room, the busy corridors of the hospital hum with activity. Healthcare providers move with practiced efficiency, their white coats a blur of determined activity. Nurses and doctors exchange professional nods, their silent communication a testament to the seamless teamwork that keeps the hospital running smoothly. The patient is resting comfortably, their steady breathing punctuated by the soft beeps of the monitoring equipment. The therapist's careful documentation is not just a record of care, but a narrative of hope and healing, meticulously chronicling the patient's journey towards recovery.\", 'situation_json': '{\"data\": {\"lighting\": \"muted\", \"equipment_sound\": \"gentle hum\", \"ventilator_status\": \"steady rhythm\", \"instruments\": [\"stethoscope\", \"spirometer\", \"pulse oximeter\"], \"room_decor\": [\"medical diagrams\", \"charts\"], \"corridor_activity\": \"busy with healthcare providers\", \"patient_status\": \"resting comfortably\", \"monitoring_equipment_sound\": \"soft beeps\", \"documentation_nature\": \"narrative of hope and healing\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  98%|█████████▊| 709/723 [4:36:23<21:29, 92.12s/ examples] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'School Psychologist', 'process': 'Research and Program Evaluation', 'situation': \"School psychologists conduct research and program evaluations to assess the effectiveness of educational programs, interventions, and services. This involves collecting and analyzing data, identifying trends, and making data-driven recommendations to improve student outcomes. \\nThe school psychologist sits at their cluttered desk, surrounded by piles of paperwork and a laptop humming softly. The desk is adorned with photos of family and inspirational quotes, reminding them of the importance of their work. The laptop screen displays complex spreadsheets and graphs, illustrating student performance trends and program evaluation data. Behind the desk, a large whiteboard is filled with notes and diagrams, outlining the research methodology and key findings.\\nThe office is quietly bustling with activity; the low hum of voices from the teacher's lounge next door indicates that some teachers are still discussing their day. The hallway outside is decorated with colorful student artwork, creating a vibrant and supportive atmosphere. A few students are walking by, chatting excitedly about their upcoming projects.\\nIn the corner of the office, a file cabinet stands tall, its drawers labeled with different research projects and student names. Stacks of printed reports and assessment tools are neatly organized on a nearby shelf, ready for use. The room is well-lit, with natural light streaming in from a large window overlooking the school campus, providing a serene view of the green playground and the distant hills.\\nThe school psychologist is engrossed in their work, meticulously reviewing the data and making notes on potential improvements. They occasionally glance at the whiteboard, considering how the findings align with the research questions. The atmosphere is focused, yet calming, reflecting the dedication and passion of the school psychologist in making a positive impact on the educational experience of the students.\", 'situation_json': '{\"surroundings\": {\"office\": {\"cluttered_desk\": {\"piles_of_paperwork\": true, \"laptop\": \"humming_softly\", \"photos_of_family\": true, \"inspirational_quotes\": true}, \"laptop_screen_display\": [\"complex_spreadsheets\", \"graphs\"], \"behind_desk\": {\"whiteboard\": {\"notes\": true, \"diagrams\": true, \"research_methodology\": true, \"key_findings\": true}}, \"office_activity\": \"quietly_bustling\", \"nearby_voices\": \"low_hum\", \"decorated_hallway\": {\"colorful_student_artwork\": true}, \"atmosphere\": \"vibrant_and_supportive\"}, \"corner_of_office\": {\"file_cabinet\": {\"drawers_labeled\": [\"research_projects\", \"student_names\"], \"tall\": true}, \"nearby_shelf\": {\"organized_stacks_of_printed_reports\": true, \"assessment_tools\": true}}, \"room_lighting\": \"well_lit\", \"natural_light\": true, \"large_window\": {\"overlooking_school_campus\": true, \"serene_view\": [\"green_playground\", \"distant_hills\"]}}, \"tasks\": {\"data_collection_and_analysis\": true, \"trend_identification\": true, \"data_driven_recommendations\": true, \"improving_student_outcomes\": true, \"reviewing_data\": true, \"making_notes_on_improvements\": true}, \"atmosphere\": {\"focused\": true, \"calming\": true, \"dedication\": true, \"passion\": true, \"positive_impact\": true}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 99238.40 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 105992.97 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 98839.14 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Patrol Officer', 'process': 'Court Appearance', 'situation': 'Inside the dimly lit courtroom, a Patrol Officer stands tall, their uniform meticulously pressed, their badge gleaming. They clutch their firearm, safety on, at their side, a constant reminder of the potential danger that could erupt amidst the tense proceedings. The soft buzz of conversation fills the air as the judge, a stern figure in black robes, presides over the packed courtroom. Lawyers, in their sharp suits, whisper heatedly as they strategize. The defendant, hands shackled in gleaming handcuffs, a stark reminder of their situation, glances nervously at the Patrol Officer, who maintains a neutral, watchful gaze. The jurors, their faces a varied map of emotions, listen intently as witnesses, their voices trembling with the weight of their words, take the stand. In the back of the courtroom, the bailiff, a silent sentry, stands guard. The Patrol Officer keeps a vigilant eye, their senses heightened, ready to react if needed. The firearm, the handcuffs, the badge, all tools of their trade, are at the ready. The court appearance, a mental challenge, drags on for an hour, but the Patrol Officer remains focused, steadfast in their duties.', 'situation_json': '{\"courtroom_lighting\": \"dim\", \"officer_uniform\": \"meticulously pressed\", \"officer_badge\": \"gleaming\", \"officer_firearm_safety\": \"on\", \"potential_danger\": \"true\", \"conversation_volume\": \"soft buzz\", \"judge_robe_color\": \"black\", \"courtroom_fullness\": \"packed\", \"lawyer_suits\": \"sharp\", \"lawyer_whispering\": \"heated\", \"defendant_hands\": \"shackled\", \"handcuff_state\": \"gleaming\", \"defendant_behavior\": \"nervous glance\", \"officer_expression\": \"neutral, watchful gaze\", \"juror_emotions\": \"varied\", \"juror_listening_intensity\": \"intently\", \"witness_voice_state\": \"trembling\", \"witness_presence\": \"taking stand\", \"bailiff_presence\": \"standing guard\", \"bailiff_behavior\": \"silent sentry\", \"officer_senses\": \"heightened\", \"officer_readiness\": \"ready to react\", \"firearm_state\": \"ready\", \"handcuffs_state\": \"ready\", \"badge_state\": \"ready\", \"court_appearance_duration\": \"1 hour\", \"court_appearance_difficulty\": \"mental challenge\", \"officer_focus\": \"steadfast\", \"officer_duties\": \"unwavering\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 130781.14 examples/s]amples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 148649.27 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 95037.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Fabricator', 'process': 'Cutting and Shaping', 'situation': \"In the heart of a bustling factory, the Fabricator skillfully maneuvers through the Cutting and Shaping process. Surrounded by an array of equipment, including three precise CNC machines and a robust lathe, they are well-equipped to handle the physical challenges of their role. The cutting machine, a crucial tool for slicing metal into specific sizes and shapes, gleams under the factory lights, its edges sharp and ready for use. Nearby, a heavy hammer lies in wait, ready to bring heated metal into the desired form. The welding machine, another indispensable tool, sits patiently, its function to fuse separate metal parts into a cohesive whole. Ensuring the Fabricator's safety are a variety of safety equipment, including robust safety hand gloves, sturdy safety work shoes, clear safety eyewear, protective safety shields, and a high-visibility safety vest. The nearby tool storage area, filled with a multitude of hand tools and measurement tools, stands ready for any necessary adjustments or verifications. To the Fabricator's right, a welding torch rests, its power to generate heat and melt metal a testament to the Fabricator's expertise in selecting the correct filler materials for each operation. Completing the Fabricator's safety ensemble is a welding helmet and a pair of welding gloves, designed to protect against the intense light and heat produced during welding. In this continuous process, the Fabricator's focus is unwavering, their skills and equipment ensuring the creation of precise, high-quality metal components.\", 'situation_json': '{\"location\": \"fabrication factory\", \"cutting_and_shaping_equipment\": {\"cnc_machines\": 3, \"lathe\": 1, \"cutting_machine\": {\"state\": \"ready\", \"properties\": {\"edge_sharpness\": \"sharp\"}}, \"hammer\": {\"state\": \"idle\", \"properties\": {\"weight\": \"heavy\"}}, \"welding_machine\": {\"state\": \"idle\", \"properties\": {\"function\": \"fuse metal parts\"}}, \"safety_equipment\": {\"hand_gloves\": \"robust\", \"work_shoes\": \"sturdy\", \"eyewear\": \"clear\", \"protective_shields\": \"available\", \"high_visibility_vest\": \"present\"}, \"hand_tool_storage\": {\"content\": \"hand tools and measurement tools\"}, \"welding_torch\": {\"state\": \"idle\", \"properties\": {\"function\": \"generate heat and melt metal\"}}, \"welding_helmet\": \"present\", \"welding_gloves\": \"present\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 86529.51 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 155980.32 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 90216.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Insurance Agent', 'process': 'Sales and Marketing', 'situation': 'As an Insurance Agent, I am nestled in my comfortable office, surrounded by a plethora of tools that aid my daily tasks. The centerpiece is my trusty laptop, humming softly as I navigate through various insurance databases and CRM software to manage leads and track sales progress. A sleek, silver phone sits within reach, a constant companion for making cold calls and maintaining relationships with existing clients. The office is adorned with wall hangings and vibrant potted plants, arranged to provide a conducive environment for sales and marketing activities. The customer service area, where I frequently meet with clients, exudes warmth and professionalism, while the meeting and training rooms are sparkling clean, ready for client meetings and regular training sessions. In the nearby reception area, potential clients wait, their first impression of the company subtly shaped by the ambiance. My colleagues, fellow Insurance Agents, bustle around, sharing best practices and offering support. The primary challenge I face, however, is mental fatigue. The process of maintaining a constant flow of new leads and dealing with an ever-changing industry can be mentally taxing. However, I mitigate these risks by taking regular breaks, engaging in team activities, and continually seeking professional development.', 'situation_json': '{\"office_tools\": [\"laptop (humming, silver, for insurance databases and CRM software)\", \"phone (silver, for cold calls and existing client calls)\", \"wall hangings\", \"potted plants\"], \"office_description\": \"comfortable, adorned with wall hangings and vibrant potted plants, arranged to provide a conducive environment for sales and marketing activities\", \"meeting_room_description\": \"sparkling clean, ready for client meetings and regular training sessions\", \"reception_area_description\": \"waiting area for potential clients, ambiance subtly shapes first impression of the company\", \"colleagues_activity_description\": \"bustle around, share best practices and offer support\", \"primary_challenge\": \"mental fatigue\", \"challenge_mitigation\": [\"regular breaks\", \"team activities\", \"continual professional development\"]}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  99%|█████████▊| 713/723 [4:36:39<04:10, 25.04s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Middle School Teacher', 'process': 'Student Counseling', 'situation': \"In the heart of a bustling middle school, a dedicated Middle School Teacher prepares for the weekly process of Student Counseling. The counseling session takes place in a quiet and private counseling room, adorned with a comforting blue hue that helps create a calm and supportive environment. The teacher, equipped with a notepad and sharp listening skills, is ready to guide and help students overcome their personal, social, or academic problems. The nearby school library, with its vast collection of books, serves as a valuable resource for the teacher, providing materials for planning lessons and offering a supportive environment for students to study and reflect. The teacher's desk, neatly organized with graded papers, tests, and assignments, serves as a testament to the teacher's commitment to the students' academic success. A whiteboard, positioned prominently in the room, is used for writing lessons and teaching concepts, while a laptop sits nearby, ready for preparing lessons and showing digital presentations. In the nearby teachers' lounge, colleagues exchange ideas and offer support, creating a collaborative atmosphere. The administrative office, a hive of activity, provides support for record-keeping tasks, ensuring that all official documentation is well-managed. The process of Student Counseling involves the teacher listening carefully to students' concerns, providing support, and offering advice. The teacher may also help students set goals for the future, develop their self-awareness, and improve their interpersonal skills. The ultimate goal is to help students achieve academic success while fostering their personal and social growth.\", 'situation_json': '{\"room_color\": \"blue\", \"resource_availability\": \"vast\", \"resource_location\": \"school library\", \"material_organization\": \"neatly organized\", \"equipment_available\": [\"notepad\", \"whiteboard\", \"grading papers\", \"tests\", \"assignments\", \"laptop\"], \"teacher_skills\": [\"sharp listening\", \"advice\", \"goal setting\", \"self-awareness\", \"interpersonal skills\"], \"additional_locations\": [\"teachers\\' lounge\", \"administrative office\"], \"process_activities\": [\"listening carefully\", \"record-keeping\"], \"environment\": \"calm and supportive\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  99%|█████████▉| 714/723 [4:37:13<04:07, 27.46s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Diagnostic Medical Sonographer', 'process': 'Patient Communication', 'situation': \"In the bustling indoor hospital, a Diagnostic Medical Sonographer is performing a daily task of patient communication in the treatment room specially designed for ultrasound operations. Two pieces of equipment are essential for this task: an ultrasound machine and a transducer probe. The machine, a large, sophisticated device mounted on wheels, has a screen displaying various buttons and dials, while the transducer probe, a handheld device, connects to the machine via a long cable. The sonographer prepares the machine by cleaning it with a sterile wipe, ensuring it is in proper working order. Meanwhile, two tubes of gel sit on a nearby counter, one of which will be used to apply a generous amount on the patient's skin, facilitating the smooth movement of the probe. In the waiting room, four patients of varying ages wait for their turn, their nervousness evident in their fidgeting movements. The Diagnostic Medical Sonographer, who has so far been joined by two colleagues, prepares to greet the patient, ready to explain the procedure and provide reassurance before moving on to the next task.\", 'situation_json': '{\"location\": \"indoor hospital treatment room\", \"equipment\": {\"ultrasound_machine\": {\"status\": \"ready\", \"cleanliness\": \"sterile\", \"display\": \"active\", \"wheels\": true}, \"transducer_probe\": {\"status\": \"ready\", \"connection\": \"connected via a long cable\"}, \"gel_tubes\": {\"quantity\": 2}}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  99%|█████████▉| 715/723 [4:48:53<30:32, 229.07s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Security Implementation', 'situation': 'In the heart of the bustling company office, a Web Developer is engrossed in the meticulous process of Security Implementation on a daily basis. Equipped with a powerful laptop, a comfortable ergonomic mouse and keyboard, and a plethora of web development tools, they are a formidable force in the digital realm. In their development environment, a server hums softly, providing the backbone for their coding tasks. Nearby, a designer is sketching out wireframes, their creativity flowing as they work together to create a secure, visually appealing website. The room is filled with the soft click-clacking of keys and the hum of focused minds, as the development team works tirelessly to create an online fortress.', 'situation_json': '{\"equipment\": {\"laptop_power_status\": \"on\", \"server_status\": \"humming\", \"mouse_comfort\": \"comfortable\", \"keyboard_ergonomics\": \"ergonomic\", \"web_dev_tools_availability\": \"plethora\"}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 125781.67 examples/s]xamples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 96325.64 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 91155.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist Assistant', 'process': 'Therapeutic Modalities Application', 'situation': \"In the heart of the bustling clinic, nestled in the zone of the therapy room, the air is filled with a sense of professional tranquility. The therapy room, bathed in the soft glow of neutral lighting, is a sanctuary of healing and restoration. At the center of the room stands the essential therapy table, generous in size with a plush, supportive surface, capable of adjusting to numerous heights for a perfect fit for each patient. Surrounding this focal point is an array of exercise equipment, neatly organized and gleaming under the lights. There are exactly five resistance bands in various hues of blue and green, coiled neatly on the side, ready to provide the precise resistance needed for each patient's rehabilitation. Beside them, an inflatable stability ball in a vibrant purple hue awaits its turn to help improve patients' balance and core strength. Additionally, three sets of dumbbells, arranged in ascending order of weight from five to ten pounds, are meticulously placed on a dedicated rack. The room is further equipped with advanced therapeutic modalities: a modern thermotherapy unit hums softly in the corner, its digital display casting a warm, inviting light; next to it, a sleek cryotherapy unit sits, ready to deliver soothing cold therapy. An electrotherapy unit, with its array of wires and electrodes, stands vigilant, prepared to deliver targeted electrical stimulation. The PTA, draped in comfortable scrubs the color of a serene sky, is deeply engrossed in their task, their hands expertly maneuvering the equipment with precision and care. Through the open door of the therapy room, a glimpse of the nearby waiting area reveals a cozy space with four potential patients patiently seated, their attention gently held by a variety of reading materials. One of them, a patient in a wheelchair, is engrossed in a magazine, while another is deeply engrossed in a book, a word puzzle laid out on the small table beside them. The reception area further ahead is alive with the soft murmur of administrative staff, their fingers dancing over keyboards as they manage appointments and ensure a smooth operation. Just outside the therapy room window, the clinic environment buzzes with activity, health professionals moving purposefully between rooms, their conversations muffled by the door but evident in their purposeful stride. Meanwhile, the Physical Therapist, robed in a crisp white uniform, is stationed in their office, meticulously reviewing patient charts, the glow of their computer screen casting a blue hue on their concentrated face. In the periphery, the scent of disinfectant wafts through the air, a testament to the clinic's commitment to cleanliness. The atmosphere is one of focused efficiency, intertwined with an underlying sense of empathy and healing.\", 'situation_json': '{}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 97500.33 examples/s]examples]\n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 92131.54 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 94950.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Patrol Officer', 'process': 'Incident Response', 'situation': \"Patrol Officers are responsible for responding to incidents and ensuring public safety. In a bustling neighborhood, filled with towering buildings and tree-lined streets, Officer Leila Thompson steers her sleek, black squad car through the bustling traffic. Her eyes, hidden behind mirrored aviators, dart across the scene, taking in every detail. The squad car, a symbol of authority and reassurance, is equipped with flashing red and blue lights and a powerful siren, ready to cut through the cacophony of the city. Inside, the vehicle is a marvel of technology and functionality, with a dashboard filled with blinking lights and screens displaying maps and data feeds. Officer Thompson's seat is adjustable, allowing her to find the perfect position for long shifts. The car's interior smells faintly of new leather and the lingering scent of aftershave. To her left, a laptop whirs softly, displaying real-time data and alerts. A radio crackles intermittently, maintaining a constant line of communication with the patrol station. As she approaches the incident, she spots a small crowd of anxious citizens huddled together, their faces a mixture of concern and curiosity. Behind them, a man in a well-worn jacket stands defiantly, hands tucked into his pockets. Officer Thompson takes a deep breath, her hand resting on the smooth grip of her firearm, ready to handle whatever challenge may come her way. Nearby, two backup officers are already on scene, their patrol cars parked strategically to divert traffic. One is taking statements from eyewitnesses, his notebook filled with hurried scribbles, while the other maintains a watchful eye on the suspect. The patrol station several blocks away is abuzz with activity, officers coming and going, the hum of conversation and purposeful movement filling the air. In the distance, the gleaming spire of the courthouse rises above the cityscape, a reminder of the justice system that Officer Thompson is sworn to uphold. As she steps out of the car, the cool breeze carries with it the faintest hint of ozone from the nearby park, where children's laughter mingles with the hum of nearby businesses. The day is filled with challenges, but Officer Thompson is ready, her training kicking in, her senses keen, and her resolve unyielding.\", 'situation_json': '{\"text\": \"Patrol Officers are responsible for responding to incidents and ensuring public safety. In a bustling neighborhood, filled with towering buildings and tree-lined streets, Officer Leila Thompson steers her sleek, black squad car through the bustling traffic. Her eyes, hidden behind mirrored aviators, dart across the scene, taking in every detail. The squad car, a symbol of authority and reassurance, is equipped with flashing red and blue lights and a powerful siren, ready to cut through the cacophony of the city. Inside, the vehicle is a marvel of technology and functionality, with a dashboard filled with blinking lights and screens displaying maps and data feeds. Officer Thompson\\'s seat is adjustable, allowing her to find the perfect position for long shifts. The car\\'s interior smells faintly of new leather and the lingering scent of aftershave. To her left, a laptop whirs softly, displaying real-time data and alerts. A radio crackles intermittently, maintaining a constant line of communication with the patrol station. As she approaches the incident, she spots a small crowd of anxious citizens huddled together, their faces a mixture of concern and curiosity. Behind them, a man in a well-worn jacket stands defiantly, hands tucked into his pockets. Officer Thompson takes a deep breath, her hand resting on the smooth grip of her firearm, ready to handle whatever challenge may come her way. Nearby, two backup officers are already on scene, their patrol cars parked strategically to divert traffic. One is taking statements from eyewitnesses, his notebook filled with hurried scribbles, while the other maintains a watchful eye on the suspect. The patrol station several blocks away is abuzz with activity, officers coming and going, the hum of conversation and purposeful movement filling the air. In the distance, the gleaming spire of the courthouse rises above the cityscape, a reminder of the justice system that Officer Thompson is sworn to uphold. As she steps out of the car, the cool breeze carries with it the faintest hint of ozone from the nearby park, where children\\'s laughter mingles with the hum of nearby businesses. The day is filled with challenges, but Officer Thompson is ready, her training kicking in, her senses keen, and her resolve unyielding.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20):  99%|█████████▉| 718/723 [4:54:48<11:38, 139.74s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Security Guard', 'process': 'Access Control', 'situation': \"You are stationed at the entrance gate of an office building, tasked with the daily responsibility of controlling access. The entrance gate is the main point of entry, where you meticulously check IDs and inspect bags before granting entry. The gate is equipped with a state-of-the-art QR scanner, its sleek black surface contrasting against the stark white guard booth. Behind you, six large CCTV monitors in the security office hum quietly, providing a panoramic view of the parking lot and the building's perimeter. The monitors display crisp, high-definition images, illuminating the gray asphalt and the cars parked in orderly rows. On your right, a walkie-talkie sits on the counter, its antenna extended, ready for communication with your colleagues patrolling the premises. Your security uniform, a crisp blue shirt and black pants, bears the security company's emblem, exuding a sense of authority and professionalism. Across the street, the building occupants go about their daily routines, while visitors approach the gate with anticipation, eager to gain entry. Nearby, a group of your colleagues are engaged in a conversation, laughter occasionally breaking through the low hum of conversation. They, too, are clad in their uniforms, a testament to the cohesive teamwork that is essential in ensuring the building's security.\", 'situation_json': '{\"description\": \"You are stationed at the entrance gate of an office building, tasked with the daily responsibility of controlling access. The entrance gate is the main point of entry, where you meticulously check IDs and inspect bags before granting entry. The gate is equipped with a state-of-the-art QR scanner, its sleek black surface contrasting against the stark white guard booth. Behind you, six large CCTV monitors in the security office hum quietly, providing a panoramic view of the parking lot and the building\\'s perimeter. The monitors display crisp, high-definition images, illuminating the gray asphalt and the cars parked in orderly rows. On your right, a walkie-talkie sits on the counter, its antenna extended, ready for communication with your colleagues patrolling the premises. Your security uniform, a crisp blue shirt and black pants, bears the security company\\'s emblem, exuding a sense of authority and professionalism. Across the street, the building occupants go about their daily routines, while visitors approach the gate with anticipation, eager to gain entry. Nearby, a group of your colleagues are engaged in a conversation, laughter occasionally breaking through the low hum of conversation. They, too, are clad in their uniforms, a testament to the cohesive teamwork that is essential in ensuring the building\\'s security.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7953/7953 [00:00<00:00, 86430.64 examples/s]xamples] \n",
      "Filter: 100%|██████████| 4271/4271 [00:00<00:00, 77055.21 examples/s]\n",
      "Filter: 100%|██████████| 645/645 [00:00<00:00, 43129.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Fabricator', 'process': 'Documentation', 'situation': 'The scenario unfolds in the controlled environment of a construction site, teeming with the whirring of machinery and punctuated by the rhythmic clangs of metal on metal. The location is defined by its sprawling setting, a landscape dotted with colossal structures and mounds of raw materials. Our focus is on the fabricator, diligently occupied within the heart of this industrial hive. The fabricator is meticulously working through the documentation process, a crucial step that ensures the precision and quality of the fabricated components. The atmosphere is electric, charged with the continuous hum of CNC machines slicing through metal with surgical precision, while lathes and mills shape the raw materials into intricate forms. The workstation is a symphony of activity, with the fabricator methodically following the detailed blueprints sprawled across the workbench. Tools of the trade litter the space—hand tools like wrenches and pliers, measuring devices such as calipers and micrometers, all meticulously arranged. The cutting machine buzzes in the adjacent cutting room, while the shaping room glows with the heat from the hammering and molding activities. Nearby, the welding room is ablaze with the intense light of the welding machine, joining meticulously cut pieces into seamless wholes. The fabricator is not alone in this industrious ballet; the supervisor overlooks the progress, ensuring each task aligns with the project timeline. Working alongside are assemblers, meticulously piecing together the final products. The site pulses with a sense of collective purpose, each professional contributing to the complex symphony of construction. The surrounding area is carefully organized—tool storage and material storage are stocked with essential equipment and raw materials, while maintenance areas buzz with the steady work of keeping all machinery in top condition. Further out, the quality control area thrums with activity as inspectors diligently check the fabricated parts for any flaw. The overall scene is a harmonious blend of precision, craftsmanship, and teamwork, where the fabricator stands as a pivotal player in transforming raw materials into the building blocks of modern infrastructure.', 'situation_json': '{\"json_document\": \"{\\\\\"location\\\\\": \\\\\"construction site\\\\\", \\\\\"environment\\\\\": \\\\\"controlled\\\\\", \\\\\"sound\\\\\": \\\\\"whirring of machinery, rhythmic clangs of metal\\\\\", \\\\\"activities\\\\\": [\\\\\"documentation\\\\\", \\\\\"CNC machines slicing metal\\\\\", \\\\\"lathes and mills shaping materials\\\\\", \\\\\"welding machine joining pieces\\\\\", \\\\\"assemblers piecing final products\\\\\", \\\\\"inspectors checking parts\\\\\"], \\\\\"tools\\\\\": [\\\\\"wrenches\\\\\", \\\\\"pliers\\\\\", \\\\\"calipers\\\\\", \\\\\"micrometers\\\\\"], \\\\\"rooms\\\\\": [\\\\\"cutting room\\\\\", \\\\\"shaping room\\\\\", \\\\\"welding room\\\\\", \\\\\"tool storage\\\\\", \\\\\"material storage\\\\\", \\\\\"maintenance areas\\\\\", \\\\\"quality control area\\\\\"], \\\\\"machines\\\\\": [\\\\\"CNC machines\\\\\", \\\\\"lathes\\\\\", \\\\\"mills\\\\\", \\\\\"welding machine\\\\\"], \\\\\"people\\\\\": [\\\\\"supervisor\\\\\", \\\\\"assemblers\\\\\", \\\\\"inspectors\\\\\"], \\\\\"atmosphere\\\\\": \\\\\"electric, charged\\\\\", \\\\\"workstation\\\\\": \\\\\"symphony of activity\\\\\", \\\\\"blueprints\\\\\": \\\\\"detailed\\\\\", \\\\\"progress\\\\\": \\\\\"aligned with project timeline\\\\\", \\\\\"surrounding area\\\\\": \\\\\"organized\\\\\", \\\\\"collective purpose\\\\\": \\\\\"precision, craftsmanship, teamwork\\\\\", \\\\\"timeline\\\\\": \\\\\"aligned\\\\\"}\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20): 100%|█████████▉| 720/723 [4:54:57<03:32, 70.96s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Web Developer', 'process': 'Testing', 'situation': \"In the heart of a bustling Web Development Agency, a Web Developer meticulously embarks on the process of Testing. This activity, a daily occurrence, is carried out within a designated locality - a spacious, ergonomically designed office desk. The desk, positioned strategically in the quiet corner of the agency, is a hub of productivity, housing a sleek, high-performance laptop adorned with stickers of favorite coding languages. Accompanying this powerhouse is a sophisticated, high-resolution monitor, a precise, ergonomic mouse, and a comfortable, backlit keyboard. The developer, a seasoned professional, is encircled by walls adorned with code snippets, algorithms, and project timelines. A rich tapestry of programming languages, libraries, and frameworks dance across these walls, offering a visual testament to the developer's vast knowledge and experience. Around the office, a coffee maker gently hums in the corner, its aroma a subtle reminder of the long hours often invested in this craft. The nearby Collaboration Area, a communal space where team members convene to brainstorm and strategize, is currently vacant, its whiteboard filled with remnants of yesterday's meeting. The developer is well-equipped with an array of testing tools and software, such as Selenium, Postman, and JIRA, designed to automate and manage the testing process. Today's task involves an assortment of testing scripts and test cases, meticulously crafted to validate the robustness and reliability of a newly developed website. With a steaming cup of coffee by their side, the developer dives into the process, their keen eyes scanning lines of code, their fingers expertly navigating the keyboard, as they embark on the quest to ensure the website's functionality and user-friendliness.\", 'situation_json': '{\"location\": \"ergonomically designed office desk\", \"location_details\": {\"position\": \"in the quiet corner of the agency\", \"size\": \"spacious\"}, \"equipment\": {\"laptop\": {\"description\": \"high-performance\", \"stickers\": [\"favorite coding languages\"]}, \"monitor\": {\"description\": \"sophisticated, high-resolution\"}, \"mouse\": \"precise, ergonomic\", \"keyboard\": \"comfortable, backlit\"}, \"decorations\": {\"code snippets\": true, \"algorithms\": true, \"project timelines\": true, \"programming languages\": true, \"libraries\": true, \"frameworks\": true}, \"peripherals\": {\"coffee_maker\": {\"status\": \"humming\", \"location\": \"in the corner\"}}, \"collaboration_area\": {\"status\": \"vacant\", \"whiteboard_status\": \"filled with remnants of yesterday\\'s meeting\"}, \"equipped_tools\": [\"Selenium\", \"Postman\", \"JIRA\"], \"task_nature\": {\"description\": \"Testing\", \"tasks\": [\"script running\", \"code validation\", \"user-friendliness check\"], \"test_tools\": [\"testing scripts\", \"test cases\"]}}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20): 100%|█████████▉| 721/723 [5:11:45<11:44, 352.14s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Physical Therapist Assistant', 'process': 'Treatment Plan Implementation', 'situation': \"In the bustling, well-lit treatment room of a modern clinic, a Physical Therapist Assistant (PTA) is meticulously implementing a treatment plan for an elderly patient recovering from a hip replacement. The room is a symphony of equipment, precision, and care: a height-adjustable, navy blue therapy table takes center stage, its padded surface comforting and supportive, while an array of exercise equipment—resistance bands, weights, balance boards, and stability balls—lies neatly organized on shelves. A nearby computer, adorned with a quietly humming monitor, displays detailed patient charts and progress notes through the documentation software, its keyboard awaiting the PTA's frequent updates. The PTA's toolkit is extensive, with assistive devices like crutches, canes, and walkers standing ready in the corner, and therapeutic modalities such as thermotherapy units, cryotherapy units, and electrotherapy units tucked neatly along the walls, their LED displays glowing softly with standby readiness. In the adjacent waiting room, a handful of patients wait their turn, flipping through magazines or quietly chatting, their occasional laughter wafting through the slightly ajar door. The PTA, dressed in crisp, pale blue scrubs, guides the patient through a series of exercises, their movements purposeful and carefully monitored. The PTA's colleagues, clad in similar scrubs, buzz around the clinic, a hive of activity—some leading patients through exercises in the neighboring gym, others consulting with the supervising Physical Therapist (PT) in the PT’s office down the hall. The atmosphere is one of concentrated focus, where the dynamic interplay of modern medicine and human care merges seamlessly, all working towards the patient's steady progress and recovery.\", 'situation_json': '{\"description\": \"In the bustling, well-lit treatment room of a modern clinic, a Physical Therapist Assistant (PTA) is meticulously implementing a treatment plan for an elderly patient recovering from a hip replacement. The room is a symphony of equipment, precision, and care: a height-adjustable, navy blue therapy table takes center stage, its padded surface comforting and supportive, while an array of exercise equipment\\\\u2014resistance bands, weights, balance boards, and stability balls\\\\u2014lies neatly organized on shelves. A nearby computer, adorned with a quietly humming monitor, displays detailed patient charts and progress notes through the documentation software, its keyboard awaiting the PTA\\'s frequent updates. The PTA\\'s toolkit is extensive, with assistive devices like crutches, canes, and walkers standing ready in the corner, and therapeutic modalities such as thermotherapy units, cryotherapy units, and electrotherapy units tucked neatly along the walls, their LED displays glowing softly with standby readiness. In the adjacent waiting room, a handful of patients wait their turn, flipping through magazines or quietly chatting, their occasional laughter wafting through the slightly ajar door. The PTA, dressed in crisp, pale blue scrubs, guides the patient through a series of exercises, their movements purposeful and carefully monitored. The PTA\\'s colleagues, clad in similar scrubs, buzz around the clinic, a hive of activity\\\\u2014some leading patients through exercises in the neighboring gym, others consulting with the supervising Physical Therapist (PT) in the PT\\\\u2019s office down the hall. The atmosphere is one of concentrated focus, where the dynamic interplay of modern medicine and human care merges seamlessly, all working towards the patient\\'s steady progress and recovery.\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20): 100%|█████████▉| 722/723 [5:12:29<04:19, 259.71s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profession': 'Security Guard', 'process': 'CCTV Monitoring', 'situation': 'In the dimly lit, cubical security office, a lone security guard is stationed. Four large CCTV monitors sit on the desk in front of them, each displaying a live feed from a different surveillance camera installed throughout the building. The guard wears a crisp, dark blue uniform and a radio is clipped to their belt. A notepad and pen sit close at hand, ready for documenting any incidents that may occur during their shift. The building is quiet, with only the hum of the monitors and the occasional chatter from the security checkpoint breaking the silence. The guard watches the screens intently, scanning each for any signs of suspicious activity. Their eyes flick between the different feeds, constantly vigilant. The guard is there for the entirety of their shift, their presence a reassuring symbol of safety and security for all within the building.', 'situation_json': '{\"office_lighting\": \"dim\", \"office_description\": \"cubical\", \"monitor_count\": 4, \"monitor_size\": \"large\", \"monitor_display\": \"CCTV\", \"monitor_source\": \"live feed\", \"monitor_source_count\": 4, \"monitor_display_count\": 4, \"uniform_color\": \"dark blue\", \"uniform_type\": \"crisp\", \"equipment_on_belt\": \"radio\", \"equipment_belt_count\": 1, \"equipment_on_desk\": [\"notepad\", \"pen\"], \"equipment_on_desk_count\": 2, \"building_noise_level\": \"quiet\", \"building_noise_source\": [\"monitor hum\", \"occasional security checkpoint chatter\"], \"guard_presence\": \"entire shift\", \"guard_role\": \"reassuring symbol of safety and security\"}'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 990, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 233, in generate_covas_commentary\n",
      "    event = generate_event(messages)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 159, in generate_event\n",
      "    openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1014, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/luca/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py\", line 1024, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Dokumente/Elite-Dangerous-AI-Integration/train/utils.py\", line 25, in batch_map\n",
      "    results = results + fn(example)\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_68624/2983531137.py\", line 249, in generate_covas_commentary\n",
      "    raise Exception(\"Too many retries\")\n",
      "Exception: Too many retries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20): 100%|██████████| 723/723 [5:13:11<00:00, 25.99s/ examples] \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 30.64ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/lucaelin/generic_covas_commentary/commit/6a5d2c2b9237860b7055e02b8ec8d24fb6051f50', commit_message='Upload dataset', commit_description='', oid='6a5d2c2b9237860b7055e02b8ec8d24fb6051f50', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import time\n",
    "from datasets import load_dataset, Dataset\n",
    "import json\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "import os\n",
    "from transformers.utils.logging import disable_progress_bar, enable_progress_bar\n",
    "\n",
    "\n",
    "default_or_options = {\n",
    "    \"max_tokens\": 8191,\n",
    "\n",
    "    \"extra_body\": {\n",
    "        \"provider\": {\n",
    "            \"ignore\": [\n",
    "                \"Hyperbolic\"\n",
    "            ],\n",
    "            \"require_parameters\": True,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "domain_events = load_dataset(\"lucaelin/generic_domain_events_v1\", split=\"train\")\n",
    "domain_action_calls = load_dataset(\"lucaelin/generic_domain_action_dialogs_v1\", split=\"train\")\n",
    "domain_actions = load_dataset(\"lucaelin/generic_domain_actions_v1\", split=\"train\")\n",
    "\n",
    "def clean_tool_id(tool_id):\n",
    "    return tool_id.replace(\" \", \"\").replace('_', '').replace('-', '')[0:9]\n",
    "\n",
    "def filter_metadata(dialog):\n",
    "    dialog = json.loads(json.dumps(dialog))\n",
    "    for msg in dialog:\n",
    "        if \"_metadata\" in msg:\n",
    "            del msg[\"_metadata\"]\n",
    "        if not 'content' in msg:\n",
    "            msg['content'] = ''\n",
    "        if 'tool_call_id' in msg:\n",
    "            msg['tool_call_id'] = clean_tool_id(msg['tool_call_id'])\n",
    "        if 'tool_calls' in msg:\n",
    "            for tool_call in msg['tool_calls']:\n",
    "                if 'id' in tool_call:\n",
    "                    tool_call['id'] = clean_tool_id(tool_call['id'])\n",
    "    \n",
    "    return dialog\n",
    "\n",
    "def generate_covas_commentary(entry):\n",
    "    results = []\n",
    "\n",
    "    available_tool_models = [\n",
    "        #'anthropic/claude-3.5-sonnet-20240620',\n",
    "        #'openai/chatgpt-4o-latest',\n",
    "        #'openai/gpt-4o-mini-2024-07-18',\n",
    "        \"mistralai/mistral-nemo\",\n",
    "        \"mistralai/mixtral-8x22b-instruct\",\n",
    "        \"mistralai/mistral-large\"\n",
    "    ]\n",
    "    available_text_models = [\n",
    "        #'anthropic/claude-3.5-sonnet-20240620',\n",
    "        #'openai/chatgpt-4o-latest',\n",
    "        #'openai/gpt-4o-mini-2024-07-18',\n",
    "        'nousresearch/hermes-3-llama-3.1-70b',\n",
    "        'nousresearch/hermes-3-llama-3.1-405b',\n",
    "        'meta-llama/llama-3.1-405b-instruct',\n",
    "        'meta-llama/llama-3.1-70b-instruct',\n",
    "        \"mistralai/mixtral-8x22b-instruct\",\n",
    "        \"mistralai/mixtral-8x22b-instruct\",\n",
    "        \"mistralai/mixtral-8x22b-instruct\",\n",
    "        \"mistralai/mixtral-8x22b-instruct\",\n",
    "        \"mistralai/mistral-large\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    disable_progress_bar()\n",
    "    related_domain_events = domain_events.filter(lambda x: x[\"profession\"] == entry[\"profession\"]).to_list()\n",
    "    if not related_domain_events:\n",
    "        return []\n",
    "    related_domain_actions = domain_actions.filter(lambda x: x[\"profession\"] == entry[\"profession\"]).to_list()\n",
    "    if not related_domain_actions:\n",
    "        return []\n",
    "    related_domain_action_calls = domain_action_calls.filter(lambda x: x[\"profession\"] == entry[\"profession\"] and x[\"process\"] == entry[\"process\"] and len(x[\"dialog\"])<15000).to_list()\n",
    "    enable_progress_bar()\n",
    "    tools = []\n",
    "\n",
    "    for action in related_domain_actions:\n",
    "        if len(action['parameter_schema']) < 10:\n",
    "            continue\n",
    "        name_lower = action[\"name\"].lower()\n",
    "        name_capitalized = ' '.join([word.lower().capitalize() for word in action[\"name\"].split(' ')])\n",
    "        action_names = [\n",
    "            name_lower.replace(\" \", \"_\"),\n",
    "            name_lower.replace(\" \", \"\"),\n",
    "            name_lower.replace(\" \", \"-\"),\n",
    "            name_capitalized.replace(\" \", \"_\"),\n",
    "            name_capitalized.replace(\" \", \"\"),\n",
    "            name_capitalized.replace(\" \", \"-\"),\n",
    "        ]\n",
    "\n",
    "        model = random.choice(available_tool_models)\n",
    "        function_name = random.choice(action_names)\n",
    "        function = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": function_name,\n",
    "                \"description\": action[\"description\"],\n",
    "                \"parameters\": json.loads(action['parameter_schema']),\n",
    "            },\n",
    "        }\n",
    "        tools.append(function)\n",
    "    \n",
    "    #print (\"tools \", tools)\n",
    "\n",
    "    user_name = random.choice(random_names)\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Let's roleplay as a {entry['profession']}.\\n\"\n",
    "            \"I will provide events in parentheses; do not create new ones. \" +\n",
    "            \"Do not hallucinate any information that is not given to you. Do not use markdown in your responses. \" +\n",
    "            f\"I am {user_name}, a professional {entry['profession']}. You are my digital assistant, sometimes also addressed as Computer. \"+\n",
    "            \"You possess extensive knowledge and can provide detailed and accurate information on a wide range of topics. \" +\n",
    "            \"Reply within one sentence, acknowledge orders, mention status/location only if relevant or asked, and don't end with a question.\"+\n",
    "            \"Guide and support me with witty commentary and humorous observations.\"\n",
    "\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"_metadata\": {\n",
    "            \"type\": \"situation\",\n",
    "            \"situation\": json.loads(entry['situation_json']),\n",
    "        },\n",
    "        \"content\": f\"(Current situation: {entry['situation_json']})\"\n",
    "    }]\n",
    "\n",
    "    def generate_commentary(dialog):\n",
    "        model = random.choice(available_text_models)\n",
    "        openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=filter_metadata(dialog),\n",
    "            #tools=tools,\n",
    "            #tool_choice=\"required\",\n",
    "            **default_or_options,\n",
    "        )\n",
    "        comment = openrouter_response.choices[0].message.content.strip()\n",
    "        if comment.startswith(\"Computer: \"):\n",
    "            comment = comment[len(\"Computer: \"):]\n",
    "        if comment.startswith('\"'):\n",
    "            comment = comment[1:-1]\n",
    "\n",
    "        return [{\n",
    "            \"role\": \"assistant\",\n",
    "            \"_metadata\": {\n",
    "                \"type\": \"comment\",\n",
    "            },\n",
    "            \"content\": comment\n",
    "        }]\n",
    "\n",
    "    def generate_event(dialog):\n",
    "        model = \"mistralai/mistral-nemo\"\n",
    "        event_names = [event[\"name\"] for event in related_domain_events]\n",
    "        random.shuffle(event_names)\n",
    "        openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=filter_metadata(dialog)+[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Continue the roleplay by selecting one of the available events, that best fits the current situation. Use the select_next_event tool to choose an event.\"\n",
    "            }],\n",
    "            tools=[{\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"select_next_event\",\n",
    "                    \"description\": \"Select the next event to happen in the roleplay.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"next_event\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": event_names,\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            }],\n",
    "            tool_choice=\"required\",\n",
    "            **default_or_options,\n",
    "        )\n",
    "        #print(dialog)\n",
    "        #print(openrouter_response)\n",
    "        event_name = json.loads(openrouter_response.choices[0].message.tool_calls[0].function.arguments)[\"next_event\"]\n",
    "        event_definitions = [event for event in related_domain_events if event[\"name\"] == event_name and len(event[\"schema\"]) > 10]\n",
    "        if not event_definitions:\n",
    "            return []\n",
    "        event_definition = event_definitions[0]\n",
    "        \n",
    "        model = random.choice(available_tool_models)\n",
    "        openrouter_response: ChatCompletion = openrouter.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=filter_metadata(dialog)+[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Continue the roleplay by creatily inventing additional content for the event {event_name} that matches the previous discussion, but may also introduce new entities. Use the generate_next_event tool to create the event.\"\n",
    "            }],\n",
    "            tools=[{\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"generate_next_event\",\n",
    "                    \"description\": \"Generate the next event to happen in the roleplay.\",\n",
    "                    \"parameters\": json.loads(event_definition[\"schema\"]),\n",
    "                },\n",
    "            }],\n",
    "            tool_choice=\"required\",\n",
    "            **default_or_options,\n",
    "        )\n",
    "        #print(dialog)\n",
    "        #print(openrouter_response)\n",
    "        event_content = json.loads(openrouter_response.choices[0].message.tool_calls[0].function.arguments)\n",
    "\n",
    "        return [{\n",
    "            \"role\": \"user\",\n",
    "            \"_metadata\": {\n",
    "                \"type\": \"event\",\n",
    "                \"name\": event_name,\n",
    "                \"content\": event_content,\n",
    "                \"definition\": event_definition,\n",
    "            },\n",
    "            \"content\": f\"({event_name}, details: {json.dumps(event_content)})\"\n",
    "        }]\n",
    "    \n",
    "    retries = 0\n",
    "    runs = 0\n",
    "    while len(filter_metadata(messages)) < 40 or (messages and messages[-1][\"role\"] != \"assistant\"):\n",
    "        runs += 1\n",
    "        if runs > 80:\n",
    "            raise Exception(\"Too many runs\")\n",
    "        #print(\"tokens\",len(json.dumps(filter_metadata(messages))) / 4)\n",
    "        try:\n",
    "            event = generate_event(messages)\n",
    "            #print(\"event \", event)\n",
    "            messages = messages + event\n",
    "            if event and event[0]['_metadata']['definition']['severity']=='high' or random.random() < 0.2:\n",
    "                comment = generate_commentary(messages)\n",
    "                #print(\"comment \", comment)\n",
    "                messages = messages + comment\n",
    "            if related_domain_action_calls and random.random() > 0.1:\n",
    "                tool_call = random.choice(related_domain_action_calls)\n",
    "                related_domain_action_calls.remove(tool_call)\n",
    "                tool_call_dialog = json.loads(tool_call[\"dialog\"])\n",
    "                #print(\"tool \", tool_call_dialog)\n",
    "                messages = messages + tool_call_dialog\n",
    "            retries = 0\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            if retries > 10:\n",
    "                raise Exception(\"Too many retries\")\n",
    "            #print(\"ERROR \", e)\n",
    "            #traceback.print_exc()\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        \n",
    "    if related_domain_action_calls:\n",
    "        tool_call = random.choice(related_domain_action_calls)\n",
    "        related_domain_action_calls.remove(tool_call)\n",
    "        tool_call_dialog = json.loads(tool_call[\"dialog\"])\n",
    "        #print(\"tool \", tool_call_dialog)\n",
    "        messages = messages + tool_call_dialog\n",
    "\n",
    "    results.append({\n",
    "        \"profession\": entry[\"profession\"],\n",
    "        \"process\": entry[\"process\"],\n",
    "        \"tools\": tools,\n",
    "        \"messages\": messages,\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "situations = load_dataset(\"lucaelin/domain_situations_v1\", split=\"train\")\n",
    "covas_commentary = situations.map(\n",
    "    sane_batch_map(generate_covas_commentary, {\"profession\": [], \"process\": [], \"tools\": [], \"messages\": []}), \n",
    "    batched=True, \n",
    "    batch_size=1, \n",
    "    num_proc=20, \n",
    "    remove_columns=situations.column_names\n",
    ")\n",
    "#covas_commentary.sort([\"profession\", \"process\"]).to_list()\n",
    "covas_commentary.sort([\"profession\", \"process\"]).push_to_hub(\"lucaelin/generic_covas_commentary\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "46849bd1b027480baf88dab488a46042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d4b45afa5e2488b93e5783fed96e321": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd02dcbafd754cdda919a6db0df33673",
      "max": 22883,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a9be91da3425445cb13fe4cc700d772d",
      "value": 22883
     }
    },
    "7ab5d845e60549238af993a7056cecc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b46fcd53f384570b87d5f4f54c64acc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "833b2f5fc84c4db689edc5dd99731a70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d77eb89c3d747e79efd1f7d745b5883": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91b4a46a4ceb460a922d4c882af792fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_833b2f5fc84c4db689edc5dd99731a70",
      "placeholder": "​",
      "style": "IPY_MODEL_46849bd1b027480baf88dab488a46042",
      "value": "Downloading readme: 100%"
     }
    },
    "a2dd77a4b781486ea107cc801d48ccd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d77eb89c3d747e79efd1f7d745b5883",
      "placeholder": "​",
      "style": "IPY_MODEL_7ab5d845e60549238af993a7056cecc0",
      "value": " 22.9k/22.9k [00:00&lt;00:00, 625kB/s]"
     }
    },
    "a9be91da3425445cb13fe4cc700d772d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cca51da725594073bd449ff599cb95e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_91b4a46a4ceb460a922d4c882af792fb",
       "IPY_MODEL_5d4b45afa5e2488b93e5783fed96e321",
       "IPY_MODEL_a2dd77a4b781486ea107cc801d48ccd5"
      ],
      "layout": "IPY_MODEL_7b46fcd53f384570b87d5f4f54c64acc"
     }
    },
    "dd02dcbafd754cdda919a6db0df33673": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
