{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"unsloth/Llama-3.2-8B-Instruct-bnb-4bit\" #\"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
    "target_model_name = \"unsloth/Llama-3.2-8B-Instruct-bnb-4bit\"\n",
    "model_name = \"lucaelin/llama-3.2-8b-instruct-cn\"\n",
    "\n",
    "dataset_name = \"lucaelin/generic_covas_commentary\"\n",
    "\n",
    "max_sequence_length = 16*1024\n",
    "lora_rank = 32\n",
    "lora_alpha = 8\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0.01\n",
    "\n",
    "instruction_template = \"<|start_header_id|>\"\n",
    "response_template = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "chat_template = \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set role = message['role'] %}{% if 'tool_calls' in message %}{% set text = '<tool_call>' + {'name': message['tool_calls'][0]['function']['name'], 'arguments':message['tool_calls'][0]['function']['arguments']|from_json}|tojson + '</tool_call>' %}{% endif %}{% if 'content' in message %}{% set text = message['content'] %}{% endif %}{% if loop.index0 == 0 and tools is defined %}{% set text = message['content'] + '\\n\\nYou are able to call the following tools, when needed, call them using the <tool_call> xml-tag, followed by name and arguments as json.\\n<tools>\\n' + tools|tojson + '\\n</tools>' %}{% endif %}{% set content = '<|start_header_id|>' + role + '<|end_header_id|>\\n\\n'+ text | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2eSvM9zX_2d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: unsloth in /usr/local/lib/python3.10/dist-packages (2024.12.2)\n",
      "Requirement already satisfied: unsloth_zoo>=2024.11.8 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2024.12.1)\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.0.28.post3)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.0)\n",
      "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (23.2)\n",
      "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.9.2)\n",
      "Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.46.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.1.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.24.1)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.0)\n",
      "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.12.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.26.5)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (0.20.3)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n",
      "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth) (24.12.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth) (9.3.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import jinja2\n",
    "jinja2.filters.FILTERS[\"fromjson\"] = lambda s: json.loads(s)\n",
    "jinja2.filters.FILTERS[\"from_json\"] = lambda s: json.loads(s)\n",
    "\n",
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "#!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460,
     "referenced_widgets": [
      "81431ee0c4014e569f89d4db77e801c5",
      "957bec7688dc42f9bb646b93277a1ccf",
      "a0affc04135f4b47aea15cb9b507b42a",
      "c853c5846e624919845211b299ab2f89",
      "7755d3bce2b940b18d8be3fb523ce08f",
      "9e977661393b4bec9d7f4b43347ad517",
      "f6825138d622477b82c6db6c3dc4f981",
      "eacf56d64bde47d594c72cf2e29d4531",
      "da048becbcdc482480f56be16c1db833",
      "9b4854cfcf6a4fd8be08714450eeee1c",
      "539cc66ddafe4ae6be7d1cfdd44c7f34",
      "b4c1e899d7a54301a3f21811039ea4e0",
      "13e947556fba4c44aaf02387040f5f8d",
      "c3e179de69f645298ff286123a79ef30",
      "a6e782277e9e433f937bf30a5dd04eda",
      "1afbd3e59ee946bf84d90521744f6602",
      "c71b169b09574eea9d24366124e5d4df",
      "e6965284c2244cca9bcd9ba18f61112e",
      "8333bc5cb44e4c3dbb41984f153b7fec",
      "711ac2da1a3e4f5fb762efcad466da9c",
      "457ccf4f4b2245fc905f8f11ed8e3296",
      "7a0f5c5af6e14063811c6c408f5bc8b2",
      "46661708ba1e4300ba92f23dc1c12a36",
      "77971a174e7f47979d7f5240455f4869",
      "e579e9e451ad43c7bebf8ec1bd5bc904",
      "18ddc325a03e4db1a7e56a2ea866cb1e",
      "a9ed6f8d80ed452d8dd12dd1245f6b54",
      "fa1be90b906648218529df89cc2bc77b",
      "36996a833ecb487eafcb506d11df8d9c",
      "65d24a42a0e34f07b25ab7e4ab219e77",
      "d8f9046ff66b430ea6749fdc08bb37bc",
      "879c5ac1b5004fa6ab711132f7babefe",
      "c8630201b006437a92b25b0338dc0795",
      "5acddc0142ab43dbbf7809f2cc03a674",
      "f5c02ba49dc54144b9141e19d6c29c32",
      "626b80709c7d4f32aecc07bb8c81cbd7",
      "76f9298d58b34c7586f33e4bb49dd817",
      "89d94add4ea04a1280a19b65b9e9d9a1",
      "8301893220784edba5cb88a104812648",
      "7da28cce72c041f9b35aeb3fb0540789",
      "9a4789c8c1b7454b940e5de7b543b722",
      "4cc307a9804547e6b59cb706cfad5a36",
      "e1a04bb25a144252aeb728b98e035677",
      "4b9e83685d074b98a36b92082aeb9093",
      "fe835885fe79493b86f4e4d294d3a543",
      "6b15532369234017a31d8c7223d24174",
      "7a328c1e583c4176811364f39d990384",
      "94233ed90a184e0aa91b4cb076f4f442",
      "65f2e1b6aec44ca4881784fe4601d388",
      "5a2c74b47b9847dab610ca6655e0f7d0",
      "6ec6ec51e4834b63a7322beeb8eaf709",
      "553abeeabccf499f8603ee6a7cc8a065",
      "06712075454443c8ab5c52815c72d5dd",
      "8f3758f6b87c4b3581728cfa526f9101",
      "534a467eaff546f8a6ad92b9a88f25db"
     ]
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "d5a55e3d-5de3-4051-8c1f-c3124babd080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2024.12.2: Fast Llama patching. Transformers:4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA A100 80GB PCIe. Max memory: 79.254 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = base_model_name, # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_sequence_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "bb26c583-0096-4464-8407-9ea79f6301c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.12.2 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = lora_alpha,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep\n",
    "We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n",
    "\n",
    "```\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "I'm great thanks!<|eot_id|>\n",
    "```\n",
    "\n",
    "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "5d6750f0aab342e981230ba969c70647",
      "c1a9b4bf8f9e462baaddbc9f5094c2b0",
      "80dab17e457f4221a5a291fe002b117e",
      "08cf2c12d955445097c34472052d01d6",
      "fad669c53606411f9a5ec0e771eec103",
      "76b3a5c56a8a4085873b0df59e8c4e75",
      "2c59b3b7217c420d9d7e1808823b2fc7",
      "93a98313ab4243aab95d7d3bd18dac33",
      "f58f2226530a41589bfcb1e45024161d",
      "fc849401ac4d4f62914b092553fe26d8",
      "9c840addea8d49b5830a50299e9ad5b8",
      "f1b590c4c9e44f358414311b5f350234",
      "c812e37c3df44866931c70a135b13593",
      "b19dd633f71546e39993b6c6e8d45e7c",
      "cfad018b0b904aef9825b268762498bc",
      "3e8c89ebdf3040ada123e51d0173c47b",
      "8f8def3f89034d0cbdc0ec3ac5973893",
      "921532441ab64f70bb20cad182feef5e",
      "54e169a109d048dc9008a9927bbad271",
      "685932bd693c4fed92068aa8264b4abf",
      "bde93e48839245638bfcdb22c4d10d77",
      "d694238683f4479aa42d3dea59faaef4",
      "638d43923e7840ba8cf8d7469e539165",
      "dca78a6e174b448ead4fbbe144826646",
      "20a621224c554bbea2d6ccc9598f436e",
      "a4a9a05d58424b6da90c767faf21dfc8",
      "c55e88a98a85445a99edc785a65bc1ee",
      "fe04310dd3a444088e14ee574cbedcc2",
      "55d868afd9734a9c96a50b1fe67682cc",
      "85690ddbef6442f19fce19a7faefda0a",
      "0e07054d52134877bdd80a3ff65297bc",
      "16a87294753647da8cf09e0dd812630d",
      "5fc677217a20451cadc89026ae10f029"
     ]
    },
    "id": "LjY75GoYUCB8",
    "outputId": "7598338b-c0cc-4044-de05-f0718f1365b4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2ef02f410f494183a29d22e7f57a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1416 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "import json\n",
    "\n",
    "tokenizer.chat_template = chat_template\n",
    "\n",
    "def formatting_prompts_func(example):\n",
    "    messages = json.loads(example[\"messages\"])\n",
    "    tools = json.loads(example[\"tools\"])\n",
    "    text = tokenizer.apply_chat_template(messages, tools=tools, tokenize = False, add_generation_prompt = False)\n",
    "    return { \"text\" : text, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(dataset_name, split = \"train\")\n",
    "\n",
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "dataset = dataset.map(formatting_prompts_func, batched = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGFzmplrEy9I",
    "outputId": "412e1530-1d16-4a32-8a80-4b302a1ded6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"role\": \"user\", \"content\": \"Can you please book a flight for me from New York to London?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but I\\'m unable to book flights. My current capabilities allow me to search for products based on given criteria such as keywords, category, and price range. Is there anything else I can assist you with within these capabilities?\"}, {\"role\": \"user\", \"content\": \"Hey, can you check if 7 is a prime number?\"}, {\"role\": \"assistant\", \"content\": \"Sure, let me check that for you.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_9539d87f-8e3b-487a-a497-4cca6cabb0d7\", \"type\": \"function\", \"function\": {\"name\": \"check_prime_number\", \"arguments\": \"{\\\\\"number\\\\\": 7}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"isPrime\\\\\": true}\", \"tool_call_id\": \"call_9539d87f-8e3b-487a-a497-4cca6cabb0d7\"}, {\"role\": \"assistant\", \"content\": \"Yes, 7 is a prime number.\"}, {\"role\": \"user\", \"content\": \"Great! Now, can you order a pizza for me?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but as an AI, I don\\'t have the capability to perform external tasks such as ordering a pizza. I can assist you with information and perform functions that I have been programmed with.\"}, {\"role\": \"user\", \"content\": \"I need to create a new contact for my friend John Doe.\"}, {\"role\": \"assistant\", \"content\": \"Sure, I can help with that. Could you please provide me with John Doe\\'s phone number and email address?\"}, {\"role\": \"user\", \"content\": \"Yes, his phone number is 123-456-7890 and his email is johndoe@example.com.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_9dc72977-4602-41ae-ad90-d4d7b3e48c17\", \"type\": \"function\", \"function\": {\"name\": \"create_contact\", \"arguments\": \"{\\\\\"name\\\\\": \\\\\"John Doe\\\\\", \\\\\"phone_number\\\\\": \\\\\"123-456-7890\\\\\", \\\\\"email\\\\\": \\\\\"johndoe@example.com\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"status\\\\\": \\\\\"success\\\\\", \\\\\"message\\\\\": \\\\\"Contact for John Doe has been successfully created\\\\\"}\", \"tool_call_id\": \"call_9dc72977-4602-41ae-ad90-d4d7b3e48c17\"}, {\"role\": \"assistant\", \"content\": \"I have successfully created the contact for John Doe with the provided phone number and email address.\"}, {\"role\": \"user\", \"content\": \"Can you please order a pizza for me?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but I can\\'t assist with that. My current capabilities are limited to creating todo items. I don\\'t have the ability to place orders or perform external tasks.\"}, {\"role\": \"user\", \"content\": \"Hi, I need to know the distance between New York and Los Angeles.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_07d80275-3030-4b57-9cb5-f7ab10528057\", \"type\": \"function\", \"function\": {\"name\": \"calculate_distance\", \"arguments\": \"{\\\\\"origin\\\\\": \\\\\"New York\\\\\", \\\\\"destination\\\\\": \\\\\"Los Angeles\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"distance\\\\\": \\\\\"2448 miles\\\\\"}\", \"tool_call_id\": \"call_07d80275-3030-4b57-9cb5-f7ab10528057\"}, {\"role\": \"assistant\", \"content\": \"The distance between New York and Los Angeles is approximately 2448 miles.\"}, {\"role\": \"user\", \"content\": \"That\\'s quite a distance. What about the distance from Los Angeles to Miami?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_07d80275-3030-4b57-9cb5-f7ab10528057\", \"type\": \"function\", \"function\": {\"name\": \"calculate_distance\", \"arguments\": \"{\\\\\"origin\\\\\": \\\\\"Los Angeles\\\\\", \\\\\"destination\\\\\": \\\\\"Miami\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"distance\\\\\": \\\\\"2342 miles\\\\\"}\", \"tool_call_id\": \"call_07d80275-3030-4b57-9cb5-f7ab10528057\"}, {\"role\": \"assistant\", \"content\": \"The distance between Los Angeles and Miami is approximately 2342 miles.\"}, {\"role\": \"user\", \"content\": \"Thank you for the information.\"}, {\"role\": \"assistant\", \"content\": \"You\\'re welcome! If you have any other questions, feel free to ask.\"}, {\"role\": \"user\", \"content\": \"Hi, I need help with calculating my loan payment.\"}, {\"role\": \"assistant\", \"content\": \"Of course, I can help with that. Could you please provide me with the principal amount, the annual interest rate, and the term of the loan in years?\"}, {\"role\": \"user\", \"content\": \"Sure, the principal amount is $50000, the annual interest rate is 5.5%, and the term is 15 years.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_e8528aa1-32c6-48dd-90b7-6d9b362c83d4\", \"type\": \"function\", \"function\": {\"name\": \"calculate_loan_payment\", \"arguments\": \"{\\\\\"principal\\\\\": 50000, \\\\\"interest_rate\\\\\": 5.5, \\\\\"term\\\\\": 15}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"monthly_payment\\\\\": \\\\\"408.54\\\\\"}\", \"tool_call_id\": \"call_e8528aa1-32c6-48dd-90b7-6d9b362c83d4\"}, {\"role\": \"assistant\", \"content\": \"Based on the information you provided, your monthly loan payment would be approximately $408.54.\"}, {\"role\": \"user\", \"content\": \"I need to schedule a meeting for tomorrow.\"}, {\"role\": \"assistant\", \"content\": \"Sure, I can help with that. Could you please provide me with the title of the meeting, and the start and end times?\"}, {\"role\": \"user\", \"content\": \"The meeting is titled \\\\\"Project Discussion\\\\\". It should start at 10:00 AM and end at 11:30 AM.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_17007ea3-3e8a-4963-9225-98b538291f45\", \"type\": \"function\", \"function\": {\"name\": \"create_calendar_event\", \"arguments\": \"{\\\\\"title\\\\\": \\\\\"Project Discussion\\\\\", \\\\\"start_time\\\\\": \\\\\"10:00 AM\\\\\", \\\\\"end_time\\\\\": \\\\\"11:30 AM\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"status\\\\\": \\\\\"success\\\\\", \\\\\"message\\\\\": \\\\\"Event \\'Project Discussion\\' has been successfully created for tomorrow from 10:00 AM to 11:30 AM.\\\\\"}\", \"tool_call_id\": \"call_17007ea3-3e8a-4963-9225-98b538291f45\"}, {\"role\": \"assistant\", \"content\": \"The meeting titled \\\\\"Project Discussion\\\\\" has been successfully scheduled for tomorrow from 10:00 AM to 11:30 AM.\"}, {\"role\": \"user\", \"content\": \"Can you please order a pizza for me?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but I\\'m unable to perform external tasks such as ordering a pizza. My capabilities are currently limited to providing definitions of words.\"}, {\"role\": \"user\", \"content\": \"I saw a dress that I liked. It was originally priced at $100 but it\\'s on a 20% discount. How much will it cost now?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_0026ee7c-e653-4a3a-85b0-c135f2f89a95\", \"type\": \"function\", \"function\": {\"name\": \"calculate_discount\", \"arguments\": \"{\\\\\"original_price\\\\\": 100, \\\\\"discount_percentage\\\\\": 20}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"discounted_price\\\\\": 80}\", \"tool_call_id\": \"call_0026ee7c-e653-4a3a-85b0-c135f2f89a95\"}, {\"role\": \"assistant\", \"content\": \"The dress will now cost you $80 after the discount.\"}, {\"role\": \"user\", \"content\": \"Can you please order a pizza for me?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but as an AI, I don\\'t have the capability to perform external tasks such as ordering a pizza. My current function allows me to calculate the tip amount for a bill. If you need help with that, feel free to ask!\"}, {\"role\": \"user\", \"content\": \"Hi, can you help me find the greatest common divisor of 36 and 48?\"}, {\"role\": \"assistant\", \"content\": \"Sure, I can help with that. Let me calculate it for you.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_3ad2e5c1-e4a0-4300-854c-7edf54abcb7e\", \"type\": \"function\", \"function\": {\"name\": \"calculate_gcd\", \"arguments\": \"{\\\\\"number1\\\\\": 36, \\\\\"number2\\\\\": 48}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"gcd\\\\\": 12}\", \"tool_call_id\": \"call_3ad2e5c1-e4a0-4300-854c-7edf54abcb7e\"}, {\"role\": \"assistant\", \"content\": \"The greatest common divisor of 36 and 48 is 12.\"}, {\"role\": \"user\", \"content\": \"That\\'s great! Can you also help me book a flight to New York?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but as an AI, I don\\'t have the capability to perform external tasks such as booking flights. My current functions are limited to calculating the greatest common divisor of two numbers.\"}, {\"role\": \"user\", \"content\": \"Hi, I need to ship a package to New York. It weighs about 5 pounds. Can you tell me how much it will cost?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_74546d14-b8ec-4ea8-8b6e-a31cc0b33d35\", \"type\": \"function\", \"function\": {\"name\": \"calculate_shipping\", \"arguments\": \"{\\\\\"weight\\\\\": 5, \\\\\"destination\\\\\": \\\\\"New York\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"cost\\\\\": 15.75}\", \"tool_call_id\": \"call_74546d14-b8ec-4ea8-8b6e-a31cc0b33d35\"}, {\"role\": \"assistant\", \"content\": \"The cost to ship your package to New York will be $15.75.\"}, {\"role\": \"user\", \"content\": \"Great, thanks for the information. Now, I have another package that weighs 10 pounds and it needs to be shipped to Los Angeles. Can you calculate the cost for this one as well?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_74546d14-b8ec-4ea8-8b6e-a31cc0b33d35\", \"type\": \"function\", \"function\": {\"name\": \"calculate_shipping\", \"arguments\": \"{\\\\\"weight\\\\\": 10, \\\\\"destination\\\\\": \\\\\"Los Angeles\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"cost\\\\\": 20.50}\", \"tool_call_id\": \"call_74546d14-b8ec-4ea8-8b6e-a31cc0b33d35\"}, {\"role\": \"assistant\", \"content\": \"The cost to ship your second package to Los Angeles will be $20.50.\"}, {\"role\": \"user\", \"content\": \"Hi, I need to convert a temperature from Fahrenheit to Celsius. The temperature is 98.6 degrees Fahrenheit.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_a56e27ab-aa7b-40b5-b51b-25290b3b8fc1\", \"type\": \"function\", \"function\": {\"name\": \"convert_temperature\", \"arguments\": \"{\\\\\"temperature\\\\\": 98.6, \\\\\"from_unit\\\\\": \\\\\"Fahrenheit\\\\\", \\\\\"to_unit\\\\\": \\\\\"Celsius\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"converted_temperature\\\\\": 37}\", \"tool_call_id\": \"call_a56e27ab-aa7b-40b5-b51b-25290b3b8fc1\"}, {\"role\": \"assistant\", \"content\": \"The converted temperature from 98.6 degrees Fahrenheit to Celsius is 37 degrees.\"}, {\"role\": \"user\", \"content\": \"Great, now can you convert 0 degrees Celsius to Fahrenheit?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_a56e27ab-aa7b-40b5-b51b-25290b3b8fc1\", \"type\": \"function\", \"function\": {\"name\": \"convert_temperature\", \"arguments\": \"{\\\\\"temperature\\\\\": 0, \\\\\"from_unit\\\\\": \\\\\"Celsius\\\\\", \\\\\"to_unit\\\\\": \\\\\"Fahrenheit\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"converted_temperature\\\\\": 32}\", \"tool_call_id\": \"call_a56e27ab-aa7b-40b5-b51b-25290b3b8fc1\"}, {\"role\": \"assistant\", \"content\": \"The converted temperature from 0 degrees Celsius to Fahrenheit is 32 degrees.\"}, {\"role\": \"user\", \"content\": \"Thank you for your help!\"}, {\"role\": \"assistant\", \"content\": \"You\\'re welcome! If you have any other questions, feel free to ask.\"}, {\"role\": \"user\", \"content\": \"I\\'m looking for a recipe that uses chicken.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_a07fafa0-de64-4d25-b643-ca4ff399742d\", \"type\": \"function\", \"function\": {\"name\": \"search_recipe\", \"arguments\": \"{\\\\\"keyword\\\\\": \\\\\"chicken\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"results\\\\\": [{\\\\\"name\\\\\": \\\\\"Chicken Parmesan\\\\\", \\\\\"ingredients\\\\\": [\\\\\"chicken\\\\\", \\\\\"parmesan\\\\\", \\\\\"tomato sauce\\\\\", \\\\\"spaghetti\\\\\"], \\\\\"instructions\\\\\": \\\\\"Preheat oven to 450 degrees F (230 degrees C). Pound chicken breasts to 1/2 inch thickness. Sprinkle each piece of chicken on both sides with salt and pepper. Place bread crumbs in a bowl. In a separate bowl, whisk together the egg and water. Dip each piece of chicken in the egg mixture, then in the bread crumbs, and place in a shallow baking dish. Bake in the preheated oven for 15 minutes. Turn chicken pieces over and bake for another 15 minutes, or until no longer pink and juices run clear. Top with tomato sauce and Parmesan cheese. Bake for an additional 5 minutes, or until cheese is melted and bubbly. Serve over spaghetti.\\\\\"}]}\", \"tool_call_id\": \"call_a07fafa0-de64-4d25-b643-ca4ff399742d\"}, {\"role\": \"assistant\", \"content\": \"I found a recipe for Chicken Parmesan. You\\'ll need chicken, parmesan, tomato sauce, and spaghetti. Here are the instructions: Preheat oven to 450 degrees F (230 degrees C). Pound chicken breasts to 1/2 inch thickness. Sprinkle each piece of chicken on both sides with salt and pepper. Place bread crumbs in a bowl. In a separate bowl, whisk together the egg and water. Dip each piece of chicken in the egg mixture, then in the bread crumbs, and place in a shallow baking dish. Bake in the preheated oven for 15 minutes. Turn chicken pieces over and bake for another 15 minutes, or until no longer pink and juices run clear. Top with tomato sauce and Parmesan cheese. Bake for an additional 5 minutes, or until cheese is melted and bubbly. Serve over spaghetti.\"}, {\"role\": \"user\", \"content\": \"Can you tell me about the movie \\\\\"Inception\\\\\"?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_bb1db7e4-1944-4059-9878-390a4b04a523\", \"type\": \"function\", \"function\": {\"name\": \"get_movie_details\", \"arguments\": \"{\\\\\"title\\\\\": \\\\\"Inception\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"title\\\\\": \\\\\"Inception\\\\\", \\\\\"year\\\\\": 2010, \\\\\"director\\\\\": \\\\\"Christopher Nolan\\\\\", \\\\\"genre\\\\\": \\\\\"Science Fiction\\\\\", \\\\\"rating\\\\\": 8.8}\", \"tool_call_id\": \"call_bb1db7e4-1944-4059-9878-390a4b04a523\"}, {\"role\": \"assistant\", \"content\": \"The movie \\\\\"Inception\\\\\" was released in the year 2010. It was directed by Christopher Nolan and falls under the genre of Science Fiction. It has a rating of 8.8.\"}, {\"role\": \"user\", \"content\": \"What about the movie \\\\\"The Godfather\\\\\"?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_bb1db7e4-1944-4059-9878-390a4b04a523\", \"type\": \"function\", \"function\": {\"name\": \"get_movie_details\", \"arguments\": \"{\\\\\"title\\\\\": \\\\\"The Godfather\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"title\\\\\": \\\\\"The Godfather\\\\\", \\\\\"year\\\\\": 1972, \\\\\"director\\\\\": \\\\\"Francis Ford Coppola\\\\\", \\\\\"genre\\\\\": \\\\\"Crime, Drama\\\\\", \\\\\"rating\\\\\": 9.2}\", \"tool_call_id\": \"call_bb1db7e4-1944-4059-9878-390a4b04a523\"}, {\"role\": \"assistant\", \"content\": \"The movie \\\\\"The Godfather\\\\\" was released in the year 1972. It was directed by Francis Ford Coppola and falls under the genre of Crime and Drama. It has a rating of 9.2.\"}, {\"role\": \"user\", \"content\": \"I need to calculate the area of a rectangle. The length is 5 units and the width is 3 units.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_e7e5804c-47dc-49f7-b3ae-8d7f71c63ab7\", \"type\": \"function\", \"function\": {\"name\": \"calculate_area\", \"arguments\": \"{\\\\\"shape\\\\\": \\\\\"rectangle\\\\\", \\\\\"dimensions\\\\\": {\\\\\"length\\\\\": 5, \\\\\"width\\\\\": 3}}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"area\\\\\": 15}\", \"tool_call_id\": \"call_e7e5804c-47dc-49f7-b3ae-8d7f71c63ab7\"}, {\"role\": \"assistant\", \"content\": \"The area of the rectangle is 15 square units.\"}, {\"role\": \"user\", \"content\": \"Now, I want to calculate the area of a circle with a radius of 4 units.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_e7e5804c-47dc-49f7-b3ae-8d7f71c63ab7\", \"type\": \"function\", \"function\": {\"name\": \"calculate_area\", \"arguments\": \"{\\\\\"shape\\\\\": \\\\\"circle\\\\\", \\\\\"dimensions\\\\\": {\\\\\"radius\\\\\": 4}}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"area\\\\\": 50.24}\", \"tool_call_id\": \"call_e7e5804c-47dc-49f7-b3ae-8d7f71c63ab7\"}, {\"role\": \"assistant\", \"content\": \"The area of the circle is approximately 50.24 square units.\"}, {\"role\": \"user\", \"content\": \"Hi, I need help with calculating my monthly mortgage payment. I have a loan amount of $300,000, an annual interest rate of 3.5%, and a loan term of 30 years.\"}, {\"role\": \"assistant\", \"content\": \"Sure, I can help with that. Let me calculate it for you.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_6b9d702d-99df-4d3d-8c83-383d40c15621\", \"type\": \"function\", \"function\": {\"name\": \"calculate_mortgage\", \"arguments\": \"{\\\\\"loan_amount\\\\\": 300000, \\\\\"interest_rate\\\\\": 3.5, \\\\\"loan_term\\\\\": 30}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"monthly_payment\\\\\": 1342.05}\", \"tool_call_id\": \"call_6b9d702d-99df-4d3d-8c83-383d40c15621\"}, {\"role\": \"assistant\", \"content\": \"Based on the details provided, your estimated monthly mortgage payment would be $1342.05.\"}, {\"role\": \"user\", \"content\": \"That\\'s great. Can you also help me find a good real estate agent in my area?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but as an AI, I don\\'t have the capability to perform external tasks such as finding a real estate agent. I suggest you search online or ask for recommendations from friends or family.\"}, {\"role\": \"user\", \"content\": \"Hi, I need a barcode for my product. The product name is \\\\\"Super Soap\\\\\" and the product id is \\\\\"SS123\\\\\".\"}, {\"role\": \"assistant\", \"content\": \"Sure, I can help with that. Let me generate the barcode for you.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_40f26e64-a874-4e03-9065-59bf34422dd8\", \"type\": \"function\", \"function\": {\"name\": \"generate_barcode\", \"arguments\": \"{\\\\\"product_name\\\\\": \\\\\"Super Soap\\\\\", \\\\\"product_id\\\\\": \\\\\"SS123\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"barcode\\\\\": \\\\\"123456789012\\\\\"}\", \"tool_call_id\": \"call_40f26e64-a874-4e03-9065-59bf34422dd8\"}, {\"role\": \"assistant\", \"content\": \"I have generated the barcode for your product. The barcode for \\\\\"Super Soap\\\\\" with product id \\\\\"SS123\\\\\" is \\\\\"123456789012\\\\\".\"}, {\"role\": \"user\", \"content\": \"Great! Can you also arrange a delivery for this product to my warehouse?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but as an AI, I don\\'t have the capability to arrange physical deliveries. My primary function is to assist with tasks that can be performed digitally, such as generating barcodes. You might want to contact a logistics service for the delivery.\"}, {\"role\": \"user\", \"content\": \"Hi, I need to convert 500 US dollars to Euros. Can you help me with that?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_70e043f3-0f59-4149-9859-91ea66329059\", \"type\": \"function\", \"function\": {\"name\": \"convert_currency\", \"arguments\": \"{\\\\\"amount\\\\\": 500, \\\\\"source_currency\\\\\": \\\\\"USD\\\\\", \\\\\"target_currency\\\\\": \\\\\"EUR\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"converted_amount\\\\\": 425.50, \\\\\"source_currency\\\\\": \\\\\"USD\\\\\", \\\\\"target_currency\\\\\": \\\\\"EUR\\\\\"}\", \"tool_call_id\": \"call_70e043f3-0f59-4149-9859-91ea66329059\"}, {\"role\": \"assistant\", \"content\": \"Sure, 500 US dollars is approximately 425.50 Euros.\"}, {\"role\": \"user\", \"content\": \"Great, thanks! Now, could you please convert 1000 Euros to Japanese Yen?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_70e043f3-0f59-4149-9859-91ea66329059\", \"type\": \"function\", \"function\": {\"name\": \"convert_currency\", \"arguments\": \"{\\\\\"amount\\\\\": 1000, \\\\\"source_currency\\\\\": \\\\\"EUR\\\\\", \\\\\"target_currency\\\\\": \\\\\"JPY\\\\\"}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"converted_amount\\\\\": 130000, \\\\\"source_currency\\\\\": \\\\\"EUR\\\\\", \\\\\"target_currency\\\\\": \\\\\"JPY\\\\\"}\", \"tool_call_id\": \"call_70e043f3-0f59-4149-9859-91ea66329059\"}, {\"role\": \"assistant\", \"content\": \"1000 Euros is approximately 130,000 Japanese Yen.\"}, {\"role\": \"user\", \"content\": \"Can you please order a pizza for me?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but I\\'m unable to perform external tasks like ordering a pizza. My current capabilities are limited to the functions provided to me. In this case, I can help you generate a random password.\"}, {\"role\": \"user\", \"content\": \"Can you order a pizza for me?\"}, {\"role\": \"assistant\", \"content\": \"I\\'m sorry, but I\\'m unable to perform external tasks like ordering a pizza. My capabilities are limited to the functions provided to me. In this case, I can help you search for books based on specified criteria.\"}, {\"role\": \"user\", \"content\": \"Hi, I need to calculate the area of a rectangle. The width is 5 units and the height is 10 units.\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_db5c7aff-2c35-4b74-9251-9e3d4861549c\", \"type\": \"function\", \"function\": {\"name\": \"calculate_rectangle_area\", \"arguments\": \"{\\\\\"width\\\\\": 5, \\\\\"height\\\\\": 10}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"area\\\\\": 50}\", \"tool_call_id\": \"call_db5c7aff-2c35-4b74-9251-9e3d4861549c\"}, {\"role\": \"assistant\", \"content\": \"The area of the rectangle with width 5 units and height 10 units is 50 square units.\"}, {\"role\": \"user\", \"content\": \"That\\'s great! Now, I have another rectangle with width 7 units and height 3 units. Can you calculate the area for this one too?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_db5c7aff-2c35-4b74-9251-9e3d4861549c\", \"type\": \"function\", \"function\": {\"name\": \"calculate_rectangle_area\", \"arguments\": \"{\\\\\"width\\\\\": 7, \\\\\"height\\\\\": 3}\"}}]}, {\"role\": \"tool\", \"content\": \"{\\\\\"area\\\\\": 21}\", \"tool_call_id\": \"call_db5c7aff-2c35-4b74-9251-9e3d4861549c\"}, {\"role\": \"assistant\", \"content\": \"The area of the rectangle with width 7 units and height 3 units is 21 square units.\"}, {\"role\": \"user\", \"content\": \"Thank you for your help!\"}, {\"role\": \"assistant\", \"content\": \"You\\'re welcome! If you have any other calculations or questions, feel free to ask.\"}]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "vhXv0xFMGNKE",
    "outputId": "f651b2e5-8bb6-41f8-c6fc-e23f48f74561"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nCan you please book a flight for me from New York to London?\\n\\nYou are able to call the following tools, when needed, call them using the <tool_call> xml-tag, followed by name and arguments as json.\\n<tools>\\n[{\"name\": \"generate_barcode\", \"description\": \"Generate a barcode for a given product\", \"parameters\": {\"type\": \"object\", \"properties\": {\"product_name\": {\"type\": \"string\", \"description\": \"The name of the product\"}, \"product_id\": {\"type\": \"string\", \"description\": \"The unique ID of the product\"}}, \"required\": [\"product_name\", \"product_id\"]}}, {\"name\": \"get_definition\", \"description\": \"Get the definition of a given word\", \"parameters\": {\"type\": \"object\", \"properties\": {\"word\": {\"type\": \"string\", \"description\": \"The word to get the definition of\"}}, \"required\": [\"word\"]}}, {\"name\": \"check_prime_number\", \"description\": \"Check if a number is a prime number\", \"parameters\": {\"type\": \"object\", \"properties\": {\"number\": {\"type\": \"integer\", \"description\": \"The number to check\"}}, \"required\": [\"number\"]}}, {\"name\": \"calculate_area\", \"description\": \"Calculate the area of a geometric shape\", \"parameters\": {\"type\": \"object\", \"properties\": {\"shape\": {\"type\": \"string\", \"description\": \"The geometric shape (e.g., rectangle, circle)\"}, \"dimensions\": {\"type\": \"object\", \"properties\": {\"length\": {\"type\": \"number\", \"description\": \"The length of the shape\"}, \"width\": {\"type\": \"number\", \"description\": \"The width of the shape\"}, \"radius\": {\"type\": \"number\", \"description\": \"The radius of the shape\"}}, \"required\": [\"length\", \"width\", \"radius\"]}}, \"required\": [\"shape\", \"dimensions\"]}}, {\"name\": \"search_books\", \"description\": \"Search for books based on specified criteria\", \"parameters\": {\"type\": \"object\", \"properties\": {\"title\": {\"type\": \"string\", \"description\": \"The title of the book\"}, \"author\": {\"type\": \"string\", \"description\": \"The author of the book\"}, \"genre\": {\"type\": \"string\", \"description\": \"The genre of the book\"}}}}, {\"name\": \"calculate_rectangle_area\", \"description\": \"Calculate the area of a rectangle based on its dimensions\", \"parameters\": {\"type\": \"object\", \"properties\": {\"width\": {\"type\": \"number\", \"description\": \"The width of the rectangle\"}, \"height\": {\"type\": \"number\", \"description\": \"The height of the rectangle\"}}, \"required\": [\"width\", \"height\"]}}, {\"name\": \"create_todo\", \"description\": \"Create a new todo item\", \"parameters\": {\"type\": \"object\", \"properties\": {\"title\": {\"type\": \"string\", \"description\": \"The title of the todo item\"}, \"description\": {\"type\": \"string\", \"description\": \"The description of the todo item\"}, \"due_date\": {\"type\": \"string\", \"description\": \"The due date of the todo item (YYYY-MM-DD)\"}}, \"required\": [\"title\", \"description\", \"due_date\"]}}, {\"name\": \"calculate_tip\", \"description\": \"Calculate the tip amount for a bill\", \"parameters\": {\"type\": \"object\", \"properties\": {\"bill_amount\": {\"type\": \"number\", \"description\": \"The total amount of the bill\"}, \"tip_percentage\": {\"type\": \"number\", \"description\": \"The percentage of the bill to tip\"}}, \"required\": [\"bill_amount\", \"tip_percentage\"]}}, {\"name\": \"calculate_shipping\", \"description\": \"Calculate the shipping cost for an item\", \"parameters\": {\"type\": \"object\", \"properties\": {\"weight\": {\"type\": \"number\", \"description\": \"The weight of the item in pounds\"}, \"destination\": {\"type\": \"string\", \"description\": \"The destination of the item\"}}, \"required\": [\"weight\", \"destination\"]}}, {\"name\": \"calculate_age_difference\", \"description\": \"Calculate the age difference between two individuals\", \"parameters\": {\"type\": \"object\", \"properties\": {\"birthdate1\": {\"type\": \"string\", \"description\": \"The birthdate of the first person\"}, \"birthdate2\": {\"type\": \"string\", \"description\": \"The birthdate of the second person\"}}, \"required\": [\"birthdate1\", \"birthdate2\"]}}, {\"name\": \"generate_random_password\", \"description\": \"Generate a random password with a given length\", \"parameters\": {\"type\": \"object\", \"properties\": {\"length\": {\"type\": \"integer\", \"description\": \"The length of the password\"}}, \"required\": [\"length\"]}}, {\"name\": \"calculate_discount\", \"description\": \"Calculate the discounted price of an item\", \"parameters\": {\"type\": \"object\", \"properties\": {\"original_price\": {\"type\": \"number\", \"description\": \"The original price of the item\"}, \"discount_percentage\": {\"type\": \"number\", \"description\": \"The discount percentage\"}}, \"required\": [\"original_price\", \"discount_percentage\"]}}, {\"name\": \"calculate_distance\", \"description\": \"Calculate the distance between two locations\", \"parameters\": {\"type\": \"object\", \"properties\": {\"origin\": {\"type\": \"string\", \"description\": \"The origin location\"}, \"destination\": {\"type\": \"string\", \"description\": \"The destination location\"}}, \"required\": [\"origin\", \"destination\"]}}, {\"name\": \"generate_invoice\", \"description\": \"Generate an invoice for a product or service\", \"parameters\": {\"type\": \"object\", \"properties\": {\"customer_name\": {\"type\": \"string\", \"description\": \"The name of the customer\"}, \"product_name\": {\"type\": \"string\", \"description\": \"The name of the product or service\"}, \"quantity\": {\"type\": \"integer\", \"description\": \"The quantity of the product or service\"}, \"price_per_unit\": {\"type\": \"number\", \"description\": \"The price per unit of the product or service\"}}, \"required\": [\"customer_name\", \"product_name\", \"quantity\", \"price_per_unit\"]}}, {\"name\": \"search_recipe\", \"description\": \"Search for a recipe based on a given keyword\", \"parameters\": {\"type\": \"object\", \"properties\": {\"keyword\": {\"type\": \"string\", \"description\": \"The keyword to search for\"}}, \"required\": [\"keyword\"]}}, {\"name\": \"create_calendar_event\", \"description\": \"Create a new event in the calendar\", \"parameters\": {\"type\": \"object\", \"properties\": {\"title\": {\"type\": \"string\", \"description\": \"The title of the event\"}, \"start_time\": {\"type\": \"string\", \"description\": \"The start time of the event\"}, \"end_time\": {\"type\": \"string\", \"description\": \"The end time of the event\"}}, \"required\": [\"title\", \"start_time\", \"end_time\"]}}, {\"name\": \"create_contact\", \"description\": \"Create a new contact\", \"parameters\": {\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\", \"description\": \"The name of the contact\"}, \"phone_number\": {\"type\": \"string\", \"description\": \"The phone number of the contact\"}, \"email\": {\"type\": \"string\", \"description\": \"The email address of the contact\"}}, \"required\": [\"name\"]}}, {\"name\": \"calculate_gcd\", \"description\": \"Calculate the greatest common divisor (GCD) of two numbers\", \"parameters\": {\"type\": \"object\", \"properties\": {\"number1\": {\"type\": \"integer\", \"description\": \"The first number\"}, \"number2\": {\"type\": \"integer\", \"description\": \"The second number\"}}, \"required\": [\"number1\", \"number2\"]}}, {\"name\": \"get_movie_details\", \"description\": \"Get the details of a movie\", \"parameters\": {\"type\": \"object\", \"properties\": {\"title\": {\"type\": \"string\", \"description\": \"The title of the movie\"}, \"year\": {\"type\": \"integer\", \"description\": \"The year of the movie\"}}, \"required\": [\"title\"]}}, {\"name\": \"calculate_loan_payment\", \"description\": \"Calculate the monthly loan payment\", \"parameters\": {\"type\": \"object\", \"properties\": {\"principal\": {\"type\": \"number\", \"description\": \"Loan principal amount\"}, \"interest_rate\": {\"type\": \"number\", \"description\": \"Annual interest rate\"}, \"term\": {\"type\": \"integer\", \"description\": \"Loan term in years\"}}, \"required\": [\"principal\", \"interest_rate\", \"term\"]}}, {\"name\": \"convert_temperature\", \"description\": \"Convert temperature from one unit to another\", \"parameters\": {\"type\": \"object\", \"properties\": {\"temperature\": {\"type\": \"number\", \"description\": \"The temperature value\"}, \"from_unit\": {\"type\": \"string\", \"description\": \"The unit to convert from\"}, \"to_unit\": {\"type\": \"string\", \"description\": \"The unit to convert to\"}}, \"required\": [\"temperature\", \"from_unit\", \"to_unit\"]}}, {\"name\": \"calculate_mortgage\", \"description\": \"Calculate the monthly mortgage payment\", \"parameters\": {\"type\": \"object\", \"properties\": {\"loan_amount\": {\"type\": \"number\", \"description\": \"The loan amount\"}, \"interest_rate\": {\"type\": \"number\", \"description\": \"The annual interest rate\"}, \"loan_term\": {\"type\": \"integer\", \"description\": \"The loan term in years\"}}, \"required\": [\"loan_amount\", \"interest_rate\", \"loan_term\"]}}, {\"name\": \"search_products\", \"description\": \"Search for products based on given criteria\", \"parameters\": {\"type\": \"object\", \"properties\": {\"keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"The keywords to search for\"}, \"category\": {\"type\": \"string\", \"description\": \"The category of products to search in\"}, \"min_price\": {\"type\": \"number\", \"description\": \"The minimum price of the products\"}, \"max_price\": {\"type\": \"number\", \"description\": \"The maximum price of the products\"}}}}, {\"name\": \"convert_currency\", \"description\": \"Convert an amount from one currency to another\", \"parameters\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"The amount to be converted\"}, \"source_currency\": {\"type\": \"string\", \"description\": \"The currency of the amount\"}, \"target_currency\": {\"type\": \"string\", \"description\": \"The currency to convert to\"}}, \"required\": [\"amount\", \"source_currency\", \"target_currency\"]}}]\\n</tools><|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but I\\'m unable to book flights. My current capabilities allow me to search for products based on given criteria such as keywords, category, and price range. Is there anything else I can assist you with within these capabilities?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHey, can you check if 7 is a prime number?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSure, let me check that for you.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"check_prime_number\", \"arguments\": {\"number\": 7}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"isPrime\": true}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nYes, 7 is a prime number.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nGreat! Now, can you order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but as an AI, I don\\'t have the capability to perform external tasks such as ordering a pizza. I can assist you with information and perform functions that I have been programmed with.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI need to create a new contact for my friend John Doe.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSure, I can help with that. Could you please provide me with John Doe\\'s phone number and email address?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYes, his phone number is 123-456-7890 and his email is johndoe@example.com.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"create_contact\", \"arguments\": {\"name\": \"John Doe\", \"phone_number\": \"123-456-7890\", \"email\": \"johndoe@example.com\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"status\": \"success\", \"message\": \"Contact for John Doe has been successfully created\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI have successfully created the contact for John Doe with the provided phone number and email address.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nCan you please order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but I can\\'t assist with that. My current capabilities are limited to creating todo items. I don\\'t have the ability to place orders or perform external tasks.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need to know the distance between New York and Los Angeles.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_distance\", \"arguments\": {\"origin\": \"New York\", \"destination\": \"Los Angeles\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"distance\": \"2448 miles\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe distance between New York and Los Angeles is approximately 2448 miles.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThat\\'s quite a distance. What about the distance from Los Angeles to Miami?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_distance\", \"arguments\": {\"origin\": \"Los Angeles\", \"destination\": \"Miami\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"distance\": \"2342 miles\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe distance between Los Angeles and Miami is approximately 2342 miles.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThank you for the information.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need help with calculating my loan payment.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nOf course, I can help with that. Could you please provide me with the principal amount, the annual interest rate, and the term of the loan in years?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nSure, the principal amount is $50000, the annual interest rate is 5.5%, and the term is 15 years.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_loan_payment\", \"arguments\": {\"principal\": 50000, \"interest_rate\": 5.5, \"term\": 15}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"monthly_payment\": \"408.54\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nBased on the information you provided, your monthly loan payment would be approximately $408.54.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI need to schedule a meeting for tomorrow.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSure, I can help with that. Could you please provide me with the title of the meeting, and the start and end times?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThe meeting is titled \"Project Discussion\". It should start at 10:00 AM and end at 11:30 AM.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"create_calendar_event\", \"arguments\": {\"title\": \"Project Discussion\", \"start_time\": \"10:00 AM\", \"end_time\": \"11:30 AM\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"status\": \"success\", \"message\": \"Event \\'Project Discussion\\' has been successfully created for tomorrow from 10:00 AM to 11:30 AM.\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe meeting titled \"Project Discussion\" has been successfully scheduled for tomorrow from 10:00 AM to 11:30 AM.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nCan you please order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but I\\'m unable to perform external tasks such as ordering a pizza. My capabilities are currently limited to providing definitions of words.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI saw a dress that I liked. It was originally priced at $100 but it\\'s on a 20% discount. How much will it cost now?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_discount\", \"arguments\": {\"original_price\": 100, \"discount_percentage\": 20}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"discounted_price\": 80}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe dress will now cost you $80 after the discount.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nCan you please order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but as an AI, I don\\'t have the capability to perform external tasks such as ordering a pizza. My current function allows me to calculate the tip amount for a bill. If you need help with that, feel free to ask!<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, can you help me find the greatest common divisor of 36 and 48?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSure, I can help with that. Let me calculate it for you.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_gcd\", \"arguments\": {\"number1\": 36, \"number2\": 48}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"gcd\": 12}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe greatest common divisor of 36 and 48 is 12.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThat\\'s great! Can you also help me book a flight to New York?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but as an AI, I don\\'t have the capability to perform external tasks such as booking flights. My current functions are limited to calculating the greatest common divisor of two numbers.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need to ship a package to New York. It weighs about 5 pounds. Can you tell me how much it will cost?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_shipping\", \"arguments\": {\"weight\": 5, \"destination\": \"New York\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"cost\": 15.75}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe cost to ship your package to New York will be $15.75.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nGreat, thanks for the information. Now, I have another package that weighs 10 pounds and it needs to be shipped to Los Angeles. Can you calculate the cost for this one as well?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_shipping\", \"arguments\": {\"weight\": 10, \"destination\": \"Los Angeles\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"cost\": 20.50}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe cost to ship your second package to Los Angeles will be $20.50.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need to convert a temperature from Fahrenheit to Celsius. The temperature is 98.6 degrees Fahrenheit.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"convert_temperature\", \"arguments\": {\"temperature\": 98.6, \"from_unit\": \"Fahrenheit\", \"to_unit\": \"Celsius\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"converted_temperature\": 37}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe converted temperature from 98.6 degrees Fahrenheit to Celsius is 37 degrees.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nGreat, now can you convert 0 degrees Celsius to Fahrenheit?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"convert_temperature\", \"arguments\": {\"temperature\": 0, \"from_unit\": \"Celsius\", \"to_unit\": \"Fahrenheit\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"converted_temperature\": 32}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe converted temperature from 0 degrees Celsius to Fahrenheit is 32 degrees.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThank you for your help!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI\\'m looking for a recipe that uses chicken.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"search_recipe\", \"arguments\": {\"keyword\": \"chicken\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"results\": [{\"name\": \"Chicken Parmesan\", \"ingredients\": [\"chicken\", \"parmesan\", \"tomato sauce\", \"spaghetti\"], \"instructions\": \"Preheat oven to 450 degrees F (230 degrees C). Pound chicken breasts to 1/2 inch thickness. Sprinkle each piece of chicken on both sides with salt and pepper. Place bread crumbs in a bowl. In a separate bowl, whisk together the egg and water. Dip each piece of chicken in the egg mixture, then in the bread crumbs, and place in a shallow baking dish. Bake in the preheated oven for 15 minutes. Turn chicken pieces over and bake for another 15 minutes, or until no longer pink and juices run clear. Top with tomato sauce and Parmesan cheese. Bake for an additional 5 minutes, or until cheese is melted and bubbly. Serve over spaghetti.\"}]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI found a recipe for Chicken Parmesan. You\\'ll need chicken, parmesan, tomato sauce, and spaghetti. Here are the instructions: Preheat oven to 450 degrees F (230 degrees C). Pound chicken breasts to 1/2 inch thickness. Sprinkle each piece of chicken on both sides with salt and pepper. Place bread crumbs in a bowl. In a separate bowl, whisk together the egg and water. Dip each piece of chicken in the egg mixture, then in the bread crumbs, and place in a shallow baking dish. Bake in the preheated oven for 15 minutes. Turn chicken pieces over and bake for another 15 minutes, or until no longer pink and juices run clear. Top with tomato sauce and Parmesan cheese. Bake for an additional 5 minutes, or until cheese is melted and bubbly. Serve over spaghetti.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nCan you tell me about the movie \"Inception\"?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"get_movie_details\", \"arguments\": {\"title\": \"Inception\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"title\": \"Inception\", \"year\": 2010, \"director\": \"Christopher Nolan\", \"genre\": \"Science Fiction\", \"rating\": 8.8}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe movie \"Inception\" was released in the year 2010. It was directed by Christopher Nolan and falls under the genre of Science Fiction. It has a rating of 8.8.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat about the movie \"The Godfather\"?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"get_movie_details\", \"arguments\": {\"title\": \"The Godfather\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"title\": \"The Godfather\", \"year\": 1972, \"director\": \"Francis Ford Coppola\", \"genre\": \"Crime, Drama\", \"rating\": 9.2}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe movie \"The Godfather\" was released in the year 1972. It was directed by Francis Ford Coppola and falls under the genre of Crime and Drama. It has a rating of 9.2.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI need to calculate the area of a rectangle. The length is 5 units and the width is 3 units.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_area\", \"arguments\": {\"shape\": \"rectangle\", \"dimensions\": {\"length\": 5, \"width\": 3}}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"area\": 15}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe area of the rectangle is 15 square units.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nNow, I want to calculate the area of a circle with a radius of 4 units.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_area\", \"arguments\": {\"shape\": \"circle\", \"dimensions\": {\"radius\": 4}}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"area\": 50.24}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe area of the circle is approximately 50.24 square units.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need help with calculating my monthly mortgage payment. I have a loan amount of $300,000, an annual interest rate of 3.5%, and a loan term of 30 years.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSure, I can help with that. Let me calculate it for you.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_mortgage\", \"arguments\": {\"loan_amount\": 300000, \"interest_rate\": 3.5, \"loan_term\": 30}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"monthly_payment\": 1342.05}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nBased on the details provided, your estimated monthly mortgage payment would be $1342.05.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThat\\'s great. Can you also help me find a good real estate agent in my area?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but as an AI, I don\\'t have the capability to perform external tasks such as finding a real estate agent. I suggest you search online or ask for recommendations from friends or family.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need a barcode for my product. The product name is \"Super Soap\" and the product id is \"SS123\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSure, I can help with that. Let me generate the barcode for you.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"generate_barcode\", \"arguments\": {\"product_name\": \"Super Soap\", \"product_id\": \"SS123\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"barcode\": \"123456789012\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI have generated the barcode for your product. The barcode for \"Super Soap\" with product id \"SS123\" is \"123456789012\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nGreat! Can you also arrange a delivery for this product to my warehouse?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but as an AI, I don\\'t have the capability to arrange physical deliveries. My primary function is to assist with tasks that can be performed digitally, such as generating barcodes. You might want to contact a logistics service for the delivery.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need to convert 500 US dollars to Euros. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"convert_currency\", \"arguments\": {\"amount\": 500, \"source_currency\": \"USD\", \"target_currency\": \"EUR\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"converted_amount\": 425.50, \"source_currency\": \"USD\", \"target_currency\": \"EUR\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSure, 500 US dollars is approximately 425.50 Euros.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nGreat, thanks! Now, could you please convert 1000 Euros to Japanese Yen?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"convert_currency\", \"arguments\": {\"amount\": 1000, \"source_currency\": \"EUR\", \"target_currency\": \"JPY\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"converted_amount\": 130000, \"source_currency\": \"EUR\", \"target_currency\": \"JPY\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n1000 Euros is approximately 130,000 Japanese Yen.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nCan you please order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but I\\'m unable to perform external tasks like ordering a pizza. My current capabilities are limited to the functions provided to me. In this case, I can help you generate a random password.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nCan you order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI\\'m sorry, but I\\'m unable to perform external tasks like ordering a pizza. My capabilities are limited to the functions provided to me. In this case, I can help you search for books based on specified criteria.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need to calculate the area of a rectangle. The width is 5 units and the height is 10 units.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_rectangle_area\", \"arguments\": {\"width\": 5, \"height\": 10}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"area\": 50}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe area of the rectangle with width 5 units and height 10 units is 50 square units.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThat\\'s great! Now, I have another rectangle with width 7 units and height 3 units. Can you calculate the area for this one too?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<tool_call>{\"name\": \"calculate_rectangle_area\", \"arguments\": {\"width\": 7, \"height\": 3}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"area\": 21}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe area of the rectangle with width 7 units and height 3 units is 21 square units.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThank you for your help!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nYou\\'re welcome! If you have any other calculations or questions, feel free to ask.<|eot_id|>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1401\n",
      "Validation dataset size: 15\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset with a fixed seed\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "# Split the dataset into 95% training and 5% validation\n",
    "split_dataset = dataset.train_test_split(test_size=0.01, seed=42)\n",
    "dataset = split_dataset['train']\n",
    "validation_dataset = split_dataset['test']\n",
    "print(f\"Training dataset size: {len(dataset)}\")\n",
    "print(f\"Validation dataset size: {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "9e4762d0c7f242359355a800f30c2771",
      "8d93fe940a5441f2af90870cd123c3bd",
      "0c586fcfaa354f8cb9c5501601c5a5ec",
      "24b137b2802846af82db926904480a6f",
      "19af594b0de549709a837436f5838dd7",
      "a6e6370ec9104168aef849d5b5a300b2",
      "a54d212948384906ae9a8a2e3a3ab84e",
      "5700d3cc345f429ea4d9531d3e22ad41",
      "98ead40e54984506b5a6aaf79e406e44",
      "9e720179d7014b39b19dc5dff52a0b37",
      "81e5a4c45dba48abb0092c74f1f3daac"
     ]
    },
    "id": "95_Nn-89DhsL",
    "outputId": "a5956d14-607f-44ec-8be2-260de8a47789"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939283f9ee7446e4aa848cc6d9adaf27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741b997cb55b4c55af3637952398eaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    eval_dataset = validation_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_sequence_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 8,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 2, # Set this for 1 full training run.\n",
    "        #max_steps = 10,\n",
    "        eval_steps = 10,\n",
    "        eval_strategy = \"steps\",\n",
    "        learning_rate = learning_rate,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = weight_decay,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_sGp5XlG6dq"
   },
   "source": [
    "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97,
     "referenced_widgets": [
      "3742990d40954972ad79f4816cfb05b1",
      "551158030c0c4a2fa50733d1a40a3a58",
      "2f3aef8c52db4e5eb7fa05568ee8a53e",
      "9e783b250dde44b688d8ce8174de6c64",
      "406ec70d96c24e30a9cad27a51022bbe",
      "46ede8c9efed4b13ad0cd3ff138884e5",
      "f2be5a53e0874e9f8f9bfee83c931cf3",
      "a380348df9bc4a168a371e665212fef7",
      "a8b83cd1eebe4fd4a353d1c4b0edaf8b",
      "d712551a85e34fa3869c4d0427381ba2",
      "32e69481e102479f99d3bcd959d799e3"
     ]
    },
    "id": "juQiExuBG5Bt",
    "outputId": "0e3b4243-8ff3-4d69-eccb-70f5373cd6dd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d8dac05fca4289a942b01bf1d9a317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6120cc809d24463bfd901f69b1383a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = instruction_template,\n",
    "    response_part = response_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dv1NBUozV78l"
   },
   "source": [
    "We verify masking is actually done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "_rD6fl8EUxnG",
    "outputId": "5451634b-fcd2-43a5-e184-4c76888f329d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \\n\\nOf course, I can help you with that. Could you please provide me with the recipient\\'s email address, the subject of the email, and the content you want to send?<|eot_id|>                                                              \\n\\n<tool_call>{\"name\": \"send_email\", \"arguments\": {\"recipient\": \"boss@company.com\", \"subject\": \"Project Update\", \"message\": \"Dear Boss, I have completed the project as per the given deadline. I have attached the final report for your review. Regards, [User\\'s Name]\"}}</tool_call><|eot_id|>                        \\n\\nThe email has been sent successfully to your boss. Is there anything else you need help with?<|eot_id|>                \\n\\nSure, I can help with that. Could you please tell me the task description and the due date?<|eot_id|>                           \\n\\n<tool_call>{\"name\": \"create_todo\", \"arguments\": {\"task\": \"Prepare a presentation for the annual meeting\", \"due_date\": \"next Friday\"}}</tool_call><|eot_id|>                                          \\n\\nYour task has been created successfully. You need to prepare a presentation for the annual meeting by next Friday.<|eot_id|>                                 \\n\\n<tool_call>{\"name\": \"calculate_bmi\", \"arguments\": {\"weight\": 70, \"height\": 1.75}}</tool_call><|eot_id|>                 \\n\\nYour Body Mass Index (BMI) is 22.86. This is considered to be within the healthy weight range.<|eot_id|>                    \\n\\nYou\\'re welcome! If you have any other questions or need further assistance, feel free to ask.<|eot_id|>                               \\n\\nSure, I can help with that. Let me calculate it for you.<|eot_id|>                                                             \\n\\nThe Fibonacci sequence up to the number 10 is: 0, 1, 1, 2, 3, 5, 8.<|eot_id|>                         \\n\\nOf course, let me calculate that for you.<|eot_id|>                                                                \\n\\nThe Fibonacci sequence up to the number 20 is: 0, 1, 1, 2, 3, 5, 8, 13.<|eot_id|>                  \\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|>                                      \\n\\n<tool_call>{\"name\": \"track_calories\", \"arguments\": {\"calories_consumed\": 2500, \"calories_burned\": 800}}</tool_call><|eot_id|>                                           \\n\\nYou have consumed 2500 calories and burned 800 calories today. Your net calorie intake is 1700 calories.<|eot_id|>                      \\n\\nThat sounds like a great plan! Remember, maintaining a balance between calories consumed and burned is key to a healthy lifestyle.<|eot_id|>                                   \\n\\n<tool_call>{\"name\": \"search_book\", \"arguments\": {\"title\": \"\", \"author\": \"Agatha Christie\", \"genre\": \"mystery\"}}</tool_call><|eot_id|>                                                                                          \\n\\nI found several mystery novels by Agatha Christie. Here are a few: \"And Then There Were None\", \"Murder on the Orient Express\", and \"The Murder of Roger Ackroyd\". Does any of these sound familiar?<|eot_id|>                      \\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|>                      \\n\\n<tool_call>{\"name\": \"get_stock_price\", \"arguments\": {\"symbol\": \"AAPL\"}}</tool_call><|eot_id|>                 \\n\\nThe current price of Apple\\'s stock (AAPL) is $145.09.<|eot_id|>                      \\n\\n<tool_call>{\"name\": \"get_stock_price\", \"arguments\": {\"symbol\": \"MSFT\"}}</tool_call><|eot_id|>                 \\n\\nThe current price of Microsoft\\'s stock (MSFT) is $216.54.<|eot_id|>                \\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|>                                  \\n\\n<tool_call>{\"name\": \"calculate_tax\", \"arguments\": {\"income\": 75000, \"tax_rate\": 25}}</tool_call><|eot_id|>                \\n\\nBased on your annual income of $75,000 and a tax rate of 25%, your tax amount for this year would be $18,750.<|eot_id|>                             \\n\\n<tool_call>{\"name\": \"calculate_tax\", \"arguments\": {\"income\": 60000, \"tax_rate\": 25}}</tool_call><|eot_id|>                \\n\\nIf your annual income was $60,000 with the same tax rate of 25%, your tax amount for this year would be $15,000.<|eot_id|>             \\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|>                 \\n\\nI\\'m sorry, but I am unable to perform external tasks such as ordering a pizza. My current capabilities are limited to the functions provided to me, such as searching for a product.<|eot_id|>                 \\n\\nSure, I can help with that. What would you like the title of the todo item to be?<|eot_id|>                 \\n\\nGreat! Would you like to add a description to your \"Grocery Shopping\" todo item?<|eot_id|>                         \\n\\n<tool_call>{\"name\": \"create_todo_item\", \"arguments\": {\"title\": \"Grocery Shopping\", \"description\": \"Buy fruits, vegetables, and bread\"}}</tool_call><|eot_id|>                                           \\n\\nYour todo item \"Grocery Shopping\" has been created successfully with the description \"Buy fruits, vegetables, and bread\".<|eot_id|>                     \\n\\nOf course, I\\'d be happy to help. Could you please provide me with the loan amount, the interest rate, and the term of the loan in months?<|eot_id|>                                    \\n\\n<tool_call>{\"name\": \"calculate_loan_payment\", \"arguments\": {\"loan_amount\": 50000, \"interest_rate\": 5.5, \"loan_term\": 60}}</tool_call><|eot_id|>                 \\n\\nBased on the information you provided, your monthly loan payment would be approximately $955.65.<|eot_id|>                                  \\n\\n<tool_call>{\"name\": \"calculate_loan_payment\", \"arguments\": {\"loan_amount\": 50000, \"interest_rate\": 5.5, \"loan_term\": 72}}</tool_call><|eot_id|>                 \\n\\nIf you extend the loan term to 72 months, your monthly payment would decrease to approximately $805.23.<|eot_id|>                  \\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|>                                    \\n\\n<tool_call>{\"name\": \"calculate_shipping_cost\", \"arguments\": {\"package_weight\": 5, \"destination_country\": \"Germany\"}}</tool_call><|eot_id|>              \\n\\nThe cost to ship your package to Germany will be $50.<|eot_id|>                       \\n\\n<tool_call>{\"name\": \"calculate_distance\", \"arguments\": {\"origin\": \"New York\", \"destination\": \"Los Angeles\"}}</tool_call><|eot_id|>                        \\n\\nThe distance between New York and Los Angeles is approximately 2448.64 miles.<|eot_id|>                      \\n\\n<tool_call>{\"name\": \"calculate_distance\", \"arguments\": {\"origin\": \"London\", \"destination\": \"Paris\"}}</tool_call><|eot_id|>                       \\n\\nThe distance between London and Paris is approximately 214.37 miles.<|eot_id|>              \\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|>                \\n\\nI\\'m sorry, but I\\'m unable to perform external tasks like ordering pizza. My current function allows me to check the word count of a given text. If you need help with that, feel free to ask!<|eot_id|>                              \\n\\n<tool_call>{\"name\": \"search_movies\", \"arguments\": {\"genre\": \"comedy\", \"year\": 1990}}</tool_call><|eot_id|>                                      \\n\\nSure, here are some comedy movies from the 90s that you might enjoy: \"Home Alone\", \"Dumb and Dumber\", \"Groundhog Day\", \"The Big Lebowski\", \"American Pie\".<|eot_id|>                              \\n\\nYou\\'re welcome! Enjoy watching \"The Big Lebowski\". It\\'s a classic!<|eot_id|>                                              \\n\\n<tool_call>{\"name\": \"calculate_discount\", \"arguments\": {\"price\": 100, \"discount_percentage\": 20}}</tool_call><|eot_id|>                \\n\\nThe dress will cost you $80 after the 20% discount.<|eot_id|>                       \\n\\n<tool_call>{\"name\": \"calculate_discount\", \"arguments\": {\"price\": 100, \"discount_percentage\": 30}}</tool_call><|eot_id|>                \\n\\nIf the discount was 30%, the dress would cost you $70.<|eot_id|>               \\n\\nYou\\'re welcome! If you have any other questions, feel free to ask.<|eot_id|>                     \\n\\n<tool_call>{\"name\": \"generate_anagram\", \"arguments\": {\"word\": \"listen\"}}</tool_call><|eot_id|>               \\n\\nThe anagram for the word \\'listen\\' is\\'silent\\'.<|eot_id|>                         \\n\\n<tool_call>{\"name\": \"generate_anagram\", \"arguments\": {\"word\": \"funeral\"}}</tool_call><|eot_id|>                \\n\\nThe anagram for the word \\'funeral\\' is\\'real fun\\'.<|eot_id|>                   \\n\\nYou\\'re welcome! If you need any more anagrams or help with anything else, feel free to ask.<|eot_id|>                                   \\n\\nOf course, I can help you with that. Could you please provide me with the author\\'s name and the title of the book?<|eot_id|>                               \\n\\n<tool_call>{\"name\": \"search_books\", \"arguments\": {\"title\": \"Harry Potter and the Philosopher\\'s Stone\", \"author\": \"J.K. Rowling\", \"isbn\": \"\"}}</tool_call><|eot_id|>                                                                \\n\\nI found the book you were looking for. The title is \"Harry Potter and the Philosopher\\'s Stone\", written by J.K. Rowling. The ISBN number is 9780747532699. It was published by Bloomsbury in the year 1997.<|eot_id|>                                                                   \\n\\n<tool_call>{\"name\": \"calculate_interest\", \"arguments\": {\"principal\": 5000, \"rate\": 2, \"time\": 3}}</tool_call><|eot_id|>              \\n\\nBased on the details you provided, you will earn an interest of $300 over a period of 3 years.<|eot_id|>                                            \\n\\n<tool_call>{\"name\": \"calculate_route_distance\", \"arguments\": {\"waypoints\": [\"New York\", \"Chicago\", \"Los Angeles\"]}}</tool_call><|eot_id|>                        \\n\\nThe total distance of your road trip from New York, through Chicago, to Los Angeles is approximately 2789.6 miles. Safe travels!<|eot_id|>                   \\n\\nSure, I can help with that. Could you please provide me with the URL of your website and the desired size of the QR code?<|eot_id|>                            \\n\\n<tool_call>{\"name\": \"generate_qr_code\", \"arguments\": {\"data\": \"www.mywebsite.com\", \"size\": 500}}</tool_call><|eot_id|>                                    \\n\\nYour QR code has been generated successfully. You can access it at this URL: www.qr-code.com/mywebsite.<|eot_id|>                     \\n\\n<tool_call>{\"name\": \"get_news_headlines\", \"arguments\": {\"category\": \"sports\", \"country\": \"United States\"}}</tool_call><|eot_id|>                                                          \\n\\nHere are the latest sports headlines from the United States:\\n1. US Women\\'s Soccer Team Wins Gold\\n2. NBA Finals: Lakers vs Nets\\n3. Super Bowl: Chiefs vs Buccaneers\\n4. US Open Tennis: Serena Williams reaches final\\n5. Olympics: US tops medal tally<|eot_id|>                          \\n\\n<tool_call>{\"name\": \"get_news_headlines\", \"arguments\": {\"category\": \"business\", \"country\": \"United Kingdom\"}}</tool_call><|eot_id|>                                                  \\n\\nHere are the latest business headlines from the United Kingdom:\\n1. UK economy grows despite Brexit\\n2. London Stock Exchange hits record high\\n3. UK tech startups raise record investment\\n4. British Airways faces strike action\\n5. UK government announces new business grants<|eot_id|>                    \\n\\n<tool_call>{\"name\": \"get_random_number\", \"arguments\": {\"min\": 1, \"max\": 100}}</tool_call><|eot_id|>              \\n\\nThe random number between 1 and 100 is 42.<|eot_id|>                          \\n\\n<tool_call>{\"name\": \"get_random_number\", \"arguments\": {\"min\": 500, \"max\": 1000}}</tool_call><|eot_id|>              \\n\\nThe random number between 500 and 1000 is 789.<|eot_id|>               \\n\\nYou\\'re welcome! If you need anything else, feel free to ask.<|eot_id|>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
    "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Memory Stats\"></a>\n",
    "### Memory Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ejIt2xSNKKp",
    "outputId": "c40a2ebe-212d-4610-d5c9-b92f074c071b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA A100 80GB PCIe. Max memory = 79.254 GB.\n",
      "6.629 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yqxqAZ7KJ4oL",
    "outputId": "53ccec49-4677-4c5a-c7dc-b15a9b3ef284"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,401 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 32 | Total steps = 132\n",
      " \"-____-\"     Number of trainable parameters = 48,627,712\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 1:22:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.813100</td>\n",
       "      <td>0.516421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.503900</td>\n",
       "      <td>0.368894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.363100</td>\n",
       "      <td>0.318391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.281990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.435100</td>\n",
       "      <td>0.260616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.244963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.234246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>0.224412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.216221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>0.212131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>0.209628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.206537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.205649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCqnaKmlO1U9",
    "outputId": "7d17221b-b08d-47a1-c98f-76470528f23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5006.1167 seconds used for training.\n",
      "83.44 minutes used for training.\n",
      "Peak reserved memory = 27.814 GB.\n",
      "Peak reserved memory for training = 21.185 GB.\n",
      "Peak reserved memory % of max memory = 35.095 %.\n",
      "Peak reserved memory for training % of max memory = 26.731 %.\n"
     ]
    }
   ],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrSvZObor0lY"
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Use the validation dataset to check model performance\n",
    "\n",
    "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:\n",
      "['<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nHi, I need a barcode for the text \"Hello World\".\\n\\nYou are able to call the following tools, when needed, call them using the <tool_call> xml-tag, followed by name and arguments as json.\\n<tools>\\n[{\"name\": \"generate_username\", \"description\": \"Generate a random username\", \"parameters\": {\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\", \"description\": \"The name to generate the username from\"}}, \"required\": [\"name\"]}}, {\"name\": \"convert_currency\", \"description\": \"Convert currency from one unit to another\", \"parameters\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"The amount to be converted\"}, \"from_currency\": {\"type\": \"string\", \"description\": \"The currency to convert from\"}, \"to_currency\": {\"type\": \"string\", \"description\": \"The currency to convert to\"}}, \"required\": [\"amount\", \"from_currency\", \"to_currency\"]}}, {\"name\": \"analyze_sentiment\", \"description\": \"Analyze the sentiment of a text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\", \"description\": \"The text to analyze\"}}, \"required\": [\"text\"]}}, {\"name\": \"get_movie_details\", \"description\": \"Get details of a movie\", \"parameters\": {\"type\": \"object\", \"properties\": {\"movie_id\": {\"type\": \"string\", \"description\": \"The ID of the movie\"}}, \"required\": [\"movie_id\"]}}, {\"name\": \"generate_random_quote\", \"description\": \"Generate a random inspirational quote\", \"parameters\": {}}, {\"name\": \"calculate_distance\", \"description\": \"Calculate the distance between two coordinates\", \"parameters\": {\"type\": \"object\", \"properties\": {\"start_latitude\": {\"type\": \"number\", \"description\": \"The latitude of the starting point\"}, \"start_longitude\": {\"type\": \"number\", \"description\": \"The longitude of the starting point\"}, \"end_latitude\": {\"type\": \"number\", \"description\": \"The latitude of the ending point\"}, \"end_longitude\": {\"type\": \"number\", \"description\": \"The longitude of the ending point\"}}, \"required\": [\"start_latitude\", \"start_longitude\", \"end_latitude\", \"end_longitude\"]}}, {\"name\": \"send_email\", \"description\": \"Send an email to a recipient\", \"parameters\": {\"type\": \"object\", \"properties\": {\"recipient_email\": {\"type\": \"string\", \"format\": \"email\", \"description\": \"The email address of the recipient\"}, \"subject\": {\"type\": \"string\", \"description\": \"The subject of the email\"}, \"message\": {\"type\": \"string\", \"description\": \"The content of the email\"}}, \"required\": [\"recipient_email\", \"subject\", \"message\"]}}, {\"name\": \"generate_barcode\", \"description\": \"Generate a barcode for a given text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\", \"description\": \"The text to encode in the barcode\"}}, \"required\": [\"text\"]}}, {\"name\": \"get_stock_price\", \"description\": \"Get the current stock price of a company\", \"parameters\": {\"type\": \"object\", \"properties\": {\"company\": {\"type\": \"string\", \"description\": \"The name of the company\"}}, \"required\": [\"company\"]}}, {\"name\": \"encrypt_data\", \"description\": \"Encrypt sensitive data\", \"parameters\": {\"type\": \"object\", \"properties\": {\"data\": {\"type\": \"string\", \"description\": \"The data to be encrypted\"}, \"key\": {\"type\": \"string\", \"description\": \"The encryption key\"}}, \"required\": [\"data\", \"key\"]}}, {\"name\": \"calculate_discount\", \"description\": \"Calculate the discounted price\", \"parameters\": {\"type\": \"object\", \"properties\": {\"original_price\": {\"type\": \"number\", \"description\": \"The original price of the item\"}, \"discount_percentage\": {\"type\": \"number\", \"description\": \"The percentage discount\"}}, \"required\": [\"original_price\", \"discount_percentage\"]}}, {\"name\": \"calculate_loan_payment\", \"description\": \"Calculate the monthly loan payment\", \"parameters\": {\"type\": \"object\", \"properties\": {\"principal\": {\"type\": \"number\", \"description\": \"The principal loan amount\"}, \"interest_rate\": {\"type\": \"number\", \"description\": \"The annual interest rate\"}, \"loan_term\": {\"type\": \"integer\", \"description\": \"The loan term in months\"}}, \"required\": [\"principal\", \"interest_rate\", \"loan_term\"]}}, {\"name\": \"get_news\", \"description\": \"Get the latest news\", \"parameters\": {\"type\": \"object\", \"properties\": {\"category\": {\"type\": \"string\", \"description\": \"The category of news, e.g. sports, politics\"}}, \"required\": [\"category\"]}}, {\"name\": \"search_recipes\", \"description\": \"Search for recipes based on ingredients\", \"parameters\": {\"type\": \"object\", \"properties\": {\"ingredients\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"The ingredients to search for\"}, \"cuisine\": {\"type\": \"string\", \"description\": \"The cuisine to filter the recipes by\"}}, \"required\": [\"ingredients\"]}}, {\"name\": \"create_reminder\", \"description\": \"Create a reminder for a specific date and time\", \"parameters\": {\"type\": \"object\", \"properties\": {\"title\": {\"type\": \"string\", \"description\": \"The title or description of the reminder\"}, \"date\": {\"type\": \"string\", \"description\": \"The date of the reminder in YYYY-MM-DD format\"}, \"time\": {\"type\": \"string\", \"description\": \"The time of the reminder in HH:MM format\"}}, \"required\": [\"title\", \"date\", \"time\"]}}, {\"name\": \"search_books\", \"description\": \"Search for books based on a keyword\", \"parameters\": {\"type\": \"object\", \"properties\": {\"keyword\": {\"type\": \"string\", \"description\": \"The keyword to search for\"}, \"author\": {\"type\": \"string\", \"description\": \"The author of the book\"}}, \"required\": [\"keyword\"]}}, {\"name\": \"get_notes\", \"description\": \"Get the user\\'s notes\", \"parameters\": {}}, {\"name\": \"calculate_bmi\", \"description\": \"Calculate the Body Mass Index (BMI)\", \"parameters\": {\"type\": \"object\", \"properties\": {\"weight\": {\"type\": \"number\", \"description\": \"The weight of the person in kilograms\"}, \"height\": {\"type\": \"number\", \"description\": \"The height of the person in meters\"}}, \"required\": [\"weight\", \"height\"]}}, {\"name\": \"calculate_age\", \"description\": \"Calculate the age based on the birth date\", \"parameters\": {\"type\": \"object\", \"properties\": {\"birth_date\": {\"type\": \"string\", \"format\": \"date\", \"description\": \"The birth date\"}}, \"required\": [\"birth_date\"]}}, {\"name\": \"track_expenses\", \"description\": \"Track personal expenses and generate reports\", \"parameters\": {\"type\": \"object\", \"properties\": {\"category\": {\"type\": \"string\", \"description\": \"The category of expense\"}, \"amount\": {\"type\": \"number\", \"description\": \"The amount spent\"}, \"date\": {\"type\": \"string\", \"format\": \"date\", \"description\": \"The date of the expense\"}}, \"required\": [\"category\", \"amount\", \"date\"]}}, {\"name\": \"get_definition\", \"description\": \"Get the definition of a word\", \"parameters\": {\"type\": \"object\", \"properties\": {\"word\": {\"type\": \"string\", \"description\": \"The word to get the definition of\"}}, \"required\": [\"word\"]}}, {\"name\": \"calculate_tip\", \"description\": \"Calculate the tip amount\", \"parameters\": {\"type\": \"object\", \"properties\": {\"bill_amount\": {\"type\": \"number\", \"description\": \"The bill amount\"}, \"tip_percentage\": {\"type\": \"number\", \"description\": \"The percentage of tip to give\"}}, \"required\": [\"bill_amount\", \"tip_percentage\"]}}, {\"name\": \"create_user_account\", \"description\": \"Create a new user account\", \"parameters\": {\"type\": \"object\", \"properties\": {\"username\": {\"type\": \"string\", \"description\": \"The username for the new account\"}, \"password\": {\"type\": \"string\", \"description\": \"The password for the new account\"}}, \"required\": [\"username\", \"password\"]}}, {\"name\": \"generate_random_number\", \"description\": \"Generate a random number within a range\", \"parameters\": {\"type\": \"object\", \"properties\": {\"min\": {\"type\": \"integer\", \"description\": \"The minimum value of the range\"}, \"max\": {\"type\": \"integer\", \"description\": \"The maximum value of the range\"}}, \"required\": [\"min\", \"max\"]}}]\\n</tools><|eot_id|>', '<tool_call>{\"name\": \"generate_barcode\", \"arguments\": {\"text\": \"Hello World\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\\n\\n{\"barcode\": \"||| || ||| | || ||| ||| ||| |\"}<|eot_id|>']\n",
      "\n",
      "Inference Result:\n",
      "<tool_call>{\"name\": \"generate_barcode\", \"arguments\": {\"text\": \"Hello World\"}}</tool_call><|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "# Pick an example from the validation dataset\n",
    "example = validation_dataset[0]\n",
    "\n",
    "# Print the ground truth\n",
    "print(\"Ground Truth:\")\n",
    "print(example[\"text\"].split(response_template)[0:2])\n",
    "\n",
    "# Extract the text until the response part\n",
    "instruction_part = example[\"text\"].split(response_template)[0]\n",
    "\n",
    "# Prepare the input for inference\n",
    "inputs = tokenizer(\n",
    "    instruction_part+response_template,\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=True,\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Run the inference\n",
    "from transformers import TextStreamer\n",
    "print(\"\\nInference Result:\")\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMuVrWbjAzhc"
   },
   "source": [
    "<a name=\"Save\"></a>\n",
    "### Saving, loading finetuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final model as LoRA adapters locally and publish to hub.\n",
    "\n",
    "**[NOTE]** We use a trick here and rewrite the base model name so that it points to the target model instead. This increases model performance somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upcOlWe7A1vc",
    "outputId": "95b05f94-316e-4ca0-a225-50855bda6ff0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/lucaelin/llama-3.2-3b-instruct-fc-cn-lora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lucaelin/llama-3.2-3b-instruct-fc-cn-lora/commit/d8b95bef9da9675db0596886f69a6a77a9d00709', commit_message='Upload tokenizer', commit_description='', oid='d8b95bef9da9675db0596886f69a6a77a9d00709', pr_url=None, repo_url=RepoUrl('https://huggingface.co/lucaelin/llama-3.2-3b-instruct-fc-cn-lora', endpoint='https://huggingface.co', repo_type='model', repo_id='lucaelin/llama-3.2-3b-instruct-fc-cn-lora'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.active_peft_config.base_model_name_or_path = target_model_name\n",
    "#model.config.update({\"base_model_name_or_path\": target_model_name})\n",
    "model.save_pretrained(model_name) # Local saving\n",
    "tokenizer.save_pretrained(model_name)\n",
    "model.push_to_hub(model_name+'-lora') # Online saving\n",
    "tokenizer.push_to_hub(model_name+'-lora') # Online saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, unload the trained model to free up resource for model merge and export "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEEcJ4qfC7Lp"
   },
   "source": [
    "Now load the model config we just saved which applies our LoRA adapter the target_model instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you help me order a pizza from my favorite restaurant?\n",
      "\n",
      "You are able to call the following tools, when needed, call them using the <tool_call> xml-tag, followed by name and arguments as json.\n",
      "<tools>\n",
      "[{\"name\": \"track_expenses\", \"description\": \"Track daily expenses\", \"parameters\": {\"type\": \"object\", \"properties\": {\"expense\": {\"type\": \"string\", \"description\": \"The description of the expense\"}, \"amount\": {\"type\": \"number\", \"description\": \"The amount spent\"}, \"date\": {\"type\": \"string\", \"description\": \"The date of the expense\"}}, \"required\": [\"expense\", \"amount\", \"date\"]}}, {\"name\": \"convert_currency\", \"description\": \"Convert currency from one type to another\", \"parameters\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"The amount of currency to convert\"}, \"from\": {\"type\": \"string\", \"description\": \"The original currency type\"}, \"to\": {\"type\": \"string\", \"description\": \"The target currency type\"}}, \"required\": [\"amount\", \"from\", \"to\"]}}, {\"name\": \"generate_qr_code\", \"description\": \"Generate a QR code for a given text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\", \"description\": \"The text to encode in the QR code\"}}, \"required\": [\"text\"]}}, {\"name\": \"find_nearest_restaurant\", \"description\": \"Find the nearest restaurant based on user's location\", \"parameters\": {\"type\": \"object\", \"properties\": {\"latitude\": {\"type\": \"number\", \"description\": \"The user's latitude\"}, \"longitude\": {\"type\": \"number\", \"description\": \"The user's longitude\"}, \"cuisine\": {\"type\": \"string\", \"description\": \"The preferred cuisine\"}}, \"required\": [\"latitude\", \"longitude\"]}}, {\"name\": \"generate_random_number\", \"description\": \"Generate a random number within a specified range\", \"parameters\": {\"type\": \"object\", \"properties\": {\"min\": {\"type\": \"integer\", \"description\": \"The minimum value of the range\"}, \"max\": {\"type\": \"integer\", \"description\": \"The maximum value of the range\"}}, \"required\": [\"min\", \"max\"]}}, {\"name\": \"calculate_bmi\", \"description\": \"Calculate the Body Mass Index (BMI)\", \"parameters\": {\"type\": \"object\", \"properties\": {\"height\": {\"type\": \"number\", \"description\": \"The height in meters\"}, \"weight\": {\"type\": \"number\", \"description\": \"The weight in kilograms\"}}, \"required\": [\"height\", \"weight\"]}}, {\"name\": \"generate_random_color\", \"description\": \"Generate a random color in hexadecimal format\", \"parameters\": {}}, {\"name\": \"create_user_account\", \"description\": \"Create a new user account\", \"parameters\": {\"type\": \"object\", \"properties\": {\"username\": {\"type\": \"string\", \"description\": \"The desired username\"}, \"password\": {\"type\": \"string\", \"description\": \"The password for the account\"}, \"email\": {\"type\": \"string\", \"description\": \"The email address of the user\"}}, \"required\": [\"username\", \"password\", \"email\"]}}, {\"name\": \"calculate_square_root\", \"description\": \"Calculate the square root of a number\", \"parameters\": {\"type\": \"object\", \"properties\": {\"number\": {\"type\": \"number\", \"description\": \"The number to calculate the square root for\"}}, \"required\": [\"number\"]}}, {\"name\": \"get_news_headlines\", \"description\": \"Get the latest news headlines\", \"parameters\": {\"type\": \"object\", \"properties\": {\"country\": {\"type\": \"string\", \"description\": \"The country for the news headlines\"}, \"category\": {\"type\": \"string\", \"description\": \"The category of news headlines\"}}}}, {\"name\": \"calculate_mortgage\", \"description\": \"Calculate the monthly mortgage payment based on loan amount, interest rate, and loan term\", \"parameters\": {\"type\": \"object\", \"properties\": {\"loan_amount\": {\"type\": \"number\", \"description\": \"The total loan amount\"}, \"interest_rate\": {\"type\": \"number\", \"description\": \"The annual interest rate\"}, \"loan_term\": {\"type\": \"integer\", \"description\": \"The duration of the loan in years\"}}, \"required\": [\"loan_amount\", \"interest_rate\", \"loan_term\"]}}, {\"name\": \"calculate_tax\", \"description\": \"Calculate tax based on income\", \"parameters\": {\"type\": \"object\", \"properties\": {\"income\": {\"type\": \"number\", \"description\": \"The annual income\"}}, \"required\": [\"income\"]}}, {\"name\": \"calculate_tip\", \"description\": \"Calculate the tip amount based on the bill\", \"parameters\": {\"type\": \"object\", \"properties\": {\"bill_amount\": {\"type\": \"number\", \"description\": \"The total bill amount\"}, \"tip_percentage\": {\"type\": \"number\", \"description\": \"The percentage of tip to be given\"}}, \"required\": [\"bill_amount\", \"tip_percentage\"]}}, {\"name\": \"calculate_loan_payment\", \"description\": \"Calculate the monthly payment for a loan\", \"parameters\": {\"type\": \"object\", \"properties\": {\"loan_amount\": {\"type\": \"number\", \"description\": \"The amount of the loan\"}, \"interest_rate\": {\"type\": \"number\", \"description\": \"The interest rate for the loan\"}, \"loan_term\": {\"type\": \"integer\", \"description\": \"The term of the loan in months\"}}, \"required\": [\"loan_amount\", \"interest_rate\", \"loan_term\"]}}, {\"name\": \"generate_random_password\", \"description\": \"Generate a random password with specified length\", \"parameters\": {\"type\": \"object\", \"properties\": {\"length\": {\"type\": \"integer\", \"description\": \"The length of the password\"}}, \"required\": [\"length\"]}}, {\"name\": \"analyze_sentiment\", \"description\": \"Analyze the sentiment of a given text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\", \"description\": \"The text to be analyzed\"}}, \"required\": [\"text\"]}}, {\"name\": \"calculate_shipping_cost\", \"description\": \"Calculate the shipping cost for a package\", \"parameters\": {\"type\": \"object\", \"properties\": {\"weight\": {\"type\": \"number\", \"description\": \"The weight of the package in kilograms\"}, \"destination\": {\"type\": \"string\", \"description\": \"The destination of the package\"}}, \"required\": [\"weight\", \"destination\"]}}, {\"name\": \"calculate_average\", \"description\": \"Calculate the average of a list of numbers\", \"parameters\": {\"type\": \"object\", \"properties\": {\"numbers\": {\"type\": \"array\", \"items\": {\"type\": \"number\"}, \"description\": \"The list of numbers\"}}, \"required\": [\"numbers\"]}}, {\"name\": \"check_stock_price\", \"description\": \"Check the current stock price of a company\", \"parameters\": {\"type\": \"object\", \"properties\": {\"company\": {\"type\": \"string\", \"description\": \"The name of the company\"}, \"symbol\": {\"type\": \"string\", \"description\": \"The stock symbol of the company\"}}, \"required\": [\"company\", \"symbol\"]}}, {\"name\": \"calculate_distance\", \"description\": \"Calculate the distance between two points\", \"parameters\": {\"type\": \"object\", \"properties\": {\"point1\": {\"type\": \"object\", \"properties\": {\"latitude\": {\"type\": \"number\", \"description\": \"The latitude of point 1\"}, \"longitude\": {\"type\": \"number\", \"description\": \"The longitude of point 1\"}}, \"required\": [\"latitude\", \"longitude\"]}, \"point2\": {\"type\": \"object\", \"properties\": {\"latitude\": {\"type\": \"number\", \"description\": \"The latitude of point 2\"}, \"longitude\": {\"type\": \"number\", \"description\": \"The longitude of point 2\"}}, \"required\": [\"latitude\", \"longitude\"]}}, \"required\": [\"point1\", \"point2\"]}}, {\"name\": \"get_movie_details\", \"description\": \"Get the details of a movie\", \"parameters\": {\"type\": \"object\", \"properties\": {\"movie_title\": {\"type\": \"string\", \"description\": \"The title of the movie\"}, \"year\": {\"type\": \"integer\", \"description\": \"The year in which the movie was released\"}}, \"required\": [\"movie_title\"]}}]\n",
      "</tools><|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm sorry, but as an AI, I don't have the capability to perform external tasks such as ordering a pizza. My current function allows me to generate a random password of a specified length. Is there anything else you need help with that's within my capabilities?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to know the distance between New York and Los Angeles. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Sure, I can help with that. Let me calculate the distance for you.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"calculate_distance\", \"arguments\": {\"point1\": {\"latitude\": 40.7128, \"longitude\": -74.006}, \"point2\": {\"latitude\": 34.0522, \"longitude\": -118.2437}}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"distance\": 2448.2, \"unit\": \"miles\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The distance between New York and Los Angeles is approximately 2448.2 miles.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you get me the latest news headlines from the United States in the category of technology?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"get_news_headlines\", \"arguments\": {\"country\": \"United States\", \"category\": \"technology\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"headlines\": [\"Tech giant releases new product\", \"Cybersecurity threats on the rise\", \"Innovation in AI technology\", \"Tech stocks soar in the market\", \"New breakthrough in quantum computing\"]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here are the latest technology news headlines from the United States:\n",
      "1. Tech giant releases new product\n",
      "2. Cybersecurity threats on the rise\n",
      "3. Innovation in AI technology\n",
      "4. Tech stocks soar in the market\n",
      "5. New breakthrough in quantum computing<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "That's interesting. Can you now get me the latest news headlines from India in the category of sports?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"get_news_headlines\", \"arguments\": {\"country\": \"India\", \"category\": \"sports\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"headlines\": [\"Cricket team wins international tournament\", \"New records set in athletics\", \"Badminton player reaches world ranking\", \"Football league sees surprising results\", \"Chess prodigy makes a mark\"]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here are the latest sports news headlines from India:\n",
      "1. Cricket team wins international tournament\n",
      "2. New records set in athletics\n",
      "3. Badminton player reaches world ranking\n",
      "4. Football league sees surprising results\n",
      "5. Chess prodigy makes a mark<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you please order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm sorry, but I can't assist with that. My current capabilities allow me to calculate the square root of a number. I don't have the ability to place orders or perform external tasks.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need some help with calculating my mortgage payment. I have a loan amount of $300,000, an annual interest rate of 3.5%, and a loan term of 30 years.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"calculate_mortgage\", \"arguments\": {\"loan_amount\": 300000, \"interest_rate\": 3.5, \"loan_term\": 30}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"monthly_payment\": 1342.05}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Based on the details you provided, your monthly mortgage payment would be approximately $1342.05.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need help with calculating a tip. My bill amount is $50 and I want to give a 20% tip.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"calculate_tip\", \"arguments\": {\"bill_amount\": 50, \"tip_percentage\": 20}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"tip_amount\": 10}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Based on the bill amount and the tip percentage you provided, the tip you should give is $10.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need a QR code for my website. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Of course, I can help you with that. Could you please provide me with the URL of your website?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Sure, it's www.mywebsite.com.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"generate_qr_code\", \"arguments\": {\"text\": \"www.mywebsite.com\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"qr_code\": \"QR_CODE_IMAGE\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I have generated the QR code for your website. Here it is: QR_CODE_IMAGE. You can scan this code to directly access your website.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you book a flight for me from New York to London?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm sorry, but I currently don't have the capability to book flights. My available function is to find the nearest restaurant based on your location. Is there anything else I can assist you with?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I want to create a new account.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Sure, I can help you with that. Could you please provide me with your desired username, password, and email address?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "My username will be \"JohnDoe\", password will be \"password123\", and my email is \"johndoe@example.com\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"create_user_account\", \"arguments\": {\"username\": \"JohnDoe\", \"password\": \"password123\", \"email\": \"johndoe@example.com\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"status\": \"success\", \"message\": \"User account successfully created\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Great news! Your user account has been successfully created.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you tell me about the movie \"Inception\"?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"get_movie_details\", \"arguments\": {\"movie_title\": \"Inception\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"movie_title\": \"Inception\", \"year\": 2010, \"director\": \"Christopher Nolan\", \"genre\": \"Science Fiction\", \"rating\": 8.8}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The movie \"Inception\" was released in the year 2010. It was directed by Christopher Nolan and falls under the genre of Science Fiction. It has a rating of 8.8.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What about \"The Dark Knight\"?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"get_movie_details\", \"arguments\": {\"movie_title\": \"The Dark Knight\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"movie_title\": \"The Dark Knight\", \"year\": 2008, \"director\": \"Christopher Nolan\", \"genre\": \"Action, Crime, Drama\", \"rating\": 9.0}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\"The Dark Knight\" was released in 2008. It was also directed by Christopher Nolan and is an Action, Crime, Drama movie. It has a high rating of 9.0.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to calculate my tax for this year. My annual income is $75,000.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"calculate_tax\", \"arguments\": {\"income\": 75000}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"tax\": 15000}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Based on your annual income of $75,000, your calculated tax for this year is $15,000.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I have a list of numbers and I need to find the average. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Of course, I can help you with that. Please provide me with the list of numbers.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The numbers are 5, 10, 15, 20, 25.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"calculate_average\", \"arguments\": {\"numbers\": [5, 10, 15, 20, 25]}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"average\": 15}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The average of the numbers you provided is 15.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm sorry, but I'm unable to perform external tasks such as ordering a pizza. My capabilities are currently limited to the functions provided to me, such as generating a random number within a specified range.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to convert 500 US dollars to Euros. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"convert_currency\", \"arguments\": {\"amount\": 500, \"from\": \"USD\", \"to\": \"EUR\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"converted_amount\": 425.50, \"from\": \"USD\", \"to\": \"EUR\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Sure, 500 US dollars is approximately 425.50 Euros.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to calculate my BMI. I am 1.75 meters tall and weigh 70 kilograms.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"calculate_bmi\", \"arguments\": {\"height\": 1.75, \"weight\": 70}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"bmi\": 22.86}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Your Body Mass Index (BMI) is 22.86. This is considered a healthy weight for your height.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I bought a new laptop today. Can you track this expense for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Of course, I can help you with that. Could you please provide me with the amount spent and the date of purchase?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I spent $1200 on it today.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"track_expenses\", \"arguments\": {\"expense\": \"Laptop\", \"amount\": 1200, \"date\": \"today\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"status\": \"success\", \"message\": \"Expense tracked successfully\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Great! Your expense for the laptop has been tracked successfully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you also order a laptop bag for me from an online store?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm sorry, but as an AI, I don't have the capability to perform external tasks such as ordering items from an online store. I suggest you order it yourself to ensure all your preferences are met.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you book a flight for me from New York to London?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm sorry, but I'm unable to assist with booking flights. My current capabilities are limited to calculating loan payments based on the loan amount, interest rate, and loan term.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to ship a package to New York. It weighs about 5 kilograms. Can you tell me how much it will cost?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"calculate_shipping_cost\", \"arguments\": {\"weight\": 5, \"destination\": \"New York\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"cost\": 50}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The cost to ship your package to New York will be $50.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "That's a bit expensive. What if the package weighs only 3 kilograms?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"calculate_shipping_cost\", \"arguments\": {\"weight\": 3, \"destination\": \"New York\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"cost\": 30}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "If the package weighs 3 kilograms, the shipping cost to New York will be $30.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "That sounds more reasonable. Thank you for your help.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "You're welcome! If you have any other questions, feel free to ask.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you check the stock price for Apple?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Sure, I can do that. However, I also need the stock symbol for Apple to proceed. Do you know it?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes, it's AAPL.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"check_stock_price\", \"arguments\": {\"company\": \"Apple\", \"symbol\": \"AAPL\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"status\": \"success\", \"data\": {\"company\": \"Apple\", \"symbol\": \"AAPL\", \"current_price\": \"$150.75\"}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The current stock price for Apple (AAPL) is $150.75.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "That's great! Can you also check for Microsoft?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Of course, I can help with that. Do you know the stock symbol for Microsoft?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Yes, it's MSFT.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<tool_call>{\"name\": \"check_stock_price\", \"arguments\": {\"company\": \"Microsoft\", \"symbol\": \"MSFT\"}}</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
      "\n",
      "{\"status\": \"success\", \"data\": {\"company\": \"Microsoft\", \"symbol\": \"MSFT\", \"current_price\": \"$280.98\"}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The current stock price for Microsoft (MSFT) is $280.98.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hey, can you order a pizza for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm sorry, but as an AI, I don't have the capability to perform external tasks such as ordering a pizza. I can assist you with tasks related to the functions I have been provided with, such as generating a random color in hexadecimal format.<|eot_id|>\n",
      "\n",
      "Inference Result:\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you help me order a pizza from my favorite restaurant?\n",
      "\n",
      "You are able to call the following tools, when needed, call them using the <tool_call> xml-tag, followed by name and arguments as json.\n",
      "<tools>\n",
      "[{\"name\": \"track_expenses\", \"description\": \"Track daily expenses\", \"parameters\": {\"type\": \"object\", \"properties\": {\"expense\": {\"type\": \"string\", \"description\": \"The description of the expense\"}, \"amount\": {\"type\": \"number\", \"description\": \"The amount spent\"}, \"date\": {\"type\": \"string\", \"description\": \"The date of the expense\"}}, \"required\": [\"expense\", \"amount\", \"date\"]}}, {\"name\": \"convert_currency\", \"description\": \"Convert currency from one type to another\", \"parameters\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"The amount of currency to convert\"}, \"from\": {\"type\": \"string\", \"description\": \"The original currency type\"}, \"to\": {\"type\": \"string\", \"description\": \"The target currency type\"}}, \"required\": [\"amount\", \"from\", \"to\"]}}, {\"name\": \"generate_qr_code\", \"description\": \"Generate a QR code for a given text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\", \"description\": \"The text to encode in the QR code\"}}, \"required\": [\"text\"]}}, {\"name\": \"find_nearest_restaurant\", \"description\": \"Find the nearest restaurant based on user's location\", \"parameters\": {\"type\": \"object\", \"properties\": {\"latitude\": {\"type\": \"number\", \"description\": \"The user's latitude\"}, \"longitude\": {\"type\": \"number\", \"description\": \"The user's longitude\"}, \"cuisine\": {\"type\": \"string\", \"description\": \"The preferred cuisine\"}}, \"required\": [\"latitude\", \"longitude\"]}}, {\"name\": \"generate_random_number\", \"description\": \"Generate a random number within a specified range\", \"parameters\": {\"type\": \"object\", \"properties\": {\"min\": {\"type\": \"integer\", \"description\": \"The minimum value of the range\"}, \"max\": {\"type\": \"integer\", \"description\": \"The maximum value of the range\"}}, \"required\": [\"min\", \"max\"]}}, {\"name\": \"calculate_bmi\", \"description\": \"Calculate the Body Mass Index (BMI)\", \"parameters\": {\"type\": \"object\", \"properties\": {\"height\": {\"type\": \"number\", \"description\": \"The height in meters\"}, \"weight\": {\"type\": \"number\", \"description\": \"The weight in kilograms\"}}, \"required\": [\"height\", \"weight\"]}}, {\"name\": \"generate_random_color\", \"description\": \"Generate a random color in hexadecimal format\", \"parameters\": {}}, {\"name\": \"create_user_account\", \"description\": \"Create a new user account\", \"parameters\": {\"type\": \"object\", \"properties\": {\"username\": {\"type\": \"string\", \"description\": \"The desired username\"}, \"password\": {\"type\": \"string\", \"description\": \"The password for the account\"}, \"email\": {\"type\": \"string\", \"description\": \"The email address of the user\"}}, \"required\": [\"username\", \"password\", \"email\"]}}, {\"name\": \"calculate_square_root\", \"description\": \"Calculate the square root of a number\", \"parameters\": {\"type\": \"object\", \"properties\": {\"number\": {\"type\": \"number\", \"description\": \"The number to calculate the square root for\"}}, \"required\": [\"number\"]}}, {\"name\": \"get_news_headlines\", \"description\": \"Get the latest news headlines\", \"parameters\": {\"type\": \"object\", \"properties\": {\"country\": {\"type\": \"string\", \"description\": \"The country for the news headlines\"}, \"category\": {\"type\": \"string\", \"description\": \"The category of news headlines\"}}}}, {\"name\": \"calculate_mortgage\", \"description\": \"Calculate the monthly mortgage payment based on loan amount, interest rate, and loan term\", \"parameters\": {\"type\": \"object\", \"properties\": {\"loan_amount\": {\"type\": \"number\", \"description\": \"The total loan amount\"}, \"interest_rate\": {\"type\": \"number\", \"description\": \"The annual interest rate\"}, \"loan_term\": {\"type\": \"integer\", \"description\": \"The duration of the loan in years\"}}, \"required\": [\"loan_amount\", \"interest_rate\", \"loan_term\"]}}, {\"name\": \"calculate_tax\", \"description\": \"Calculate tax based on income\", \"parameters\": {\"type\": \"object\", \"properties\": {\"income\": {\"type\": \"number\", \"description\": \"The annual income\"}}, \"required\": [\"income\"]}}, {\"name\": \"calculate_tip\", \"description\": \"Calculate the tip amount based on the bill\", \"parameters\": {\"type\": \"object\", \"properties\": {\"bill_amount\": {\"type\": \"number\", \"description\": \"The total bill amount\"}, \"tip_percentage\": {\"type\": \"number\", \"description\": \"The percentage of tip to be given\"}}, \"required\": [\"bill_amount\", \"tip_percentage\"]}}, {\"name\": \"calculate_loan_payment\", \"description\": \"Calculate the monthly payment for a loan\", \"parameters\": {\"type\": \"object\", \"properties\": {\"loan_amount\": {\"type\": \"number\", \"description\": \"The amount of the loan\"}, \"interest_rate\": {\"type\": \"number\", \"description\": \"The interest rate for the loan\"}, \"loan_term\": {\"type\": \"integer\", \"description\": \"The term of the loan in months\"}}, \"required\": [\"loan_amount\", \"interest_rate\", \"loan_term\"]}}, {\"name\": \"generate_random_password\", \"description\": \"Generate a random password with specified length\", \"parameters\": {\"type\": \"object\", \"properties\": {\"length\": {\"type\": \"integer\", \"description\": \"The length of the password\"}}, \"required\": [\"length\"]}}, {\"name\": \"analyze_sentiment\", \"description\": \"Analyze the sentiment of a given text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\", \"description\": \"The text to be analyzed\"}}, \"required\": [\"text\"]}}, {\"name\": \"calculate_shipping_cost\", \"description\": \"Calculate the shipping cost for a package\", \"parameters\": {\"type\": \"object\", \"properties\": {\"weight\": {\"type\": \"number\", \"description\": \"The weight of the package in kilograms\"}, \"destination\": {\"type\": \"string\", \"description\": \"The destination of the package\"}}, \"required\": [\"weight\", \"destination\"]}}, {\"name\": \"calculate_average\", \"description\": \"Calculate the average of a list of numbers\", \"parameters\": {\"type\": \"object\", \"properties\": {\"numbers\": {\"type\": \"array\", \"items\": {\"type\": \"number\"}, \"description\": \"The list of numbers\"}}, \"required\": [\"numbers\"]}}, {\"name\": \"check_stock_price\", \"description\": \"Check the current stock price of a company\", \"parameters\": {\"type\": \"object\", \"properties\": {\"company\": {\"type\": \"string\", \"description\": \"The name of the company\"}, \"symbol\": {\"type\": \"string\", \"description\": \"The stock symbol of the company\"}}, \"required\": [\"company\", \"symbol\"]}}, {\"name\": \"calculate_distance\", \"description\": \"Calculate the distance between two points\", \"parameters\": {\"type\": \"object\", \"properties\": {\"point1\": {\"type\": \"object\", \"properties\": {\"latitude\": {\"type\": \"number\", \"description\": \"The latitude of point 1\"}, \"longitude\": {\"type\": \"number\", \"description\": \"The longitude of point 1\"}}, \"required\": [\"latitude\", \"longitude\"]}, \"point2\": {\"type\": \"object\", \"properties\": {\"latitude\": {\"type\": \"number\", \"description\": \"The latitude of point 2\"}, \"longitude\": {\"type\": \"number\", \"description\": \"The longitude of point 2\"}}, \"required\": [\"latitude\", \"longitude\"]}}, \"required\": [\"point1\", \"point2\"]}}, {\"name\": \"get_movie_details\", \"description\": \"Get the details of a movie\", \"parameters\": {\"type\": \"object\", \"properties\": {\"movie_title\": {\"type\": \"string\", \"description\": \"The title of the movie\"}, \"year\": {\"type\": \"integer\", \"description\": \"The year in which the movie was released\"}}, \"required\": [\"movie_title\"]}}]\n",
      "</tools><|eot_id|>\n",
      "---\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm sorry, but as an AI, I don't have the capability to call external tools or APIs. My function is limited to generating random color.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Pick an example from the validation dataset\n",
    "example = validation_dataset[1]\n",
    "\n",
    "# Print the ground truth\n",
    "print(\"Ground Truth:\")\n",
    "print(example[\"text\"])\n",
    "\n",
    "# Extract the text until the response part\n",
    "instruction_part = response_template.join(example[\"text\"].split(response_template)[0:1])\n",
    "\n",
    "# Prepare the input for inference\n",
    "inputs = tokenizer(\n",
    "    instruction_part,\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=False,\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Run the inference\n",
    "from transformers import TextStreamer\n",
    "print(\"\\nInference Result:\")\n",
    "print(instruction_part)\n",
    "print('---')\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f422JgM9sdVT"
   },
   "source": [
    "### Saving to float16 for VLLM\n",
    "\n",
    "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHjt_SMYsd3P"
   },
   "outputs": [],
   "source": [
    "# Merge to 16bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
    "\n",
    "# Merge to 4bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
    "\n",
    "# Just LoRA adapters\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCv4vXHd61i7"
   },
   "source": [
    "### GGUF / llama.cpp Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "FqfebeAdT073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 746.08 out of 1007.69 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 108.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Converting llama model. Can use fast conversion = False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q4_k_m', 'q8_0'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
      "Unsloth: [1] Converting model at lucaelin/llama-3.2-3b-instruct-fc-cn-gguf into bf16 GGUF format.\n",
      "The output location will be /workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.BF16.gguf\n",
      "This might take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: llama-3.2-3b-instruct-fc-cn-gguf\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00002.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {3072, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00002.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 131072\n",
      "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
      "INFO:hf-to-gguf:gguf: head count = 24\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 32\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128009\n",
      "INFO:gguf.vocab:Setting special token type pad to 128004\n",
      "INFO:gguf.vocab:Setting chat_template to {% set loop_messages = messages %}{% for message in loop_messages %}{% set role = message['role'] %}{% if 'tool_calls' in message %}{% set text = '<tool_call>' + {'name': message['tool_calls'][0]['function']['name'], 'arguments':message['tool_calls'][0]['function']['arguments']|from_json}|tojson + '</tool_call>' %}{% endif %}{% if 'content' in message %}{% set text = message['content'] %}{% endif %}{% if loop.index0 == 0 and tools is defined %}{% set text = message['content'] + '\n",
      "\n",
      "You are able to call the following tools, when needed, call them using the <tool_call> xml-tag, followed by name and arguments as json.\n",
      "<tools>\n",
      "' + tools|tojson + '\n",
      "</tools>' %}{% endif %}{% set content = '<|start_header_id|>' + role + '<|end_header_id|>\n",
      "\n",
      "'+ text | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:/workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.BF16.gguf: n_tensors = 255, total_size = 6.4G\n",
      "Writing: 100%|██████████| 6.43G/6.43G [00:20<00:00, 310Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to /workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.BF16.gguf\n",
      "Unsloth: Conversion completed! Output location: /workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.BF16.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
      "main: build = 4277 (c5ede384)\n",
      "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
      "main: quantizing '/workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.BF16.gguf' to '/workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.Q4_K_M.gguf' as Q4_K_M using 384 threads\n",
      "llama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3b Instruct\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = instruct\n",
      "llama_model_loader: - kv   5:                           general.basename str              = llama-3.2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 3B\n",
      "llama_model_loader: - kv   7:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128004\n",
      "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type bf16:  197 tensors\n",
      "[   1/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[   2/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   3/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =   bf16, converting to q6_K .. size =   751.50 MiB ->   308.23 MiB\n",
      "[   4/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[   5/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[   6/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[   7/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[   8/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[   9/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  10/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  11/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  12/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  13/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  14/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  15/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  16/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  17/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  18/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  19/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  20/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  21/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  22/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  23/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  24/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  25/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  26/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  27/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  28/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  29/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  30/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  31/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  32/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  33/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  34/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  35/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  36/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  37/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  38/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  39/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  40/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  41/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  42/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  43/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  44/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  45/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  46/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  47/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  48/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  49/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  50/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  51/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  52/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  53/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  54/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  55/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  56/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  57/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  58/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  59/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  60/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  61/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  62/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  63/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  64/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  65/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  66/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  67/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  68/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  69/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  70/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  71/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  72/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  73/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  74/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  75/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  76/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  77/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  78/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  79/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  80/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  81/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  82/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  83/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  84/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  85/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  86/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  87/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  88/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  89/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  90/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  91/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  92/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  93/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  94/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  95/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  96/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  97/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  98/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  99/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 100/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 101/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 102/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 103/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 104/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 105/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 106/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 107/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 108/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 109/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 110/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 111/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 112/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 113/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 114/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 115/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 116/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 117/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 118/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 119/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 120/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 121/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 122/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 123/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 124/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 125/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 126/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 127/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 128/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 129/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 130/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 131/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 132/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 133/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 134/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 135/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 136/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 137/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 138/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 139/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 140/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 141/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 142/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 143/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 144/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 145/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 146/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 147/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 148/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 149/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 150/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 151/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 152/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 153/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 154/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 155/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 156/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 157/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 158/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 159/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 160/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 161/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 162/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 163/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 164/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 165/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 166/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 167/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 168/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 169/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 170/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 171/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 172/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 173/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 174/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 175/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 176/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 177/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 178/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 179/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 180/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 181/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 182/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 183/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 184/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 185/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 186/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 187/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 188/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 189/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 190/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 192/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 193/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 194/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 195/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 196/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 197/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 198/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 199/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 200/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 201/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 202/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 203/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 204/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 205/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 206/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 207/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 208/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 209/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 210/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 211/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 212/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 213/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 214/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 215/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 216/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 217/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 218/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 219/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 220/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 221/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 222/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 223/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 224/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 225/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 226/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 227/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 228/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 229/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 230/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 231/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 232/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 233/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 234/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 235/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 236/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 237/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 238/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 239/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 240/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 241/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 242/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 243/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 244/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 245/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 246/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 247/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 248/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 249/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 250/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 251/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 252/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 253/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 254/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 255/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "llama_model_quantize_internal: model size  =  6128.17 MB\n",
      "llama_model_quantize_internal: quant size  =  1918.35 MB\n",
      "\n",
      "main: quantize time = 24333.65 ms\n",
      "main:    total time = 24333.65 ms\n",
      "Unsloth: Conversion completed! Output location: /workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.Q4_K_M.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q8_0. This might take 20 minutes...\n",
      "main: build = 4277 (c5ede384)\n",
      "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
      "main: quantizing '/workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.BF16.gguf' to '/workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.Q8_0.gguf' as Q8_0 using 384 threads\n",
      "llama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3b Instruct\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = instruct\n",
      "llama_model_loader: - kv   5:                           general.basename str              = llama-3.2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 3B\n",
      "llama_model_loader: - kv   7:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128004\n",
      "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type bf16:  197 tensors\n",
      "[   1/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[   2/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   3/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =   bf16, converting to q8_0 .. size =   751.50 MiB ->   399.23 MiB\n",
      "[   4/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[   5/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[   6/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[   7/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[   8/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[   9/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  10/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  11/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  12/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  13/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  14/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  15/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  16/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  17/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  18/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  19/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  20/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  21/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  22/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  23/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  24/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  25/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  26/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  27/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  28/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  29/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  30/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  31/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  32/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  33/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  34/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  35/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  36/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  37/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  38/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  39/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  40/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  41/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  42/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  43/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  44/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  45/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  46/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  47/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  48/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  49/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  50/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  51/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  52/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  53/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  54/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  55/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  56/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  57/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  58/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  59/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  60/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  61/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  62/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  63/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  64/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  65/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  66/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  67/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  68/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  69/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  70/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  71/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  72/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  73/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  74/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  75/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  76/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  77/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  78/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  79/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  80/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  81/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  82/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  83/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  84/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  85/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  86/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  87/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  88/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  89/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  90/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  91/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  92/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  93/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  94/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  95/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[  96/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  97/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  98/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  99/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 100/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 101/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 102/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 103/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 104/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 105/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 106/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 107/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 108/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 109/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 110/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 111/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 112/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 113/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 114/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 115/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 116/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 117/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 118/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 119/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 120/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 121/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 122/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 123/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 124/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 125/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 126/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 127/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 128/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 129/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 130/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 131/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 132/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 133/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 134/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 135/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 136/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 137/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 138/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 139/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 140/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 141/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 142/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 143/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 144/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 145/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 146/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 147/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 148/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 149/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 150/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 151/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 152/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 153/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 154/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 155/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 156/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 157/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 158/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 159/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 160/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 161/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 162/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 163/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 164/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 165/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 166/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 167/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 168/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 169/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 170/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 171/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 172/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 173/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 174/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 175/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 176/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 177/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 178/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 179/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 180/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 181/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 182/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 183/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 184/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 185/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 186/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 187/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 188/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 189/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 190/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 192/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 193/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 194/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 195/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 196/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 197/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 198/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 199/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 200/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 201/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 202/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 203/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 204/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 205/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 206/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 207/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 208/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 209/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 210/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 211/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 212/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 213/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 214/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 215/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 216/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 217/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 218/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 219/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 220/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 221/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 222/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 223/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 224/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 225/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 226/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 227/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 228/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 229/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 230/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 231/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 232/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 233/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 234/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 235/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 236/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 237/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 238/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 239/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 240/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 241/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 242/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 243/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 244/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 245/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 246/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 247/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 248/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 249/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 250/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 251/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 252/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 253/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 254/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
      "[ 255/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "llama_model_quantize_internal: model size  =  6128.17 MB\n",
      "llama_model_quantize_internal: quant size  =  3255.90 MB\n",
      "\n",
      "main: quantize time = 16437.03 ms\n",
      "main:    total time = 16437.03 ms\n",
      "Unsloth: Conversion completed! Output location: /workspace/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554b57b5d65e45c4a8b05331f0229a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458dd6d0483a4257840d7c2cc2d41120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q4_K_M.gguf:   0%|          | 0.00/2.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63da2c3177b44d0d9a6cca52b34acf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1df255b6e6140e0b6113eaadb848ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q8_0.gguf:   0%|          | 0.00/3.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/lucaelin/llama-3.2-3b-instruct-fc-cn-gguf\n"
     ]
    }
   ],
   "source": [
    "# Save to multiple GGUF options\n",
    "model.push_to_hub_gguf(\n",
    "    model_name+'-gguf',\n",
    "    tokenizer,\n",
    "    quantization_method = [\"q4_k_m\", \"q8_0\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06712075454443c8ab5c52815c72d5dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08cf2c12d955445097c34472052d01d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc849401ac4d4f62914b092553fe26d8",
      "placeholder": "​",
      "style": "IPY_MODEL_9c840addea8d49b5830a50299e9ad5b8",
      "value": " 982/982 [00:00&lt;00:00, 27.1kB/s]"
     }
    },
    "093d57e370004b079221a4595f054372": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c586fcfaa354f8cb9c5501601c5a5ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5700d3cc345f429ea4d9531d3e22ad41",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98ead40e54984506b5a6aaf79e406e44",
      "value": 100000
     }
    },
    "0e07054d52134877bdd80a3ff65297bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "13e947556fba4c44aaf02387040f5f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c71b169b09574eea9d24366124e5d4df",
      "placeholder": "​",
      "style": "IPY_MODEL_e6965284c2244cca9bcd9ba18f61112e",
      "value": "generation_config.json: 100%"
     }
    },
    "16a87294753647da8cf09e0dd812630d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18ddc325a03e4db1a7e56a2ea866cb1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_879c5ac1b5004fa6ab711132f7babefe",
      "placeholder": "​",
      "style": "IPY_MODEL_c8630201b006437a92b25b0338dc0795",
      "value": " 54.6k/54.6k [00:00&lt;00:00, 2.43MB/s]"
     }
    },
    "19af594b0de549709a837436f5838dd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1afbd3e59ee946bf84d90521744f6602": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20a621224c554bbea2d6ccc9598f436e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85690ddbef6442f19fce19a7faefda0a",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e07054d52134877bdd80a3ff65297bc",
      "value": 100000
     }
    },
    "24b137b2802846af82db926904480a6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e720179d7014b39b19dc5dff52a0b37",
      "placeholder": "​",
      "style": "IPY_MODEL_81e5a4c45dba48abb0092c74f1f3daac",
      "value": " 100000/100000 [03:01&lt;00:00, 541.48 examples/s]"
     }
    },
    "26f59196a00045d5991aeba38a0e7f14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f17783bff93f46db8ae51ee750ec5bbf",
      "placeholder": "​",
      "style": "IPY_MODEL_5e04416af2bd4eaf8c10eef805016e32",
      "value": " 100000/100000 [00:19&lt;00:00, 4773.17 examples/s]"
     }
    },
    "2a649d446c204e3eb7fb04a3019f17de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0287ccdda1f4c5894b821ae05b02098",
      "placeholder": "​",
      "style": "IPY_MODEL_8bff82b3775e4f6d9b58338c26ffa6b7",
      "value": "Standardizing format: 100%"
     }
    },
    "2c59b3b7217c420d9d7e1808823b2fc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f3aef8c52db4e5eb7fa05568ee8a53e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a380348df9bc4a168a371e665212fef7",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8b83cd1eebe4fd4a353d1c4b0edaf8b",
      "value": 100000
     }
    },
    "32e69481e102479f99d3bcd959d799e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "361228c34bf6452895ae0e9ae92fe7c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36996a833ecb487eafcb506d11df8d9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3742990d40954972ad79f4816cfb05b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_551158030c0c4a2fa50733d1a40a3a58",
       "IPY_MODEL_2f3aef8c52db4e5eb7fa05568ee8a53e",
       "IPY_MODEL_9e783b250dde44b688d8ce8174de6c64"
      ],
      "layout": "IPY_MODEL_406ec70d96c24e30a9cad27a51022bbe"
     }
    },
    "3e8c89ebdf3040ada123e51d0173c47b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40344215275b45bb86059b2bb349d2b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "406ec70d96c24e30a9cad27a51022bbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4078d8170bfc441ca0a5326fd1465d9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40344215275b45bb86059b2bb349d2b7",
      "placeholder": "​",
      "style": "IPY_MODEL_093d57e370004b079221a4595f054372",
      "value": "Map: 100%"
     }
    },
    "457ccf4f4b2245fc905f8f11ed8e3296": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46661708ba1e4300ba92f23dc1c12a36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77971a174e7f47979d7f5240455f4869",
       "IPY_MODEL_e579e9e451ad43c7bebf8ec1bd5bc904",
       "IPY_MODEL_18ddc325a03e4db1a7e56a2ea866cb1e"
      ],
      "layout": "IPY_MODEL_a9ed6f8d80ed452d8dd12dd1245f6b54"
     }
    },
    "46ede8c9efed4b13ad0cd3ff138884e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b9e83685d074b98a36b92082aeb9093": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cc307a9804547e6b59cb706cfad5a36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "534a467eaff546f8a6ad92b9a88f25db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "539cc66ddafe4ae6be7d1cfdd44c7f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54e169a109d048dc9008a9927bbad271": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "551158030c0c4a2fa50733d1a40a3a58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46ede8c9efed4b13ad0cd3ff138884e5",
      "placeholder": "​",
      "style": "IPY_MODEL_f2be5a53e0874e9f8f9bfee83c931cf3",
      "value": "Map: 100%"
     }
    },
    "553abeeabccf499f8603ee6a7cc8a065": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55d868afd9734a9c96a50b1fe67682cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5700d3cc345f429ea4d9531d3e22ad41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2c74b47b9847dab610ca6655e0f7d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5acddc0142ab43dbbf7809f2cc03a674": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5c02ba49dc54144b9141e19d6c29c32",
       "IPY_MODEL_626b80709c7d4f32aecc07bb8c81cbd7",
       "IPY_MODEL_76f9298d58b34c7586f33e4bb49dd817"
      ],
      "layout": "IPY_MODEL_89d94add4ea04a1280a19b65b9e9d9a1"
     }
    },
    "5d6750f0aab342e981230ba969c70647": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c1a9b4bf8f9e462baaddbc9f5094c2b0",
       "IPY_MODEL_80dab17e457f4221a5a291fe002b117e",
       "IPY_MODEL_08cf2c12d955445097c34472052d01d6"
      ],
      "layout": "IPY_MODEL_fad669c53606411f9a5ec0e771eec103"
     }
    },
    "5e04416af2bd4eaf8c10eef805016e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e8452768c0a4eac9c19b1a01d8c90cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ef521502a084a10a749519e8f00b73f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5fc677217a20451cadc89026ae10f029": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "626b80709c7d4f32aecc07bb8c81cbd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a4789c8c1b7454b940e5de7b543b722",
      "max": 17209920,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4cc307a9804547e6b59cb706cfad5a36",
      "value": 17209920
     }
    },
    "6322b3c8c91b48a88938bda0be7cf408": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6784da7ad3b847e0895b43801c0e4cc4",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ef521502a084a10a749519e8f00b73f",
      "value": 100000
     }
    },
    "638d43923e7840ba8cf8d7469e539165": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dca78a6e174b448ead4fbbe144826646",
       "IPY_MODEL_20a621224c554bbea2d6ccc9598f436e",
       "IPY_MODEL_a4a9a05d58424b6da90c767faf21dfc8"
      ],
      "layout": "IPY_MODEL_c55e88a98a85445a99edc785a65bc1ee"
     }
    },
    "65d24a42a0e34f07b25ab7e4ab219e77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65f2e1b6aec44ca4881784fe4601d388": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6784da7ad3b847e0895b43801c0e4cc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "685932bd693c4fed92068aa8264b4abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b15532369234017a31d8c7223d24174": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a2c74b47b9847dab610ca6655e0f7d0",
      "placeholder": "​",
      "style": "IPY_MODEL_6ec6ec51e4834b63a7322beeb8eaf709",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "6ec6ec51e4834b63a7322beeb8eaf709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "711ac2da1a3e4f5fb762efcad466da9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "76b3a5c56a8a4085873b0df59e8c4e75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76f9298d58b34c7586f33e4bb49dd817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1a04bb25a144252aeb728b98e035677",
      "placeholder": "​",
      "style": "IPY_MODEL_4b9e83685d074b98a36b92082aeb9093",
      "value": " 17.2M/17.2M [00:00&lt;00:00, 18.6MB/s]"
     }
    },
    "7755d3bce2b940b18d8be3fb523ce08f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77971a174e7f47979d7f5240455f4869": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa1be90b906648218529df89cc2bc77b",
      "placeholder": "​",
      "style": "IPY_MODEL_36996a833ecb487eafcb506d11df8d9c",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "7a0f5c5af6e14063811c6c408f5bc8b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a328c1e583c4176811364f39d990384": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_553abeeabccf499f8603ee6a7cc8a065",
      "max": 454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06712075454443c8ab5c52815c72d5dd",
      "value": 454
     }
    },
    "7da28cce72c041f9b35aeb3fb0540789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fcc9cc9eae94247a7b7e4899b91580c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80dab17e457f4221a5a291fe002b117e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93a98313ab4243aab95d7d3bd18dac33",
      "max": 982,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f58f2226530a41589bfcb1e45024161d",
      "value": 982
     }
    },
    "81431ee0c4014e569f89d4db77e801c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_957bec7688dc42f9bb646b93277a1ccf",
       "IPY_MODEL_a0affc04135f4b47aea15cb9b507b42a",
       "IPY_MODEL_c853c5846e624919845211b299ab2f89"
      ],
      "layout": "IPY_MODEL_7755d3bce2b940b18d8be3fb523ce08f"
     }
    },
    "81e5a4c45dba48abb0092c74f1f3daac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8301893220784edba5cb88a104812648": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8333bc5cb44e4c3dbb41984f153b7fec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83e298d84cfc4c7bacd32792346c352a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fcc9cc9eae94247a7b7e4899b91580c",
      "placeholder": "​",
      "style": "IPY_MODEL_d9f738986ba24465b1d6112d74cc9374",
      "value": " 100000/100000 [00:07&lt;00:00, 16209.38 examples/s]"
     }
    },
    "85690ddbef6442f19fce19a7faefda0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "879c5ac1b5004fa6ab711132f7babefe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89d94add4ea04a1280a19b65b9e9d9a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bff82b3775e4f6d9b58338c26ffa6b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d93fe940a5441f2af90870cd123c3bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6e6370ec9104168aef849d5b5a300b2",
      "placeholder": "​",
      "style": "IPY_MODEL_a54d212948384906ae9a8a2e3a3ab84e",
      "value": "Map (num_proc=2): 100%"
     }
    },
    "8f3758f6b87c4b3581728cfa526f9101": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f8def3f89034d0cbdc0ec3ac5973893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "921532441ab64f70bb20cad182feef5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93a98313ab4243aab95d7d3bd18dac33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94233ed90a184e0aa91b4cb076f4f442": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f3758f6b87c4b3581728cfa526f9101",
      "placeholder": "​",
      "style": "IPY_MODEL_534a467eaff546f8a6ad92b9a88f25db",
      "value": " 454/454 [00:00&lt;00:00, 27.5kB/s]"
     }
    },
    "94f5309adec943d69d7c5a7a395c378f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4078d8170bfc441ca0a5326fd1465d9d",
       "IPY_MODEL_c495c99b3c7d49e8b0082ac580046586",
       "IPY_MODEL_26f59196a00045d5991aeba38a0e7f14"
      ],
      "layout": "IPY_MODEL_baf8af03961b4b9a92811265e0ddcd88"
     }
    },
    "957bec7688dc42f9bb646b93277a1ccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e977661393b4bec9d7f4b43347ad517",
      "placeholder": "​",
      "style": "IPY_MODEL_f6825138d622477b82c6db6c3dc4f981",
      "value": "model.safetensors: 100%"
     }
    },
    "98ead40e54984506b5a6aaf79e406e44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9a4789c8c1b7454b940e5de7b543b722": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b4854cfcf6a4fd8be08714450eeee1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c840addea8d49b5830a50299e9ad5b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e4762d0c7f242359355a800f30c2771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d93fe940a5441f2af90870cd123c3bd",
       "IPY_MODEL_0c586fcfaa354f8cb9c5501601c5a5ec",
       "IPY_MODEL_24b137b2802846af82db926904480a6f"
      ],
      "layout": "IPY_MODEL_19af594b0de549709a837436f5838dd7"
     }
    },
    "9e720179d7014b39b19dc5dff52a0b37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e783b250dde44b688d8ce8174de6c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d712551a85e34fa3869c4d0427381ba2",
      "placeholder": "​",
      "style": "IPY_MODEL_32e69481e102479f99d3bcd959d799e3",
      "value": " 100000/100000 [00:51&lt;00:00, 2207.40 examples/s]"
     }
    },
    "9e977661393b4bec9d7f4b43347ad517": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0affc04135f4b47aea15cb9b507b42a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eacf56d64bde47d594c72cf2e29d4531",
      "max": 2242762780,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da048becbcdc482480f56be16c1db833",
      "value": 2242762567
     }
    },
    "a380348df9bc4a168a371e665212fef7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4a9a05d58424b6da90c767faf21dfc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16a87294753647da8cf09e0dd812630d",
      "placeholder": "​",
      "style": "IPY_MODEL_5fc677217a20451cadc89026ae10f029",
      "value": " 100000/100000 [00:03&lt;00:00, 33021.00 examples/s]"
     }
    },
    "a54d212948384906ae9a8a2e3a3ab84e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6e6370ec9104168aef849d5b5a300b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6e782277e9e433f937bf30a5dd04eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_457ccf4f4b2245fc905f8f11ed8e3296",
      "placeholder": "​",
      "style": "IPY_MODEL_7a0f5c5af6e14063811c6c408f5bc8b2",
      "value": " 184/184 [00:00&lt;00:00, 15.1kB/s]"
     }
    },
    "a8b83cd1eebe4fd4a353d1c4b0edaf8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a9ed6f8d80ed452d8dd12dd1245f6b54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acde173e93b24f7688f7d2f1b3b88e53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b19dd633f71546e39993b6c6e8d45e7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54e169a109d048dc9008a9927bbad271",
      "max": 116531415,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_685932bd693c4fed92068aa8264b4abf",
      "value": 116531404
     }
    },
    "b4c1e899d7a54301a3f21811039ea4e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13e947556fba4c44aaf02387040f5f8d",
       "IPY_MODEL_c3e179de69f645298ff286123a79ef30",
       "IPY_MODEL_a6e782277e9e433f937bf30a5dd04eda"
      ],
      "layout": "IPY_MODEL_1afbd3e59ee946bf84d90521744f6602"
     }
    },
    "baf8af03961b4b9a92811265e0ddcd88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcba1ab4a0384004afedbaff9fee7466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a649d446c204e3eb7fb04a3019f17de",
       "IPY_MODEL_6322b3c8c91b48a88938bda0be7cf408",
       "IPY_MODEL_83e298d84cfc4c7bacd32792346c352a"
      ],
      "layout": "IPY_MODEL_5e8452768c0a4eac9c19b1a01d8c90cd"
     }
    },
    "bde93e48839245638bfcdb22c4d10d77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0287ccdda1f4c5894b821ae05b02098": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1a9b4bf8f9e462baaddbc9f5094c2b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76b3a5c56a8a4085873b0df59e8c4e75",
      "placeholder": "​",
      "style": "IPY_MODEL_2c59b3b7217c420d9d7e1808823b2fc7",
      "value": "README.md: 100%"
     }
    },
    "c3e179de69f645298ff286123a79ef30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8333bc5cb44e4c3dbb41984f153b7fec",
      "max": 184,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_711ac2da1a3e4f5fb762efcad466da9c",
      "value": 184
     }
    },
    "c495c99b3c7d49e8b0082ac580046586": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acde173e93b24f7688f7d2f1b3b88e53",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_361228c34bf6452895ae0e9ae92fe7c9",
      "value": 100000
     }
    },
    "c55e88a98a85445a99edc785a65bc1ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c71b169b09574eea9d24366124e5d4df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c812e37c3df44866931c70a135b13593": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f8def3f89034d0cbdc0ec3ac5973893",
      "placeholder": "​",
      "style": "IPY_MODEL_921532441ab64f70bb20cad182feef5e",
      "value": "train-00000-of-00001.parquet: 100%"
     }
    },
    "c853c5846e624919845211b299ab2f89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b4854cfcf6a4fd8be08714450eeee1c",
      "placeholder": "​",
      "style": "IPY_MODEL_539cc66ddafe4ae6be7d1cfdd44c7f34",
      "value": " 2.24G/2.24G [00:17&lt;00:00, 312MB/s]"
     }
    },
    "c8630201b006437a92b25b0338dc0795": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfad018b0b904aef9825b268762498bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bde93e48839245638bfcdb22c4d10d77",
      "placeholder": "​",
      "style": "IPY_MODEL_d694238683f4479aa42d3dea59faaef4",
      "value": " 117M/117M [00:00&lt;00:00, 163MB/s]"
     }
    },
    "d694238683f4479aa42d3dea59faaef4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d712551a85e34fa3869c4d0427381ba2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8f9046ff66b430ea6749fdc08bb37bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9f738986ba24465b1d6112d74cc9374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da048becbcdc482480f56be16c1db833": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dca78a6e174b448ead4fbbe144826646": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe04310dd3a444088e14ee574cbedcc2",
      "placeholder": "​",
      "style": "IPY_MODEL_55d868afd9734a9c96a50b1fe67682cc",
      "value": "Generating train split: 100%"
     }
    },
    "e1a04bb25a144252aeb728b98e035677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e579e9e451ad43c7bebf8ec1bd5bc904": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65d24a42a0e34f07b25ab7e4ab219e77",
      "max": 54598,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8f9046ff66b430ea6749fdc08bb37bc",
      "value": 54598
     }
    },
    "e6965284c2244cca9bcd9ba18f61112e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eacf56d64bde47d594c72cf2e29d4531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f17783bff93f46db8ae51ee750ec5bbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1b590c4c9e44f358414311b5f350234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c812e37c3df44866931c70a135b13593",
       "IPY_MODEL_b19dd633f71546e39993b6c6e8d45e7c",
       "IPY_MODEL_cfad018b0b904aef9825b268762498bc"
      ],
      "layout": "IPY_MODEL_3e8c89ebdf3040ada123e51d0173c47b"
     }
    },
    "f2be5a53e0874e9f8f9bfee83c931cf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f58f2226530a41589bfcb1e45024161d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5c02ba49dc54144b9141e19d6c29c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8301893220784edba5cb88a104812648",
      "placeholder": "​",
      "style": "IPY_MODEL_7da28cce72c041f9b35aeb3fb0540789",
      "value": "tokenizer.json: 100%"
     }
    },
    "f6825138d622477b82c6db6c3dc4f981": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa1be90b906648218529df89cc2bc77b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fad669c53606411f9a5ec0e771eec103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc849401ac4d4f62914b092553fe26d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe04310dd3a444088e14ee574cbedcc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe835885fe79493b86f4e4d294d3a543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b15532369234017a31d8c7223d24174",
       "IPY_MODEL_7a328c1e583c4176811364f39d990384",
       "IPY_MODEL_94233ed90a184e0aa91b4cb076f4f442"
      ],
      "layout": "IPY_MODEL_65f2e1b6aec44ca4881784fe4601d388"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
